{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 3: Shape Reconstruction\n",
    "\n",
    "**Submission Deadline**: 22.12.2023, 23:55\n",
    "\n",
    "We will take a look at two major approaches for 3D shape reconstruction in this last exercise.\n",
    "\n",
    "Note that training reconstruction methods generally takes relatively long, even for simple shape completion. Training the generalization will take a few hours. **Thus, please make sure to start training well before the submission deadline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Running this notebook\n",
    "We recommend running this notebook on a CUDA compatible local gpu. You can also run training on cpu, it will just take longer.\n",
    "\n",
    "You have three options for running this exercise on a GPU, choose one of them and start the exercise below in section \"Imports\":\n",
    "1. Locally on your own GPU\n",
    "2. On our dedicated compute cluster\n",
    "3. On Google Colab\n",
    "\n",
    "We describe every option in more detail below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### (a) Local Execution\n",
    "\n",
    "If you run this notebook locally, you have to first install the python dependiencies again. They are the same as for exercise 1 so you can re-use the environment you used last time. If you use [poetry](https://python-poetry.org), you can also simply re-install everything (`poetry install`) and then run this notebook via `poetry run jupyter notebook`.\n",
    "\n",
    "In case you are working with a RTX 3000-series GPU, you need to install a patched version of pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:49:16.420345845Z",
     "start_time": "2023-12-14T00:49:14.392530139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (47.1.0)\n",
      "Requirement already satisfied: wheel in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.3)\n",
      "Requirement already satisfied: numpy in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/berfin/venvs/python3.7/ml43d/lib/python3.7/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Compute Cluster\n",
    "\n",
    "We provide access to a small compute cluster for the exercises and projects, consisting of a login node and 4 compute nodes with one dedicated RTX 3090 GPU each.\n",
    "Please send us a short email with your name and preferred username so we can add you as a user.\n",
    "\n",
    "We uploaded a PDF to Moodle with detailed information on how to access and use the cluster.\n",
    "\n",
    "Since the cluster contains RTX 3000-series GPUs, you will need to install a patched version of pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:49:16.439420884Z",
     "start_time": "2023-12-14T00:49:16.414541787Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Google Colab\n",
    "\n",
    "If you don't have access to a GPU and don't want to use our cluster, you can also use Google Colab. However, we experienced the issue that inline visualization of shapes or inline images didn't work on colab, so just keep that in mind.\n",
    "What you can also do is only train networks on colab, download the checkpoint, and visualize inference locally.\n",
    "\n",
    "In case you're using Google Colab, you can upload the exercise folder (containing `exercise_2.ipynb`, directory `exercise_2` and the file `requirements.txt`) as `3d-machine-learning` to google drive (make sure you don't upload extracted datasets files).\n",
    "Additionally you'd need to open the notebook `exercise_2.ipynb` in Colab using `File > Open Notebook > Upload`.\n",
    "\n",
    "Next you'll need to run these two cells for setting up the environment. Before you do that make sure your instance has a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:49:16.483439671Z",
     "start_time": "2023-12-14T00:49:16.430991027Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nfrom google.colab import drive\\ndrive.mount('/content/drive', force_remount=True)\\n\\n# We assume you uploaded the exercise folder in root Google Drive folder\\n\\n!cp -r /content/drive/MyDrive/3d-machine-learning 3d-machine-learning/\\nos.chdir('/content/3d-machine-learning/')\\nprint('Installing requirements')\\n%pip install -r requirements.txt\\n\\n# Make sure you restart runtime when directed by Colab\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# We assume you uploaded the exercise folder in root Google Drive folder\n",
    "\n",
    "!cp -r /content/drive/MyDrive/3d-machine-learning 3d-machine-learning/\n",
    "os.chdir('/content/3d-machine-learning/')\n",
    "print('Installing requirements')\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Make sure you restart runtime when directed by Colab\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell after restarting your colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T21:42:35.517999041Z",
     "start_time": "2023-12-12T21:42:35.483783715Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport sys\\nimport torch\\nos.chdir(\\'/content/3d-machine-learning/\\')\\nsys.path.insert(1, \"/content/3d-machine-learning/\")\\nprint(\\'CUDA availability:\\', torch.cuda.is_available())\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import sys\n",
    "import torch\n",
    "os.chdir('/content/3d-machine-learning/')\n",
    "sys.path.insert(1, \"/content/3d-machine-learning/\")\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Imports\n",
    "\n",
    "The following imports should work regardless of whether you are using Colab or local execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following imports should work regardless of whether you are using Colab or local execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:49:25.273120978Z",
     "start_time": "2023-12-14T00:49:23.113261665Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to test whether a GPU was detected by pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T00:49:25.351338928Z",
     "start_time": "2023-12-14T00:49:25.278359862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Shape Reconstruction from 3D SDF grids with 3D-EPN\n",
    "\n",
    "In the first part of this exercise, we will take a look at shape complation using [3D-EPN](https://arxiv.org/abs/1612.00101). This approach was also introduced in the lecture.\n",
    "\n",
    "The visualization below shows an overview of the method: From an incomplete shape observation (which you would get when scanning an object with a depth sensor for example), we use a 3D encoder-predictor network that first encodes the incomplete shapes into a common latent space using several 3D convolution layers and then decodes them again using multiple 3D transpose convolutions.\n",
    "\n",
    "This way, we get from a 32^3 SDF voxel grid to a 32^3 DF (unsigned) voxel grid that represents the completed shape. We only focus on this part here; in the original implementation, this 32^3 completed prediction would then be further improved (in an offline step after inference) by sampling parts from a shape database to get the final resolution to 128^3.\n",
    "\n",
    "<img src=\"exercise_3/images/3depn_teaser.png\" alt=\"3D-EPN Teaser\" style=\"width: 800px;\"/>\n",
    "\n",
    "The next steps will follow the structure we established in exercise 2: Taking a look at the dataset structure and downloading the data; then, implementing dataset, model, and training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Downloading the data\n",
    "We will use the original dataset used in the official implementation. It consists of SDF and DF grids (representing incomplete input data and complete target data) with a resolution of 32^3 each. Each input-target pair is generated from a ShapeNet shape.\n",
    "\n",
    "The incomplete SDF data are generated by sampling virtual camera trajectories around every object. Each trajectory is assigned an ID which is part of the file names (see below). The camera views for each trajectory are combined into a common SDF grid by volumetric fusion. It is easy to generate an SDF here since we know both camera location and object surface: Everything between camera and surface is known free space and outside the object, leading to a positive SDF sign. Everything behind the surface has a negative sign. \n",
    "\n",
    "For the complete shapes, however, deciding whether a voxel in the DF grid is inside or outside an object is not a trivial problem. This is why we use unsigned distance fields as target and prediction representation instead. This still encodes **the distance to the closest surface** but does not contain explicit information about the inside/outside location.\n",
    "\n",
    "In terms of dataset layout, we follow the ShapeNet directory structure as seen in the last exercise:\n",
    "Each folder in the `exercise_3/data/shapenet_dim32_sdf` and `exercise_3/data/shapenet_dim32_df` directories contains one shape category represented by a number, e.g. `02691156`.\n",
    "\n",
    "We provide the mapping between these numbers and the corresponding names in `exercise_3/data/shape_info.json`. Each of these shape category folders contains lots of shapes in sdf or df format. In addition to that, every shape now also contains multiple trajectories: 0 to 7, encoded as `__0__` to `__7__`. These 8 files are just different input representations, meaning they vary in the level of completeness and location of missing parts; they all map to the `.df` file with corresponding shape ID and `__0__` at the end.\n",
    "\n",
    "```\n",
    "# contents of exercise_2/data/shapenet_dim32_sdf\n",
    "02691156/                                           # Shape category folder with all its shapes\n",
    "    ├── 10155655850468db78d106ce0a280f87__0__.sdf   # Trajectory 0 for a shape of the category\n",
    "    ├── 10155655850468db78d106ce0a280f87__1__.sdf   # Trajectory 1 for the same shape\n",
    "    ├── :                                      \n",
    "    ├── 10155655850468db78d106ce0a280f87__7__.sdf   # Trajectory 7 for the same shape\n",
    "    ├── 10155655850468db78d106ce0a280f87__0__.sdf   # Trajectory 0 for another shape\n",
    "    ├── :                                           # And so on ...\n",
    "02933112/                                           # Another shape category folder\n",
    "02958343/                                           # In total you should have 8 shape category folders\n",
    ":\n",
    "\n",
    "# contents of exercise_2/data/shapenet_dim32_df\n",
    "02691156/                                           # Shape category folder with all its shapes\n",
    "    ├── 10155655850468db78d106ce0a280f87__0__.df    # A single shape of the category\n",
    "    ├── 1021a0914a7207aff927ed529ad90a11__0__.df    # Another shape of the category\n",
    "    ├── :                                           # And so on ...\n",
    "02933112/                                           # Another shape category folder\n",
    "02958343/                                           # In total you should have 55 shape category folders\n",
    ":\n",
    "```\n",
    "\n",
    "Download and extract the data with the code cell below.\n",
    "\n",
    "**Note**: If you are training on Google Colab and are running out of disk space, you can do the following:\n",
    "- Only download the zip files below without extracting them (comment out all lines after `print('Extracting ...')`)\n",
    "- Change `from exercise_3.data.shapenet import ShapeNet` to `from exercise_3.data.shapenet_zip import ShapeNet`\n",
    "- Implement your dataset in `shapenet_zip.py`. This implementation extracts the data on-the-fly without taking up any additional disk space. Your training will therefore run a bit slower.\n",
    "- Make sure you uncomment the lines setting the worker_init_fn in `train_3depn.py` (marked with TODOs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:16:02.254764649Z",
     "start_time": "2023-12-13T16:16:01.775557426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('Downloading ...')\\n# File sizes: 11GB for shapenet_dim32_sdf.zip (incomplete scans), 4GB for shapenet_dim32_df.zip (target shapes)\\n!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_sdf.zip -P exercise_3/data\\n!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_df.zip -P exercise_3/data\\nprint('Extracting ...')\\n!unzip -q exercise_3/data/shapenet_dim32_sdf.zip -d exercise_3/data\\n!unzip -q exercise_3/data/shapenet_dim32_df.zip -d exercise_3/data\\n!rm exercise_3/data/shapenet_dim32_sdf.zip\\n!rm exercise_3/data/shapenet_dim32_df.zip\\nprint('Done.')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('Downloading ...')\n",
    "# File sizes: 11GB for shapenet_dim32_sdf.zip (incomplete scans), 4GB for shapenet_dim32_df.zip (target shapes)\n",
    "!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_sdf.zip -P exercise_3/data\n",
    "!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_df.zip -P exercise_3/data\n",
    "print('Extracting ...')\n",
    "!unzip -q exercise_3/data/shapenet_dim32_sdf.zip -d exercise_3/data\n",
    "!unzip -q exercise_3/data/shapenet_dim32_df.zip -d exercise_3/data\n",
    "!rm exercise_3/data/shapenet_dim32_sdf.zip\n",
    "!rm exercise_3/data/shapenet_dim32_df.zip\n",
    "print('Done.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:16:02.941879421Z",
     "start_time": "2023-12-13T16:16:02.918055403Z"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip -q exercise_3/data/shapenet_dim32_sdf.zip -d exercise_3/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:16:03.093028507Z",
     "start_time": "2023-12-13T16:16:03.073929379Z"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip -q exercise_3/data/shapenet_dim32_df.zip -d exercise_3/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dataset\n",
    "\n",
    "The dataset implementation follows the same general structure as in exercise 2. We prepared an initial implementation already in `exercise_3/data/shapenet.py`; your task is to resolve all TODOs there.\n",
    "\n",
    "The data for SDFs and DFs in `.sdf`/`.df` files are stored in binary form as follows:\n",
    "```\n",
    "dimX    #uint64 \n",
    "dimY    #uint64 \n",
    "dimZ    #uint64 \n",
    "data    #(dimX*dimY*dimZ) floats for sdf/df values\n",
    "```\n",
    "The SDF values stored per-voxel represent the distance to the closest surface *in voxels*.\n",
    "\n",
    "You have to take care of three important steps before returning the SDF and DF for the corresponding `index` in `__getitem__`:\n",
    "1. **Truncation**: 3D-EPN uses a truncated SDF which means that for each voxel, the distance to the closest surface will be clamped to a max absolute value. This is helpful since we do not care about longer distances (Marching Cubes only cares about distances close to the surface). It allows us to focus our predictions on the voxels near the surface. We use a `truncation_distance` of 3 (voxels) which means we expect to get an SDF with values between -3 and 3 as input to the model.\n",
    "2. **Separation** of distances and sign: 3D-EPN uses as input a 2x32x32x32 SDF grid, with absolute distance values of the SDF in channel 0 and the signs (-1 or 1) in channel 1.\n",
    "3. **Log** scaling: We scale targets and prediction with a log operation to further guide predictions to focus on the surface voxels. Therefore, you should return target DFs as `log(df + 1)`.\n",
    "\n",
    "**Hint**: An easy way to load the data from `.sdf` and `.df` files is to use `np.fromfile`. First, load the dimensions, then the data, then reshape everything into the shape you loaded in the beginning. Make sure you get the datatypes and byte offsets right! If you are using the zip version of the dataset as explained above, you should use `np.frombuffer` instead of `np.fromfile` to load from the `data`-buffer. The syntax is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:59.077614249Z",
     "start_time": "2023-12-13T16:48:58.992110472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 153540\n",
      "Length of val set: 32304\n",
      "Length of overfit set: 64\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train')\n",
    "val_dataset = ShapeNet('val')\n",
    "overfit_dataset = ShapeNet('overfit')\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 32304\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:59.521386876Z",
     "start_time": "2023-12-13T16:48:59.446860062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
      "Input SDF: (2, 32, 32, 32)\n",
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e44b47c88924c2ca88970b6bc6d39eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some shapes\n",
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "train_sample = train_dataset[1]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:48:59.903190350Z",
     "start_time": "2023-12-13T16:48:59.861631064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 04379243/a1be21c9a71d133dc5beea20858a99d5__5__-04379243/a1be21c9a71d133dc5beea20858a99d5__0__\n",
      "Input SDF: (2, 32, 32, 32)\n",
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129e3d9dd11f4bd29a2ee05eda66a4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sample = train_dataset[223]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 04379243/a1be21c9a71d133dc5beea20858a99d5__5__-04379243/a1be21c9a71d133dc5beea20858a99d5__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:00.174640208Z",
     "start_time": "2023-12-13T16:49:00.129165163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 03636649/3889631e42a84b0f51f77a6d7299806__2__-03636649/3889631e42a84b0f51f77a6d7299806__0__\n",
      "Input SDF: (2, 32, 32, 32)\n",
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252063408f64448e80a53a33cc84c9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sample = train_dataset[95]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 03636649/3889631e42a84b0f51f77a6d7299806__2__-03636649/3889631e42a84b0f51f77a6d7299806__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Model\n",
    "\n",
    "The model architecture of 3D-EPN is visualized below:\n",
    "\n",
    "<img src=\"exercise_3/images/3depn.png\" alt=\"3D-EPN Architecture\" style=\"width: 800px;\"/>\n",
    "\n",
    "For this exercise, we simplify the model by omitting the classification part - this will not have a big impact since most of the shape completion performance comes from the 3D encoder-decoder unet.\n",
    "\n",
    "The model consists of three parts: The encoder, the bottleneck, and the decoder. Encoder and decoder are constructed with the same architecture, just mirrored.\n",
    "\n",
    "The details of each part are:\n",
    "- **Encoder**: 4 layers, each one containing a 3D convolution (with kernel size 4, as seen in the visualization), a 3D batch norm (except the very first layer), and a leaky ReLU with a negative slope of 0.2. Our goal is to reduce the spatial dimension from 32x32x32 to 1x1x1 and to get the feature dimension from 2 (absolute values and sign) to `num_features * 8`. We do this by using a stride of 2 and padding of 1 for all convolutions except for the last one where we use a stride of 1 and no padding. The feature channels are increased from 2 to `num_features` in the first layer and then doubled with every subsequent layer.\n",
    "- **Decoder**: Same architecture as encoder, just mirrored: Going from `num_features * 8 * 2` (the 2 will be explained later) to 1 (the DF values). The spatial dimensions go from 1x1x1 to 32x32x32. Each layer use a 3D Transpose convolution now, together with 3D batch norm and ReLU (no leaky ReLUs anymore). Note that the last layer uses neither Batch Norms nor a ReLU since we do not want to constrain the range of possible values for the prediction.\n",
    "- **Bottleneck**: This is realized with 2 fully connected layers, each one going from a vector of size 640 (which is `num_features * 8`) to a vector of size 640. Each such layer is followed by a ReLU activation.\n",
    "\n",
    "Some minor details:\n",
    "- **Skip connections** allow the decoder to use information from the encoder and also improve gradient flow. We use it here to connect the output of encoder layer 1 to decoder layer 4, the output of encoder layer 2 to decoder layer 3, and so on. This means that the input to a decoder layer is the concatenation of the previous decoder output with the corresponding encoder output, along the feature dimension. Hence, the number of input features for each decoder layer are twice those of the encoder layers, as mentioned above.\n",
    "- **Log scaling**: You also need to scale the final outputs of the network logarithmically: `out = log(abs(out) + 1)`. This is the same transformation you applied to the target shapes in the dataloader before and ensures that prediction and target volumes are comparable.\n",
    "\n",
    "With this in mind, implement the network architecture and `forward()` function in `exercise_3/model/threedepn.py`. You can check your architecture with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:01.776808179Z",
     "start_time": "2023-12-13T16:49:01.378003814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type            | Params  \n",
      "----------------------------------------------------\n",
      "0  | enc1         | Sequential      | 10320   \n",
      "1  | enc1.0       | Conv3d          | 10320   \n",
      "2  | enc1.1       | LeakyReLU       | 0       \n",
      "3  | enc2         | Sequential      | 819680  \n",
      "4  | enc2.0       | Conv3d          | 819360  \n",
      "5  | enc2.1       | BatchNorm3d     | 320     \n",
      "6  | enc2.2       | LeakyReLU       | 0       \n",
      "7  | enc3         | Sequential      | 3277760 \n",
      "8  | enc3.0       | Conv3d          | 3277120 \n",
      "9  | enc3.1       | BatchNorm3d     | 640     \n",
      "10 | enc3.2       | LeakyReLU       | 0       \n",
      "11 | enc4         | Sequential      | 13109120\n",
      "12 | enc4.0       | Conv3d          | 13107840\n",
      "13 | enc4.1       | BatchNorm3d     | 1280    \n",
      "14 | enc4.2       | LeakyReLU       | 0       \n",
      "15 | bottleneck   | Sequential      | 820480  \n",
      "16 | bottleneck.0 | Linear          | 410240  \n",
      "17 | bottleneck.1 | ReLU            | 0       \n",
      "18 | bottleneck.2 | Linear          | 410240  \n",
      "19 | bottleneck.3 | ReLU            | 0       \n",
      "20 | dec1         | Sequential      | 26215360\n",
      "21 | dec1.0       | ConvTranspose3d | 26214720\n",
      "22 | dec1.1       | BatchNorm3d     | 640     \n",
      "23 | dec1.2       | ReLU            | 0       \n",
      "24 | dec2         | Sequential      | 6554080 \n",
      "25 | dec2.0       | ConvTranspose3d | 6553760 \n",
      "26 | dec2.1       | BatchNorm3d     | 320     \n",
      "27 | dec2.2       | ReLU            | 0       \n",
      "28 | dec3         | Sequential      | 1638640 \n",
      "29 | dec3.0       | ConvTranspose3d | 1638480 \n",
      "30 | dec3.1       | BatchNorm3d     | 160     \n",
      "31 | dec3.2       | ReLU            | 0       \n",
      "32 | dec4         | Sequential      | 10241   \n",
      "33 | dec4.0       | ConvTranspose3d | 10241   \n",
      "34 | TOTAL        | ThreeDEPN       | 52455681\n",
      "Output tensor shape:  torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.model.threedepn import ThreeDEPN\n",
    "from exercise_3.util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPN()\n",
    "print(summarize_model(threedepn))  # Expected: Rows 0-34 and TOTAL = 52455681\n",
    "\n",
    "sdf = torch.randn(4, 1, 32, 32, 32) * 2. - 1.\n",
    "input_tensor = torch.cat([torch.abs(sdf), torch.sign(sdf)], dim=1)\n",
    "predictions = threedepn(input_tensor)\n",
    "\n",
    "print('Output tensor shape: ', predictions.shape)  # Expected: torch.Size([4, 32, 32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Training script and overfitting to a single shape reconstruction\n",
    "\n",
    "You can now go to the train script in `exercise_3/training/train_3depn.py` and fill in the missing pieces as you did for exercise 2. Then, verify that your training work by overfitting to a few samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T17:05:53.199492435Z",
     "start_time": "2023-12-13T16:49:03.615580101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6262/718075939.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m'validate_every_n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_3depn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# should be able to get <0.0025 train_loss and <0.13 val_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ML for 3D Geometry/exercises/ml43d-exercises/exercise3/exercise_3/training/train_3depn.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ML for 3D Geometry/exercises/ml43d-exercises/exercise3/exercise_3/training/train_3depn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, device, config)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# 4. Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# 5. Update network parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/python3.7/ml43d/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/python3.7/ml43d/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_3depn\n",
    "config = {\n",
    "    'experiment_name': '3_1_3depn_overfitting',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 250,\n",
    "    'print_every_n': 10,\n",
    "    'validate_every_n': 25,\n",
    "}\n",
    "train_3depn.main(config)  # should be able to get <0.0025 train_loss and <0.13 val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Training over the entire training set\n",
    "If the overfitting works, we can go ahead with training on the entire dataset.\n",
    "\n",
    "**Note**: As is the case with most reconstruction networks and considering the size of the model (> 50M parameters), this training will take a few hours on a GPU. *Please make sure to start training early enough before the submission deadline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': '3_1_3depn_generalization',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 5,\n",
    "    'print_every_n': 50,\n",
    "    'validate_every_n': 1000,\n",
    "}\n",
    "train_3depn.main(config)  # should be able to get best_loss_val < 0.1 after a few hours and 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Inference\n",
    "\n",
    "Implement the missing bits in `exercise_3/inference/infer_3depn.py`. You should then be able to see your reconstructions below.\n",
    "\n",
    "The outputs of our provided visualization functions are, from left to right:\n",
    "- Input, partial shape\n",
    "- Predicted completion\n",
    "- Target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T17:05:53.201930971Z",
     "start_time": "2023-12-13T17:05:53.201419762Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exercise_3/runs/3_1_3depn_generalization/model_best.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6262/2676225088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create a handler for inference using a trained checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minferer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferenceHandler3DEPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exercise_3/runs/3_1_3depn_generalization/model_best.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# TODO: sanity check for dimensions, delete later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML for 3D Geometry/exercises/ml43d-exercises/exercise3/exercise_3/inference/infer_3depn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ckpt)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \"\"\"\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreeDEPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncation_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/python3.7/ml43d/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/python3.7/ml43d/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/python3.7/ml43d/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exercise_3/runs/3_1_3depn_generalization/model_best.ckpt'"
     ]
    }
   ],
   "source": [
    "from exercise_3.util.visualization import visualize_meshes\n",
    "from exercise_3.inference.infer_3depn import InferenceHandler3DEPN\n",
    "\n",
    "# create a handler for inference using a trained checkpoint\n",
    "inferer = InferenceHandler3DEPN('exercise_3/runs/3_1_3depn_generalization/model_best.ckpt')\n",
    "\n",
    "# TODO: sanity check for dimensions, delete later \n",
    "# inferer = InferenceHandler3DEPN('exercise_3/runs/3_1_3depn_overfitting/model_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T17:05:53.201726023Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6262/45062768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'03636649/b286c9c136784db2af1744fdb1fbe7df__0__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvisualize_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inferer' is not defined"
     ]
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('03636649/b286c9c136784db2af1744fdb1fbe7df__0__')\n",
    "target_df = ShapeNet.get_shape_df('03636649/b286c9c136784db2af1744fdb1fbe7df__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T17:05:53.206580944Z",
     "start_time": "2023-12-13T17:05:53.202876525Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6262/1874454406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'03636649/23eaba9bdd51a5b0dfe9cab879fd37e8__0__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvisualize_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inferer' is not defined"
     ]
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('03636649/23eaba9bdd51a5b0dfe9cab879fd37e8__1__')\n",
    "target_df = ShapeNet.get_shape_df('03636649/23eaba9bdd51a5b0dfe9cab879fd37e8__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-13T17:05:53.203793325Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6262/2661107163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'02691156/5de2cc606b65b960e0b6546e08902f28__0__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvisualize_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_mesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mesh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inferer' is not defined"
     ]
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('02691156/5de2cc606b65b960e0b6546e08902f28__0__')\n",
    "target_df = ShapeNet.get_shape_df('02691156/5de2cc606b65b960e0b6546e08902f28__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DeepSDF\n",
    "\n",
    "\n",
    "Here, we will take a look at 3D-reconstruction using [DeepSDF](https://arxiv.org/abs/1901.05103). We recommend reading the paper before attempting the exercise.\n",
    "\n",
    "DeepSDF is an **auto-decoder** based approach that learns a **continuous SDF representation** for a class of shapes. Once trained, it can be used for shape representation, interpolation and shape completion. We'll look at each of these applications.\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_teaser.png\" alt=\"deepsdf_teaser\" style=\"width: 800px;\"/>\n",
    "\n",
    "During training, the autodecoder optimizes **both the network parameters and the latent codes** representing each of the training shapes. Once trained, to reconstruct a shape given its SDF observations, **a latent code is optimized keeping the network parameters fixed**, such that the optimized latent code gives the lowest error with observed SDF values.\n",
    "\n",
    "An advantage that implicit representations have over voxel/grid based approaches is that they are not tied to a particular grid resolution, and can be evaluated at any resolution once trained.\n",
    "\n",
    "Similar to previous exercise, we'll first download the processed dataset, look at the implementation of the dataset, the model and the trainer, try out overfitting and generalization over the entire dataset, and finally inference on unseen samples.\n",
    "\n",
    "### (a) Downloading the data\n",
    "\n",
    "Whereas volumetric models output entire 3d shape representations, implicit models like DeepSDF work on per point basis. The network takes in a 3D-coordinate (and additionally the latent vector) and outputs the SDF value at the queried point. To train such a model,\n",
    "we therefore need, for each of the training shapes, a bunch of points with their corresponding SDF values for supervision. Points are sampled more aggressively near the surface of the object as we want to capture a more detailed SDF near the surface. For those curious,\n",
    "data preparation is decribed in more detail in section 5 of the paper.\n",
    "\n",
    "We'll be using the ShapeNet Sofa class for the experiments in this exercise. We've already prepared this data, so that you don't need to deal with the preprocessing. For each shape, the following files are provided:\n",
    "- `mesh.obj` representing the mesh representation of the shape\n",
    "- `sdf.npz` file containing large number of points sampled on and around the mesh and their sdf values; contains numpy arrays under keys \"pos\" and \"neg\", containing points with positive and negative sdf values respectively\n",
    "\n",
    "```\n",
    "# contents of exercise_3/data/sdf_sofas\n",
    "1faa4c299b93a3e5593ebeeedbff73b/                    # shape 0\n",
    "    ├── mesh.obj                                    # shape 0 mesh\n",
    "    ├── sdf.npz                                     # shape 0 sdf\n",
    "    ├── surface.obj                                 # shape 0 surface\n",
    "1fde48d83065ef5877a929f61fea4d0/                    # shape 1\n",
    "1fe1411b6c8097acf008d8a3590fb522/                   # shape 2\n",
    ":\n",
    "```\n",
    "Download and extract the data with the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('Downloading ...')\\n# File sizes: ~10GB\\n!wget https://www.dropbox.com/s/4k5pw126nzus8ef/sdf_sofas.zip\\\\?dl\\\\=0 -O exercise_3/data/sdf_sofas.zip -P exercise_3/data\\n\\nprint('Extracting ...')\\n!unzip -q exercise_3/data/sdf_sofas.zip -d exercise_3/data\\n!rm exercise_3/data/sdf_sofas.zip\\n\\nprint('Done.')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('Downloading ...')\n",
    "# File sizes: ~10GB\n",
    "!wget https://www.dropbox.com/s/4k5pw126nzus8ef/sdf_sofas.zip\\?dl\\=0 -O exercise_3/data/sdf_sofas.zip -P exercise_3/data\n",
    "\n",
    "print('Extracting ...')\n",
    "!unzip -q exercise_3/data/sdf_sofas.zip -d exercise_3/data\n",
    "!rm exercise_3/data/sdf_sofas.zip\n",
    "\n",
    "print('Done.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dataset\n",
    "\n",
    "We provide a partial implementation of the dataset in `exercise_3/data/shape_implicit.py`.\n",
    "Your task is to complete the `#TODOs` so that the dataset works as specified by the docstrings.\n",
    "\n",
    "Once done, you can try running the following code blocks as sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T09:53:40.168735975Z",
     "start_time": "2023-12-15T09:53:38.660242655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 1226\n",
      "Length of val set: 137\n",
      "Length of overfit set: 1\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.data.shape_implicit import ShapeImplicit\n",
    "\n",
    "num_points_to_samples = 40000\n",
    "train_dataset = ShapeImplicit(num_points_to_samples, \"train\")\n",
    "val_dataset = ShapeImplicit(num_points_to_samples, \"val\")\n",
    "overfit_dataset = ShapeImplicit(num_points_to_samples, \"overfit\")\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 1226\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 137\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at the points sampled for a particular shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T09:53:44.815395755Z",
     "start_time": "2023-12-15T09:53:44.633112675Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh, visualize_pointcloud\n",
    "\n",
    "shape_id = train_dataset[0]['name']\n",
    "points = train_dataset[0]['points']\n",
    "sdf = train_dataset[0]['sdf']\n",
    "\n",
    "# sampled points inside the shape\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "\n",
    "# sampled points outside the shape\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T09:53:46.102827505Z",
     "start_time": "2023-12-15T09:53:46.072135738Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/jevtic/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-0lwVUghf-py3.8/lib/python3.8/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e244fe075b46b7abb0c4593d610910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh = ShapeImplicit.get_mesh(shape_id)\n",
    "print('Mesh')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled points with negative SDF (inside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ced5e54eef14543bb49d3bbfe165c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sampled points with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled points with positive SDF (outside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd77b48d05248c78592f673fd9bde07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sampled points with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that more points are sampled close to the surface rather than away from the surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (c) Model\n",
    "\n",
    "The DeepSDF auto-decoder architecture is visualized below:\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_architecture.png\" alt=\"deepsdf_arch\" style=\"width: 640px;\"/>\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- The network takes in the latent code for a shape concatenated with the query 3d coordinate, making up a 259 length vector (assuming latent code length is 256).\n",
    "- The network consist of a sequence of weight-normed linear layers, each followed by a ReLU and a dropout. For weight norming a layer, check out `torch.nn.utils.weight_norm`. Each of these linear layers outputs a 512 dimensional vector, except the 4th layer which outputs a 253 dimensional vector.\n",
    "- The output of the 4th layer is concatenated with the input, making the input to the 5th layer a 512 dimensional vector.\n",
    "- The final layer is a simple linear layer without any norm, dropout or non-linearity, with a single dimensional output representing the SDF value.\n",
    "\n",
    "Implement this architecture in file `exercise_3/model/deepsdf.py`.\n",
    "\n",
    "Here are some basic sanity tests once you're done with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T10:37:32.083078738Z",
     "start_time": "2023-12-15T10:37:32.034935020Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name    | Type           | Params \n",
      "---------------------------------------------\n",
      "0  | fc0     | Linear         | 133632 \n",
      "1  | fc1     | Linear         | 263168 \n",
      "2  | fc2     | Linear         | 263168 \n",
      "3  | fc3     | Linear         | 130042 \n",
      "4  | fc4     | Linear         | 263168 \n",
      "5  | fc5     | Linear         | 263168 \n",
      "6  | fc6     | Linear         | 263168 \n",
      "7  | fc7     | Linear         | 263168 \n",
      "8  | fc8     | Linear         | 514    \n",
      "9  | relu    | ReLU           | 0      \n",
      "10 | dropout | Dropout        | 0      \n",
      "11 | TOTAL   | DeepSDFDecoder | 1843196\n",
      "\n",
      "Output tensor shape:  torch.Size([4096, 1])\n",
      "\n",
      "Number of traininable params: 1.84M\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.model.deepsdf import DeepSDFDecoder\n",
    "from exercise_3.util.model import summarize_model\n",
    "\n",
    "deepsdf = DeepSDFDecoder(latent_size=256)\n",
    "print(summarize_model(deepsdf))\n",
    "\n",
    "# input to the network is a concatenation of point coordinates (3) and the latent code (256 in this example);\n",
    "# here we use a batch of 4096 points\n",
    "input_tensor = torch.randn(4096, 3 + 256)\n",
    "predictions = deepsdf(input_tensor)\n",
    "\n",
    "print('\\nOutput tensor shape: ', predictions.shape)  # expected output: 4096, 1\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in deepsdf.parameters() if p.requires_grad) / 1e6\n",
    "print(f'\\nNumber of traininable params: {num_trainable_params:.2f}M')  # expected output: ~1.8M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T10:38:40.743515687Z",
     "start_time": "2023-12-15T10:38:40.733709272Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO delete later \n",
    "layer_param_diff = 263168 - 262656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Training script and overfitting to a single shape\n",
    "\n",
    "Fill in the train script in `exercise_3/training/train_deepsdf.py`, and verify that your training work by overfitting to a few samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T10:47:08.703923896Z",
     "start_time": "2023-12-15T10:47:08.659654991Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[049/00000] train_loss: 0.037006\n",
      "[099/00000] train_loss: 0.024509\n",
      "[149/00000] train_loss: 0.018126\n",
      "[199/00000] train_loss: 0.014168\n",
      "[249/00000] train_loss: 0.012223\n",
      "[299/00000] train_loss: 0.011056\n",
      "[349/00000] train_loss: 0.010344\n",
      "[399/00000] train_loss: 0.009882\n",
      "[449/00000] train_loss: 0.009073\n",
      "[499/00000] train_loss: 0.008658\n",
      "[549/00000] train_loss: 0.008139\n",
      "[599/00000] train_loss: 0.008015\n",
      "[649/00000] train_loss: 0.007866\n",
      "[699/00000] train_loss: 0.007661\n",
      "[749/00000] train_loss: 0.007544\n",
      "[799/00000] train_loss: 0.007445\n",
      "[849/00000] train_loss: 0.007404\n",
      "[899/00000] train_loss: 0.007167\n",
      "[949/00000] train_loss: 0.007156\n",
      "[999/00000] train_loss: 0.007019\n",
      "[1049/00000] train_loss: 0.006849\n",
      "[1099/00000] train_loss: 0.006768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_453897/3422390465.py\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_deepsdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_config\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# expected loss around 0.0062\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cluster/53/jevtic/ml43d-exercises/exercise3/exercise_3/training/train_deepsdf.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cluster/53/jevtic/ml43d-exercises/exercise3/exercise_3/training/train_deepsdf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, latent_vectors, train_dataloader, device, config)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# save best train model and latent codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'exercise_3/runs/{config[\"experiment_name\"]}/model_best.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'exercise_3/runs/{config[\"experiment_name\"]}/latent_best.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-0lwVUghf-py3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-0lwVUghf-py3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_deepsdf\n",
    "\n",
    "overfit_config = {\n",
    "    'experiment_name': '3_2_deepsdf_overfit',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'num_sample_points': 4096,\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 16,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 250,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(overfit_config)  # expected loss around 0.0062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the overfitted shape reconstruction to check if it looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize GT mesh of the overfit sample\n",
    "gt_mesh = ShapeImplicit.get_mesh('7e728818848f191bee7d178666aae23d')\n",
    "print('GT')\n",
    "visualize_mesh(gt_mesh.vertices, gt_mesh.faces, flip_axes=True)\n",
    "\n",
    "# Load and visualize reconstructed overfit sample; it's okay if they don't look visually exact, since we don't run \n",
    "# the training too long and have a learning rate decay while training \n",
    "mesh_path = \"exercise_3/runs/3_2_deepsdf_overfit/meshes/01999_000.obj\"\n",
    "overfit_output = trimesh.load(mesh_path)\n",
    "print('Overfit')\n",
    "visualize_mesh(overfit_output.vertices, overfit_output.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Training over entire train set\n",
    "\n",
    "Once overfitting works, we can train on the entire train set.\n",
    "\n",
    "Note: This training will take a few hours on a GPU (took ~3 hrs for 500 epochs on our 2080Ti, which already gave decent results). Please make sure to start training early enough before the submission deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00049] train_loss: 0.036262\n",
      "[000/00099] train_loss: 0.032879\n",
      "[000/00149] train_loss: 0.032865\n",
      "[000/00199] train_loss: 0.032209\n",
      "[000/00249] train_loss: 0.032531\n",
      "[000/00299] train_loss: 0.032977\n",
      "[000/00349] train_loss: 0.033360\n",
      "[000/00399] train_loss: 0.033816\n",
      "[000/00449] train_loss: 0.031579\n",
      "[000/00499] train_loss: 0.032512\n",
      "[000/00549] train_loss: 0.031795\n",
      "[000/00599] train_loss: 0.031602\n",
      "[000/00649] train_loss: 0.030922\n",
      "[000/00699] train_loss: 0.032588\n",
      "[000/00749] train_loss: 0.030792\n",
      "[000/00799] train_loss: 0.032925\n",
      "[000/00849] train_loss: 0.031387\n",
      "[000/00899] train_loss: 0.030435\n",
      "[000/00949] train_loss: 0.032237\n",
      "[000/00999] train_loss: 0.032392\n",
      "[000/01049] train_loss: 0.033664\n",
      "[000/01099] train_loss: 0.032122\n",
      "[000/01149] train_loss: 0.029913\n",
      "[000/01199] train_loss: 0.032443\n",
      "[001/00023] train_loss: 0.030707\n",
      "[001/00073] train_loss: 0.031173\n",
      "[001/00123] train_loss: 0.030950\n",
      "[001/00173] train_loss: 0.030342\n",
      "[001/00223] train_loss: 0.030844\n",
      "[001/00273] train_loss: 0.029649\n",
      "[001/00323] train_loss: 0.030786\n",
      "[001/00373] train_loss: 0.029718\n",
      "[001/00423] train_loss: 0.029412\n",
      "[001/00473] train_loss: 0.030937\n",
      "[001/00523] train_loss: 0.030765\n",
      "[001/00573] train_loss: 0.029614\n",
      "[001/00623] train_loss: 0.030876\n",
      "[001/00673] train_loss: 0.029492\n",
      "[001/00723] train_loss: 0.029997\n",
      "[001/00773] train_loss: 0.029974\n",
      "[001/00823] train_loss: 0.029122\n",
      "[001/00873] train_loss: 0.030401\n",
      "[001/00923] train_loss: 0.030014\n",
      "[001/00973] train_loss: 0.029866\n",
      "[001/01023] train_loss: 0.029652\n",
      "[001/01073] train_loss: 0.029419\n",
      "[001/01123] train_loss: 0.030879\n",
      "[001/01173] train_loss: 0.030811\n",
      "[001/01223] train_loss: 0.029435\n",
      "[002/00047] train_loss: 0.031183\n",
      "[002/00097] train_loss: 0.028414\n",
      "[002/00147] train_loss: 0.030256\n",
      "[002/00197] train_loss: 0.028924\n",
      "[002/00247] train_loss: 0.029797\n",
      "[002/00297] train_loss: 0.029098\n",
      "[002/00347] train_loss: 0.029045\n",
      "[002/00397] train_loss: 0.028869\n",
      "[002/00447] train_loss: 0.028235\n",
      "[002/00497] train_loss: 0.028784\n",
      "[002/00547] train_loss: 0.029245\n",
      "[002/00597] train_loss: 0.028922\n",
      "[002/00647] train_loss: 0.027756\n",
      "[002/00697] train_loss: 0.028406\n",
      "[002/00747] train_loss: 0.028835\n",
      "[002/00797] train_loss: 0.028501\n",
      "[002/00847] train_loss: 0.028742\n",
      "[002/00897] train_loss: 0.029234\n",
      "[002/00947] train_loss: 0.029207\n",
      "[002/00997] train_loss: 0.027863\n",
      "[002/01047] train_loss: 0.028979\n",
      "[002/01097] train_loss: 0.028316\n",
      "[002/01147] train_loss: 0.029416\n",
      "[002/01197] train_loss: 0.029242\n",
      "[003/00021] train_loss: 0.030178\n",
      "[003/00071] train_loss: 0.031031\n",
      "[003/00121] train_loss: 0.028760\n",
      "[003/00171] train_loss: 0.027129\n",
      "[003/00221] train_loss: 0.027174\n",
      "[003/00271] train_loss: 0.028900\n",
      "[003/00321] train_loss: 0.026887\n",
      "[003/00371] train_loss: 0.028369\n",
      "[003/00421] train_loss: 0.028497\n",
      "[003/00471] train_loss: 0.027281\n",
      "[003/00521] train_loss: 0.026706\n",
      "[003/00571] train_loss: 0.027631\n",
      "[003/00621] train_loss: 0.027185\n",
      "[003/00671] train_loss: 0.027772\n",
      "[003/00721] train_loss: 0.027257\n",
      "[003/00771] train_loss: 0.026410\n",
      "[003/00821] train_loss: 0.027479\n",
      "[003/00871] train_loss: 0.028864\n",
      "[003/00921] train_loss: 0.027526\n",
      "[003/00971] train_loss: 0.026825\n",
      "[003/01021] train_loss: 0.027466\n",
      "[003/01071] train_loss: 0.027481\n",
      "[003/01121] train_loss: 0.027052\n",
      "[003/01171] train_loss: 0.027237\n",
      "[003/01221] train_loss: 0.027855\n",
      "[004/00045] train_loss: 0.031426\n",
      "[004/00095] train_loss: 0.030849\n",
      "[004/00145] train_loss: 0.028225\n",
      "[004/00195] train_loss: 0.026960\n",
      "[004/00245] train_loss: 0.027207\n",
      "[004/00295] train_loss: 0.027666\n",
      "[004/00345] train_loss: 0.026377\n",
      "[004/00395] train_loss: 0.025584\n",
      "[004/00445] train_loss: 0.026378\n",
      "[004/00495] train_loss: 0.026030\n",
      "[004/00545] train_loss: 0.027295\n",
      "[004/00595] train_loss: 0.025458\n",
      "[004/00645] train_loss: 0.025534\n",
      "[004/00695] train_loss: 0.026876\n",
      "[004/00745] train_loss: 0.026366\n",
      "[004/00795] train_loss: 0.026312\n",
      "[004/00845] train_loss: 0.027270\n",
      "[004/00895] train_loss: 0.026854\n",
      "[004/00945] train_loss: 0.027627\n",
      "[004/00995] train_loss: 0.027025\n",
      "[004/01045] train_loss: 0.027240\n",
      "[004/01095] train_loss: 0.025809\n",
      "[004/01145] train_loss: 0.026285\n",
      "[004/01195] train_loss: 0.026314\n",
      "[005/00019] train_loss: 0.030527\n",
      "[005/00069] train_loss: 0.029108\n",
      "[005/00119] train_loss: 0.027393\n",
      "[005/00169] train_loss: 0.026890\n",
      "[005/00219] train_loss: 0.025979\n",
      "[005/00269] train_loss: 0.026765\n",
      "[005/00319] train_loss: 0.025912\n",
      "[005/00369] train_loss: 0.025745\n",
      "[005/00419] train_loss: 0.027158\n",
      "[005/00469] train_loss: 0.026899\n",
      "[005/00519] train_loss: 0.025819\n",
      "[005/00569] train_loss: 0.025206\n",
      "[005/00619] train_loss: 0.026474\n",
      "[005/00669] train_loss: 0.025107\n",
      "[005/00719] train_loss: 0.025445\n",
      "[005/00769] train_loss: 0.026618\n",
      "[005/00819] train_loss: 0.024100\n",
      "[005/00869] train_loss: 0.025949\n",
      "[005/00919] train_loss: 0.025542\n",
      "[005/00969] train_loss: 0.026225\n",
      "[005/01019] train_loss: 0.025755\n",
      "[005/01069] train_loss: 0.025736\n",
      "[005/01119] train_loss: 0.025020\n",
      "[005/01169] train_loss: 0.025736\n",
      "[005/01219] train_loss: 0.025513\n",
      "[006/00043] train_loss: 0.031815\n",
      "[006/00093] train_loss: 0.029143\n",
      "[006/00143] train_loss: 0.027905\n",
      "[006/00193] train_loss: 0.026865\n",
      "[006/00243] train_loss: 0.025158\n",
      "[006/00293] train_loss: 0.025594\n",
      "[006/00343] train_loss: 0.024861\n",
      "[006/00393] train_loss: 0.024141\n",
      "[006/00443] train_loss: 0.025354\n",
      "[006/00493] train_loss: 0.025899\n",
      "[006/00543] train_loss: 0.024659\n",
      "[006/00593] train_loss: 0.025482\n",
      "[006/00643] train_loss: 0.024814\n",
      "[006/00693] train_loss: 0.024432\n",
      "[006/00743] train_loss: 0.024892\n",
      "[006/00793] train_loss: 0.024582\n",
      "[006/00843] train_loss: 0.024798\n",
      "[006/00893] train_loss: 0.023397\n",
      "[006/00943] train_loss: 0.025019\n",
      "[006/00993] train_loss: 0.024763\n",
      "[006/01043] train_loss: 0.025194\n",
      "[006/01093] train_loss: 0.024672\n",
      "[006/01143] train_loss: 0.024581\n",
      "[006/01193] train_loss: 0.024208\n",
      "[007/00017] train_loss: 0.028319\n",
      "[007/00067] train_loss: 0.029644\n",
      "[007/00117] train_loss: 0.027431\n",
      "[007/00167] train_loss: 0.025730\n",
      "[007/00217] train_loss: 0.025532\n",
      "[007/00267] train_loss: 0.025297\n",
      "[007/00317] train_loss: 0.024582\n",
      "[007/00367] train_loss: 0.024198\n",
      "[007/00417] train_loss: 0.024815\n",
      "[007/00467] train_loss: 0.024446\n",
      "[007/00517] train_loss: 0.023906\n",
      "[007/00567] train_loss: 0.024176\n",
      "[007/00617] train_loss: 0.023486\n",
      "[007/00667] train_loss: 0.023565\n",
      "[007/00717] train_loss: 0.023620\n",
      "[007/00767] train_loss: 0.023611\n",
      "[007/00817] train_loss: 0.024741\n",
      "[007/00867] train_loss: 0.024597\n",
      "[007/00917] train_loss: 0.024492\n",
      "[007/00967] train_loss: 0.024862\n",
      "[007/01017] train_loss: 0.024784\n",
      "[007/01067] train_loss: 0.024147\n",
      "[007/01117] train_loss: 0.024874\n",
      "[007/01167] train_loss: 0.023977\n",
      "[007/01217] train_loss: 0.024370\n",
      "[008/00041] train_loss: 0.030634\n",
      "[008/00091] train_loss: 0.026110\n",
      "[008/00141] train_loss: 0.023712\n",
      "[008/00191] train_loss: 0.024061\n",
      "[008/00241] train_loss: 0.024682\n",
      "[008/00291] train_loss: 0.023233\n",
      "[008/00341] train_loss: 0.024384\n",
      "[008/00391] train_loss: 0.024380\n",
      "[008/00441] train_loss: 0.024421\n",
      "[008/00491] train_loss: 0.023953\n",
      "[008/00541] train_loss: 0.023172\n",
      "[008/00591] train_loss: 0.025149\n",
      "[008/00641] train_loss: 0.023629\n",
      "[008/00691] train_loss: 0.024076\n",
      "[008/00741] train_loss: 0.024620\n",
      "[008/00791] train_loss: 0.024227\n",
      "[008/00841] train_loss: 0.024047\n",
      "[008/00891] train_loss: 0.023614\n",
      "[008/00941] train_loss: 0.023776\n",
      "[008/00991] train_loss: 0.023872\n",
      "[008/01041] train_loss: 0.023437\n",
      "[008/01091] train_loss: 0.023382\n",
      "[008/01141] train_loss: 0.023510\n",
      "[008/01191] train_loss: 0.024113\n",
      "[009/00015] train_loss: 0.027855\n",
      "[009/00065] train_loss: 0.027275\n",
      "[009/00115] train_loss: 0.026072\n",
      "[009/00165] train_loss: 0.024504\n",
      "[009/00215] train_loss: 0.024016\n",
      "[009/00265] train_loss: 0.023677\n",
      "[009/00315] train_loss: 0.024016\n",
      "[009/00365] train_loss: 0.023336\n",
      "[009/00415] train_loss: 0.023448\n",
      "[009/00465] train_loss: 0.022482\n",
      "[009/00515] train_loss: 0.023313\n",
      "[009/00565] train_loss: 0.022800\n",
      "[009/00615] train_loss: 0.023982\n",
      "[009/00665] train_loss: 0.023264\n",
      "[009/00715] train_loss: 0.022476\n",
      "[009/00765] train_loss: 0.022464\n",
      "[009/00815] train_loss: 0.022126\n",
      "[009/00865] train_loss: 0.023455\n",
      "[009/00915] train_loss: 0.022218\n",
      "[009/00965] train_loss: 0.022913\n",
      "[009/01015] train_loss: 0.022965\n",
      "[009/01065] train_loss: 0.022441\n",
      "[009/01115] train_loss: 0.022665\n",
      "[009/01165] train_loss: 0.023654\n",
      "[009/01215] train_loss: 0.022789\n",
      "[010/00039] train_loss: 0.030836\n",
      "[010/00089] train_loss: 0.028289\n",
      "[010/00139] train_loss: 0.025143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/00189] train_loss: 0.023727\n",
      "[010/00239] train_loss: 0.023117\n",
      "[010/00289] train_loss: 0.023309\n",
      "[010/00339] train_loss: 0.023796\n",
      "[010/00389] train_loss: 0.023104\n",
      "[010/00439] train_loss: 0.022343\n",
      "[010/00489] train_loss: 0.022934\n",
      "[010/00539] train_loss: 0.022442\n",
      "[010/00589] train_loss: 0.022605\n",
      "[010/00639] train_loss: 0.023342\n",
      "[010/00689] train_loss: 0.022703\n",
      "[010/00739] train_loss: 0.023337\n",
      "[010/00789] train_loss: 0.023125\n",
      "[010/00839] train_loss: 0.022754\n",
      "[010/00889] train_loss: 0.022794\n",
      "[010/00939] train_loss: 0.022485\n",
      "[010/00989] train_loss: 0.022339\n",
      "[010/01039] train_loss: 0.023355\n",
      "[010/01089] train_loss: 0.022542\n",
      "[010/01139] train_loss: 0.023393\n",
      "[010/01189] train_loss: 0.021505\n",
      "[011/00013] train_loss: 0.026149\n",
      "[011/00063] train_loss: 0.028944\n",
      "[011/00113] train_loss: 0.026634\n",
      "[011/00163] train_loss: 0.024445\n",
      "[011/00213] train_loss: 0.024621\n",
      "[011/00263] train_loss: 0.022558\n",
      "[011/00313] train_loss: 0.022228\n",
      "[011/00363] train_loss: 0.022530\n",
      "[011/00413] train_loss: 0.022641\n",
      "[011/00463] train_loss: 0.023485\n",
      "[011/00513] train_loss: 0.021989\n",
      "[011/00563] train_loss: 0.022590\n",
      "[011/00613] train_loss: 0.022937\n",
      "[011/00663] train_loss: 0.022588\n",
      "[011/00713] train_loss: 0.023048\n",
      "[011/00763] train_loss: 0.021982\n",
      "[011/00813] train_loss: 0.022692\n",
      "[011/00863] train_loss: 0.022808\n",
      "[011/00913] train_loss: 0.022396\n",
      "[011/00963] train_loss: 0.021108\n",
      "[011/01013] train_loss: 0.022619\n",
      "[011/01063] train_loss: 0.022632\n",
      "[011/01113] train_loss: 0.023915\n",
      "[011/01163] train_loss: 0.022145\n",
      "[011/01213] train_loss: 0.022057\n",
      "[012/00037] train_loss: 0.028255\n",
      "[012/00087] train_loss: 0.027807\n",
      "[012/00137] train_loss: 0.025224\n",
      "[012/00187] train_loss: 0.022953\n",
      "[012/00237] train_loss: 0.022996\n",
      "[012/00287] train_loss: 0.022563\n",
      "[012/00337] train_loss: 0.023156\n",
      "[012/00387] train_loss: 0.021828\n",
      "[012/00437] train_loss: 0.022522\n",
      "[012/00487] train_loss: 0.023459\n",
      "[012/00537] train_loss: 0.021146\n",
      "[012/00587] train_loss: 0.022588\n",
      "[012/00637] train_loss: 0.022066\n",
      "[012/00687] train_loss: 0.022328\n",
      "[012/00737] train_loss: 0.022059\n",
      "[012/00787] train_loss: 0.021869\n",
      "[012/00837] train_loss: 0.022132\n",
      "[012/00887] train_loss: 0.022108\n",
      "[012/00937] train_loss: 0.022892\n",
      "[012/00987] train_loss: 0.021328\n",
      "[012/01037] train_loss: 0.021181\n",
      "[012/01087] train_loss: 0.022266\n",
      "[012/01137] train_loss: 0.021985\n",
      "[012/01187] train_loss: 0.022281\n",
      "[013/00011] train_loss: 0.025210\n",
      "[013/00061] train_loss: 0.028789\n",
      "[013/00111] train_loss: 0.026011\n",
      "[013/00161] train_loss: 0.024034\n",
      "[013/00211] train_loss: 0.022918\n",
      "[013/00261] train_loss: 0.022780\n",
      "[013/00311] train_loss: 0.022395\n",
      "[013/00361] train_loss: 0.021946\n",
      "[013/00411] train_loss: 0.021092\n",
      "[013/00461] train_loss: 0.020879\n",
      "[013/00511] train_loss: 0.021078\n",
      "[013/00561] train_loss: 0.022159\n",
      "[013/00611] train_loss: 0.021661\n",
      "[013/00661] train_loss: 0.021926\n",
      "[013/00711] train_loss: 0.021965\n",
      "[013/00761] train_loss: 0.021465\n",
      "[013/00811] train_loss: 0.021358\n",
      "[013/00861] train_loss: 0.021726\n",
      "[013/00911] train_loss: 0.021074\n",
      "[013/00961] train_loss: 0.021263\n",
      "[013/01011] train_loss: 0.022535\n",
      "[013/01061] train_loss: 0.022839\n",
      "[013/01111] train_loss: 0.021474\n",
      "[013/01161] train_loss: 0.021299\n",
      "[013/01211] train_loss: 0.022287\n",
      "[014/00035] train_loss: 0.030366\n",
      "[014/00085] train_loss: 0.026682\n",
      "[014/00135] train_loss: 0.023628\n",
      "[014/00185] train_loss: 0.023841\n",
      "[014/00235] train_loss: 0.021770\n",
      "[014/00285] train_loss: 0.021809\n",
      "[014/00335] train_loss: 0.021727\n",
      "[014/00385] train_loss: 0.021656\n",
      "[014/00435] train_loss: 0.020821\n",
      "[014/00485] train_loss: 0.021675\n",
      "[014/00535] train_loss: 0.021254\n",
      "[014/00585] train_loss: 0.021185\n",
      "[014/00635] train_loss: 0.021519\n",
      "[014/00685] train_loss: 0.021038\n",
      "[014/00735] train_loss: 0.022487\n",
      "[014/00785] train_loss: 0.021978\n",
      "[014/00835] train_loss: 0.022017\n",
      "[014/00885] train_loss: 0.021653\n",
      "[014/00935] train_loss: 0.021540\n",
      "[014/00985] train_loss: 0.020534\n",
      "[014/01035] train_loss: 0.021114\n",
      "[014/01085] train_loss: 0.022513\n",
      "[014/01135] train_loss: 0.020681\n",
      "[014/01185] train_loss: 0.022176\n",
      "[015/00009] train_loss: 0.024174\n",
      "[015/00059] train_loss: 0.030119\n",
      "[015/00109] train_loss: 0.026597\n",
      "[015/00159] train_loss: 0.022250\n",
      "[015/00209] train_loss: 0.022188\n",
      "[015/00259] train_loss: 0.021491\n",
      "[015/00309] train_loss: 0.021719\n",
      "[015/00359] train_loss: 0.021976\n",
      "[015/00409] train_loss: 0.022025\n",
      "[015/00459] train_loss: 0.022146\n",
      "[015/00509] train_loss: 0.021931\n",
      "[015/00559] train_loss: 0.021032\n",
      "[015/00609] train_loss: 0.021698\n",
      "[015/00659] train_loss: 0.021059\n",
      "[015/00709] train_loss: 0.022514\n",
      "[015/00759] train_loss: 0.020954\n",
      "[015/00809] train_loss: 0.021728\n",
      "[015/00859] train_loss: 0.021130\n",
      "[015/00909] train_loss: 0.021117\n",
      "[015/00959] train_loss: 0.021171\n",
      "[015/01009] train_loss: 0.021324\n",
      "[015/01059] train_loss: 0.021178\n",
      "[015/01109] train_loss: 0.020923\n",
      "[015/01159] train_loss: 0.021892\n",
      "[015/01209] train_loss: 0.021434\n",
      "[016/00033] train_loss: 0.030430\n",
      "[016/00083] train_loss: 0.026941\n",
      "[016/00133] train_loss: 0.024027\n",
      "[016/00183] train_loss: 0.022127\n",
      "[016/00233] train_loss: 0.022080\n",
      "[016/00283] train_loss: 0.021126\n",
      "[016/00333] train_loss: 0.021395\n",
      "[016/00383] train_loss: 0.022029\n",
      "[016/00433] train_loss: 0.020213\n",
      "[016/00483] train_loss: 0.020886\n",
      "[016/00533] train_loss: 0.021504\n",
      "[016/00583] train_loss: 0.020769\n",
      "[016/00633] train_loss: 0.021248\n",
      "[016/00683] train_loss: 0.021360\n",
      "[016/00733] train_loss: 0.021516\n",
      "[016/00783] train_loss: 0.020297\n",
      "[016/00833] train_loss: 0.020542\n",
      "[016/00883] train_loss: 0.020804\n",
      "[016/00933] train_loss: 0.020864\n",
      "[016/00983] train_loss: 0.020967\n",
      "[016/01033] train_loss: 0.021850\n",
      "[016/01083] train_loss: 0.020665\n",
      "[016/01133] train_loss: 0.021362\n",
      "[016/01183] train_loss: 0.020943\n",
      "[017/00007] train_loss: 0.022993\n",
      "[017/00057] train_loss: 0.029538\n",
      "[017/00107] train_loss: 0.025175\n",
      "[017/00157] train_loss: 0.022803\n",
      "[017/00207] train_loss: 0.022046\n",
      "[017/00257] train_loss: 0.021578\n",
      "[017/00307] train_loss: 0.021588\n",
      "[017/00357] train_loss: 0.021157\n",
      "[017/00407] train_loss: 0.021266\n",
      "[017/00457] train_loss: 0.021155\n",
      "[017/00507] train_loss: 0.020670\n",
      "[017/00557] train_loss: 0.021546\n",
      "[017/00607] train_loss: 0.021172\n",
      "[017/00657] train_loss: 0.020543\n",
      "[017/00707] train_loss: 0.021111\n",
      "[017/00757] train_loss: 0.020806\n",
      "[017/00807] train_loss: 0.020578\n",
      "[017/00857] train_loss: 0.020748\n",
      "[017/00907] train_loss: 0.020306\n",
      "[017/00957] train_loss: 0.020718\n",
      "[017/01007] train_loss: 0.019799\n",
      "[017/01057] train_loss: 0.021730\n",
      "[017/01107] train_loss: 0.021130\n",
      "[017/01157] train_loss: 0.020597\n",
      "[017/01207] train_loss: 0.021667\n",
      "[018/00031] train_loss: 0.028048\n",
      "[018/00081] train_loss: 0.027723\n",
      "[018/00131] train_loss: 0.024508\n",
      "[018/00181] train_loss: 0.022049\n",
      "[018/00231] train_loss: 0.020744\n",
      "[018/00281] train_loss: 0.021179\n",
      "[018/00331] train_loss: 0.020798\n",
      "[018/00381] train_loss: 0.020454\n",
      "[018/00431] train_loss: 0.021641\n",
      "[018/00481] train_loss: 0.021253\n",
      "[018/00531] train_loss: 0.021079\n",
      "[018/00581] train_loss: 0.021747\n",
      "[018/00631] train_loss: 0.020983\n",
      "[018/00681] train_loss: 0.020688\n",
      "[018/00731] train_loss: 0.019384\n",
      "[018/00781] train_loss: 0.020348\n",
      "[018/00831] train_loss: 0.020700\n",
      "[018/00881] train_loss: 0.021104\n",
      "[018/00931] train_loss: 0.019590\n",
      "[018/00981] train_loss: 0.020788\n",
      "[018/01031] train_loss: 0.020060\n",
      "[018/01081] train_loss: 0.021002\n",
      "[018/01131] train_loss: 0.021180\n",
      "[018/01181] train_loss: 0.020710\n",
      "[019/00005] train_loss: 0.023884\n",
      "[019/00055] train_loss: 0.030253\n",
      "[019/00105] train_loss: 0.025045\n",
      "[019/00155] train_loss: 0.022704\n",
      "[019/00205] train_loss: 0.021733\n",
      "[019/00255] train_loss: 0.021168\n",
      "[019/00305] train_loss: 0.021742\n",
      "[019/00355] train_loss: 0.019681\n",
      "[019/00405] train_loss: 0.021569\n",
      "[019/00455] train_loss: 0.021093\n",
      "[019/00505] train_loss: 0.020087\n",
      "[019/00555] train_loss: 0.021060\n",
      "[019/00605] train_loss: 0.020716\n",
      "[019/00655] train_loss: 0.020765\n",
      "[019/00705] train_loss: 0.020793\n",
      "[019/00755] train_loss: 0.020256\n",
      "[019/00805] train_loss: 0.020586\n",
      "[019/00855] train_loss: 0.021645\n",
      "[019/00905] train_loss: 0.020317\n",
      "[019/00955] train_loss: 0.020087\n",
      "[019/01005] train_loss: 0.019337\n",
      "[019/01055] train_loss: 0.021656\n",
      "[019/01105] train_loss: 0.021135\n",
      "[019/01155] train_loss: 0.022154\n",
      "[019/01205] train_loss: 0.020454\n",
      "[020/00029] train_loss: 0.028467\n",
      "[020/00079] train_loss: 0.026439\n",
      "[020/00129] train_loss: 0.022665\n",
      "[020/00179] train_loss: 0.021953\n",
      "[020/00229] train_loss: 0.020429\n",
      "[020/00279] train_loss: 0.021591\n",
      "[020/00329] train_loss: 0.020201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/00379] train_loss: 0.019966\n",
      "[020/00429] train_loss: 0.020557\n",
      "[020/00479] train_loss: 0.020262\n",
      "[020/00529] train_loss: 0.020401\n",
      "[020/00579] train_loss: 0.020502\n",
      "[020/00629] train_loss: 0.019540\n",
      "[020/00679] train_loss: 0.020539\n",
      "[020/00729] train_loss: 0.020467\n",
      "[020/00779] train_loss: 0.019943\n",
      "[020/00829] train_loss: 0.020124\n",
      "[020/00879] train_loss: 0.021892\n",
      "[020/00929] train_loss: 0.020916\n",
      "[020/00979] train_loss: 0.019297\n",
      "[020/01029] train_loss: 0.020466\n",
      "[020/01079] train_loss: 0.019998\n",
      "[020/01129] train_loss: 0.020469\n",
      "[020/01179] train_loss: 0.020225\n",
      "[021/00003] train_loss: 0.023043\n",
      "[021/00053] train_loss: 0.031325\n",
      "[021/00103] train_loss: 0.024997\n",
      "[021/00153] train_loss: 0.022059\n",
      "[021/00203] train_loss: 0.021210\n",
      "[021/00253] train_loss: 0.020598\n",
      "[021/00303] train_loss: 0.019870\n",
      "[021/00353] train_loss: 0.020645\n",
      "[021/00403] train_loss: 0.019506\n",
      "[021/00453] train_loss: 0.019541\n",
      "[021/00503] train_loss: 0.019920\n",
      "[021/00553] train_loss: 0.019692\n",
      "[021/00603] train_loss: 0.019276\n",
      "[021/00653] train_loss: 0.020637\n",
      "[021/00703] train_loss: 0.019032\n",
      "[021/00753] train_loss: 0.019211\n",
      "[021/00803] train_loss: 0.020246\n",
      "[021/00853] train_loss: 0.020263\n",
      "[021/00903] train_loss: 0.019628\n",
      "[021/00953] train_loss: 0.020078\n",
      "[021/01003] train_loss: 0.020766\n",
      "[021/01053] train_loss: 0.021443\n",
      "[021/01103] train_loss: 0.020425\n",
      "[021/01153] train_loss: 0.019387\n",
      "[021/01203] train_loss: 0.020809\n",
      "[022/00027] train_loss: 0.028773\n",
      "[022/00077] train_loss: 0.027411\n",
      "[022/00127] train_loss: 0.023827\n",
      "[022/00177] train_loss: 0.021732\n",
      "[022/00227] train_loss: 0.020811\n",
      "[022/00277] train_loss: 0.021285\n",
      "[022/00327] train_loss: 0.021502\n",
      "[022/00377] train_loss: 0.020439\n",
      "[022/00427] train_loss: 0.020862\n",
      "[022/00477] train_loss: 0.020856\n",
      "[022/00527] train_loss: 0.020716\n",
      "[022/00577] train_loss: 0.018661\n",
      "[022/00627] train_loss: 0.020324\n",
      "[022/00677] train_loss: 0.020155\n",
      "[022/00727] train_loss: 0.020037\n",
      "[022/00777] train_loss: 0.019185\n",
      "[022/00827] train_loss: 0.019686\n",
      "[022/00877] train_loss: 0.019662\n",
      "[022/00927] train_loss: 0.019860\n",
      "[022/00977] train_loss: 0.019500\n",
      "[022/01027] train_loss: 0.020756\n",
      "[022/01077] train_loss: 0.020811\n",
      "[022/01127] train_loss: 0.020033\n",
      "[022/01177] train_loss: 0.019765\n",
      "[023/00001] train_loss: 0.021238\n",
      "[023/00051] train_loss: 0.029534\n",
      "[023/00101] train_loss: 0.024578\n",
      "[023/00151] train_loss: 0.022868\n",
      "[023/00201] train_loss: 0.020957\n",
      "[023/00251] train_loss: 0.021474\n",
      "[023/00301] train_loss: 0.019743\n",
      "[023/00351] train_loss: 0.020148\n",
      "[023/00401] train_loss: 0.020262\n",
      "[023/00451] train_loss: 0.020819\n",
      "[023/00501] train_loss: 0.020137\n",
      "[023/00551] train_loss: 0.020141\n",
      "[023/00601] train_loss: 0.020157\n",
      "[023/00651] train_loss: 0.020041\n",
      "[023/00701] train_loss: 0.020178\n",
      "[023/00751] train_loss: 0.020011\n",
      "[023/00801] train_loss: 0.020037\n",
      "[023/00851] train_loss: 0.019318\n",
      "[023/00901] train_loss: 0.019508\n",
      "[023/00951] train_loss: 0.019869\n",
      "[023/01001] train_loss: 0.020114\n",
      "[023/01051] train_loss: 0.019625\n",
      "[023/01101] train_loss: 0.020267\n",
      "[023/01151] train_loss: 0.020031\n",
      "[023/01201] train_loss: 0.019023\n",
      "[024/00025] train_loss: 0.028863\n",
      "[024/00075] train_loss: 0.026928\n",
      "[024/00125] train_loss: 0.024413\n",
      "[024/00175] train_loss: 0.021218\n",
      "[024/00225] train_loss: 0.019749\n",
      "[024/00275] train_loss: 0.020140\n",
      "[024/00325] train_loss: 0.020419\n",
      "[024/00375] train_loss: 0.019179\n",
      "[024/00425] train_loss: 0.020752\n",
      "[024/00475] train_loss: 0.019574\n",
      "[024/00525] train_loss: 0.019454\n",
      "[024/00575] train_loss: 0.018803\n",
      "[024/00625] train_loss: 0.020075\n",
      "[024/00675] train_loss: 0.020807\n",
      "[024/00725] train_loss: 0.019365\n",
      "[024/00775] train_loss: 0.019681\n",
      "[024/00825] train_loss: 0.018880\n",
      "[024/00875] train_loss: 0.019737\n",
      "[024/00925] train_loss: 0.019840\n",
      "[024/00975] train_loss: 0.019998\n",
      "[024/01025] train_loss: 0.020386\n",
      "[024/01075] train_loss: 0.019129\n",
      "[024/01125] train_loss: 0.020478\n",
      "[024/01175] train_loss: 0.020682\n",
      "[024/01225] train_loss: 0.019812\n",
      "[025/00049] train_loss: 0.032565\n",
      "[025/00099] train_loss: 0.025543\n",
      "[025/00149] train_loss: 0.023221\n",
      "[025/00199] train_loss: 0.021292\n",
      "[025/00249] train_loss: 0.021161\n",
      "[025/00299] train_loss: 0.020143\n",
      "[025/00349] train_loss: 0.020110\n",
      "[025/00399] train_loss: 0.020150\n",
      "[025/00449] train_loss: 0.020360\n",
      "[025/00499] train_loss: 0.019482\n",
      "[025/00549] train_loss: 0.019636\n",
      "[025/00599] train_loss: 0.021115\n",
      "[025/00649] train_loss: 0.019854\n",
      "[025/00699] train_loss: 0.019290\n",
      "[025/00749] train_loss: 0.019185\n",
      "[025/00799] train_loss: 0.019041\n",
      "[025/00849] train_loss: 0.020188\n",
      "[025/00899] train_loss: 0.019851\n",
      "[025/00949] train_loss: 0.019425\n",
      "[025/00999] train_loss: 0.019460\n",
      "[025/01049] train_loss: 0.019677\n",
      "[025/01099] train_loss: 0.019225\n",
      "[025/01149] train_loss: 0.019779\n",
      "[025/01199] train_loss: 0.019831\n",
      "[026/00023] train_loss: 0.025712\n",
      "[026/00073] train_loss: 0.028171\n",
      "[026/00123] train_loss: 0.023416\n",
      "[026/00173] train_loss: 0.021340\n",
      "[026/00223] train_loss: 0.022155\n",
      "[026/00273] train_loss: 0.020898\n",
      "[026/00323] train_loss: 0.019015\n",
      "[026/00373] train_loss: 0.019792\n",
      "[026/00423] train_loss: 0.019004\n",
      "[026/00473] train_loss: 0.020086\n",
      "[026/00523] train_loss: 0.018570\n",
      "[026/00573] train_loss: 0.019278\n",
      "[026/00623] train_loss: 0.019314\n",
      "[026/00673] train_loss: 0.019540\n",
      "[026/00723] train_loss: 0.019562\n",
      "[026/00773] train_loss: 0.020080\n",
      "[026/00823] train_loss: 0.018727\n",
      "[026/00873] train_loss: 0.019999\n",
      "[026/00923] train_loss: 0.019472\n",
      "[026/00973] train_loss: 0.018850\n",
      "[026/01023] train_loss: 0.019615\n",
      "[026/01073] train_loss: 0.020139\n",
      "[026/01123] train_loss: 0.018866\n",
      "[026/01173] train_loss: 0.019742\n",
      "[026/01223] train_loss: 0.020078\n",
      "[027/00047] train_loss: 0.029251\n",
      "[027/00097] train_loss: 0.024146\n",
      "[027/00147] train_loss: 0.020913\n",
      "[027/00197] train_loss: 0.021484\n",
      "[027/00247] train_loss: 0.018717\n",
      "[027/00297] train_loss: 0.020694\n",
      "[027/00347] train_loss: 0.020808\n",
      "[027/00397] train_loss: 0.019189\n",
      "[027/00447] train_loss: 0.019706\n",
      "[027/00497] train_loss: 0.019697\n",
      "[027/00547] train_loss: 0.018861\n",
      "[027/00597] train_loss: 0.019037\n",
      "[027/00647] train_loss: 0.019559\n",
      "[027/00697] train_loss: 0.018394\n",
      "[027/00747] train_loss: 0.019602\n",
      "[027/00797] train_loss: 0.019777\n",
      "[027/00847] train_loss: 0.019765\n",
      "[027/00897] train_loss: 0.018588\n",
      "[027/00947] train_loss: 0.018829\n",
      "[027/00997] train_loss: 0.020623\n",
      "[027/01047] train_loss: 0.019619\n",
      "[027/01097] train_loss: 0.019218\n",
      "[027/01147] train_loss: 0.019009\n",
      "[027/01197] train_loss: 0.019762\n",
      "[028/00021] train_loss: 0.026389\n",
      "[028/00071] train_loss: 0.027994\n",
      "[028/00121] train_loss: 0.024081\n",
      "[028/00171] train_loss: 0.021988\n",
      "[028/00221] train_loss: 0.020776\n",
      "[028/00271] train_loss: 0.019862\n",
      "[028/00321] train_loss: 0.019329\n",
      "[028/00371] train_loss: 0.019535\n",
      "[028/00421] train_loss: 0.020580\n",
      "[028/00471] train_loss: 0.018783\n",
      "[028/00521] train_loss: 0.019327\n",
      "[028/00571] train_loss: 0.019987\n",
      "[028/00621] train_loss: 0.019738\n",
      "[028/00671] train_loss: 0.019765\n",
      "[028/00721] train_loss: 0.018769\n",
      "[028/00771] train_loss: 0.019136\n",
      "[028/00821] train_loss: 0.019397\n",
      "[028/00871] train_loss: 0.019868\n",
      "[028/00921] train_loss: 0.019617\n",
      "[028/00971] train_loss: 0.020212\n",
      "[028/01021] train_loss: 0.018959\n",
      "[028/01071] train_loss: 0.019848\n",
      "[028/01121] train_loss: 0.019296\n",
      "[028/01171] train_loss: 0.019236\n",
      "[028/01221] train_loss: 0.020617\n",
      "[029/00045] train_loss: 0.030125\n",
      "[029/00095] train_loss: 0.024969\n",
      "[029/00145] train_loss: 0.021524\n",
      "[029/00195] train_loss: 0.020780\n",
      "[029/00245] train_loss: 0.020230\n",
      "[029/00295] train_loss: 0.019293\n",
      "[029/00345] train_loss: 0.020386\n",
      "[029/00395] train_loss: 0.019723\n",
      "[029/00445] train_loss: 0.018778\n",
      "[029/00495] train_loss: 0.020041\n",
      "[029/00545] train_loss: 0.019327\n",
      "[029/00595] train_loss: 0.020466\n",
      "[029/00645] train_loss: 0.019090\n",
      "[029/00695] train_loss: 0.019492\n",
      "[029/00745] train_loss: 0.019255\n",
      "[029/00795] train_loss: 0.018470\n",
      "[029/00845] train_loss: 0.018929\n",
      "[029/00895] train_loss: 0.019258\n",
      "[029/00945] train_loss: 0.020040\n",
      "[029/00995] train_loss: 0.018174\n",
      "[029/01045] train_loss: 0.020410\n",
      "[029/01095] train_loss: 0.019292\n",
      "[029/01145] train_loss: 0.017960\n",
      "[029/01195] train_loss: 0.019929\n",
      "[030/00019] train_loss: 0.024814\n",
      "[030/00069] train_loss: 0.027098\n",
      "[030/00119] train_loss: 0.022071\n",
      "[030/00169] train_loss: 0.021229\n",
      "[030/00219] train_loss: 0.020049\n",
      "[030/00269] train_loss: 0.019088\n",
      "[030/00319] train_loss: 0.019118\n",
      "[030/00369] train_loss: 0.019743\n",
      "[030/00419] train_loss: 0.020047\n",
      "[030/00469] train_loss: 0.019221\n",
      "[030/00519] train_loss: 0.018344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/00569] train_loss: 0.018848\n",
      "[030/00619] train_loss: 0.019426\n",
      "[030/00669] train_loss: 0.020220\n",
      "[030/00719] train_loss: 0.019449\n",
      "[030/00769] train_loss: 0.019493\n",
      "[030/00819] train_loss: 0.018466\n",
      "[030/00869] train_loss: 0.019090\n",
      "[030/00919] train_loss: 0.020033\n",
      "[030/00969] train_loss: 0.020696\n",
      "[030/01019] train_loss: 0.018990\n",
      "[030/01069] train_loss: 0.019563\n",
      "[030/01119] train_loss: 0.018760\n",
      "[030/01169] train_loss: 0.019239\n",
      "[030/01219] train_loss: 0.019332\n",
      "[031/00043] train_loss: 0.028375\n",
      "[031/00093] train_loss: 0.024250\n",
      "[031/00143] train_loss: 0.022068\n",
      "[031/00193] train_loss: 0.020192\n",
      "[031/00243] train_loss: 0.019805\n",
      "[031/00293] train_loss: 0.019594\n",
      "[031/00343] train_loss: 0.018897\n",
      "[031/00393] train_loss: 0.019978\n",
      "[031/00443] train_loss: 0.018846\n",
      "[031/00493] train_loss: 0.018423\n",
      "[031/00543] train_loss: 0.018889\n",
      "[031/00593] train_loss: 0.018428\n",
      "[031/00643] train_loss: 0.018723\n",
      "[031/00693] train_loss: 0.018240\n",
      "[031/00743] train_loss: 0.019370\n",
      "[031/00793] train_loss: 0.019088\n",
      "[031/00843] train_loss: 0.019004\n",
      "[031/00893] train_loss: 0.018641\n",
      "[031/00943] train_loss: 0.019565\n",
      "[031/00993] train_loss: 0.019721\n",
      "[031/01043] train_loss: 0.019094\n",
      "[031/01093] train_loss: 0.019011\n",
      "[031/01143] train_loss: 0.018324\n",
      "[031/01193] train_loss: 0.019584\n",
      "[032/00017] train_loss: 0.025217\n",
      "[032/00067] train_loss: 0.027039\n",
      "[032/00117] train_loss: 0.023162\n",
      "[032/00167] train_loss: 0.019673\n",
      "[032/00217] train_loss: 0.019638\n",
      "[032/00267] train_loss: 0.019031\n",
      "[032/00317] train_loss: 0.018792\n",
      "[032/00367] train_loss: 0.019255\n",
      "[032/00417] train_loss: 0.018830\n",
      "[032/00467] train_loss: 0.018862\n",
      "[032/00517] train_loss: 0.019450\n",
      "[032/00567] train_loss: 0.019301\n",
      "[032/00617] train_loss: 0.019246\n",
      "[032/00667] train_loss: 0.018915\n",
      "[032/00717] train_loss: 0.018954\n",
      "[032/00767] train_loss: 0.019112\n",
      "[032/00817] train_loss: 0.018994\n",
      "[032/00867] train_loss: 0.018758\n",
      "[032/00917] train_loss: 0.018942\n",
      "[032/00967] train_loss: 0.019285\n",
      "[032/01017] train_loss: 0.018749\n",
      "[032/01067] train_loss: 0.018739\n",
      "[032/01117] train_loss: 0.018131\n",
      "[032/01167] train_loss: 0.018762\n",
      "[032/01217] train_loss: 0.018690\n",
      "[033/00041] train_loss: 0.029036\n",
      "[033/00091] train_loss: 0.025870\n",
      "[033/00141] train_loss: 0.021725\n",
      "[033/00191] train_loss: 0.019731\n",
      "[033/00241] train_loss: 0.019457\n",
      "[033/00291] train_loss: 0.020049\n",
      "[033/00341] train_loss: 0.019845\n",
      "[033/00391] train_loss: 0.019075\n",
      "[033/00441] train_loss: 0.019157\n",
      "[033/00491] train_loss: 0.018457\n",
      "[033/00541] train_loss: 0.019626\n",
      "[033/00591] train_loss: 0.018917\n",
      "[033/00641] train_loss: 0.018869\n",
      "[033/00691] train_loss: 0.019720\n",
      "[033/00741] train_loss: 0.019314\n",
      "[033/00791] train_loss: 0.019793\n",
      "[033/00841] train_loss: 0.019090\n",
      "[033/00891] train_loss: 0.019613\n",
      "[033/00941] train_loss: 0.018935\n",
      "[033/00991] train_loss: 0.018711\n",
      "[033/01041] train_loss: 0.018936\n",
      "[033/01091] train_loss: 0.019584\n",
      "[033/01141] train_loss: 0.018375\n",
      "[033/01191] train_loss: 0.019373\n",
      "[034/00015] train_loss: 0.025708\n",
      "[034/00065] train_loss: 0.026424\n",
      "[034/00115] train_loss: 0.021925\n",
      "[034/00165] train_loss: 0.020631\n",
      "[034/00215] train_loss: 0.019878\n",
      "[034/00265] train_loss: 0.019062\n",
      "[034/00315] train_loss: 0.018651\n",
      "[034/00365] train_loss: 0.019307\n",
      "[034/00415] train_loss: 0.019373\n",
      "[034/00465] train_loss: 0.018982\n",
      "[034/00515] train_loss: 0.018300\n",
      "[034/00565] train_loss: 0.018928\n",
      "[034/00615] train_loss: 0.018679\n",
      "[034/00665] train_loss: 0.018216\n",
      "[034/00715] train_loss: 0.019609\n",
      "[034/00765] train_loss: 0.018269\n",
      "[034/00815] train_loss: 0.019586\n",
      "[034/00865] train_loss: 0.019549\n",
      "[034/00915] train_loss: 0.020671\n",
      "[034/00965] train_loss: 0.018908\n",
      "[034/01015] train_loss: 0.019191\n",
      "[034/01065] train_loss: 0.019422\n",
      "[034/01115] train_loss: 0.018917\n",
      "[034/01165] train_loss: 0.019904\n",
      "[034/01215] train_loss: 0.019363\n",
      "[035/00039] train_loss: 0.027882\n",
      "[035/00089] train_loss: 0.024385\n",
      "[035/00139] train_loss: 0.021587\n",
      "[035/00189] train_loss: 0.020130\n",
      "[035/00239] train_loss: 0.020233\n",
      "[035/00289] train_loss: 0.019607\n",
      "[035/00339] train_loss: 0.019671\n",
      "[035/00389] train_loss: 0.018831\n",
      "[035/00439] train_loss: 0.019421\n",
      "[035/00489] train_loss: 0.018921\n",
      "[035/00539] train_loss: 0.018860\n",
      "[035/00589] train_loss: 0.018426\n",
      "[035/00639] train_loss: 0.018277\n",
      "[035/00689] train_loss: 0.018123\n",
      "[035/00739] train_loss: 0.018465\n",
      "[035/00789] train_loss: 0.018860\n",
      "[035/00839] train_loss: 0.018742\n",
      "[035/00889] train_loss: 0.018860\n",
      "[035/00939] train_loss: 0.019498\n",
      "[035/00989] train_loss: 0.018963\n",
      "[035/01039] train_loss: 0.020557\n",
      "[035/01089] train_loss: 0.019852\n",
      "[035/01139] train_loss: 0.018603\n",
      "[035/01189] train_loss: 0.019692\n",
      "[036/00013] train_loss: 0.023496\n",
      "[036/00063] train_loss: 0.027476\n",
      "[036/00113] train_loss: 0.022915\n",
      "[036/00163] train_loss: 0.020725\n",
      "[036/00213] train_loss: 0.019478\n",
      "[036/00263] train_loss: 0.018830\n",
      "[036/00313] train_loss: 0.019740\n",
      "[036/00363] train_loss: 0.018567\n",
      "[036/00413] train_loss: 0.018504\n",
      "[036/00463] train_loss: 0.019215\n",
      "[036/00513] train_loss: 0.019398\n",
      "[036/00563] train_loss: 0.018308\n",
      "[036/00613] train_loss: 0.018467\n",
      "[036/00663] train_loss: 0.017764\n",
      "[036/00713] train_loss: 0.018639\n",
      "[036/00763] train_loss: 0.019201\n",
      "[036/00813] train_loss: 0.019353\n",
      "[036/00863] train_loss: 0.019730\n",
      "[036/00913] train_loss: 0.017664\n",
      "[036/00963] train_loss: 0.018716\n",
      "[036/01013] train_loss: 0.019386\n",
      "[036/01063] train_loss: 0.018592\n",
      "[036/01113] train_loss: 0.019256\n",
      "[036/01163] train_loss: 0.018309\n",
      "[036/01213] train_loss: 0.018478\n",
      "[037/00037] train_loss: 0.027658\n",
      "[037/00087] train_loss: 0.024097\n",
      "[037/00137] train_loss: 0.021594\n",
      "[037/00187] train_loss: 0.020353\n",
      "[037/00237] train_loss: 0.018630\n",
      "[037/00287] train_loss: 0.018807\n",
      "[037/00337] train_loss: 0.018828\n",
      "[037/00387] train_loss: 0.019106\n",
      "[037/00437] train_loss: 0.018982\n",
      "[037/00487] train_loss: 0.019339\n",
      "[037/00537] train_loss: 0.018162\n",
      "[037/00587] train_loss: 0.018805\n",
      "[037/00637] train_loss: 0.018775\n",
      "[037/00687] train_loss: 0.018902\n",
      "[037/00737] train_loss: 0.017880\n",
      "[037/00787] train_loss: 0.019172\n",
      "[037/00837] train_loss: 0.017966\n",
      "[037/00887] train_loss: 0.018666\n",
      "[037/00937] train_loss: 0.018608\n",
      "[037/00987] train_loss: 0.019769\n",
      "[037/01037] train_loss: 0.018684\n",
      "[037/01087] train_loss: 0.018529\n",
      "[037/01137] train_loss: 0.018774\n",
      "[037/01187] train_loss: 0.019072\n",
      "[038/00011] train_loss: 0.021580\n",
      "[038/00061] train_loss: 0.027407\n",
      "[038/00111] train_loss: 0.023440\n",
      "[038/00161] train_loss: 0.020654\n",
      "[038/00211] train_loss: 0.020698\n",
      "[038/00261] train_loss: 0.019954\n",
      "[038/00311] train_loss: 0.019230\n",
      "[038/00361] train_loss: 0.019219\n",
      "[038/00411] train_loss: 0.018504\n",
      "[038/00461] train_loss: 0.018045\n",
      "[038/00511] train_loss: 0.018557\n",
      "[038/00561] train_loss: 0.018171\n",
      "[038/00611] train_loss: 0.018227\n",
      "[038/00661] train_loss: 0.018800\n",
      "[038/00711] train_loss: 0.018059\n",
      "[038/00761] train_loss: 0.019442\n",
      "[038/00811] train_loss: 0.018959\n",
      "[038/00861] train_loss: 0.018687\n",
      "[038/00911] train_loss: 0.018973\n",
      "[038/00961] train_loss: 0.018002\n",
      "[038/01011] train_loss: 0.017403\n",
      "[038/01061] train_loss: 0.019328\n",
      "[038/01111] train_loss: 0.019476\n",
      "[038/01161] train_loss: 0.018761\n",
      "[038/01211] train_loss: 0.018431\n",
      "[039/00035] train_loss: 0.027008\n",
      "[039/00085] train_loss: 0.024406\n",
      "[039/00135] train_loss: 0.021192\n",
      "[039/00185] train_loss: 0.019592\n",
      "[039/00235] train_loss: 0.019331\n",
      "[039/00285] train_loss: 0.018903\n",
      "[039/00335] train_loss: 0.018831\n",
      "[039/00385] train_loss: 0.020354\n",
      "[039/00435] train_loss: 0.018962\n",
      "[039/00485] train_loss: 0.018004\n",
      "[039/00535] train_loss: 0.018073\n",
      "[039/00585] train_loss: 0.019407\n",
      "[039/00635] train_loss: 0.018000\n",
      "[039/00685] train_loss: 0.018221\n",
      "[039/00735] train_loss: 0.017999\n",
      "[039/00785] train_loss: 0.017907\n",
      "[039/00835] train_loss: 0.018221\n",
      "[039/00885] train_loss: 0.019057\n",
      "[039/00935] train_loss: 0.018907\n",
      "[039/00985] train_loss: 0.018351\n",
      "[039/01035] train_loss: 0.018569\n",
      "[039/01085] train_loss: 0.018583\n",
      "[039/01135] train_loss: 0.018304\n",
      "[039/01185] train_loss: 0.018562\n",
      "[040/00009] train_loss: 0.024042\n",
      "[040/00059] train_loss: 0.026845\n",
      "[040/00109] train_loss: 0.022831\n",
      "[040/00159] train_loss: 0.019728\n",
      "[040/00209] train_loss: 0.020152\n",
      "[040/00259] train_loss: 0.019698\n",
      "[040/00309] train_loss: 0.018979\n",
      "[040/00359] train_loss: 0.018490\n",
      "[040/00409] train_loss: 0.019316\n",
      "[040/00459] train_loss: 0.018475\n",
      "[040/00509] train_loss: 0.018167\n",
      "[040/00559] train_loss: 0.018874\n",
      "[040/00609] train_loss: 0.018292\n",
      "[040/00659] train_loss: 0.018479\n",
      "[040/00709] train_loss: 0.018959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/00759] train_loss: 0.019317\n",
      "[040/00809] train_loss: 0.019085\n",
      "[040/00859] train_loss: 0.019453\n",
      "[040/00909] train_loss: 0.018625\n",
      "[040/00959] train_loss: 0.018924\n",
      "[040/01009] train_loss: 0.017947\n",
      "[040/01059] train_loss: 0.018582\n",
      "[040/01109] train_loss: 0.018724\n",
      "[040/01159] train_loss: 0.019010\n",
      "[040/01209] train_loss: 0.018846\n",
      "[041/00033] train_loss: 0.025395\n",
      "[041/00083] train_loss: 0.024280\n",
      "[041/00133] train_loss: 0.022087\n",
      "[041/00183] train_loss: 0.019532\n",
      "[041/00233] train_loss: 0.019480\n",
      "[041/00283] train_loss: 0.020341\n",
      "[041/00333] train_loss: 0.018548\n",
      "[041/00383] train_loss: 0.019125\n",
      "[041/00433] train_loss: 0.018084\n",
      "[041/00483] train_loss: 0.018836\n",
      "[041/00533] train_loss: 0.018151\n",
      "[041/00583] train_loss: 0.018487\n",
      "[041/00633] train_loss: 0.018580\n",
      "[041/00683] train_loss: 0.018909\n",
      "[041/00733] train_loss: 0.017796\n",
      "[041/00783] train_loss: 0.018934\n",
      "[041/00833] train_loss: 0.018101\n",
      "[041/00883] train_loss: 0.018039\n",
      "[041/00933] train_loss: 0.018265\n",
      "[041/00983] train_loss: 0.019130\n",
      "[041/01033] train_loss: 0.017987\n",
      "[041/01083] train_loss: 0.018192\n",
      "[041/01133] train_loss: 0.018423\n",
      "[041/01183] train_loss: 0.018853\n",
      "[042/00007] train_loss: 0.021265\n",
      "[042/00057] train_loss: 0.028979\n",
      "[042/00107] train_loss: 0.023232\n",
      "[042/00157] train_loss: 0.020387\n",
      "[042/00207] train_loss: 0.019457\n",
      "[042/00257] train_loss: 0.019334\n",
      "[042/00307] train_loss: 0.019167\n",
      "[042/00357] train_loss: 0.018755\n",
      "[042/00407] train_loss: 0.018829\n",
      "[042/00457] train_loss: 0.017588\n",
      "[042/00507] train_loss: 0.019490\n",
      "[042/00557] train_loss: 0.017910\n",
      "[042/00607] train_loss: 0.018694\n",
      "[042/00657] train_loss: 0.018704\n",
      "[042/00707] train_loss: 0.018132\n",
      "[042/00757] train_loss: 0.018585\n",
      "[042/00807] train_loss: 0.019842\n",
      "[042/00857] train_loss: 0.018158\n",
      "[042/00907] train_loss: 0.019474\n",
      "[042/00957] train_loss: 0.018104\n",
      "[042/01007] train_loss: 0.018715\n",
      "[042/01057] train_loss: 0.019139\n",
      "[042/01107] train_loss: 0.018296\n",
      "[042/01157] train_loss: 0.019112\n",
      "[042/01207] train_loss: 0.018693\n",
      "[043/00031] train_loss: 0.025461\n",
      "[043/00081] train_loss: 0.025098\n",
      "[043/00131] train_loss: 0.022198\n",
      "[043/00181] train_loss: 0.020136\n",
      "[043/00231] train_loss: 0.019465\n",
      "[043/00281] train_loss: 0.018937\n",
      "[043/00331] train_loss: 0.018994\n",
      "[043/00381] train_loss: 0.019183\n",
      "[043/00431] train_loss: 0.019569\n",
      "[043/00481] train_loss: 0.018725\n",
      "[043/00531] train_loss: 0.017556\n",
      "[043/00581] train_loss: 0.018352\n",
      "[043/00631] train_loss: 0.018474\n",
      "[043/00681] train_loss: 0.017738\n",
      "[043/00731] train_loss: 0.018049\n",
      "[043/00781] train_loss: 0.018860\n",
      "[043/00831] train_loss: 0.018063\n",
      "[043/00881] train_loss: 0.019004\n",
      "[043/00931] train_loss: 0.019100\n",
      "[043/00981] train_loss: 0.019470\n",
      "[043/01031] train_loss: 0.017825\n",
      "[043/01081] train_loss: 0.018166\n",
      "[043/01131] train_loss: 0.018301\n",
      "[043/01181] train_loss: 0.018702\n",
      "[044/00005] train_loss: 0.019378\n",
      "[044/00055] train_loss: 0.026205\n",
      "[044/00105] train_loss: 0.022989\n",
      "[044/00155] train_loss: 0.019946\n",
      "[044/00205] train_loss: 0.019377\n",
      "[044/00255] train_loss: 0.018496\n",
      "[044/00305] train_loss: 0.019184\n",
      "[044/00355] train_loss: 0.018206\n",
      "[044/00405] train_loss: 0.018672\n",
      "[044/00455] train_loss: 0.018329\n",
      "[044/00505] train_loss: 0.018744\n",
      "[044/00555] train_loss: 0.019351\n",
      "[044/00605] train_loss: 0.017581\n",
      "[044/00655] train_loss: 0.019209\n",
      "[044/00705] train_loss: 0.018923\n",
      "[044/00755] train_loss: 0.018992\n",
      "[044/00805] train_loss: 0.018739\n",
      "[044/00855] train_loss: 0.019281\n",
      "[044/00905] train_loss: 0.017954\n",
      "[044/00955] train_loss: 0.017907\n",
      "[044/01005] train_loss: 0.019448\n",
      "[044/01055] train_loss: 0.019056\n",
      "[044/01105] train_loss: 0.018011\n",
      "[044/01155] train_loss: 0.018315\n",
      "[044/01205] train_loss: 0.019070\n",
      "[045/00029] train_loss: 0.027574\n",
      "[045/00079] train_loss: 0.025322\n",
      "[045/00129] train_loss: 0.020450\n",
      "[045/00179] train_loss: 0.019677\n",
      "[045/00229] train_loss: 0.019773\n",
      "[045/00279] train_loss: 0.019007\n",
      "[045/00329] train_loss: 0.018147\n",
      "[045/00379] train_loss: 0.018615\n",
      "[045/00429] train_loss: 0.017982\n",
      "[045/00479] train_loss: 0.017782\n",
      "[045/00529] train_loss: 0.018729\n",
      "[045/00579] train_loss: 0.019158\n",
      "[045/00629] train_loss: 0.019284\n",
      "[045/00679] train_loss: 0.018720\n",
      "[045/00729] train_loss: 0.018460\n",
      "[045/00779] train_loss: 0.017826\n",
      "[045/00829] train_loss: 0.018370\n",
      "[045/00879] train_loss: 0.017779\n",
      "[045/00929] train_loss: 0.019039\n",
      "[045/00979] train_loss: 0.018580\n",
      "[045/01029] train_loss: 0.018453\n",
      "[045/01079] train_loss: 0.018769\n",
      "[045/01129] train_loss: 0.018428\n",
      "[045/01179] train_loss: 0.019039\n",
      "[046/00003] train_loss: 0.018903\n",
      "[046/00053] train_loss: 0.029561\n",
      "[046/00103] train_loss: 0.023525\n",
      "[046/00153] train_loss: 0.020894\n",
      "[046/00203] train_loss: 0.019263\n",
      "[046/00253] train_loss: 0.018371\n",
      "[046/00303] train_loss: 0.019376\n",
      "[046/00353] train_loss: 0.018442\n",
      "[046/00403] train_loss: 0.018479\n",
      "[046/00453] train_loss: 0.018383\n",
      "[046/00503] train_loss: 0.018041\n",
      "[046/00553] train_loss: 0.018735\n",
      "[046/00603] train_loss: 0.018562\n",
      "[046/00653] train_loss: 0.018535\n",
      "[046/00703] train_loss: 0.018062\n",
      "[046/00753] train_loss: 0.018290\n",
      "[046/00803] train_loss: 0.018690\n",
      "[046/00853] train_loss: 0.018320\n",
      "[046/00903] train_loss: 0.018010\n",
      "[046/00953] train_loss: 0.018130\n",
      "[046/01003] train_loss: 0.019151\n",
      "[046/01053] train_loss: 0.018513\n",
      "[046/01103] train_loss: 0.018095\n",
      "[046/01153] train_loss: 0.018094\n",
      "[046/01203] train_loss: 0.019599\n",
      "[047/00027] train_loss: 0.024833\n",
      "[047/00077] train_loss: 0.025178\n",
      "[047/00127] train_loss: 0.020991\n",
      "[047/00177] train_loss: 0.020173\n",
      "[047/00227] train_loss: 0.019122\n",
      "[047/00277] train_loss: 0.018164\n",
      "[047/00327] train_loss: 0.018770\n",
      "[047/00377] train_loss: 0.018904\n",
      "[047/00427] train_loss: 0.018785\n",
      "[047/00477] train_loss: 0.018144\n",
      "[047/00527] train_loss: 0.018002\n",
      "[047/00577] train_loss: 0.019135\n",
      "[047/00627] train_loss: 0.017824\n",
      "[047/00677] train_loss: 0.018766\n",
      "[047/00727] train_loss: 0.019000\n",
      "[047/00777] train_loss: 0.017703\n",
      "[047/00827] train_loss: 0.018212\n",
      "[047/00877] train_loss: 0.018743\n",
      "[047/00927] train_loss: 0.018459\n",
      "[047/00977] train_loss: 0.018056\n",
      "[047/01027] train_loss: 0.018213\n",
      "[047/01077] train_loss: 0.019007\n",
      "[047/01127] train_loss: 0.018555\n",
      "[047/01177] train_loss: 0.018019\n",
      "[048/00001] train_loss: 0.019032\n",
      "[048/00051] train_loss: 0.028719\n",
      "[048/00101] train_loss: 0.023025\n",
      "[048/00151] train_loss: 0.019819\n",
      "[048/00201] train_loss: 0.019082\n",
      "[048/00251] train_loss: 0.018315\n",
      "[048/00301] train_loss: 0.017899\n",
      "[048/00351] train_loss: 0.018458\n",
      "[048/00401] train_loss: 0.019013\n",
      "[048/00451] train_loss: 0.018061\n",
      "[048/00501] train_loss: 0.017527\n",
      "[048/00551] train_loss: 0.016922\n",
      "[048/00601] train_loss: 0.018877\n",
      "[048/00651] train_loss: 0.018005\n",
      "[048/00701] train_loss: 0.018462\n",
      "[048/00751] train_loss: 0.018048\n",
      "[048/00801] train_loss: 0.018245\n",
      "[048/00851] train_loss: 0.019203\n",
      "[048/00901] train_loss: 0.018531\n",
      "[048/00951] train_loss: 0.018968\n",
      "[048/01001] train_loss: 0.017640\n",
      "[048/01051] train_loss: 0.019164\n",
      "[048/01101] train_loss: 0.018634\n",
      "[048/01151] train_loss: 0.017969\n",
      "[048/01201] train_loss: 0.018405\n",
      "[049/00025] train_loss: 0.024557\n",
      "[049/00075] train_loss: 0.026143\n",
      "[049/00125] train_loss: 0.020860\n",
      "[049/00175] train_loss: 0.020057\n",
      "[049/00225] train_loss: 0.020156\n",
      "[049/00275] train_loss: 0.017361\n",
      "[049/00325] train_loss: 0.018406\n",
      "[049/00375] train_loss: 0.018960\n",
      "[049/00425] train_loss: 0.018301\n",
      "[049/00475] train_loss: 0.017484\n",
      "[049/00525] train_loss: 0.017492\n",
      "[049/00575] train_loss: 0.018154\n",
      "[049/00625] train_loss: 0.018282\n",
      "[049/00675] train_loss: 0.018060\n",
      "[049/00725] train_loss: 0.018249\n",
      "[049/00775] train_loss: 0.019031\n",
      "[049/00825] train_loss: 0.018520\n",
      "[049/00875] train_loss: 0.018465\n",
      "[049/00925] train_loss: 0.018124\n",
      "[049/00975] train_loss: 0.018910\n",
      "[049/01025] train_loss: 0.019054\n",
      "[049/01075] train_loss: 0.019749\n",
      "[049/01125] train_loss: 0.017634\n",
      "[049/01175] train_loss: 0.018434\n",
      "[049/01225] train_loss: 0.017541\n",
      "[050/00049] train_loss: 0.028310\n",
      "[050/00099] train_loss: 0.023803\n",
      "[050/00149] train_loss: 0.020156\n",
      "[050/00199] train_loss: 0.019651\n",
      "[050/00249] train_loss: 0.018020\n",
      "[050/00299] train_loss: 0.019010\n",
      "[050/00349] train_loss: 0.018072\n",
      "[050/00399] train_loss: 0.017550\n",
      "[050/00449] train_loss: 0.018515\n",
      "[050/00499] train_loss: 0.018906\n",
      "[050/00549] train_loss: 0.017958\n",
      "[050/00599] train_loss: 0.018193\n",
      "[050/00649] train_loss: 0.017680\n",
      "[050/00699] train_loss: 0.018785\n",
      "[050/00749] train_loss: 0.018524\n",
      "[050/00799] train_loss: 0.018608\n",
      "[050/00849] train_loss: 0.018879\n",
      "[050/00899] train_loss: 0.017774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/00949] train_loss: 0.017681\n",
      "[050/00999] train_loss: 0.018414\n",
      "[050/01049] train_loss: 0.018620\n",
      "[050/01099] train_loss: 0.017909\n",
      "[050/01149] train_loss: 0.017665\n",
      "[050/01199] train_loss: 0.018068\n",
      "[051/00023] train_loss: 0.024564\n",
      "[051/00073] train_loss: 0.025477\n",
      "[051/00123] train_loss: 0.022083\n",
      "[051/00173] train_loss: 0.018966\n",
      "[051/00223] train_loss: 0.018662\n",
      "[051/00273] train_loss: 0.017548\n",
      "[051/00323] train_loss: 0.018476\n",
      "[051/00373] train_loss: 0.017355\n",
      "[051/00423] train_loss: 0.017343\n",
      "[051/00473] train_loss: 0.018214\n",
      "[051/00523] train_loss: 0.018061\n",
      "[051/00573] train_loss: 0.017395\n",
      "[051/00623] train_loss: 0.017655\n",
      "[051/00673] train_loss: 0.017892\n",
      "[051/00723] train_loss: 0.018882\n",
      "[051/00773] train_loss: 0.018341\n",
      "[051/00823] train_loss: 0.018110\n",
      "[051/00873] train_loss: 0.018653\n",
      "[051/00923] train_loss: 0.017950\n",
      "[051/00973] train_loss: 0.018203\n",
      "[051/01023] train_loss: 0.017624\n",
      "[051/01073] train_loss: 0.018031\n",
      "[051/01123] train_loss: 0.019168\n",
      "[051/01173] train_loss: 0.018922\n",
      "[051/01223] train_loss: 0.018962\n",
      "[052/00047] train_loss: 0.030396\n",
      "[052/00097] train_loss: 0.022667\n",
      "[052/00147] train_loss: 0.020423\n",
      "[052/00197] train_loss: 0.019643\n",
      "[052/00247] train_loss: 0.018432\n",
      "[052/00297] train_loss: 0.018792\n",
      "[052/00347] train_loss: 0.018061\n",
      "[052/00397] train_loss: 0.018562\n",
      "[052/00447] train_loss: 0.017972\n",
      "[052/00497] train_loss: 0.017792\n",
      "[052/00547] train_loss: 0.018006\n",
      "[052/00597] train_loss: 0.018040\n",
      "[052/00647] train_loss: 0.018121\n",
      "[052/00697] train_loss: 0.017475\n",
      "[052/00747] train_loss: 0.018722\n",
      "[052/00797] train_loss: 0.017597\n",
      "[052/00847] train_loss: 0.018140\n",
      "[052/00897] train_loss: 0.017988\n",
      "[052/00947] train_loss: 0.018471\n",
      "[052/00997] train_loss: 0.016667\n",
      "[052/01047] train_loss: 0.018295\n",
      "[052/01097] train_loss: 0.017467\n",
      "[052/01147] train_loss: 0.018726\n",
      "[052/01197] train_loss: 0.017571\n",
      "[053/00021] train_loss: 0.024312\n",
      "[053/00071] train_loss: 0.025891\n",
      "[053/00121] train_loss: 0.020545\n",
      "[053/00171] train_loss: 0.019249\n",
      "[053/00221] train_loss: 0.018549\n",
      "[053/00271] train_loss: 0.019326\n",
      "[053/00321] train_loss: 0.018606\n",
      "[053/00371] train_loss: 0.018862\n",
      "[053/00421] train_loss: 0.018282\n",
      "[053/00471] train_loss: 0.017673\n",
      "[053/00521] train_loss: 0.017481\n",
      "[053/00571] train_loss: 0.017969\n",
      "[053/00621] train_loss: 0.018667\n",
      "[053/00671] train_loss: 0.017002\n",
      "[053/00721] train_loss: 0.017846\n",
      "[053/00771] train_loss: 0.018653\n",
      "[053/00821] train_loss: 0.019099\n",
      "[053/00871] train_loss: 0.018413\n",
      "[053/00921] train_loss: 0.017564\n",
      "[053/00971] train_loss: 0.018299\n",
      "[053/01021] train_loss: 0.018460\n",
      "[053/01071] train_loss: 0.018639\n",
      "[053/01121] train_loss: 0.018515\n",
      "[053/01171] train_loss: 0.018185\n",
      "[053/01221] train_loss: 0.018661\n",
      "[054/00045] train_loss: 0.027526\n",
      "[054/00095] train_loss: 0.024470\n",
      "[054/00145] train_loss: 0.019266\n",
      "[054/00195] train_loss: 0.018519\n",
      "[054/00245] train_loss: 0.018006\n",
      "[054/00295] train_loss: 0.018357\n",
      "[054/00345] train_loss: 0.018722\n",
      "[054/00395] train_loss: 0.018490\n",
      "[054/00445] train_loss: 0.018239\n",
      "[054/00495] train_loss: 0.018127\n",
      "[054/00545] train_loss: 0.018306\n",
      "[054/00595] train_loss: 0.018057\n",
      "[054/00645] train_loss: 0.018882\n",
      "[054/00695] train_loss: 0.018289\n",
      "[054/00745] train_loss: 0.017382\n",
      "[054/00795] train_loss: 0.017504\n",
      "[054/00845] train_loss: 0.019045\n",
      "[054/00895] train_loss: 0.017942\n",
      "[054/00945] train_loss: 0.017527\n",
      "[054/00995] train_loss: 0.018063\n",
      "[054/01045] train_loss: 0.018463\n",
      "[054/01095] train_loss: 0.019018\n",
      "[054/01145] train_loss: 0.017576\n",
      "[054/01195] train_loss: 0.017866\n",
      "[055/00019] train_loss: 0.023959\n",
      "[055/00069] train_loss: 0.024500\n",
      "[055/00119] train_loss: 0.021149\n",
      "[055/00169] train_loss: 0.018895\n",
      "[055/00219] train_loss: 0.018179\n",
      "[055/00269] train_loss: 0.018581\n",
      "[055/00319] train_loss: 0.018123\n",
      "[055/00369] train_loss: 0.018471\n",
      "[055/00419] train_loss: 0.018149\n",
      "[055/00469] train_loss: 0.018787\n",
      "[055/00519] train_loss: 0.018283\n",
      "[055/00569] train_loss: 0.017722\n",
      "[055/00619] train_loss: 0.017599\n",
      "[055/00669] train_loss: 0.018029\n",
      "[055/00719] train_loss: 0.018346\n",
      "[055/00769] train_loss: 0.017393\n",
      "[055/00819] train_loss: 0.017741\n",
      "[055/00869] train_loss: 0.017577\n",
      "[055/00919] train_loss: 0.017355\n",
      "[055/00969] train_loss: 0.018592\n",
      "[055/01019] train_loss: 0.018618\n",
      "[055/01069] train_loss: 0.017864\n",
      "[055/01119] train_loss: 0.017924\n",
      "[055/01169] train_loss: 0.017948\n",
      "[055/01219] train_loss: 0.018174\n",
      "[056/00043] train_loss: 0.029705\n",
      "[056/00093] train_loss: 0.023158\n",
      "[056/00143] train_loss: 0.019116\n",
      "[056/00193] train_loss: 0.018699\n",
      "[056/00243] train_loss: 0.017843\n",
      "[056/00293] train_loss: 0.018416\n",
      "[056/00343] train_loss: 0.018107\n",
      "[056/00393] train_loss: 0.018001\n",
      "[056/00443] train_loss: 0.016362\n",
      "[056/00493] train_loss: 0.018306\n",
      "[056/00543] train_loss: 0.017901\n",
      "[056/00593] train_loss: 0.017475\n",
      "[056/00643] train_loss: 0.017943\n",
      "[056/00693] train_loss: 0.016693\n",
      "[056/00743] train_loss: 0.018401\n",
      "[056/00793] train_loss: 0.018330\n",
      "[056/00843] train_loss: 0.017440\n",
      "[056/00893] train_loss: 0.017495\n",
      "[056/00943] train_loss: 0.017695\n",
      "[056/00993] train_loss: 0.019389\n",
      "[056/01043] train_loss: 0.018649\n",
      "[056/01093] train_loss: 0.018098\n",
      "[056/01143] train_loss: 0.018099\n",
      "[056/01193] train_loss: 0.018785\n",
      "[057/00017] train_loss: 0.023027\n",
      "[057/00067] train_loss: 0.024922\n",
      "[057/00117] train_loss: 0.020672\n",
      "[057/00167] train_loss: 0.019812\n",
      "[057/00217] train_loss: 0.018397\n",
      "[057/00267] train_loss: 0.018049\n",
      "[057/00317] train_loss: 0.018345\n",
      "[057/00367] train_loss: 0.017743\n",
      "[057/00417] train_loss: 0.018057\n",
      "[057/00467] train_loss: 0.017806\n",
      "[057/00517] train_loss: 0.017364\n",
      "[057/00567] train_loss: 0.019524\n",
      "[057/00617] train_loss: 0.018055\n",
      "[057/00667] train_loss: 0.018235\n",
      "[057/00717] train_loss: 0.017133\n",
      "[057/00767] train_loss: 0.017292\n",
      "[057/00817] train_loss: 0.017839\n",
      "[057/00867] train_loss: 0.018108\n",
      "[057/00917] train_loss: 0.019467\n",
      "[057/00967] train_loss: 0.017626\n",
      "[057/01017] train_loss: 0.017580\n",
      "[057/01067] train_loss: 0.017370\n",
      "[057/01117] train_loss: 0.017525\n",
      "[057/01167] train_loss: 0.017798\n",
      "[057/01217] train_loss: 0.018475\n",
      "[058/00041] train_loss: 0.025890\n",
      "[058/00091] train_loss: 0.022880\n",
      "[058/00141] train_loss: 0.019850\n",
      "[058/00191] train_loss: 0.018425\n",
      "[058/00241] train_loss: 0.017394\n",
      "[058/00291] train_loss: 0.017955\n",
      "[058/00341] train_loss: 0.018346\n",
      "[058/00391] train_loss: 0.018157\n",
      "[058/00441] train_loss: 0.017523\n",
      "[058/00491] train_loss: 0.018236\n",
      "[058/00541] train_loss: 0.018244\n",
      "[058/00591] train_loss: 0.017594\n",
      "[058/00641] train_loss: 0.018635\n",
      "[058/00691] train_loss: 0.018099\n",
      "[058/00741] train_loss: 0.018027\n",
      "[058/00791] train_loss: 0.018890\n",
      "[058/00841] train_loss: 0.019213\n",
      "[058/00891] train_loss: 0.017771\n",
      "[058/00941] train_loss: 0.017746\n",
      "[058/00991] train_loss: 0.018048\n",
      "[058/01041] train_loss: 0.018819\n",
      "[058/01091] train_loss: 0.017767\n",
      "[058/01141] train_loss: 0.017972\n",
      "[058/01191] train_loss: 0.018660\n",
      "[059/00015] train_loss: 0.023186\n",
      "[059/00065] train_loss: 0.026813\n",
      "[059/00115] train_loss: 0.021685\n",
      "[059/00165] train_loss: 0.018619\n",
      "[059/00215] train_loss: 0.019326\n",
      "[059/00265] train_loss: 0.018021\n",
      "[059/00315] train_loss: 0.018232\n",
      "[059/00365] train_loss: 0.018536\n",
      "[059/00415] train_loss: 0.017884\n",
      "[059/00465] train_loss: 0.017036\n",
      "[059/00515] train_loss: 0.017509\n",
      "[059/00565] train_loss: 0.017787\n",
      "[059/00615] train_loss: 0.017989\n",
      "[059/00665] train_loss: 0.018286\n",
      "[059/00715] train_loss: 0.018444\n",
      "[059/00765] train_loss: 0.018009\n",
      "[059/00815] train_loss: 0.017631\n",
      "[059/00865] train_loss: 0.017884\n",
      "[059/00915] train_loss: 0.017143\n",
      "[059/00965] train_loss: 0.017756\n",
      "[059/01015] train_loss: 0.018964\n",
      "[059/01065] train_loss: 0.018367\n",
      "[059/01115] train_loss: 0.017571\n",
      "[059/01165] train_loss: 0.019268\n",
      "[059/01215] train_loss: 0.017756\n",
      "[060/00039] train_loss: 0.025836\n",
      "[060/00089] train_loss: 0.024788\n",
      "[060/00139] train_loss: 0.020313\n",
      "[060/00189] train_loss: 0.019532\n",
      "[060/00239] train_loss: 0.018834\n",
      "[060/00289] train_loss: 0.017990\n",
      "[060/00339] train_loss: 0.017068\n",
      "[060/00389] train_loss: 0.017547\n",
      "[060/00439] train_loss: 0.017750\n",
      "[060/00489] train_loss: 0.018131\n",
      "[060/00539] train_loss: 0.017658\n",
      "[060/00589] train_loss: 0.016712\n",
      "[060/00639] train_loss: 0.018635\n",
      "[060/00689] train_loss: 0.018568\n",
      "[060/00739] train_loss: 0.017989\n",
      "[060/00789] train_loss: 0.017846\n",
      "[060/00839] train_loss: 0.018285\n",
      "[060/00889] train_loss: 0.018735\n",
      "[060/00939] train_loss: 0.017315\n",
      "[060/00989] train_loss: 0.016617\n",
      "[060/01039] train_loss: 0.018645\n",
      "[060/01089] train_loss: 0.018069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[060/01139] train_loss: 0.017979\n",
      "[060/01189] train_loss: 0.017379\n",
      "[061/00013] train_loss: 0.022999\n",
      "[061/00063] train_loss: 0.024313\n",
      "[061/00113] train_loss: 0.021386\n",
      "[061/00163] train_loss: 0.018516\n",
      "[061/00213] train_loss: 0.018196\n",
      "[061/00263] train_loss: 0.017831\n",
      "[061/00313] train_loss: 0.017385\n",
      "[061/00363] train_loss: 0.018062\n",
      "[061/00413] train_loss: 0.017242\n",
      "[061/00463] train_loss: 0.017439\n",
      "[061/00513] train_loss: 0.017864\n",
      "[061/00563] train_loss: 0.018085\n",
      "[061/00613] train_loss: 0.016737\n",
      "[061/00663] train_loss: 0.018333\n",
      "[061/00713] train_loss: 0.018259\n",
      "[061/00763] train_loss: 0.017919\n",
      "[061/00813] train_loss: 0.018154\n",
      "[061/00863] train_loss: 0.017340\n",
      "[061/00913] train_loss: 0.017578\n",
      "[061/00963] train_loss: 0.018225\n",
      "[061/01013] train_loss: 0.017328\n",
      "[061/01063] train_loss: 0.017532\n",
      "[061/01113] train_loss: 0.018266\n",
      "[061/01163] train_loss: 0.019536\n",
      "[061/01213] train_loss: 0.018034\n",
      "[062/00037] train_loss: 0.024781\n",
      "[062/00087] train_loss: 0.023137\n",
      "[062/00137] train_loss: 0.020134\n",
      "[062/00187] train_loss: 0.018965\n",
      "[062/00237] train_loss: 0.018124\n",
      "[062/00287] train_loss: 0.017990\n",
      "[062/00337] train_loss: 0.018243\n",
      "[062/00387] train_loss: 0.017829\n",
      "[062/00437] train_loss: 0.018154\n",
      "[062/00487] train_loss: 0.018183\n",
      "[062/00537] train_loss: 0.017439\n",
      "[062/00587] train_loss: 0.016186\n",
      "[062/00637] train_loss: 0.018148\n",
      "[062/00687] train_loss: 0.018462\n",
      "[062/00737] train_loss: 0.017060\n",
      "[062/00787] train_loss: 0.018737\n",
      "[062/00837] train_loss: 0.017663\n",
      "[062/00887] train_loss: 0.018528\n",
      "[062/00937] train_loss: 0.018848\n",
      "[062/00987] train_loss: 0.018028\n",
      "[062/01037] train_loss: 0.017343\n",
      "[062/01087] train_loss: 0.016804\n",
      "[062/01137] train_loss: 0.018105\n",
      "[062/01187] train_loss: 0.018326\n",
      "[063/00011] train_loss: 0.021123\n",
      "[063/00061] train_loss: 0.026307\n",
      "[063/00111] train_loss: 0.022654\n",
      "[063/00161] train_loss: 0.018727\n",
      "[063/00211] train_loss: 0.018656\n",
      "[063/00261] train_loss: 0.017746\n",
      "[063/00311] train_loss: 0.018852\n",
      "[063/00361] train_loss: 0.017828\n",
      "[063/00411] train_loss: 0.018116\n",
      "[063/00461] train_loss: 0.018028\n",
      "[063/00511] train_loss: 0.018471\n",
      "[063/00561] train_loss: 0.017674\n",
      "[063/00611] train_loss: 0.018087\n",
      "[063/00661] train_loss: 0.016572\n",
      "[063/00711] train_loss: 0.016998\n",
      "[063/00761] train_loss: 0.017777\n",
      "[063/00811] train_loss: 0.017953\n",
      "[063/00861] train_loss: 0.017342\n",
      "[063/00911] train_loss: 0.018344\n",
      "[063/00961] train_loss: 0.017989\n",
      "[063/01011] train_loss: 0.017847\n",
      "[063/01061] train_loss: 0.017670\n",
      "[063/01111] train_loss: 0.017774\n",
      "[063/01161] train_loss: 0.018402\n",
      "[063/01211] train_loss: 0.017970\n",
      "[064/00035] train_loss: 0.025379\n",
      "[064/00085] train_loss: 0.023886\n",
      "[064/00135] train_loss: 0.020773\n",
      "[064/00185] train_loss: 0.018849\n",
      "[064/00235] train_loss: 0.018004\n",
      "[064/00285] train_loss: 0.017929\n",
      "[064/00335] train_loss: 0.018123\n",
      "[064/00385] train_loss: 0.017925\n",
      "[064/00435] train_loss: 0.018699\n",
      "[064/00485] train_loss: 0.017647\n",
      "[064/00535] train_loss: 0.016325\n",
      "[064/00585] train_loss: 0.017130\n",
      "[064/00635] train_loss: 0.018738\n",
      "[064/00685] train_loss: 0.017472\n",
      "[064/00735] train_loss: 0.017625\n",
      "[064/00785] train_loss: 0.017407\n",
      "[064/00835] train_loss: 0.017411\n",
      "[064/00885] train_loss: 0.018538\n",
      "[064/00935] train_loss: 0.017419\n",
      "[064/00985] train_loss: 0.017185\n",
      "[064/01035] train_loss: 0.017450\n",
      "[064/01085] train_loss: 0.017549\n",
      "[064/01135] train_loss: 0.018369\n",
      "[064/01185] train_loss: 0.018191\n",
      "[065/00009] train_loss: 0.020840\n",
      "[065/00059] train_loss: 0.026318\n",
      "[065/00109] train_loss: 0.021501\n",
      "[065/00159] train_loss: 0.018419\n",
      "[065/00209] train_loss: 0.018134\n",
      "[065/00259] train_loss: 0.018170\n",
      "[065/00309] train_loss: 0.018383\n",
      "[065/00359] train_loss: 0.018223\n",
      "[065/00409] train_loss: 0.018131\n",
      "[065/00459] train_loss: 0.018133\n",
      "[065/00509] train_loss: 0.018209\n",
      "[065/00559] train_loss: 0.018169\n",
      "[065/00609] train_loss: 0.018036\n",
      "[065/00659] train_loss: 0.017692\n",
      "[065/00709] train_loss: 0.016904\n",
      "[065/00759] train_loss: 0.018108\n",
      "[065/00809] train_loss: 0.018067\n",
      "[065/00859] train_loss: 0.017297\n",
      "[065/00909] train_loss: 0.017412\n",
      "[065/00959] train_loss: 0.017683\n",
      "[065/01009] train_loss: 0.017220\n",
      "[065/01059] train_loss: 0.017659\n",
      "[065/01109] train_loss: 0.018051\n",
      "[065/01159] train_loss: 0.017647\n",
      "[065/01209] train_loss: 0.017813\n",
      "[066/00033] train_loss: 0.025554\n",
      "[066/00083] train_loss: 0.024117\n",
      "[066/00133] train_loss: 0.020303\n",
      "[066/00183] train_loss: 0.018875\n",
      "[066/00233] train_loss: 0.018942\n",
      "[066/00283] train_loss: 0.017648\n",
      "[066/00333] train_loss: 0.018622\n",
      "[066/00383] train_loss: 0.018415\n",
      "[066/00433] train_loss: 0.017221\n",
      "[066/00483] train_loss: 0.017301\n",
      "[066/00533] train_loss: 0.017779\n",
      "[066/00583] train_loss: 0.017585\n",
      "[066/00633] train_loss: 0.017026\n",
      "[066/00683] train_loss: 0.017435\n",
      "[066/00733] train_loss: 0.018351\n",
      "[066/00783] train_loss: 0.017137\n",
      "[066/00833] train_loss: 0.018244\n",
      "[066/00883] train_loss: 0.017592\n",
      "[066/00933] train_loss: 0.017710\n",
      "[066/00983] train_loss: 0.017493\n",
      "[066/01033] train_loss: 0.015688\n",
      "[066/01083] train_loss: 0.018386\n",
      "[066/01133] train_loss: 0.017867\n",
      "[066/01183] train_loss: 0.018359\n",
      "[067/00007] train_loss: 0.020284\n",
      "[067/00057] train_loss: 0.024415\n",
      "[067/00107] train_loss: 0.021381\n",
      "[067/00157] train_loss: 0.019575\n",
      "[067/00207] train_loss: 0.019247\n",
      "[067/00257] train_loss: 0.017696\n",
      "[067/00307] train_loss: 0.018461\n",
      "[067/00357] train_loss: 0.017548\n",
      "[067/00407] train_loss: 0.017731\n",
      "[067/00457] train_loss: 0.017506\n",
      "[067/00507] train_loss: 0.017509\n",
      "[067/00557] train_loss: 0.017929\n",
      "[067/00607] train_loss: 0.018083\n",
      "[067/00657] train_loss: 0.017815\n",
      "[067/00707] train_loss: 0.017232\n",
      "[067/00757] train_loss: 0.018190\n",
      "[067/00807] train_loss: 0.017402\n",
      "[067/00857] train_loss: 0.017046\n",
      "[067/00907] train_loss: 0.017444\n",
      "[067/00957] train_loss: 0.017854\n",
      "[067/01007] train_loss: 0.017278\n",
      "[067/01057] train_loss: 0.017706\n",
      "[067/01107] train_loss: 0.017868\n",
      "[067/01157] train_loss: 0.017263\n",
      "[067/01207] train_loss: 0.017750\n",
      "[068/00031] train_loss: 0.026258\n",
      "[068/00081] train_loss: 0.024371\n",
      "[068/00131] train_loss: 0.020435\n",
      "[068/00181] train_loss: 0.018700\n",
      "[068/00231] train_loss: 0.018313\n",
      "[068/00281] train_loss: 0.017958\n",
      "[068/00331] train_loss: 0.017968\n",
      "[068/00381] train_loss: 0.017288\n",
      "[068/00431] train_loss: 0.017778\n",
      "[068/00481] train_loss: 0.017444\n",
      "[068/00531] train_loss: 0.018227\n",
      "[068/00581] train_loss: 0.017036\n",
      "[068/00631] train_loss: 0.017915\n",
      "[068/00681] train_loss: 0.017939\n",
      "[068/00731] train_loss: 0.017366\n",
      "[068/00781] train_loss: 0.017282\n",
      "[068/00831] train_loss: 0.017289\n",
      "[068/00881] train_loss: 0.018040\n",
      "[068/00931] train_loss: 0.017612\n",
      "[068/00981] train_loss: 0.018050\n",
      "[068/01031] train_loss: 0.017455\n",
      "[068/01081] train_loss: 0.017719\n",
      "[068/01131] train_loss: 0.018385\n",
      "[068/01181] train_loss: 0.018387\n",
      "[069/00005] train_loss: 0.019861\n",
      "[069/00055] train_loss: 0.026887\n",
      "[069/00105] train_loss: 0.021028\n",
      "[069/00155] train_loss: 0.018853\n",
      "[069/00205] train_loss: 0.017962\n",
      "[069/00255] train_loss: 0.018223\n",
      "[069/00305] train_loss: 0.018279\n",
      "[069/00355] train_loss: 0.018479\n",
      "[069/00405] train_loss: 0.016793\n",
      "[069/00455] train_loss: 0.017934\n",
      "[069/00505] train_loss: 0.017474\n",
      "[069/00555] train_loss: 0.018013\n",
      "[069/00605] train_loss: 0.017247\n",
      "[069/00655] train_loss: 0.017707\n",
      "[069/00705] train_loss: 0.016189\n",
      "[069/00755] train_loss: 0.017388\n",
      "[069/00805] train_loss: 0.017620\n",
      "[069/00855] train_loss: 0.018121\n",
      "[069/00905] train_loss: 0.017621\n",
      "[069/00955] train_loss: 0.017835\n",
      "[069/01005] train_loss: 0.018846\n",
      "[069/01055] train_loss: 0.017322\n",
      "[069/01105] train_loss: 0.017191\n",
      "[069/01155] train_loss: 0.017056\n",
      "[069/01205] train_loss: 0.017998\n",
      "[070/00029] train_loss: 0.025548\n",
      "[070/00079] train_loss: 0.023658\n",
      "[070/00129] train_loss: 0.020947\n",
      "[070/00179] train_loss: 0.019331\n",
      "[070/00229] train_loss: 0.017742\n",
      "[070/00279] train_loss: 0.017883\n",
      "[070/00329] train_loss: 0.018108\n",
      "[070/00379] train_loss: 0.016658\n",
      "[070/00429] train_loss: 0.018097\n",
      "[070/00479] train_loss: 0.018316\n",
      "[070/00529] train_loss: 0.016707\n",
      "[070/00579] train_loss: 0.017097\n",
      "[070/00629] train_loss: 0.016651\n",
      "[070/00679] train_loss: 0.018091\n",
      "[070/00729] train_loss: 0.017007\n",
      "[070/00779] train_loss: 0.018667\n",
      "[070/00829] train_loss: 0.017848\n",
      "[070/00879] train_loss: 0.017672\n",
      "[070/00929] train_loss: 0.017973\n",
      "[070/00979] train_loss: 0.017812\n",
      "[070/01029] train_loss: 0.017901\n",
      "[070/01079] train_loss: 0.018189\n",
      "[070/01129] train_loss: 0.017093\n",
      "[070/01179] train_loss: 0.018361\n",
      "[071/00003] train_loss: 0.017952\n",
      "[071/00053] train_loss: 0.026494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[071/00103] train_loss: 0.020306\n",
      "[071/00153] train_loss: 0.018845\n",
      "[071/00203] train_loss: 0.017115\n",
      "[071/00253] train_loss: 0.017703\n",
      "[071/00303] train_loss: 0.017511\n",
      "[071/00353] train_loss: 0.018056\n",
      "[071/00403] train_loss: 0.018492\n",
      "[071/00453] train_loss: 0.017699\n",
      "[071/00503] train_loss: 0.017683\n",
      "[071/00553] train_loss: 0.017466\n",
      "[071/00603] train_loss: 0.017956\n",
      "[071/00653] train_loss: 0.018355\n",
      "[071/00703] train_loss: 0.016994\n",
      "[071/00753] train_loss: 0.017207\n",
      "[071/00803] train_loss: 0.018036\n",
      "[071/00853] train_loss: 0.016775\n",
      "[071/00903] train_loss: 0.018173\n",
      "[071/00953] train_loss: 0.017973\n",
      "[071/01003] train_loss: 0.017763\n",
      "[071/01053] train_loss: 0.017632\n",
      "[071/01103] train_loss: 0.016719\n",
      "[071/01153] train_loss: 0.018339\n",
      "[071/01203] train_loss: 0.017343\n",
      "[072/00027] train_loss: 0.023772\n",
      "[072/00077] train_loss: 0.024412\n",
      "[072/00127] train_loss: 0.020804\n",
      "[072/00177] train_loss: 0.018976\n",
      "[072/00227] train_loss: 0.019289\n",
      "[072/00277] train_loss: 0.017564\n",
      "[072/00327] train_loss: 0.018020\n",
      "[072/00377] train_loss: 0.017446\n",
      "[072/00427] train_loss: 0.018052\n",
      "[072/00477] train_loss: 0.017489\n",
      "[072/00527] train_loss: 0.017546\n",
      "[072/00577] train_loss: 0.017071\n",
      "[072/00627] train_loss: 0.017273\n",
      "[072/00677] train_loss: 0.016777\n",
      "[072/00727] train_loss: 0.018512\n",
      "[072/00777] train_loss: 0.017551\n",
      "[072/00827] train_loss: 0.016704\n",
      "[072/00877] train_loss: 0.016963\n",
      "[072/00927] train_loss: 0.017665\n",
      "[072/00977] train_loss: 0.017301\n",
      "[072/01027] train_loss: 0.017607\n",
      "[072/01077] train_loss: 0.016864\n",
      "[072/01127] train_loss: 0.018437\n",
      "[072/01177] train_loss: 0.018605\n",
      "[073/00001] train_loss: 0.018220\n",
      "[073/00051] train_loss: 0.026703\n",
      "[073/00101] train_loss: 0.021158\n",
      "[073/00151] train_loss: 0.018639\n",
      "[073/00201] train_loss: 0.018734\n",
      "[073/00251] train_loss: 0.018347\n",
      "[073/00301] train_loss: 0.018124\n",
      "[073/00351] train_loss: 0.017538\n",
      "[073/00401] train_loss: 0.017968\n",
      "[073/00451] train_loss: 0.017410\n",
      "[073/00501] train_loss: 0.017480\n",
      "[073/00551] train_loss: 0.017569\n",
      "[073/00601] train_loss: 0.017083\n",
      "[073/00651] train_loss: 0.017147\n",
      "[073/00701] train_loss: 0.017442\n",
      "[073/00751] train_loss: 0.017250\n",
      "[073/00801] train_loss: 0.017859\n",
      "[073/00851] train_loss: 0.017187\n",
      "[073/00901] train_loss: 0.017359\n",
      "[073/00951] train_loss: 0.017613\n",
      "[073/01001] train_loss: 0.018345\n",
      "[073/01051] train_loss: 0.017557\n",
      "[073/01101] train_loss: 0.017358\n",
      "[073/01151] train_loss: 0.017096\n",
      "[073/01201] train_loss: 0.017917\n",
      "[074/00025] train_loss: 0.024125\n",
      "[074/00075] train_loss: 0.023988\n",
      "[074/00125] train_loss: 0.021415\n",
      "[074/00175] train_loss: 0.018388\n",
      "[074/00225] train_loss: 0.018741\n",
      "[074/00275] train_loss: 0.017485\n",
      "[074/00325] train_loss: 0.017781\n",
      "[074/00375] train_loss: 0.017843\n",
      "[074/00425] train_loss: 0.018241\n",
      "[074/00475] train_loss: 0.017299\n",
      "[074/00525] train_loss: 0.016336\n",
      "[074/00575] train_loss: 0.017156\n",
      "[074/00625] train_loss: 0.017630\n",
      "[074/00675] train_loss: 0.017578\n",
      "[074/00725] train_loss: 0.016816\n",
      "[074/00775] train_loss: 0.017295\n",
      "[074/00825] train_loss: 0.018609\n",
      "[074/00875] train_loss: 0.018284\n",
      "[074/00925] train_loss: 0.017620\n",
      "[074/00975] train_loss: 0.017730\n",
      "[074/01025] train_loss: 0.017347\n",
      "[074/01075] train_loss: 0.017978\n",
      "[074/01125] train_loss: 0.017280\n",
      "[074/01175] train_loss: 0.017226\n",
      "[074/01225] train_loss: 0.018309\n",
      "[075/00049] train_loss: 0.027610\n",
      "[075/00099] train_loss: 0.021865\n",
      "[075/00149] train_loss: 0.019388\n",
      "[075/00199] train_loss: 0.018812\n",
      "[075/00249] train_loss: 0.017786\n",
      "[075/00299] train_loss: 0.017346\n",
      "[075/00349] train_loss: 0.017802\n",
      "[075/00399] train_loss: 0.018128\n",
      "[075/00449] train_loss: 0.017198\n",
      "[075/00499] train_loss: 0.017067\n",
      "[075/00549] train_loss: 0.017804\n",
      "[075/00599] train_loss: 0.017348\n",
      "[075/00649] train_loss: 0.016187\n",
      "[075/00699] train_loss: 0.017843\n",
      "[075/00749] train_loss: 0.016766\n",
      "[075/00799] train_loss: 0.017195\n",
      "[075/00849] train_loss: 0.016683\n",
      "[075/00899] train_loss: 0.017716\n",
      "[075/00949] train_loss: 0.016598\n",
      "[075/00999] train_loss: 0.017432\n",
      "[075/01049] train_loss: 0.017685\n",
      "[075/01099] train_loss: 0.017591\n",
      "[075/01149] train_loss: 0.017757\n",
      "[075/01199] train_loss: 0.017677\n",
      "[076/00023] train_loss: 0.023913\n",
      "[076/00073] train_loss: 0.024281\n",
      "[076/00123] train_loss: 0.020306\n",
      "[076/00173] train_loss: 0.018502\n",
      "[076/00223] train_loss: 0.018140\n",
      "[076/00273] train_loss: 0.018001\n",
      "[076/00323] train_loss: 0.017661\n",
      "[076/00373] train_loss: 0.017488\n",
      "[076/00423] train_loss: 0.017627\n",
      "[076/00473] train_loss: 0.017438\n",
      "[076/00523] train_loss: 0.016134\n",
      "[076/00573] train_loss: 0.018548\n",
      "[076/00623] train_loss: 0.016536\n",
      "[076/00673] train_loss: 0.018185\n",
      "[076/00723] train_loss: 0.016454\n",
      "[076/00773] train_loss: 0.017474\n",
      "[076/00823] train_loss: 0.018006\n",
      "[076/00873] train_loss: 0.018017\n",
      "[076/00923] train_loss: 0.016771\n",
      "[076/00973] train_loss: 0.018691\n",
      "[076/01023] train_loss: 0.017931\n",
      "[076/01073] train_loss: 0.017097\n",
      "[076/01123] train_loss: 0.017715\n",
      "[076/01173] train_loss: 0.016737\n",
      "[076/01223] train_loss: 0.017658\n",
      "[077/00047] train_loss: 0.028329\n",
      "[077/00097] train_loss: 0.020382\n",
      "[077/00147] train_loss: 0.019407\n",
      "[077/00197] train_loss: 0.019092\n",
      "[077/00247] train_loss: 0.018145\n",
      "[077/00297] train_loss: 0.018066\n",
      "[077/00347] train_loss: 0.017276\n",
      "[077/00397] train_loss: 0.018174\n",
      "[077/00447] train_loss: 0.017112\n",
      "[077/00497] train_loss: 0.016632\n",
      "[077/00547] train_loss: 0.018230\n",
      "[077/00597] train_loss: 0.017675\n",
      "[077/00647] train_loss: 0.017519\n",
      "[077/00697] train_loss: 0.017361\n",
      "[077/00747] train_loss: 0.016847\n",
      "[077/00797] train_loss: 0.017184\n",
      "[077/00847] train_loss: 0.017586\n",
      "[077/00897] train_loss: 0.017394\n",
      "[077/00947] train_loss: 0.018992\n",
      "[077/00997] train_loss: 0.017200\n",
      "[077/01047] train_loss: 0.017345\n",
      "[077/01097] train_loss: 0.017109\n",
      "[077/01147] train_loss: 0.016594\n",
      "[077/01197] train_loss: 0.018220\n",
      "[078/00021] train_loss: 0.020091\n",
      "[078/00071] train_loss: 0.023837\n",
      "[078/00121] train_loss: 0.021118\n",
      "[078/00171] train_loss: 0.018474\n",
      "[078/00221] train_loss: 0.018383\n",
      "[078/00271] train_loss: 0.018371\n",
      "[078/00321] train_loss: 0.017876\n",
      "[078/00371] train_loss: 0.017669\n",
      "[078/00421] train_loss: 0.016978\n",
      "[078/00471] train_loss: 0.017247\n",
      "[078/00521] train_loss: 0.017530\n",
      "[078/00571] train_loss: 0.017927\n",
      "[078/00621] train_loss: 0.016896\n",
      "[078/00671] train_loss: 0.017684\n",
      "[078/00721] train_loss: 0.015623\n",
      "[078/00771] train_loss: 0.017943\n",
      "[078/00821] train_loss: 0.018367\n",
      "[078/00871] train_loss: 0.017299\n",
      "[078/00921] train_loss: 0.017932\n",
      "[078/00971] train_loss: 0.017905\n",
      "[078/01021] train_loss: 0.018269\n",
      "[078/01071] train_loss: 0.018304\n",
      "[078/01121] train_loss: 0.017839\n",
      "[078/01171] train_loss: 0.016711\n",
      "[078/01221] train_loss: 0.017553\n",
      "[079/00045] train_loss: 0.027001\n",
      "[079/00095] train_loss: 0.022585\n",
      "[079/00145] train_loss: 0.019421\n",
      "[079/00195] train_loss: 0.018165\n",
      "[079/00245] train_loss: 0.018669\n",
      "[079/00295] train_loss: 0.018024\n",
      "[079/00345] train_loss: 0.016834\n",
      "[079/00395] train_loss: 0.017369\n",
      "[079/00445] train_loss: 0.017280\n",
      "[079/00495] train_loss: 0.017861\n",
      "[079/00545] train_loss: 0.017492\n",
      "[079/00595] train_loss: 0.017295\n",
      "[079/00645] train_loss: 0.017164\n",
      "[079/00695] train_loss: 0.016375\n",
      "[079/00745] train_loss: 0.018249\n",
      "[079/00795] train_loss: 0.017321\n",
      "[079/00845] train_loss: 0.017410\n",
      "[079/00895] train_loss: 0.017605\n",
      "[079/00945] train_loss: 0.018859\n",
      "[079/00995] train_loss: 0.017612\n",
      "[079/01045] train_loss: 0.017448\n",
      "[079/01095] train_loss: 0.016850\n",
      "[079/01145] train_loss: 0.018388\n",
      "[079/01195] train_loss: 0.016829\n",
      "[080/00019] train_loss: 0.022052\n",
      "[080/00069] train_loss: 0.024144\n",
      "[080/00119] train_loss: 0.021393\n",
      "[080/00169] train_loss: 0.018326\n",
      "[080/00219] train_loss: 0.018586\n",
      "[080/00269] train_loss: 0.018923\n",
      "[080/00319] train_loss: 0.017063\n",
      "[080/00369] train_loss: 0.017002\n",
      "[080/00419] train_loss: 0.017768\n",
      "[080/00469] train_loss: 0.016869\n",
      "[080/00519] train_loss: 0.017106\n",
      "[080/00569] train_loss: 0.017382\n",
      "[080/00619] train_loss: 0.017447\n",
      "[080/00669] train_loss: 0.018323\n",
      "[080/00719] train_loss: 0.017139\n",
      "[080/00769] train_loss: 0.016190\n",
      "[080/00819] train_loss: 0.017808\n",
      "[080/00869] train_loss: 0.018339\n",
      "[080/00919] train_loss: 0.017469\n",
      "[080/00969] train_loss: 0.016711\n",
      "[080/01019] train_loss: 0.016835\n",
      "[080/01069] train_loss: 0.017129\n",
      "[080/01119] train_loss: 0.017867\n",
      "[080/01169] train_loss: 0.017310\n",
      "[080/01219] train_loss: 0.017156\n",
      "[081/00043] train_loss: 0.025430\n",
      "[081/00093] train_loss: 0.022544\n",
      "[081/00143] train_loss: 0.018241\n",
      "[081/00193] train_loss: 0.018263\n",
      "[081/00243] train_loss: 0.017848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[081/00293] train_loss: 0.017301\n",
      "[081/00343] train_loss: 0.017322\n",
      "[081/00393] train_loss: 0.016941\n",
      "[081/00443] train_loss: 0.016687\n",
      "[081/00493] train_loss: 0.017665\n",
      "[081/00543] train_loss: 0.017882\n",
      "[081/00593] train_loss: 0.017536\n",
      "[081/00643] train_loss: 0.016869\n",
      "[081/00693] train_loss: 0.016390\n",
      "[081/00743] train_loss: 0.017063\n",
      "[081/00793] train_loss: 0.017148\n",
      "[081/00843] train_loss: 0.017032\n",
      "[081/00893] train_loss: 0.018227\n",
      "[081/00943] train_loss: 0.018258\n",
      "[081/00993] train_loss: 0.017378\n",
      "[081/01043] train_loss: 0.017224\n",
      "[081/01093] train_loss: 0.017885\n",
      "[081/01143] train_loss: 0.017026\n",
      "[081/01193] train_loss: 0.017602\n",
      "[082/00017] train_loss: 0.021973\n",
      "[082/00067] train_loss: 0.025722\n",
      "[082/00117] train_loss: 0.020955\n",
      "[082/00167] train_loss: 0.018763\n",
      "[082/00217] train_loss: 0.017478\n",
      "[082/00267] train_loss: 0.017388\n",
      "[082/00317] train_loss: 0.018227\n",
      "[082/00367] train_loss: 0.017463\n",
      "[082/00417] train_loss: 0.017195\n",
      "[082/00467] train_loss: 0.016585\n",
      "[082/00517] train_loss: 0.016817\n",
      "[082/00567] train_loss: 0.016776\n",
      "[082/00617] train_loss: 0.016713\n",
      "[082/00667] train_loss: 0.017239\n",
      "[082/00717] train_loss: 0.017286\n",
      "[082/00767] train_loss: 0.017169\n",
      "[082/00817] train_loss: 0.017508\n",
      "[082/00867] train_loss: 0.017314\n",
      "[082/00917] train_loss: 0.017769\n",
      "[082/00967] train_loss: 0.016740\n",
      "[082/01017] train_loss: 0.017003\n",
      "[082/01067] train_loss: 0.016687\n",
      "[082/01117] train_loss: 0.017037\n",
      "[082/01167] train_loss: 0.018334\n",
      "[082/01217] train_loss: 0.018413\n",
      "[083/00041] train_loss: 0.027315\n",
      "[083/00091] train_loss: 0.022660\n",
      "[083/00141] train_loss: 0.019157\n",
      "[083/00191] train_loss: 0.017789\n",
      "[083/00241] train_loss: 0.018466\n",
      "[083/00291] train_loss: 0.016812\n",
      "[083/00341] train_loss: 0.017538\n",
      "[083/00391] train_loss: 0.016724\n",
      "[083/00441] train_loss: 0.016911\n",
      "[083/00491] train_loss: 0.017659\n",
      "[083/00541] train_loss: 0.016973\n",
      "[083/00591] train_loss: 0.017400\n",
      "[083/00641] train_loss: 0.017161\n",
      "[083/00691] train_loss: 0.017255\n",
      "[083/00741] train_loss: 0.017228\n",
      "[083/00791] train_loss: 0.016606\n",
      "[083/00841] train_loss: 0.017292\n",
      "[083/00891] train_loss: 0.018002\n",
      "[083/00941] train_loss: 0.017610\n",
      "[083/00991] train_loss: 0.017160\n",
      "[083/01041] train_loss: 0.017499\n",
      "[083/01091] train_loss: 0.018205\n",
      "[083/01141] train_loss: 0.016944\n",
      "[083/01191] train_loss: 0.017925\n",
      "[084/00015] train_loss: 0.021364\n",
      "[084/00065] train_loss: 0.025485\n",
      "[084/00115] train_loss: 0.021116\n",
      "[084/00165] train_loss: 0.018472\n",
      "[084/00215] train_loss: 0.017525\n",
      "[084/00265] train_loss: 0.018067\n",
      "[084/00315] train_loss: 0.018113\n",
      "[084/00365] train_loss: 0.017280\n",
      "[084/00415] train_loss: 0.018409\n",
      "[084/00465] train_loss: 0.017519\n",
      "[084/00515] train_loss: 0.017596\n",
      "[084/00565] train_loss: 0.016490\n",
      "[084/00615] train_loss: 0.017618\n",
      "[084/00665] train_loss: 0.017386\n",
      "[084/00715] train_loss: 0.016144\n",
      "[084/00765] train_loss: 0.017349\n",
      "[084/00815] train_loss: 0.017562\n",
      "[084/00865] train_loss: 0.017816\n",
      "[084/00915] train_loss: 0.017634\n",
      "[084/00965] train_loss: 0.017698\n",
      "[084/01015] train_loss: 0.017654\n",
      "[084/01065] train_loss: 0.016939\n",
      "[084/01115] train_loss: 0.017394\n",
      "[084/01165] train_loss: 0.017378\n",
      "[084/01215] train_loss: 0.017007\n",
      "[085/00039] train_loss: 0.024527\n",
      "[085/00089] train_loss: 0.021707\n",
      "[085/00139] train_loss: 0.018886\n",
      "[085/00189] train_loss: 0.018629\n",
      "[085/00239] train_loss: 0.017559\n",
      "[085/00289] train_loss: 0.017208\n",
      "[085/00339] train_loss: 0.016951\n",
      "[085/00389] train_loss: 0.018637\n",
      "[085/00439] train_loss: 0.017904\n",
      "[085/00489] train_loss: 0.017252\n",
      "[085/00539] train_loss: 0.017772\n",
      "[085/00589] train_loss: 0.018144\n",
      "[085/00639] train_loss: 0.017137\n",
      "[085/00689] train_loss: 0.017959\n",
      "[085/00739] train_loss: 0.016512\n",
      "[085/00789] train_loss: 0.015962\n",
      "[085/00839] train_loss: 0.017723\n",
      "[085/00889] train_loss: 0.017463\n",
      "[085/00939] train_loss: 0.017620\n",
      "[085/00989] train_loss: 0.017552\n",
      "[085/01039] train_loss: 0.017731\n",
      "[085/01089] train_loss: 0.016903\n",
      "[085/01139] train_loss: 0.017051\n",
      "[085/01189] train_loss: 0.017511\n",
      "[086/00013] train_loss: 0.020532\n",
      "[086/00063] train_loss: 0.025250\n",
      "[086/00113] train_loss: 0.021055\n",
      "[086/00163] train_loss: 0.018715\n",
      "[086/00213] train_loss: 0.017718\n",
      "[086/00263] train_loss: 0.016876\n",
      "[086/00313] train_loss: 0.018375\n",
      "[086/00363] train_loss: 0.016969\n",
      "[086/00413] train_loss: 0.017563\n",
      "[086/00463] train_loss: 0.017167\n",
      "[086/00513] train_loss: 0.017419\n",
      "[086/00563] train_loss: 0.017857\n",
      "[086/00613] train_loss: 0.016456\n",
      "[086/00663] train_loss: 0.016759\n",
      "[086/00713] train_loss: 0.017223\n",
      "[086/00763] train_loss: 0.016837\n",
      "[086/00813] train_loss: 0.016789\n",
      "[086/00863] train_loss: 0.017571\n",
      "[086/00913] train_loss: 0.016951\n",
      "[086/00963] train_loss: 0.018980\n",
      "[086/01013] train_loss: 0.017078\n",
      "[086/01063] train_loss: 0.017503\n",
      "[086/01113] train_loss: 0.017286\n",
      "[086/01163] train_loss: 0.017352\n",
      "[086/01213] train_loss: 0.017925\n",
      "[087/00037] train_loss: 0.026428\n",
      "[087/00087] train_loss: 0.021925\n",
      "[087/00137] train_loss: 0.019088\n",
      "[087/00187] train_loss: 0.017516\n",
      "[087/00237] train_loss: 0.017957\n",
      "[087/00287] train_loss: 0.017986\n",
      "[087/00337] train_loss: 0.017957\n",
      "[087/00387] train_loss: 0.017936\n",
      "[087/00437] train_loss: 0.016545\n",
      "[087/00487] train_loss: 0.016589\n",
      "[087/00537] train_loss: 0.017515\n",
      "[087/00587] train_loss: 0.017578\n",
      "[087/00637] train_loss: 0.017350\n",
      "[087/00687] train_loss: 0.018224\n",
      "[087/00737] train_loss: 0.016267\n",
      "[087/00787] train_loss: 0.016145\n",
      "[087/00837] train_loss: 0.017418\n",
      "[087/00887] train_loss: 0.017302\n",
      "[087/00937] train_loss: 0.017216\n",
      "[087/00987] train_loss: 0.018102\n",
      "[087/01037] train_loss: 0.017412\n",
      "[087/01087] train_loss: 0.018501\n",
      "[087/01137] train_loss: 0.016776\n",
      "[087/01187] train_loss: 0.017745\n",
      "[088/00011] train_loss: 0.021167\n",
      "[088/00061] train_loss: 0.024475\n",
      "[088/00111] train_loss: 0.021149\n",
      "[088/00161] train_loss: 0.017571\n",
      "[088/00211] train_loss: 0.018330\n",
      "[088/00261] train_loss: 0.017468\n",
      "[088/00311] train_loss: 0.016381\n",
      "[088/00361] train_loss: 0.017306\n",
      "[088/00411] train_loss: 0.017326\n",
      "[088/00461] train_loss: 0.016978\n",
      "[088/00511] train_loss: 0.016496\n",
      "[088/00561] train_loss: 0.016331\n",
      "[088/00611] train_loss: 0.017557\n",
      "[088/00661] train_loss: 0.016827\n",
      "[088/00711] train_loss: 0.016527\n",
      "[088/00761] train_loss: 0.016245\n",
      "[088/00811] train_loss: 0.017237\n",
      "[088/00861] train_loss: 0.016035\n",
      "[088/00911] train_loss: 0.017213\n",
      "[088/00961] train_loss: 0.019315\n",
      "[088/01011] train_loss: 0.017901\n",
      "[088/01061] train_loss: 0.018524\n",
      "[088/01111] train_loss: 0.017493\n",
      "[088/01161] train_loss: 0.018155\n",
      "[088/01211] train_loss: 0.017230\n",
      "[089/00035] train_loss: 0.024815\n",
      "[089/00085] train_loss: 0.023202\n",
      "[089/00135] train_loss: 0.020447\n",
      "[089/00185] train_loss: 0.018064\n",
      "[089/00235] train_loss: 0.018394\n",
      "[089/00285] train_loss: 0.017745\n",
      "[089/00335] train_loss: 0.017910\n",
      "[089/00385] train_loss: 0.017987\n",
      "[089/00435] train_loss: 0.016170\n",
      "[089/00485] train_loss: 0.016809\n",
      "[089/00535] train_loss: 0.017527\n",
      "[089/00585] train_loss: 0.016868\n",
      "[089/00635] train_loss: 0.016365\n",
      "[089/00685] train_loss: 0.017814\n",
      "[089/00735] train_loss: 0.017911\n",
      "[089/00785] train_loss: 0.017414\n",
      "[089/00835] train_loss: 0.017417\n",
      "[089/00885] train_loss: 0.017176\n",
      "[089/00935] train_loss: 0.016768\n",
      "[089/00985] train_loss: 0.017735\n",
      "[089/01035] train_loss: 0.017858\n",
      "[089/01085] train_loss: 0.016658\n",
      "[089/01135] train_loss: 0.017383\n",
      "[089/01185] train_loss: 0.018367\n",
      "[090/00009] train_loss: 0.020130\n",
      "[090/00059] train_loss: 0.025562\n",
      "[090/00109] train_loss: 0.019897\n",
      "[090/00159] train_loss: 0.018673\n",
      "[090/00209] train_loss: 0.017631\n",
      "[090/00259] train_loss: 0.018151\n",
      "[090/00309] train_loss: 0.017404\n",
      "[090/00359] train_loss: 0.017503\n",
      "[090/00409] train_loss: 0.017583\n",
      "[090/00459] train_loss: 0.017670\n",
      "[090/00509] train_loss: 0.017133\n",
      "[090/00559] train_loss: 0.016421\n",
      "[090/00609] train_loss: 0.017081\n",
      "[090/00659] train_loss: 0.017906\n",
      "[090/00709] train_loss: 0.018010\n",
      "[090/00759] train_loss: 0.016809\n",
      "[090/00809] train_loss: 0.017347\n",
      "[090/00859] train_loss: 0.017042\n",
      "[090/00909] train_loss: 0.018441\n",
      "[090/00959] train_loss: 0.016976\n",
      "[090/01009] train_loss: 0.016785\n",
      "[090/01059] train_loss: 0.017416\n",
      "[090/01109] train_loss: 0.016965\n",
      "[090/01159] train_loss: 0.017493\n",
      "[090/01209] train_loss: 0.017105\n",
      "[091/00033] train_loss: 0.024574\n",
      "[091/00083] train_loss: 0.022593\n",
      "[091/00133] train_loss: 0.018792\n",
      "[091/00183] train_loss: 0.018549\n",
      "[091/00233] train_loss: 0.017086\n",
      "[091/00283] train_loss: 0.017460\n",
      "[091/00333] train_loss: 0.017673\n",
      "[091/00383] train_loss: 0.016646\n",
      "[091/00433] train_loss: 0.016200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[091/00483] train_loss: 0.017319\n",
      "[091/00533] train_loss: 0.017462\n",
      "[091/00583] train_loss: 0.017583\n",
      "[091/00633] train_loss: 0.017027\n",
      "[091/00683] train_loss: 0.016824\n",
      "[091/00733] train_loss: 0.017533\n",
      "[091/00783] train_loss: 0.018262\n",
      "[091/00833] train_loss: 0.015371\n",
      "[091/00883] train_loss: 0.016499\n",
      "[091/00933] train_loss: 0.017617\n",
      "[091/00983] train_loss: 0.017221\n",
      "[091/01033] train_loss: 0.017160\n",
      "[091/01083] train_loss: 0.017120\n",
      "[091/01133] train_loss: 0.017575\n",
      "[091/01183] train_loss: 0.017174\n",
      "[092/00007] train_loss: 0.019217\n",
      "[092/00057] train_loss: 0.023588\n",
      "[092/00107] train_loss: 0.020134\n",
      "[092/00157] train_loss: 0.018391\n",
      "[092/00207] train_loss: 0.017850\n",
      "[092/00257] train_loss: 0.018163\n",
      "[092/00307] train_loss: 0.018416\n",
      "[092/00357] train_loss: 0.016826\n",
      "[092/00407] train_loss: 0.017211\n",
      "[092/00457] train_loss: 0.016378\n",
      "[092/00507] train_loss: 0.017884\n",
      "[092/00557] train_loss: 0.017420\n",
      "[092/00607] train_loss: 0.016737\n",
      "[092/00657] train_loss: 0.017099\n",
      "[092/00707] train_loss: 0.017469\n",
      "[092/00757] train_loss: 0.017022\n",
      "[092/00807] train_loss: 0.017405\n",
      "[092/00857] train_loss: 0.017272\n",
      "[092/00907] train_loss: 0.016382\n",
      "[092/00957] train_loss: 0.017003\n",
      "[092/01007] train_loss: 0.017902\n",
      "[092/01057] train_loss: 0.016954\n",
      "[092/01107] train_loss: 0.017080\n",
      "[092/01157] train_loss: 0.017008\n",
      "[092/01207] train_loss: 0.018108\n",
      "[093/00031] train_loss: 0.023376\n",
      "[093/00081] train_loss: 0.024459\n",
      "[093/00131] train_loss: 0.020848\n",
      "[093/00181] train_loss: 0.018844\n",
      "[093/00231] train_loss: 0.017572\n",
      "[093/00281] train_loss: 0.017956\n",
      "[093/00331] train_loss: 0.017218\n",
      "[093/00381] train_loss: 0.017598\n",
      "[093/00431] train_loss: 0.017554\n",
      "[093/00481] train_loss: 0.017346\n",
      "[093/00531] train_loss: 0.017299\n",
      "[093/00581] train_loss: 0.016783\n",
      "[093/00631] train_loss: 0.016946\n",
      "[093/00681] train_loss: 0.017230\n",
      "[093/00731] train_loss: 0.016235\n",
      "[093/00781] train_loss: 0.017467\n",
      "[093/00831] train_loss: 0.017128\n",
      "[093/00881] train_loss: 0.017089\n",
      "[093/00931] train_loss: 0.017788\n",
      "[093/00981] train_loss: 0.017079\n",
      "[093/01031] train_loss: 0.017268\n",
      "[093/01081] train_loss: 0.017639\n",
      "[093/01131] train_loss: 0.017129\n",
      "[093/01181] train_loss: 0.017174\n",
      "[094/00005] train_loss: 0.019681\n",
      "[094/00055] train_loss: 0.025139\n",
      "[094/00105] train_loss: 0.021352\n",
      "[094/00155] train_loss: 0.018365\n",
      "[094/00205] train_loss: 0.017777\n",
      "[094/00255] train_loss: 0.018137\n",
      "[094/00305] train_loss: 0.016882\n",
      "[094/00355] train_loss: 0.016417\n",
      "[094/00405] train_loss: 0.017606\n",
      "[094/00455] train_loss: 0.016435\n",
      "[094/00505] train_loss: 0.015981\n",
      "[094/00555] train_loss: 0.016843\n",
      "[094/00605] train_loss: 0.017964\n",
      "[094/00655] train_loss: 0.018058\n",
      "[094/00705] train_loss: 0.017604\n",
      "[094/00755] train_loss: 0.016136\n",
      "[094/00805] train_loss: 0.017358\n",
      "[094/00855] train_loss: 0.016697\n",
      "[094/00905] train_loss: 0.017664\n",
      "[094/00955] train_loss: 0.016774\n",
      "[094/01005] train_loss: 0.017268\n",
      "[094/01055] train_loss: 0.018336\n",
      "[094/01105] train_loss: 0.017449\n",
      "[094/01155] train_loss: 0.017207\n",
      "[094/01205] train_loss: 0.016936\n",
      "[095/00029] train_loss: 0.022576\n",
      "[095/00079] train_loss: 0.023789\n",
      "[095/00129] train_loss: 0.019944\n",
      "[095/00179] train_loss: 0.017571\n",
      "[095/00229] train_loss: 0.017962\n",
      "[095/00279] train_loss: 0.017268\n",
      "[095/00329] train_loss: 0.018072\n",
      "[095/00379] train_loss: 0.017430\n",
      "[095/00429] train_loss: 0.017558\n",
      "[095/00479] train_loss: 0.017265\n",
      "[095/00529] train_loss: 0.018578\n",
      "[095/00579] train_loss: 0.017032\n",
      "[095/00629] train_loss: 0.017164\n",
      "[095/00679] train_loss: 0.016218\n",
      "[095/00729] train_loss: 0.016799\n",
      "[095/00779] train_loss: 0.017057\n",
      "[095/00829] train_loss: 0.017881\n",
      "[095/00879] train_loss: 0.017186\n",
      "[095/00929] train_loss: 0.016774\n",
      "[095/00979] train_loss: 0.017962\n",
      "[095/01029] train_loss: 0.016721\n",
      "[095/01079] train_loss: 0.017046\n",
      "[095/01129] train_loss: 0.017789\n",
      "[095/01179] train_loss: 0.017920\n",
      "[096/00003] train_loss: 0.017697\n",
      "[096/00053] train_loss: 0.026723\n",
      "[096/00103] train_loss: 0.021404\n",
      "[096/00153] train_loss: 0.018570\n",
      "[096/00203] train_loss: 0.018354\n",
      "[096/00253] train_loss: 0.018092\n",
      "[096/00303] train_loss: 0.016909\n",
      "[096/00353] train_loss: 0.017984\n",
      "[096/00403] train_loss: 0.016931\n",
      "[096/00453] train_loss: 0.017034\n",
      "[096/00503] train_loss: 0.016928\n",
      "[096/00553] train_loss: 0.018020\n",
      "[096/00603] train_loss: 0.017657\n",
      "[096/00653] train_loss: 0.016569\n",
      "[096/00703] train_loss: 0.017384\n",
      "[096/00753] train_loss: 0.016769\n",
      "[096/00803] train_loss: 0.017188\n",
      "[096/00853] train_loss: 0.016984\n",
      "[096/00903] train_loss: 0.017454\n",
      "[096/00953] train_loss: 0.016998\n",
      "[096/01003] train_loss: 0.016605\n",
      "[096/01053] train_loss: 0.017689\n",
      "[096/01103] train_loss: 0.018084\n",
      "[096/01153] train_loss: 0.017015\n",
      "[096/01203] train_loss: 0.016764\n",
      "[097/00027] train_loss: 0.022945\n",
      "[097/00077] train_loss: 0.022652\n",
      "[097/00127] train_loss: 0.020044\n",
      "[097/00177] train_loss: 0.017512\n",
      "[097/00227] train_loss: 0.017452\n",
      "[097/00277] train_loss: 0.017578\n",
      "[097/00327] train_loss: 0.016803\n",
      "[097/00377] train_loss: 0.016380\n",
      "[097/00427] train_loss: 0.017698\n",
      "[097/00477] train_loss: 0.017447\n",
      "[097/00527] train_loss: 0.017762\n",
      "[097/00577] train_loss: 0.016988\n",
      "[097/00627] train_loss: 0.016176\n",
      "[097/00677] train_loss: 0.016965\n",
      "[097/00727] train_loss: 0.017254\n",
      "[097/00777] train_loss: 0.017228\n",
      "[097/00827] train_loss: 0.017323\n",
      "[097/00877] train_loss: 0.017602\n",
      "[097/00927] train_loss: 0.017539\n",
      "[097/00977] train_loss: 0.017535\n",
      "[097/01027] train_loss: 0.017516\n",
      "[097/01077] train_loss: 0.017110\n",
      "[097/01127] train_loss: 0.017706\n",
      "[097/01177] train_loss: 0.017043\n",
      "[098/00001] train_loss: 0.018068\n",
      "[098/00051] train_loss: 0.026000\n",
      "[098/00101] train_loss: 0.021082\n",
      "[098/00151] train_loss: 0.019096\n",
      "[098/00201] train_loss: 0.018264\n",
      "[098/00251] train_loss: 0.018096\n",
      "[098/00301] train_loss: 0.017151\n",
      "[098/00351] train_loss: 0.016923\n",
      "[098/00401] train_loss: 0.016618\n",
      "[098/00451] train_loss: 0.018373\n",
      "[098/00501] train_loss: 0.016261\n",
      "[098/00551] train_loss: 0.017044\n",
      "[098/00601] train_loss: 0.016861\n",
      "[098/00651] train_loss: 0.016139\n",
      "[098/00701] train_loss: 0.017316\n",
      "[098/00751] train_loss: 0.017422\n",
      "[098/00801] train_loss: 0.018211\n",
      "[098/00851] train_loss: 0.017608\n",
      "[098/00901] train_loss: 0.016961\n",
      "[098/00951] train_loss: 0.017159\n",
      "[098/01001] train_loss: 0.016765\n",
      "[098/01051] train_loss: 0.017378\n",
      "[098/01101] train_loss: 0.016465\n",
      "[098/01151] train_loss: 0.017526\n",
      "[098/01201] train_loss: 0.016883\n",
      "[099/00025] train_loss: 0.023106\n",
      "[099/00075] train_loss: 0.022883\n",
      "[099/00125] train_loss: 0.018694\n",
      "[099/00175] train_loss: 0.018410\n",
      "[099/00225] train_loss: 0.018047\n",
      "[099/00275] train_loss: 0.017207\n",
      "[099/00325] train_loss: 0.018045\n",
      "[099/00375] train_loss: 0.018537\n",
      "[099/00425] train_loss: 0.016868\n",
      "[099/00475] train_loss: 0.017045\n",
      "[099/00525] train_loss: 0.017865\n",
      "[099/00575] train_loss: 0.017942\n",
      "[099/00625] train_loss: 0.016948\n",
      "[099/00675] train_loss: 0.016820\n",
      "[099/00725] train_loss: 0.017702\n",
      "[099/00775] train_loss: 0.016950\n",
      "[099/00825] train_loss: 0.017184\n",
      "[099/00875] train_loss: 0.016872\n",
      "[099/00925] train_loss: 0.017205\n",
      "[099/00975] train_loss: 0.017859\n",
      "[099/01025] train_loss: 0.017110\n",
      "[099/01075] train_loss: 0.016798\n",
      "[099/01125] train_loss: 0.016979\n",
      "[099/01175] train_loss: 0.017314\n",
      "[099/01225] train_loss: 0.017825\n",
      "[100/00049] train_loss: 0.027271\n",
      "[100/00099] train_loss: 0.021224\n",
      "[100/00149] train_loss: 0.018178\n",
      "[100/00199] train_loss: 0.018256\n",
      "[100/00249] train_loss: 0.017848\n",
      "[100/00299] train_loss: 0.017160\n",
      "[100/00349] train_loss: 0.016725\n",
      "[100/00399] train_loss: 0.017282\n",
      "[100/00449] train_loss: 0.017171\n",
      "[100/00499] train_loss: 0.016375\n",
      "[100/00549] train_loss: 0.016525\n",
      "[100/00599] train_loss: 0.017472\n",
      "[100/00649] train_loss: 0.017548\n",
      "[100/00699] train_loss: 0.016721\n",
      "[100/00749] train_loss: 0.016691\n",
      "[100/00799] train_loss: 0.017593\n",
      "[100/00849] train_loss: 0.018084\n",
      "[100/00899] train_loss: 0.017173\n",
      "[100/00949] train_loss: 0.016894\n",
      "[100/00999] train_loss: 0.018087\n",
      "[100/01049] train_loss: 0.017331\n",
      "[100/01099] train_loss: 0.017377\n",
      "[100/01149] train_loss: 0.017766\n",
      "[100/01199] train_loss: 0.016896\n",
      "[101/00023] train_loss: 0.021636\n",
      "[101/00073] train_loss: 0.022759\n",
      "[101/00123] train_loss: 0.019605\n",
      "[101/00173] train_loss: 0.018806\n",
      "[101/00223] train_loss: 0.017423\n",
      "[101/00273] train_loss: 0.017415\n",
      "[101/00323] train_loss: 0.017661\n",
      "[101/00373] train_loss: 0.017228\n",
      "[101/00423] train_loss: 0.017213\n",
      "[101/00473] train_loss: 0.017148\n",
      "[101/00523] train_loss: 0.016834\n",
      "[101/00573] train_loss: 0.016790\n",
      "[101/00623] train_loss: 0.016914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/00673] train_loss: 0.017284\n",
      "[101/00723] train_loss: 0.017432\n",
      "[101/00773] train_loss: 0.017128\n",
      "[101/00823] train_loss: 0.016680\n",
      "[101/00873] train_loss: 0.016976\n",
      "[101/00923] train_loss: 0.016713\n",
      "[101/00973] train_loss: 0.016534\n",
      "[101/01023] train_loss: 0.018225\n",
      "[101/01073] train_loss: 0.018270\n",
      "[101/01123] train_loss: 0.017761\n",
      "[101/01173] train_loss: 0.017653\n",
      "[101/01223] train_loss: 0.017398\n",
      "[102/00047] train_loss: 0.025764\n",
      "[102/00097] train_loss: 0.022481\n",
      "[102/00147] train_loss: 0.020690\n",
      "[102/00197] train_loss: 0.017403\n",
      "[102/00247] train_loss: 0.017113\n",
      "[102/00297] train_loss: 0.017771\n",
      "[102/00347] train_loss: 0.017408\n",
      "[102/00397] train_loss: 0.017261\n",
      "[102/00447] train_loss: 0.016570\n",
      "[102/00497] train_loss: 0.017736\n",
      "[102/00547] train_loss: 0.018402\n",
      "[102/00597] train_loss: 0.016990\n",
      "[102/00647] train_loss: 0.016614\n",
      "[102/00697] train_loss: 0.017519\n",
      "[102/00747] train_loss: 0.016976\n",
      "[102/00797] train_loss: 0.017039\n",
      "[102/00847] train_loss: 0.017749\n",
      "[102/00897] train_loss: 0.016626\n",
      "[102/00947] train_loss: 0.017543\n",
      "[102/00997] train_loss: 0.017820\n",
      "[102/01047] train_loss: 0.016918\n",
      "[102/01097] train_loss: 0.017243\n",
      "[102/01147] train_loss: 0.016862\n",
      "[102/01197] train_loss: 0.016812\n",
      "[103/00021] train_loss: 0.022320\n",
      "[103/00071] train_loss: 0.022223\n",
      "[103/00121] train_loss: 0.019873\n",
      "[103/00171] train_loss: 0.017712\n",
      "[103/00221] train_loss: 0.017285\n",
      "[103/00271] train_loss: 0.017535\n",
      "[103/00321] train_loss: 0.016264\n",
      "[103/00371] train_loss: 0.016695\n",
      "[103/00421] train_loss: 0.017123\n",
      "[103/00471] train_loss: 0.017434\n",
      "[103/00521] train_loss: 0.016975\n",
      "[103/00571] train_loss: 0.016643\n",
      "[103/00621] train_loss: 0.016951\n",
      "[103/00671] train_loss: 0.017024\n",
      "[103/00721] train_loss: 0.017580\n",
      "[103/00771] train_loss: 0.017810\n",
      "[103/00821] train_loss: 0.016985\n",
      "[103/00871] train_loss: 0.017271\n",
      "[103/00921] train_loss: 0.016538\n",
      "[103/00971] train_loss: 0.016219\n",
      "[103/01021] train_loss: 0.016947\n",
      "[103/01071] train_loss: 0.017309\n",
      "[103/01121] train_loss: 0.016590\n",
      "[103/01171] train_loss: 0.018292\n",
      "[103/01221] train_loss: 0.016724\n",
      "[104/00045] train_loss: 0.025932\n",
      "[104/00095] train_loss: 0.021716\n",
      "[104/00145] train_loss: 0.019263\n",
      "[104/00195] train_loss: 0.017002\n",
      "[104/00245] train_loss: 0.015874\n",
      "[104/00295] train_loss: 0.017329\n",
      "[104/00345] train_loss: 0.017773\n",
      "[104/00395] train_loss: 0.016957\n",
      "[104/00445] train_loss: 0.016937\n",
      "[104/00495] train_loss: 0.017236\n",
      "[104/00545] train_loss: 0.017144\n",
      "[104/00595] train_loss: 0.017316\n",
      "[104/00645] train_loss: 0.016979\n",
      "[104/00695] train_loss: 0.017033\n",
      "[104/00745] train_loss: 0.017333\n",
      "[104/00795] train_loss: 0.017325\n",
      "[104/00845] train_loss: 0.017037\n",
      "[104/00895] train_loss: 0.016865\n",
      "[104/00945] train_loss: 0.017744\n",
      "[104/00995] train_loss: 0.017484\n",
      "[104/01045] train_loss: 0.016809\n",
      "[104/01095] train_loss: 0.016491\n",
      "[104/01145] train_loss: 0.018213\n",
      "[104/01195] train_loss: 0.016928\n",
      "[105/00019] train_loss: 0.021252\n",
      "[105/00069] train_loss: 0.024519\n",
      "[105/00119] train_loss: 0.021001\n",
      "[105/00169] train_loss: 0.018320\n",
      "[105/00219] train_loss: 0.017850\n",
      "[105/00269] train_loss: 0.018024\n",
      "[105/00319] train_loss: 0.017963\n",
      "[105/00369] train_loss: 0.017058\n",
      "[105/00419] train_loss: 0.017206\n",
      "[105/00469] train_loss: 0.016561\n",
      "[105/00519] train_loss: 0.016333\n",
      "[105/00569] train_loss: 0.017135\n",
      "[105/00619] train_loss: 0.016669\n",
      "[105/00669] train_loss: 0.016930\n",
      "[105/00719] train_loss: 0.016331\n",
      "[105/00769] train_loss: 0.017411\n",
      "[105/00819] train_loss: 0.016474\n",
      "[105/00869] train_loss: 0.017697\n",
      "[105/00919] train_loss: 0.017042\n",
      "[105/00969] train_loss: 0.016001\n",
      "[105/01019] train_loss: 0.017553\n",
      "[105/01069] train_loss: 0.017897\n",
      "[105/01119] train_loss: 0.018385\n",
      "[105/01169] train_loss: 0.016946\n",
      "[105/01219] train_loss: 0.018404\n",
      "[106/00043] train_loss: 0.025921\n",
      "[106/00093] train_loss: 0.021878\n",
      "[106/00143] train_loss: 0.019557\n",
      "[106/00193] train_loss: 0.017029\n",
      "[106/00243] train_loss: 0.017312\n",
      "[106/00293] train_loss: 0.017895\n",
      "[106/00343] train_loss: 0.017851\n",
      "[106/00393] train_loss: 0.017959\n",
      "[106/00443] train_loss: 0.016703\n",
      "[106/00493] train_loss: 0.017023\n",
      "[106/00543] train_loss: 0.016342\n",
      "[106/00593] train_loss: 0.016295\n",
      "[106/00643] train_loss: 0.017430\n",
      "[106/00693] train_loss: 0.017201\n",
      "[106/00743] train_loss: 0.017380\n",
      "[106/00793] train_loss: 0.017231\n",
      "[106/00843] train_loss: 0.017224\n",
      "[106/00893] train_loss: 0.016575\n",
      "[106/00943] train_loss: 0.017406\n",
      "[106/00993] train_loss: 0.017474\n",
      "[106/01043] train_loss: 0.017430\n",
      "[106/01093] train_loss: 0.017153\n",
      "[106/01143] train_loss: 0.017201\n",
      "[106/01193] train_loss: 0.017487\n",
      "[107/00017] train_loss: 0.022252\n",
      "[107/00067] train_loss: 0.022967\n",
      "[107/00117] train_loss: 0.019260\n",
      "[107/00167] train_loss: 0.018733\n",
      "[107/00217] train_loss: 0.018536\n",
      "[107/00267] train_loss: 0.017123\n",
      "[107/00317] train_loss: 0.016843\n",
      "[107/00367] train_loss: 0.016864\n",
      "[107/00417] train_loss: 0.016921\n",
      "[107/00467] train_loss: 0.016735\n",
      "[107/00517] train_loss: 0.015599\n",
      "[107/00567] train_loss: 0.017383\n",
      "[107/00617] train_loss: 0.016643\n",
      "[107/00667] train_loss: 0.017224\n",
      "[107/00717] train_loss: 0.017501\n",
      "[107/00767] train_loss: 0.017245\n",
      "[107/00817] train_loss: 0.017014\n",
      "[107/00867] train_loss: 0.016119\n",
      "[107/00917] train_loss: 0.016623\n",
      "[107/00967] train_loss: 0.017212\n",
      "[107/01017] train_loss: 0.018348\n",
      "[107/01067] train_loss: 0.017366\n",
      "[107/01117] train_loss: 0.017156\n",
      "[107/01167] train_loss: 0.017335\n",
      "[107/01217] train_loss: 0.017636\n",
      "[108/00041] train_loss: 0.025449\n",
      "[108/00091] train_loss: 0.021843\n",
      "[108/00141] train_loss: 0.019421\n",
      "[108/00191] train_loss: 0.017465\n",
      "[108/00241] train_loss: 0.017044\n",
      "[108/00291] train_loss: 0.018120\n",
      "[108/00341] train_loss: 0.017185\n",
      "[108/00391] train_loss: 0.016962\n",
      "[108/00441] train_loss: 0.016889\n",
      "[108/00491] train_loss: 0.017166\n",
      "[108/00541] train_loss: 0.017258\n",
      "[108/00591] train_loss: 0.017276\n",
      "[108/00641] train_loss: 0.016674\n",
      "[108/00691] train_loss: 0.017259\n",
      "[108/00741] train_loss: 0.017160\n",
      "[108/00791] train_loss: 0.017336\n",
      "[108/00841] train_loss: 0.017121\n",
      "[108/00891] train_loss: 0.016599\n",
      "[108/00941] train_loss: 0.017084\n",
      "[108/00991] train_loss: 0.016753\n",
      "[108/01041] train_loss: 0.017478\n",
      "[108/01091] train_loss: 0.017788\n",
      "[108/01141] train_loss: 0.017682\n",
      "[108/01191] train_loss: 0.017711\n",
      "[109/00015] train_loss: 0.020762\n",
      "[109/00065] train_loss: 0.024208\n",
      "[109/00115] train_loss: 0.019868\n",
      "[109/00165] train_loss: 0.017768\n",
      "[109/00215] train_loss: 0.017796\n",
      "[109/00265] train_loss: 0.017669\n",
      "[109/00315] train_loss: 0.017397\n",
      "[109/00365] train_loss: 0.017268\n",
      "[109/00415] train_loss: 0.017130\n",
      "[109/00465] train_loss: 0.017341\n",
      "[109/00515] train_loss: 0.018034\n",
      "[109/00565] train_loss: 0.016427\n",
      "[109/00615] train_loss: 0.017024\n",
      "[109/00665] train_loss: 0.017155\n",
      "[109/00715] train_loss: 0.017391\n",
      "[109/00765] train_loss: 0.016330\n",
      "[109/00815] train_loss: 0.016522\n",
      "[109/00865] train_loss: 0.016813\n",
      "[109/00915] train_loss: 0.017100\n",
      "[109/00965] train_loss: 0.017532\n",
      "[109/01015] train_loss: 0.017219\n",
      "[109/01065] train_loss: 0.016508\n",
      "[109/01115] train_loss: 0.017011\n",
      "[109/01165] train_loss: 0.018006\n",
      "[109/01215] train_loss: 0.017226\n",
      "[110/00039] train_loss: 0.024798\n",
      "[110/00089] train_loss: 0.021115\n",
      "[110/00139] train_loss: 0.019368\n",
      "[110/00189] train_loss: 0.017688\n",
      "[110/00239] train_loss: 0.017780\n",
      "[110/00289] train_loss: 0.017267\n",
      "[110/00339] train_loss: 0.017546\n",
      "[110/00389] train_loss: 0.017307\n",
      "[110/00439] train_loss: 0.016619\n",
      "[110/00489] train_loss: 0.017333\n",
      "[110/00539] train_loss: 0.016670\n",
      "[110/00589] train_loss: 0.017291\n",
      "[110/00639] train_loss: 0.016420\n",
      "[110/00689] train_loss: 0.017101\n",
      "[110/00739] train_loss: 0.017130\n",
      "[110/00789] train_loss: 0.017366\n",
      "[110/00839] train_loss: 0.017519\n",
      "[110/00889] train_loss: 0.016138\n",
      "[110/00939] train_loss: 0.018086\n",
      "[110/00989] train_loss: 0.017971\n",
      "[110/01039] train_loss: 0.017125\n",
      "[110/01089] train_loss: 0.016461\n",
      "[110/01139] train_loss: 0.016657\n",
      "[110/01189] train_loss: 0.017312\n",
      "[111/00013] train_loss: 0.020940\n",
      "[111/00063] train_loss: 0.023616\n",
      "[111/00113] train_loss: 0.019923\n",
      "[111/00163] train_loss: 0.018564\n",
      "[111/00213] train_loss: 0.017304\n",
      "[111/00263] train_loss: 0.017349\n",
      "[111/00313] train_loss: 0.016365\n",
      "[111/00363] train_loss: 0.017055\n",
      "[111/00413] train_loss: 0.017066\n",
      "[111/00463] train_loss: 0.016723\n",
      "[111/00513] train_loss: 0.016610\n",
      "[111/00563] train_loss: 0.017221\n",
      "[111/00613] train_loss: 0.017468\n",
      "[111/00663] train_loss: 0.016558\n",
      "[111/00713] train_loss: 0.017397\n",
      "[111/00763] train_loss: 0.016280\n",
      "[111/00813] train_loss: 0.016594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/00863] train_loss: 0.016997\n",
      "[111/00913] train_loss: 0.016948\n",
      "[111/00963] train_loss: 0.017841\n",
      "[111/01013] train_loss: 0.017285\n",
      "[111/01063] train_loss: 0.017227\n",
      "[111/01113] train_loss: 0.016719\n",
      "[111/01163] train_loss: 0.017599\n",
      "[111/01213] train_loss: 0.017239\n",
      "[112/00037] train_loss: 0.024687\n",
      "[112/00087] train_loss: 0.023130\n",
      "[112/00137] train_loss: 0.019149\n",
      "[112/00187] train_loss: 0.017091\n",
      "[112/00237] train_loss: 0.017392\n",
      "[112/00287] train_loss: 0.018196\n",
      "[112/00337] train_loss: 0.016989\n",
      "[112/00387] train_loss: 0.016740\n",
      "[112/00437] train_loss: 0.016989\n",
      "[112/00487] train_loss: 0.017305\n",
      "[112/00537] train_loss: 0.017489\n",
      "[112/00587] train_loss: 0.018218\n",
      "[112/00637] train_loss: 0.016499\n",
      "[112/00687] train_loss: 0.016493\n",
      "[112/00737] train_loss: 0.016981\n",
      "[112/00787] train_loss: 0.016196\n",
      "[112/00837] train_loss: 0.017229\n",
      "[112/00887] train_loss: 0.016723\n",
      "[112/00937] train_loss: 0.016002\n",
      "[112/00987] train_loss: 0.017483\n",
      "[112/01037] train_loss: 0.016988\n",
      "[112/01087] train_loss: 0.017323\n",
      "[112/01137] train_loss: 0.018288\n",
      "[112/01187] train_loss: 0.017801\n",
      "[113/00011] train_loss: 0.020528\n",
      "[113/00061] train_loss: 0.024119\n",
      "[113/00111] train_loss: 0.019782\n",
      "[113/00161] train_loss: 0.018613\n",
      "[113/00211] train_loss: 0.016966\n",
      "[113/00261] train_loss: 0.017969\n",
      "[113/00311] train_loss: 0.017121\n",
      "[113/00361] train_loss: 0.017079\n",
      "[113/00411] train_loss: 0.016867\n",
      "[113/00461] train_loss: 0.016717\n",
      "[113/00511] train_loss: 0.017581\n",
      "[113/00561] train_loss: 0.016448\n",
      "[113/00611] train_loss: 0.015984\n",
      "[113/00661] train_loss: 0.016899\n",
      "[113/00711] train_loss: 0.017540\n",
      "[113/00761] train_loss: 0.016029\n",
      "[113/00811] train_loss: 0.017345\n",
      "[113/00861] train_loss: 0.016765\n",
      "[113/00911] train_loss: 0.017162\n",
      "[113/00961] train_loss: 0.017329\n",
      "[113/01011] train_loss: 0.017404\n",
      "[113/01061] train_loss: 0.017638\n",
      "[113/01111] train_loss: 0.017122\n",
      "[113/01161] train_loss: 0.016813\n",
      "[113/01211] train_loss: 0.017959\n",
      "[114/00035] train_loss: 0.025105\n",
      "[114/00085] train_loss: 0.023277\n",
      "[114/00135] train_loss: 0.019575\n",
      "[114/00185] train_loss: 0.017238\n",
      "[114/00235] train_loss: 0.016881\n",
      "[114/00285] train_loss: 0.017330\n",
      "[114/00335] train_loss: 0.017372\n",
      "[114/00385] train_loss: 0.016873\n",
      "[114/00435] train_loss: 0.017739\n",
      "[114/00485] train_loss: 0.016520\n",
      "[114/00535] train_loss: 0.016068\n",
      "[114/00585] train_loss: 0.017524\n",
      "[114/00635] train_loss: 0.015800\n",
      "[114/00685] train_loss: 0.016621\n",
      "[114/00735] train_loss: 0.017225\n",
      "[114/00785] train_loss: 0.017830\n",
      "[114/00835] train_loss: 0.016720\n",
      "[114/00885] train_loss: 0.016598\n",
      "[114/00935] train_loss: 0.017060\n",
      "[114/00985] train_loss: 0.016299\n",
      "[114/01035] train_loss: 0.016797\n",
      "[114/01085] train_loss: 0.016021\n",
      "[114/01135] train_loss: 0.016519\n",
      "[114/01185] train_loss: 0.017736\n",
      "[115/00009] train_loss: 0.019325\n",
      "[115/00059] train_loss: 0.023639\n",
      "[115/00109] train_loss: 0.021009\n",
      "[115/00159] train_loss: 0.017694\n",
      "[115/00209] train_loss: 0.018645\n",
      "[115/00259] train_loss: 0.017412\n",
      "[115/00309] train_loss: 0.017480\n",
      "[115/00359] train_loss: 0.016926\n",
      "[115/00409] train_loss: 0.015827\n",
      "[115/00459] train_loss: 0.017702\n",
      "[115/00509] train_loss: 0.017331\n",
      "[115/00559] train_loss: 0.016238\n",
      "[115/00609] train_loss: 0.016705\n",
      "[115/00659] train_loss: 0.016934\n",
      "[115/00709] train_loss: 0.016931\n",
      "[115/00759] train_loss: 0.017267\n",
      "[115/00809] train_loss: 0.016429\n",
      "[115/00859] train_loss: 0.016955\n",
      "[115/00909] train_loss: 0.017074\n",
      "[115/00959] train_loss: 0.017011\n",
      "[115/01009] train_loss: 0.016426\n",
      "[115/01059] train_loss: 0.016983\n",
      "[115/01109] train_loss: 0.016324\n",
      "[115/01159] train_loss: 0.016991\n",
      "[115/01209] train_loss: 0.018291\n",
      "[116/00033] train_loss: 0.024074\n",
      "[116/00083] train_loss: 0.022178\n",
      "[116/00133] train_loss: 0.019104\n",
      "[116/00183] train_loss: 0.017652\n",
      "[116/00233] train_loss: 0.017077\n",
      "[116/00283] train_loss: 0.017272\n",
      "[116/00333] train_loss: 0.016939\n",
      "[116/00383] train_loss: 0.017288\n",
      "[116/00433] train_loss: 0.017764\n",
      "[116/00483] train_loss: 0.017086\n",
      "[116/00533] train_loss: 0.016533\n",
      "[116/00583] train_loss: 0.016176\n",
      "[116/00633] train_loss: 0.016288\n",
      "[116/00683] train_loss: 0.016800\n",
      "[116/00733] train_loss: 0.017671\n",
      "[116/00783] train_loss: 0.017441\n",
      "[116/00833] train_loss: 0.017320\n",
      "[116/00883] train_loss: 0.017228\n",
      "[116/00933] train_loss: 0.016796\n",
      "[116/00983] train_loss: 0.016743\n",
      "[116/01033] train_loss: 0.017017\n",
      "[116/01083] train_loss: 0.016780\n",
      "[116/01133] train_loss: 0.017560\n",
      "[116/01183] train_loss: 0.016855\n",
      "[117/00007] train_loss: 0.018935\n",
      "[117/00057] train_loss: 0.024799\n",
      "[117/00107] train_loss: 0.020372\n",
      "[117/00157] train_loss: 0.018210\n",
      "[117/00207] train_loss: 0.017390\n",
      "[117/00257] train_loss: 0.017209\n",
      "[117/00307] train_loss: 0.017645\n",
      "[117/00357] train_loss: 0.017563\n",
      "[117/00407] train_loss: 0.017495\n",
      "[117/00457] train_loss: 0.017078\n",
      "[117/00507] train_loss: 0.017087\n",
      "[117/00557] train_loss: 0.017155\n",
      "[117/00607] train_loss: 0.016191\n",
      "[117/00657] train_loss: 0.017674\n",
      "[117/00707] train_loss: 0.016852\n",
      "[117/00757] train_loss: 0.017833\n",
      "[117/00807] train_loss: 0.017001\n",
      "[117/00857] train_loss: 0.016555\n",
      "[117/00907] train_loss: 0.017510\n",
      "[117/00957] train_loss: 0.016332\n",
      "[117/01007] train_loss: 0.017600\n",
      "[117/01057] train_loss: 0.016880\n",
      "[117/01107] train_loss: 0.017580\n",
      "[117/01157] train_loss: 0.016899\n",
      "[117/01207] train_loss: 0.016875\n",
      "[118/00031] train_loss: 0.023308\n",
      "[118/00081] train_loss: 0.023360\n",
      "[118/00131] train_loss: 0.019940\n",
      "[118/00181] train_loss: 0.018150\n",
      "[118/00231] train_loss: 0.017712\n",
      "[118/00281] train_loss: 0.017758\n",
      "[118/00331] train_loss: 0.017128\n",
      "[118/00381] train_loss: 0.017196\n",
      "[118/00431] train_loss: 0.017476\n",
      "[118/00481] train_loss: 0.017409\n",
      "[118/00531] train_loss: 0.016089\n",
      "[118/00581] train_loss: 0.015911\n",
      "[118/00631] train_loss: 0.016675\n",
      "[118/00681] train_loss: 0.016912\n",
      "[118/00731] train_loss: 0.016855\n",
      "[118/00781] train_loss: 0.017192\n",
      "[118/00831] train_loss: 0.017943\n",
      "[118/00881] train_loss: 0.016969\n",
      "[118/00931] train_loss: 0.017096\n",
      "[118/00981] train_loss: 0.017828\n",
      "[118/01031] train_loss: 0.017116\n",
      "[118/01081] train_loss: 0.016882\n",
      "[118/01131] train_loss: 0.016627\n",
      "[118/01181] train_loss: 0.017181\n",
      "[119/00005] train_loss: 0.018719\n",
      "[119/00055] train_loss: 0.025324\n",
      "[119/00105] train_loss: 0.020704\n",
      "[119/00155] train_loss: 0.018279\n",
      "[119/00205] train_loss: 0.018228\n",
      "[119/00255] train_loss: 0.017714\n",
      "[119/00305] train_loss: 0.016785\n",
      "[119/00355] train_loss: 0.017167\n",
      "[119/00405] train_loss: 0.017280\n",
      "[119/00455] train_loss: 0.017880\n",
      "[119/00505] train_loss: 0.017194\n",
      "[119/00555] train_loss: 0.015822\n",
      "[119/00605] train_loss: 0.016947\n",
      "[119/00655] train_loss: 0.017102\n",
      "[119/00705] train_loss: 0.017945\n",
      "[119/00755] train_loss: 0.017260\n",
      "[119/00805] train_loss: 0.018111\n",
      "[119/00855] train_loss: 0.016160\n",
      "[119/00905] train_loss: 0.015866\n",
      "[119/00955] train_loss: 0.016864\n",
      "[119/01005] train_loss: 0.017356\n",
      "[119/01055] train_loss: 0.016947\n",
      "[119/01105] train_loss: 0.017347\n",
      "[119/01155] train_loss: 0.017089\n",
      "[119/01205] train_loss: 0.016717\n",
      "[120/00029] train_loss: 0.022015\n",
      "[120/00079] train_loss: 0.021510\n",
      "[120/00129] train_loss: 0.020216\n",
      "[120/00179] train_loss: 0.017452\n",
      "[120/00229] train_loss: 0.017013\n",
      "[120/00279] train_loss: 0.017538\n",
      "[120/00329] train_loss: 0.017800\n",
      "[120/00379] train_loss: 0.016238\n",
      "[120/00429] train_loss: 0.016363\n",
      "[120/00479] train_loss: 0.016769\n",
      "[120/00529] train_loss: 0.016332\n",
      "[120/00579] train_loss: 0.016909\n",
      "[120/00629] train_loss: 0.017000\n",
      "[120/00679] train_loss: 0.017746\n",
      "[120/00729] train_loss: 0.016698\n",
      "[120/00779] train_loss: 0.015954\n",
      "[120/00829] train_loss: 0.017641\n",
      "[120/00879] train_loss: 0.017134\n",
      "[120/00929] train_loss: 0.017339\n",
      "[120/00979] train_loss: 0.016264\n",
      "[120/01029] train_loss: 0.017117\n",
      "[120/01079] train_loss: 0.017112\n",
      "[120/01129] train_loss: 0.016692\n",
      "[120/01179] train_loss: 0.016974\n",
      "[121/00003] train_loss: 0.017565\n",
      "[121/00053] train_loss: 0.024286\n",
      "[121/00103] train_loss: 0.020626\n",
      "[121/00153] train_loss: 0.017450\n",
      "[121/00203] train_loss: 0.017984\n",
      "[121/00253] train_loss: 0.017789\n",
      "[121/00303] train_loss: 0.016761\n",
      "[121/00353] train_loss: 0.017340\n",
      "[121/00403] train_loss: 0.016854\n",
      "[121/00453] train_loss: 0.017119\n",
      "[121/00503] train_loss: 0.016561\n",
      "[121/00553] train_loss: 0.016675\n",
      "[121/00603] train_loss: 0.016738\n",
      "[121/00653] train_loss: 0.017518\n",
      "[121/00703] train_loss: 0.016684\n",
      "[121/00753] train_loss: 0.015844\n",
      "[121/00803] train_loss: 0.017453\n",
      "[121/00853] train_loss: 0.016617\n",
      "[121/00903] train_loss: 0.016881\n",
      "[121/00953] train_loss: 0.017306\n",
      "[121/01003] train_loss: 0.015530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/01053] train_loss: 0.017183\n",
      "[121/01103] train_loss: 0.016732\n",
      "[121/01153] train_loss: 0.017292\n",
      "[121/01203] train_loss: 0.017909\n",
      "[122/00027] train_loss: 0.024068\n",
      "[122/00077] train_loss: 0.022981\n",
      "[122/00127] train_loss: 0.019646\n",
      "[122/00177] train_loss: 0.017472\n",
      "[122/00227] train_loss: 0.018248\n",
      "[122/00277] train_loss: 0.017295\n",
      "[122/00327] train_loss: 0.017173\n",
      "[122/00377] train_loss: 0.017585\n",
      "[122/00427] train_loss: 0.016123\n",
      "[122/00477] train_loss: 0.017820\n",
      "[122/00527] train_loss: 0.016234\n",
      "[122/00577] train_loss: 0.017249\n",
      "[122/00627] train_loss: 0.017088\n",
      "[122/00677] train_loss: 0.017148\n",
      "[122/00727] train_loss: 0.016537\n",
      "[122/00777] train_loss: 0.016266\n",
      "[122/00827] train_loss: 0.017486\n",
      "[122/00877] train_loss: 0.015975\n",
      "[122/00927] train_loss: 0.016326\n",
      "[122/00977] train_loss: 0.017726\n",
      "[122/01027] train_loss: 0.017366\n",
      "[122/01077] train_loss: 0.017541\n",
      "[122/01127] train_loss: 0.016614\n",
      "[122/01177] train_loss: 0.016312\n",
      "[123/00001] train_loss: 0.017853\n",
      "[123/00051] train_loss: 0.025370\n",
      "[123/00101] train_loss: 0.020174\n",
      "[123/00151] train_loss: 0.017694\n",
      "[123/00201] train_loss: 0.018238\n",
      "[123/00251] train_loss: 0.016815\n",
      "[123/00301] train_loss: 0.016877\n",
      "[123/00351] train_loss: 0.016575\n",
      "[123/00401] train_loss: 0.017187\n",
      "[123/00451] train_loss: 0.016929\n",
      "[123/00501] train_loss: 0.016088\n",
      "[123/00551] train_loss: 0.017151\n",
      "[123/00601] train_loss: 0.016940\n",
      "[123/00651] train_loss: 0.017155\n",
      "[123/00701] train_loss: 0.017339\n",
      "[123/00751] train_loss: 0.016518\n",
      "[123/00801] train_loss: 0.016416\n",
      "[123/00851] train_loss: 0.017727\n",
      "[123/00901] train_loss: 0.016708\n",
      "[123/00951] train_loss: 0.017005\n",
      "[123/01001] train_loss: 0.016755\n",
      "[123/01051] train_loss: 0.016866\n",
      "[123/01101] train_loss: 0.017639\n",
      "[123/01151] train_loss: 0.017991\n",
      "[123/01201] train_loss: 0.018461\n",
      "[124/00025] train_loss: 0.023782\n",
      "[124/00075] train_loss: 0.023322\n",
      "[124/00125] train_loss: 0.019878\n",
      "[124/00175] train_loss: 0.017926\n",
      "[124/00225] train_loss: 0.018173\n",
      "[124/00275] train_loss: 0.017902\n",
      "[124/00325] train_loss: 0.018050\n",
      "[124/00375] train_loss: 0.016280\n",
      "[124/00425] train_loss: 0.016335\n",
      "[124/00475] train_loss: 0.016125\n",
      "[124/00525] train_loss: 0.016098\n",
      "[124/00575] train_loss: 0.015775\n",
      "[124/00625] train_loss: 0.017690\n",
      "[124/00675] train_loss: 0.017272\n",
      "[124/00725] train_loss: 0.016398\n",
      "[124/00775] train_loss: 0.016957\n",
      "[124/00825] train_loss: 0.016239\n",
      "[124/00875] train_loss: 0.016580\n",
      "[124/00925] train_loss: 0.016550\n",
      "[124/00975] train_loss: 0.017579\n",
      "[124/01025] train_loss: 0.017207\n",
      "[124/01075] train_loss: 0.016809\n",
      "[124/01125] train_loss: 0.017232\n",
      "[124/01175] train_loss: 0.016588\n",
      "[124/01225] train_loss: 0.016873\n",
      "[125/00049] train_loss: 0.026069\n",
      "[125/00099] train_loss: 0.020940\n",
      "[125/00149] train_loss: 0.017914\n",
      "[125/00199] train_loss: 0.017816\n",
      "[125/00249] train_loss: 0.017842\n",
      "[125/00299] train_loss: 0.016907\n",
      "[125/00349] train_loss: 0.017061\n",
      "[125/00399] train_loss: 0.017443\n",
      "[125/00449] train_loss: 0.017414\n",
      "[125/00499] train_loss: 0.016799\n",
      "[125/00549] train_loss: 0.017298\n",
      "[125/00599] train_loss: 0.017320\n",
      "[125/00649] train_loss: 0.017484\n",
      "[125/00699] train_loss: 0.017048\n",
      "[125/00749] train_loss: 0.016776\n",
      "[125/00799] train_loss: 0.017197\n",
      "[125/00849] train_loss: 0.017889\n",
      "[125/00899] train_loss: 0.016654\n",
      "[125/00949] train_loss: 0.017843\n",
      "[125/00999] train_loss: 0.016856\n",
      "[125/01049] train_loss: 0.016618\n",
      "[125/01099] train_loss: 0.017170\n",
      "[125/01149] train_loss: 0.017613\n",
      "[125/01199] train_loss: 0.017226\n",
      "[126/00023] train_loss: 0.021224\n",
      "[126/00073] train_loss: 0.023650\n",
      "[126/00123] train_loss: 0.018795\n",
      "[126/00173] train_loss: 0.018039\n",
      "[126/00223] train_loss: 0.017468\n",
      "[126/00273] train_loss: 0.017001\n",
      "[126/00323] train_loss: 0.016878\n",
      "[126/00373] train_loss: 0.016892\n",
      "[126/00423] train_loss: 0.017494\n",
      "[126/00473] train_loss: 0.016093\n",
      "[126/00523] train_loss: 0.017042\n",
      "[126/00573] train_loss: 0.016387\n",
      "[126/00623] train_loss: 0.016699\n",
      "[126/00673] train_loss: 0.017162\n",
      "[126/00723] train_loss: 0.016361\n",
      "[126/00773] train_loss: 0.016073\n",
      "[126/00823] train_loss: 0.017260\n",
      "[126/00873] train_loss: 0.017011\n",
      "[126/00923] train_loss: 0.016577\n",
      "[126/00973] train_loss: 0.017696\n",
      "[126/01023] train_loss: 0.016862\n",
      "[126/01073] train_loss: 0.016698\n",
      "[126/01123] train_loss: 0.016981\n",
      "[126/01173] train_loss: 0.017412\n",
      "[126/01223] train_loss: 0.016772\n",
      "[127/00047] train_loss: 0.025108\n",
      "[127/00097] train_loss: 0.020383\n",
      "[127/00147] train_loss: 0.018204\n",
      "[127/00197] train_loss: 0.018037\n",
      "[127/00247] train_loss: 0.017193\n",
      "[127/00297] train_loss: 0.016292\n",
      "[127/00347] train_loss: 0.015952\n",
      "[127/00397] train_loss: 0.017357\n",
      "[127/00447] train_loss: 0.016952\n",
      "[127/00497] train_loss: 0.016710\n",
      "[127/00547] train_loss: 0.017001\n",
      "[127/00597] train_loss: 0.016699\n",
      "[127/00647] train_loss: 0.016956\n",
      "[127/00697] train_loss: 0.016574\n",
      "[127/00747] train_loss: 0.017377\n",
      "[127/00797] train_loss: 0.017294\n",
      "[127/00847] train_loss: 0.016399\n",
      "[127/00897] train_loss: 0.017477\n",
      "[127/00947] train_loss: 0.017748\n",
      "[127/00997] train_loss: 0.017220\n",
      "[127/01047] train_loss: 0.017773\n",
      "[127/01097] train_loss: 0.016652\n",
      "[127/01147] train_loss: 0.016976\n",
      "[127/01197] train_loss: 0.017569\n",
      "[128/00021] train_loss: 0.021765\n",
      "[128/00071] train_loss: 0.023432\n",
      "[128/00121] train_loss: 0.019223\n",
      "[128/00171] train_loss: 0.017049\n",
      "[128/00221] train_loss: 0.016848\n",
      "[128/00271] train_loss: 0.016566\n",
      "[128/00321] train_loss: 0.016647\n",
      "[128/00371] train_loss: 0.016449\n",
      "[128/00421] train_loss: 0.017339\n",
      "[128/00471] train_loss: 0.016911\n",
      "[128/00521] train_loss: 0.017184\n",
      "[128/00571] train_loss: 0.016944\n",
      "[128/00621] train_loss: 0.017479\n",
      "[128/00671] train_loss: 0.017621\n",
      "[128/00721] train_loss: 0.016626\n",
      "[128/00771] train_loss: 0.016947\n",
      "[128/00821] train_loss: 0.016056\n",
      "[128/00871] train_loss: 0.017899\n",
      "[128/00921] train_loss: 0.016745\n",
      "[128/00971] train_loss: 0.017915\n",
      "[128/01021] train_loss: 0.017212\n",
      "[128/01071] train_loss: 0.016629\n",
      "[128/01121] train_loss: 0.015660\n",
      "[128/01171] train_loss: 0.016957\n",
      "[128/01221] train_loss: 0.016863\n",
      "[129/00045] train_loss: 0.025379\n",
      "[129/00095] train_loss: 0.022301\n",
      "[129/00145] train_loss: 0.018249\n",
      "[129/00195] train_loss: 0.017243\n",
      "[129/00245] train_loss: 0.017550\n",
      "[129/00295] train_loss: 0.017532\n",
      "[129/00345] train_loss: 0.017041\n",
      "[129/00395] train_loss: 0.016857\n",
      "[129/00445] train_loss: 0.016934\n",
      "[129/00495] train_loss: 0.016102\n",
      "[129/00545] train_loss: 0.017401\n",
      "[129/00595] train_loss: 0.016347\n",
      "[129/00645] train_loss: 0.017049\n",
      "[129/00695] train_loss: 0.016527\n",
      "[129/00745] train_loss: 0.016787\n",
      "[129/00795] train_loss: 0.016900\n",
      "[129/00845] train_loss: 0.017510\n",
      "[129/00895] train_loss: 0.017287\n",
      "[129/00945] train_loss: 0.016910\n",
      "[129/00995] train_loss: 0.017322\n",
      "[129/01045] train_loss: 0.016896\n",
      "[129/01095] train_loss: 0.017281\n",
      "[129/01145] train_loss: 0.017650\n",
      "[129/01195] train_loss: 0.015940\n",
      "[130/00019] train_loss: 0.020749\n",
      "[130/00069] train_loss: 0.023079\n",
      "[130/00119] train_loss: 0.019049\n",
      "[130/00169] train_loss: 0.017561\n",
      "[130/00219] train_loss: 0.017123\n",
      "[130/00269] train_loss: 0.016945\n",
      "[130/00319] train_loss: 0.016648\n",
      "[130/00369] train_loss: 0.017180\n",
      "[130/00419] train_loss: 0.016377\n",
      "[130/00469] train_loss: 0.016976\n",
      "[130/00519] train_loss: 0.016796\n",
      "[130/00569] train_loss: 0.016095\n",
      "[130/00619] train_loss: 0.017350\n",
      "[130/00669] train_loss: 0.017555\n",
      "[130/00719] train_loss: 0.017344\n",
      "[130/00769] train_loss: 0.016534\n",
      "[130/00819] train_loss: 0.016546\n",
      "[130/00869] train_loss: 0.016006\n",
      "[130/00919] train_loss: 0.017090\n",
      "[130/00969] train_loss: 0.017327\n",
      "[130/01019] train_loss: 0.015913\n",
      "[130/01069] train_loss: 0.017195\n",
      "[130/01119] train_loss: 0.017421\n",
      "[130/01169] train_loss: 0.017466\n",
      "[130/01219] train_loss: 0.017332\n",
      "[131/00043] train_loss: 0.023744\n",
      "[131/00093] train_loss: 0.021292\n",
      "[131/00143] train_loss: 0.019044\n",
      "[131/00193] train_loss: 0.017602\n",
      "[131/00243] train_loss: 0.016798\n",
      "[131/00293] train_loss: 0.016844\n",
      "[131/00343] train_loss: 0.016214\n",
      "[131/00393] train_loss: 0.016849\n",
      "[131/00443] train_loss: 0.016397\n",
      "[131/00493] train_loss: 0.017299\n",
      "[131/00543] train_loss: 0.016395\n",
      "[131/00593] train_loss: 0.016748\n",
      "[131/00643] train_loss: 0.016672\n",
      "[131/00693] train_loss: 0.016530\n",
      "[131/00743] train_loss: 0.016626\n",
      "[131/00793] train_loss: 0.016838\n",
      "[131/00843] train_loss: 0.017665\n",
      "[131/00893] train_loss: 0.016655\n",
      "[131/00943] train_loss: 0.017043\n",
      "[131/00993] train_loss: 0.016406\n",
      "[131/01043] train_loss: 0.016929\n",
      "[131/01093] train_loss: 0.017617\n",
      "[131/01143] train_loss: 0.016784\n",
      "[131/01193] train_loss: 0.017664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132/00017] train_loss: 0.021551\n",
      "[132/00067] train_loss: 0.023471\n",
      "[132/00117] train_loss: 0.019981\n",
      "[132/00167] train_loss: 0.019026\n",
      "[132/00217] train_loss: 0.017468\n",
      "[132/00267] train_loss: 0.017509\n",
      "[132/00317] train_loss: 0.017643\n",
      "[132/00367] train_loss: 0.017575\n",
      "[132/00417] train_loss: 0.016014\n",
      "[132/00467] train_loss: 0.017253\n",
      "[132/00517] train_loss: 0.016721\n",
      "[132/00567] train_loss: 0.016686\n",
      "[132/00617] train_loss: 0.016820\n",
      "[132/00667] train_loss: 0.016691\n",
      "[132/00717] train_loss: 0.016952\n",
      "[132/00767] train_loss: 0.015955\n",
      "[132/00817] train_loss: 0.017028\n",
      "[132/00867] train_loss: 0.016771\n",
      "[132/00917] train_loss: 0.017169\n",
      "[132/00967] train_loss: 0.017977\n",
      "[132/01017] train_loss: 0.016635\n",
      "[132/01067] train_loss: 0.015888\n",
      "[132/01117] train_loss: 0.017325\n",
      "[132/01167] train_loss: 0.016336\n",
      "[132/01217] train_loss: 0.017507\n",
      "[133/00041] train_loss: 0.024357\n",
      "[133/00091] train_loss: 0.021301\n",
      "[133/00141] train_loss: 0.018140\n",
      "[133/00191] train_loss: 0.017894\n",
      "[133/00241] train_loss: 0.018216\n",
      "[133/00291] train_loss: 0.016803\n",
      "[133/00341] train_loss: 0.016652\n",
      "[133/00391] train_loss: 0.017033\n",
      "[133/00441] train_loss: 0.016381\n",
      "[133/00491] train_loss: 0.016829\n",
      "[133/00541] train_loss: 0.016562\n",
      "[133/00591] train_loss: 0.016967\n",
      "[133/00641] train_loss: 0.015967\n",
      "[133/00691] train_loss: 0.016147\n",
      "[133/00741] train_loss: 0.017258\n",
      "[133/00791] train_loss: 0.017477\n",
      "[133/00841] train_loss: 0.016230\n",
      "[133/00891] train_loss: 0.016507\n",
      "[133/00941] train_loss: 0.017449\n",
      "[133/00991] train_loss: 0.017458\n",
      "[133/01041] train_loss: 0.017510\n",
      "[133/01091] train_loss: 0.016921\n",
      "[133/01141] train_loss: 0.017793\n",
      "[133/01191] train_loss: 0.016908\n",
      "[134/00015] train_loss: 0.021301\n",
      "[134/00065] train_loss: 0.022847\n",
      "[134/00115] train_loss: 0.020117\n",
      "[134/00165] train_loss: 0.018009\n",
      "[134/00215] train_loss: 0.016549\n",
      "[134/00265] train_loss: 0.016725\n",
      "[134/00315] train_loss: 0.016788\n",
      "[134/00365] train_loss: 0.017542\n",
      "[134/00415] train_loss: 0.017238\n",
      "[134/00465] train_loss: 0.017689\n",
      "[134/00515] train_loss: 0.016215\n",
      "[134/00565] train_loss: 0.016763\n",
      "[134/00615] train_loss: 0.016587\n",
      "[134/00665] train_loss: 0.016947\n",
      "[134/00715] train_loss: 0.017318\n",
      "[134/00765] train_loss: 0.016616\n",
      "[134/00815] train_loss: 0.016369\n",
      "[134/00865] train_loss: 0.017153\n",
      "[134/00915] train_loss: 0.017245\n",
      "[134/00965] train_loss: 0.017219\n",
      "[134/01015] train_loss: 0.016697\n",
      "[134/01065] train_loss: 0.016449\n",
      "[134/01115] train_loss: 0.017422\n",
      "[134/01165] train_loss: 0.017116\n",
      "[134/01215] train_loss: 0.017315\n",
      "[135/00039] train_loss: 0.024770\n",
      "[135/00089] train_loss: 0.021093\n",
      "[135/00139] train_loss: 0.018576\n",
      "[135/00189] train_loss: 0.017695\n",
      "[135/00239] train_loss: 0.017516\n",
      "[135/00289] train_loss: 0.015957\n",
      "[135/00339] train_loss: 0.016373\n",
      "[135/00389] train_loss: 0.016872\n",
      "[135/00439] train_loss: 0.016640\n",
      "[135/00489] train_loss: 0.016281\n",
      "[135/00539] train_loss: 0.017360\n",
      "[135/00589] train_loss: 0.016707\n",
      "[135/00639] train_loss: 0.015850\n",
      "[135/00689] train_loss: 0.016267\n",
      "[135/00739] train_loss: 0.016481\n",
      "[135/00789] train_loss: 0.017033\n",
      "[135/00839] train_loss: 0.016450\n",
      "[135/00889] train_loss: 0.017074\n",
      "[135/00939] train_loss: 0.017210\n",
      "[135/00989] train_loss: 0.017105\n",
      "[135/01039] train_loss: 0.016816\n",
      "[135/01089] train_loss: 0.017027\n",
      "[135/01139] train_loss: 0.017851\n",
      "[135/01189] train_loss: 0.017477\n",
      "[136/00013] train_loss: 0.021174\n",
      "[136/00063] train_loss: 0.023561\n",
      "[136/00113] train_loss: 0.018849\n",
      "[136/00163] train_loss: 0.016958\n",
      "[136/00213] train_loss: 0.016648\n",
      "[136/00263] train_loss: 0.017059\n",
      "[136/00313] train_loss: 0.016926\n",
      "[136/00363] train_loss: 0.017501\n",
      "[136/00413] train_loss: 0.016793\n",
      "[136/00463] train_loss: 0.016363\n",
      "[136/00513] train_loss: 0.016583\n",
      "[136/00563] train_loss: 0.017594\n",
      "[136/00613] train_loss: 0.016704\n",
      "[136/00663] train_loss: 0.016302\n",
      "[136/00713] train_loss: 0.017352\n",
      "[136/00763] train_loss: 0.017781\n",
      "[136/00813] train_loss: 0.016454\n",
      "[136/00863] train_loss: 0.016905\n",
      "[136/00913] train_loss: 0.017388\n",
      "[136/00963] train_loss: 0.015863\n",
      "[136/01013] train_loss: 0.016835\n",
      "[136/01063] train_loss: 0.017639\n",
      "[136/01113] train_loss: 0.015682\n",
      "[136/01163] train_loss: 0.017176\n",
      "[136/01213] train_loss: 0.017625\n",
      "[137/00037] train_loss: 0.023499\n",
      "[137/00087] train_loss: 0.023089\n",
      "[137/00137] train_loss: 0.019581\n",
      "[137/00187] train_loss: 0.016883\n",
      "[137/00237] train_loss: 0.017820\n",
      "[137/00287] train_loss: 0.016865\n",
      "[137/00337] train_loss: 0.015989\n",
      "[137/00387] train_loss: 0.017403\n",
      "[137/00437] train_loss: 0.016902\n",
      "[137/00487] train_loss: 0.016987\n",
      "[137/00537] train_loss: 0.016531\n",
      "[137/00587] train_loss: 0.017238\n",
      "[137/00637] train_loss: 0.016735\n",
      "[137/00687] train_loss: 0.017318\n",
      "[137/00737] train_loss: 0.016087\n",
      "[137/00787] train_loss: 0.015929\n",
      "[137/00837] train_loss: 0.016790\n",
      "[137/00887] train_loss: 0.016929\n",
      "[137/00937] train_loss: 0.016736\n",
      "[137/00987] train_loss: 0.016692\n",
      "[137/01037] train_loss: 0.016904\n",
      "[137/01087] train_loss: 0.016679\n",
      "[137/01137] train_loss: 0.016655\n",
      "[137/01187] train_loss: 0.017051\n",
      "[138/00011] train_loss: 0.020562\n",
      "[138/00061] train_loss: 0.024162\n",
      "[138/00111] train_loss: 0.020700\n",
      "[138/00161] train_loss: 0.018180\n",
      "[138/00211] train_loss: 0.017619\n",
      "[138/00261] train_loss: 0.016797\n",
      "[138/00311] train_loss: 0.017676\n",
      "[138/00361] train_loss: 0.016568\n",
      "[138/00411] train_loss: 0.016704\n",
      "[138/00461] train_loss: 0.016932\n",
      "[138/00511] train_loss: 0.017463\n",
      "[138/00561] train_loss: 0.017336\n",
      "[138/00611] train_loss: 0.016069\n",
      "[138/00661] train_loss: 0.016034\n",
      "[138/00711] train_loss: 0.016842\n",
      "[138/00761] train_loss: 0.015898\n",
      "[138/00811] train_loss: 0.016345\n",
      "[138/00861] train_loss: 0.017129\n",
      "[138/00911] train_loss: 0.017838\n",
      "[138/00961] train_loss: 0.017484\n",
      "[138/01011] train_loss: 0.017119\n",
      "[138/01061] train_loss: 0.016637\n",
      "[138/01111] train_loss: 0.016700\n",
      "[138/01161] train_loss: 0.016257\n",
      "[138/01211] train_loss: 0.017270\n",
      "[139/00035] train_loss: 0.023751\n",
      "[139/00085] train_loss: 0.021210\n",
      "[139/00135] train_loss: 0.018617\n",
      "[139/00185] train_loss: 0.017873\n",
      "[139/00235] train_loss: 0.017312\n",
      "[139/00285] train_loss: 0.017300\n",
      "[139/00335] train_loss: 0.017385\n",
      "[139/00385] train_loss: 0.016697\n",
      "[139/00435] train_loss: 0.016417\n",
      "[139/00485] train_loss: 0.016581\n",
      "[139/00535] train_loss: 0.016365\n",
      "[139/00585] train_loss: 0.016560\n",
      "[139/00635] train_loss: 0.016921\n",
      "[139/00685] train_loss: 0.015859\n",
      "[139/00735] train_loss: 0.017748\n",
      "[139/00785] train_loss: 0.017239\n",
      "[139/00835] train_loss: 0.017999\n",
      "[139/00885] train_loss: 0.016858\n",
      "[139/00935] train_loss: 0.016230\n",
      "[139/00985] train_loss: 0.017229\n",
      "[139/01035] train_loss: 0.016567\n",
      "[139/01085] train_loss: 0.017198\n",
      "[139/01135] train_loss: 0.016228\n",
      "[139/01185] train_loss: 0.016952\n",
      "[140/00009] train_loss: 0.018894\n",
      "[140/00059] train_loss: 0.024941\n",
      "[140/00109] train_loss: 0.021563\n",
      "[140/00159] train_loss: 0.018853\n",
      "[140/00209] train_loss: 0.017596\n",
      "[140/00259] train_loss: 0.017595\n",
      "[140/00309] train_loss: 0.017648\n",
      "[140/00359] train_loss: 0.016540\n",
      "[140/00409] train_loss: 0.016509\n",
      "[140/00459] train_loss: 0.017254\n",
      "[140/00509] train_loss: 0.016974\n",
      "[140/00559] train_loss: 0.015614\n",
      "[140/00609] train_loss: 0.016735\n",
      "[140/00659] train_loss: 0.016409\n",
      "[140/00709] train_loss: 0.016793\n",
      "[140/00759] train_loss: 0.016488\n",
      "[140/00809] train_loss: 0.017511\n",
      "[140/00859] train_loss: 0.016953\n",
      "[140/00909] train_loss: 0.016761\n",
      "[140/00959] train_loss: 0.016618\n",
      "[140/01009] train_loss: 0.017207\n",
      "[140/01059] train_loss: 0.016349\n",
      "[140/01109] train_loss: 0.016123\n",
      "[140/01159] train_loss: 0.017271\n",
      "[140/01209] train_loss: 0.017256\n",
      "[141/00033] train_loss: 0.024496\n",
      "[141/00083] train_loss: 0.023249\n",
      "[141/00133] train_loss: 0.018950\n",
      "[141/00183] train_loss: 0.018588\n",
      "[141/00233] train_loss: 0.016990\n",
      "[141/00283] train_loss: 0.016315\n",
      "[141/00333] train_loss: 0.016991\n",
      "[141/00383] train_loss: 0.017592\n",
      "[141/00433] train_loss: 0.016287\n",
      "[141/00483] train_loss: 0.017235\n",
      "[141/00533] train_loss: 0.015676\n",
      "[141/00583] train_loss: 0.017516\n",
      "[141/00633] train_loss: 0.016304\n",
      "[141/00683] train_loss: 0.016785\n",
      "[141/00733] train_loss: 0.016259\n",
      "[141/00783] train_loss: 0.016089\n",
      "[141/00833] train_loss: 0.017142\n",
      "[141/00883] train_loss: 0.016808\n",
      "[141/00933] train_loss: 0.016493\n",
      "[141/00983] train_loss: 0.016465\n",
      "[141/01033] train_loss: 0.016586\n",
      "[141/01083] train_loss: 0.017584\n",
      "[141/01133] train_loss: 0.016446\n",
      "[141/01183] train_loss: 0.019201\n",
      "[142/00007] train_loss: 0.018478\n",
      "[142/00057] train_loss: 0.023536\n",
      "[142/00107] train_loss: 0.019845\n",
      "[142/00157] train_loss: 0.017478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/00207] train_loss: 0.017469\n",
      "[142/00257] train_loss: 0.016807\n",
      "[142/00307] train_loss: 0.016804\n",
      "[142/00357] train_loss: 0.016827\n",
      "[142/00407] train_loss: 0.017203\n",
      "[142/00457] train_loss: 0.017145\n",
      "[142/00507] train_loss: 0.016603\n",
      "[142/00557] train_loss: 0.016336\n",
      "[142/00607] train_loss: 0.016660\n",
      "[142/00657] train_loss: 0.016999\n",
      "[142/00707] train_loss: 0.016463\n",
      "[142/00757] train_loss: 0.016807\n",
      "[142/00807] train_loss: 0.015676\n",
      "[142/00857] train_loss: 0.016310\n",
      "[142/00907] train_loss: 0.017147\n",
      "[142/00957] train_loss: 0.016308\n",
      "[142/01007] train_loss: 0.016884\n",
      "[142/01057] train_loss: 0.017069\n",
      "[142/01107] train_loss: 0.017237\n",
      "[142/01157] train_loss: 0.016841\n",
      "[142/01207] train_loss: 0.017231\n",
      "[143/00031] train_loss: 0.023158\n",
      "[143/00081] train_loss: 0.022640\n",
      "[143/00131] train_loss: 0.019321\n",
      "[143/00181] train_loss: 0.017051\n",
      "[143/00231] train_loss: 0.016971\n",
      "[143/00281] train_loss: 0.017869\n",
      "[143/00331] train_loss: 0.017244\n",
      "[143/00381] train_loss: 0.017808\n",
      "[143/00431] train_loss: 0.017951\n",
      "[143/00481] train_loss: 0.017431\n",
      "[143/00531] train_loss: 0.017600\n",
      "[143/00581] train_loss: 0.017100\n",
      "[143/00631] train_loss: 0.016186\n",
      "[143/00681] train_loss: 0.016889\n",
      "[143/00731] train_loss: 0.016520\n",
      "[143/00781] train_loss: 0.016880\n",
      "[143/00831] train_loss: 0.016720\n",
      "[143/00881] train_loss: 0.015991\n",
      "[143/00931] train_loss: 0.017592\n",
      "[143/00981] train_loss: 0.017705\n",
      "[143/01031] train_loss: 0.016625\n",
      "[143/01081] train_loss: 0.017214\n",
      "[143/01131] train_loss: 0.016895\n",
      "[143/01181] train_loss: 0.016918\n",
      "[144/00005] train_loss: 0.019012\n",
      "[144/00055] train_loss: 0.024237\n",
      "[144/00105] train_loss: 0.020351\n",
      "[144/00155] train_loss: 0.017709\n",
      "[144/00205] train_loss: 0.018114\n",
      "[144/00255] train_loss: 0.016441\n",
      "[144/00305] train_loss: 0.016512\n",
      "[144/00355] train_loss: 0.016287\n",
      "[144/00405] train_loss: 0.016942\n",
      "[144/00455] train_loss: 0.016646\n",
      "[144/00505] train_loss: 0.016803\n",
      "[144/00555] train_loss: 0.015935\n",
      "[144/00605] train_loss: 0.016145\n",
      "[144/00655] train_loss: 0.017073\n",
      "[144/00705] train_loss: 0.017363\n",
      "[144/00755] train_loss: 0.017093\n",
      "[144/00805] train_loss: 0.016462\n",
      "[144/00855] train_loss: 0.017676\n",
      "[144/00905] train_loss: 0.016684\n",
      "[144/00955] train_loss: 0.016937\n",
      "[144/01005] train_loss: 0.016537\n",
      "[144/01055] train_loss: 0.016964\n",
      "[144/01105] train_loss: 0.016743\n",
      "[144/01155] train_loss: 0.016713\n",
      "[144/01205] train_loss: 0.015893\n",
      "[145/00029] train_loss: 0.021355\n",
      "[145/00079] train_loss: 0.023577\n",
      "[145/00129] train_loss: 0.018649\n",
      "[145/00179] train_loss: 0.017366\n",
      "[145/00229] train_loss: 0.016878\n",
      "[145/00279] train_loss: 0.016790\n",
      "[145/00329] train_loss: 0.017479\n",
      "[145/00379] train_loss: 0.017070\n",
      "[145/00429] train_loss: 0.017759\n",
      "[145/00479] train_loss: 0.016311\n",
      "[145/00529] train_loss: 0.016769\n",
      "[145/00579] train_loss: 0.016954\n",
      "[145/00629] train_loss: 0.016787\n",
      "[145/00679] train_loss: 0.016785\n",
      "[145/00729] train_loss: 0.016509\n",
      "[145/00779] train_loss: 0.017757\n",
      "[145/00829] train_loss: 0.016992\n",
      "[145/00879] train_loss: 0.016770\n",
      "[145/00929] train_loss: 0.016315\n",
      "[145/00979] train_loss: 0.016881\n",
      "[145/01029] train_loss: 0.015977\n",
      "[145/01079] train_loss: 0.016438\n",
      "[145/01129] train_loss: 0.017265\n",
      "[145/01179] train_loss: 0.016342\n",
      "[146/00003] train_loss: 0.017111\n",
      "[146/00053] train_loss: 0.026432\n",
      "[146/00103] train_loss: 0.021226\n",
      "[146/00153] train_loss: 0.018070\n",
      "[146/00203] train_loss: 0.016667\n",
      "[146/00253] train_loss: 0.017649\n",
      "[146/00303] train_loss: 0.017942\n",
      "[146/00353] train_loss: 0.016607\n",
      "[146/00403] train_loss: 0.017048\n",
      "[146/00453] train_loss: 0.015844\n",
      "[146/00503] train_loss: 0.015971\n",
      "[146/00553] train_loss: 0.017310\n",
      "[146/00603] train_loss: 0.017452\n",
      "[146/00653] train_loss: 0.016912\n",
      "[146/00703] train_loss: 0.016897\n",
      "[146/00753] train_loss: 0.016946\n",
      "[146/00803] train_loss: 0.016786\n",
      "[146/00853] train_loss: 0.017243\n",
      "[146/00903] train_loss: 0.015812\n",
      "[146/00953] train_loss: 0.016086\n",
      "[146/01003] train_loss: 0.016308\n",
      "[146/01053] train_loss: 0.016735\n",
      "[146/01103] train_loss: 0.017415\n",
      "[146/01153] train_loss: 0.016324\n",
      "[146/01203] train_loss: 0.015359\n",
      "[147/00027] train_loss: 0.022165\n",
      "[147/00077] train_loss: 0.022218\n",
      "[147/00127] train_loss: 0.019199\n",
      "[147/00177] train_loss: 0.017246\n",
      "[147/00227] train_loss: 0.016339\n",
      "[147/00277] train_loss: 0.017618\n",
      "[147/00327] train_loss: 0.016781\n",
      "[147/00377] train_loss: 0.016870\n",
      "[147/00427] train_loss: 0.016887\n",
      "[147/00477] train_loss: 0.016615\n",
      "[147/00527] train_loss: 0.017701\n",
      "[147/00577] train_loss: 0.017076\n",
      "[147/00627] train_loss: 0.016427\n",
      "[147/00677] train_loss: 0.016565\n",
      "[147/00727] train_loss: 0.016218\n",
      "[147/00777] train_loss: 0.016843\n",
      "[147/00827] train_loss: 0.017803\n",
      "[147/00877] train_loss: 0.016979\n",
      "[147/00927] train_loss: 0.016289\n",
      "[147/00977] train_loss: 0.016959\n",
      "[147/01027] train_loss: 0.017162\n",
      "[147/01077] train_loss: 0.016053\n",
      "[147/01127] train_loss: 0.016682\n",
      "[147/01177] train_loss: 0.016261\n",
      "[148/00001] train_loss: 0.017519\n",
      "[148/00051] train_loss: 0.024855\n",
      "[148/00101] train_loss: 0.020888\n",
      "[148/00151] train_loss: 0.017965\n",
      "[148/00201] train_loss: 0.017912\n",
      "[148/00251] train_loss: 0.016997\n",
      "[148/00301] train_loss: 0.017418\n",
      "[148/00351] train_loss: 0.016996\n",
      "[148/00401] train_loss: 0.016947\n",
      "[148/00451] train_loss: 0.016363\n",
      "[148/00501] train_loss: 0.016692\n",
      "[148/00551] train_loss: 0.016999\n",
      "[148/00601] train_loss: 0.017421\n",
      "[148/00651] train_loss: 0.016378\n",
      "[148/00701] train_loss: 0.016330\n",
      "[148/00751] train_loss: 0.016361\n",
      "[148/00801] train_loss: 0.015823\n",
      "[148/00851] train_loss: 0.017293\n",
      "[148/00901] train_loss: 0.015776\n",
      "[148/00951] train_loss: 0.017220\n",
      "[148/01001] train_loss: 0.017197\n",
      "[148/01051] train_loss: 0.017506\n",
      "[148/01101] train_loss: 0.017412\n",
      "[148/01151] train_loss: 0.017217\n",
      "[148/01201] train_loss: 0.017451\n",
      "[149/00025] train_loss: 0.023116\n",
      "[149/00075] train_loss: 0.022919\n",
      "[149/00125] train_loss: 0.019379\n",
      "[149/00175] train_loss: 0.017412\n",
      "[149/00225] train_loss: 0.017355\n",
      "[149/00275] train_loss: 0.016188\n",
      "[149/00325] train_loss: 0.016080\n",
      "[149/00375] train_loss: 0.017491\n",
      "[149/00425] train_loss: 0.016155\n",
      "[149/00475] train_loss: 0.016374\n",
      "[149/00525] train_loss: 0.016983\n",
      "[149/00575] train_loss: 0.017197\n",
      "[149/00625] train_loss: 0.016554\n",
      "[149/00675] train_loss: 0.017937\n",
      "[149/00725] train_loss: 0.016383\n",
      "[149/00775] train_loss: 0.016809\n",
      "[149/00825] train_loss: 0.017475\n",
      "[149/00875] train_loss: 0.016768\n",
      "[149/00925] train_loss: 0.016108\n",
      "[149/00975] train_loss: 0.016698\n",
      "[149/01025] train_loss: 0.016953\n",
      "[149/01075] train_loss: 0.016974\n",
      "[149/01125] train_loss: 0.016809\n",
      "[149/01175] train_loss: 0.016725\n",
      "[149/01225] train_loss: 0.016966\n",
      "[150/00049] train_loss: 0.024648\n",
      "[150/00099] train_loss: 0.020187\n",
      "[150/00149] train_loss: 0.018293\n",
      "[150/00199] train_loss: 0.017355\n",
      "[150/00249] train_loss: 0.016924\n",
      "[150/00299] train_loss: 0.017878\n",
      "[150/00349] train_loss: 0.016281\n",
      "[150/00399] train_loss: 0.017242\n",
      "[150/00449] train_loss: 0.015976\n",
      "[150/00499] train_loss: 0.016367\n",
      "[150/00549] train_loss: 0.016960\n",
      "[150/00599] train_loss: 0.016668\n",
      "[150/00649] train_loss: 0.015743\n",
      "[150/00699] train_loss: 0.017215\n",
      "[150/00749] train_loss: 0.017118\n",
      "[150/00799] train_loss: 0.016983\n",
      "[150/00849] train_loss: 0.016281\n",
      "[150/00899] train_loss: 0.017312\n",
      "[150/00949] train_loss: 0.017066\n",
      "[150/00999] train_loss: 0.016716\n",
      "[150/01049] train_loss: 0.017774\n",
      "[150/01099] train_loss: 0.017409\n",
      "[150/01149] train_loss: 0.016196\n",
      "[150/01199] train_loss: 0.016249\n",
      "[151/00023] train_loss: 0.022389\n",
      "[151/00073] train_loss: 0.022857\n",
      "[151/00123] train_loss: 0.019531\n",
      "[151/00173] train_loss: 0.017490\n",
      "[151/00223] train_loss: 0.017343\n",
      "[151/00273] train_loss: 0.016552\n",
      "[151/00323] train_loss: 0.016435\n",
      "[151/00373] train_loss: 0.016898\n",
      "[151/00423] train_loss: 0.016420\n",
      "[151/00473] train_loss: 0.017206\n",
      "[151/00523] train_loss: 0.015382\n",
      "[151/00573] train_loss: 0.016789\n",
      "[151/00623] train_loss: 0.016757\n",
      "[151/00673] train_loss: 0.016568\n",
      "[151/00723] train_loss: 0.017265\n",
      "[151/00773] train_loss: 0.016053\n",
      "[151/00823] train_loss: 0.018177\n",
      "[151/00873] train_loss: 0.016910\n",
      "[151/00923] train_loss: 0.017003\n",
      "[151/00973] train_loss: 0.017538\n",
      "[151/01023] train_loss: 0.015849\n",
      "[151/01073] train_loss: 0.016641\n",
      "[151/01123] train_loss: 0.017346\n",
      "[151/01173] train_loss: 0.017554\n",
      "[151/01223] train_loss: 0.016168\n",
      "[152/00047] train_loss: 0.024369\n",
      "[152/00097] train_loss: 0.020280\n",
      "[152/00147] train_loss: 0.017385\n",
      "[152/00197] train_loss: 0.019136\n",
      "[152/00247] train_loss: 0.017130\n",
      "[152/00297] train_loss: 0.016227\n",
      "[152/00347] train_loss: 0.016572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152/00397] train_loss: 0.016893\n",
      "[152/00447] train_loss: 0.016285\n",
      "[152/00497] train_loss: 0.016523\n",
      "[152/00547] train_loss: 0.016279\n",
      "[152/00597] train_loss: 0.016918\n",
      "[152/00647] train_loss: 0.017312\n",
      "[152/00697] train_loss: 0.016419\n",
      "[152/00747] train_loss: 0.016935\n",
      "[152/00797] train_loss: 0.017037\n",
      "[152/00847] train_loss: 0.016452\n",
      "[152/00897] train_loss: 0.016782\n",
      "[152/00947] train_loss: 0.016470\n",
      "[152/00997] train_loss: 0.017321\n",
      "[152/01047] train_loss: 0.017006\n",
      "[152/01097] train_loss: 0.016683\n",
      "[152/01147] train_loss: 0.015930\n",
      "[152/01197] train_loss: 0.016709\n",
      "[153/00021] train_loss: 0.021196\n",
      "[153/00071] train_loss: 0.022503\n",
      "[153/00121] train_loss: 0.019260\n",
      "[153/00171] train_loss: 0.018314\n",
      "[153/00221] train_loss: 0.017143\n",
      "[153/00271] train_loss: 0.016916\n",
      "[153/00321] train_loss: 0.016327\n",
      "[153/00371] train_loss: 0.017085\n",
      "[153/00421] train_loss: 0.016683\n",
      "[153/00471] train_loss: 0.017620\n",
      "[153/00521] train_loss: 0.017175\n",
      "[153/00571] train_loss: 0.016777\n",
      "[153/00621] train_loss: 0.016074\n",
      "[153/00671] train_loss: 0.015338\n",
      "[153/00721] train_loss: 0.017221\n",
      "[153/00771] train_loss: 0.017041\n",
      "[153/00821] train_loss: 0.016166\n",
      "[153/00871] train_loss: 0.017008\n",
      "[153/00921] train_loss: 0.017010\n",
      "[153/00971] train_loss: 0.017105\n",
      "[153/01021] train_loss: 0.017912\n",
      "[153/01071] train_loss: 0.016516\n",
      "[153/01121] train_loss: 0.016307\n",
      "[153/01171] train_loss: 0.017114\n",
      "[153/01221] train_loss: 0.016672\n",
      "[154/00045] train_loss: 0.024096\n",
      "[154/00095] train_loss: 0.022365\n",
      "[154/00145] train_loss: 0.019428\n",
      "[154/00195] train_loss: 0.017136\n",
      "[154/00245] train_loss: 0.016218\n",
      "[154/00295] train_loss: 0.017966\n",
      "[154/00345] train_loss: 0.017608\n",
      "[154/00395] train_loss: 0.017300\n",
      "[154/00445] train_loss: 0.015925\n",
      "[154/00495] train_loss: 0.017288\n",
      "[154/00545] train_loss: 0.016713\n",
      "[154/00595] train_loss: 0.016888\n",
      "[154/00645] train_loss: 0.016809\n",
      "[154/00695] train_loss: 0.015655\n",
      "[154/00745] train_loss: 0.016094\n",
      "[154/00795] train_loss: 0.016649\n",
      "[154/00845] train_loss: 0.015952\n",
      "[154/00895] train_loss: 0.015416\n",
      "[154/00945] train_loss: 0.016885\n",
      "[154/00995] train_loss: 0.016650\n",
      "[154/01045] train_loss: 0.015922\n",
      "[154/01095] train_loss: 0.016315\n",
      "[154/01145] train_loss: 0.017394\n",
      "[154/01195] train_loss: 0.016398\n",
      "[155/00019] train_loss: 0.021095\n",
      "[155/00069] train_loss: 0.021974\n",
      "[155/00119] train_loss: 0.018709\n",
      "[155/00169] train_loss: 0.017391\n",
      "[155/00219] train_loss: 0.017904\n",
      "[155/00269] train_loss: 0.016200\n",
      "[155/00319] train_loss: 0.016822\n",
      "[155/00369] train_loss: 0.016561\n",
      "[155/00419] train_loss: 0.017150\n",
      "[155/00469] train_loss: 0.016851\n",
      "[155/00519] train_loss: 0.016389\n",
      "[155/00569] train_loss: 0.016964\n",
      "[155/00619] train_loss: 0.017250\n",
      "[155/00669] train_loss: 0.016863\n",
      "[155/00719] train_loss: 0.016916\n",
      "[155/00769] train_loss: 0.016827\n",
      "[155/00819] train_loss: 0.016537\n",
      "[155/00869] train_loss: 0.016781\n",
      "[155/00919] train_loss: 0.016727\n",
      "[155/00969] train_loss: 0.015587\n",
      "[155/01019] train_loss: 0.016003\n",
      "[155/01069] train_loss: 0.016477\n",
      "[155/01119] train_loss: 0.016020\n",
      "[155/01169] train_loss: 0.016255\n",
      "[155/01219] train_loss: 0.017038\n",
      "[156/00043] train_loss: 0.024086\n",
      "[156/00093] train_loss: 0.022215\n",
      "[156/00143] train_loss: 0.019555\n",
      "[156/00193] train_loss: 0.017169\n",
      "[156/00243] train_loss: 0.016591\n",
      "[156/00293] train_loss: 0.017301\n",
      "[156/00343] train_loss: 0.017413\n",
      "[156/00393] train_loss: 0.017032\n",
      "[156/00443] train_loss: 0.017477\n",
      "[156/00493] train_loss: 0.016245\n",
      "[156/00543] train_loss: 0.016758\n",
      "[156/00593] train_loss: 0.016634\n",
      "[156/00643] train_loss: 0.015696\n",
      "[156/00693] train_loss: 0.017221\n",
      "[156/00743] train_loss: 0.016937\n",
      "[156/00793] train_loss: 0.016442\n",
      "[156/00843] train_loss: 0.015401\n",
      "[156/00893] train_loss: 0.016540\n",
      "[156/00943] train_loss: 0.017997\n",
      "[156/00993] train_loss: 0.017316\n",
      "[156/01043] train_loss: 0.016986\n",
      "[156/01093] train_loss: 0.016414\n",
      "[156/01143] train_loss: 0.017013\n",
      "[156/01193] train_loss: 0.016981\n",
      "[157/00017] train_loss: 0.020728\n",
      "[157/00067] train_loss: 0.022423\n",
      "[157/00117] train_loss: 0.018329\n",
      "[157/00167] train_loss: 0.016876\n",
      "[157/00217] train_loss: 0.018132\n",
      "[157/00267] train_loss: 0.017861\n",
      "[157/00317] train_loss: 0.017230\n",
      "[157/00367] train_loss: 0.016254\n",
      "[157/00417] train_loss: 0.015965\n",
      "[157/00467] train_loss: 0.015738\n",
      "[157/00517] train_loss: 0.017343\n",
      "[157/00567] train_loss: 0.016389\n",
      "[157/00617] train_loss: 0.016658\n",
      "[157/00667] train_loss: 0.017070\n",
      "[157/00717] train_loss: 0.016226\n",
      "[157/00767] train_loss: 0.016999\n",
      "[157/00817] train_loss: 0.016581\n",
      "[157/00867] train_loss: 0.016587\n",
      "[157/00917] train_loss: 0.017038\n",
      "[157/00967] train_loss: 0.016590\n",
      "[157/01017] train_loss: 0.017845\n",
      "[157/01067] train_loss: 0.016333\n",
      "[157/01117] train_loss: 0.016973\n",
      "[157/01167] train_loss: 0.016723\n",
      "[157/01217] train_loss: 0.016791\n",
      "[158/00041] train_loss: 0.025046\n",
      "[158/00091] train_loss: 0.020360\n",
      "[158/00141] train_loss: 0.017906\n",
      "[158/00191] train_loss: 0.017186\n",
      "[158/00241] train_loss: 0.017701\n",
      "[158/00291] train_loss: 0.015901\n",
      "[158/00341] train_loss: 0.017313\n",
      "[158/00391] train_loss: 0.017481\n",
      "[158/00441] train_loss: 0.016221\n",
      "[158/00491] train_loss: 0.016844\n",
      "[158/00541] train_loss: 0.016526\n",
      "[158/00591] train_loss: 0.016587\n",
      "[158/00641] train_loss: 0.016261\n",
      "[158/00691] train_loss: 0.017696\n",
      "[158/00741] train_loss: 0.016000\n",
      "[158/00791] train_loss: 0.017288\n",
      "[158/00841] train_loss: 0.016646\n",
      "[158/00891] train_loss: 0.016218\n",
      "[158/00941] train_loss: 0.016619\n",
      "[158/00991] train_loss: 0.016893\n",
      "[158/01041] train_loss: 0.017166\n",
      "[158/01091] train_loss: 0.017071\n",
      "[158/01141] train_loss: 0.017195\n",
      "[158/01191] train_loss: 0.017592\n",
      "[159/00015] train_loss: 0.022047\n",
      "[159/00065] train_loss: 0.022938\n",
      "[159/00115] train_loss: 0.018781\n",
      "[159/00165] train_loss: 0.017921\n",
      "[159/00215] train_loss: 0.017416\n",
      "[159/00265] train_loss: 0.016579\n",
      "[159/00315] train_loss: 0.017043\n",
      "[159/00365] train_loss: 0.016553\n",
      "[159/00415] train_loss: 0.016098\n",
      "[159/00465] train_loss: 0.015724\n",
      "[159/00515] train_loss: 0.017525\n",
      "[159/00565] train_loss: 0.016240\n",
      "[159/00615] train_loss: 0.016025\n",
      "[159/00665] train_loss: 0.016803\n",
      "[159/00715] train_loss: 0.016874\n",
      "[159/00765] train_loss: 0.016001\n",
      "[159/00815] train_loss: 0.016202\n",
      "[159/00865] train_loss: 0.017376\n",
      "[159/00915] train_loss: 0.017799\n",
      "[159/00965] train_loss: 0.017052\n",
      "[159/01015] train_loss: 0.017346\n",
      "[159/01065] train_loss: 0.016715\n",
      "[159/01115] train_loss: 0.017464\n",
      "[159/01165] train_loss: 0.016740\n",
      "[159/01215] train_loss: 0.015930\n",
      "[160/00039] train_loss: 0.022999\n",
      "[160/00089] train_loss: 0.020615\n",
      "[160/00139] train_loss: 0.018539\n",
      "[160/00189] train_loss: 0.018260\n",
      "[160/00239] train_loss: 0.017753\n",
      "[160/00289] train_loss: 0.016758\n",
      "[160/00339] train_loss: 0.016291\n",
      "[160/00389] train_loss: 0.016477\n",
      "[160/00439] train_loss: 0.017566\n",
      "[160/00489] train_loss: 0.016217\n",
      "[160/00539] train_loss: 0.015984\n",
      "[160/00589] train_loss: 0.016494\n",
      "[160/00639] train_loss: 0.016340\n",
      "[160/00689] train_loss: 0.016184\n",
      "[160/00739] train_loss: 0.016501\n",
      "[160/00789] train_loss: 0.016780\n",
      "[160/00839] train_loss: 0.016710\n",
      "[160/00889] train_loss: 0.016122\n",
      "[160/00939] train_loss: 0.016214\n",
      "[160/00989] train_loss: 0.017349\n",
      "[160/01039] train_loss: 0.017724\n",
      "[160/01089] train_loss: 0.017393\n",
      "[160/01139] train_loss: 0.017206\n",
      "[160/01189] train_loss: 0.016994\n",
      "[161/00013] train_loss: 0.020216\n",
      "[161/00063] train_loss: 0.023178\n",
      "[161/00113] train_loss: 0.020291\n",
      "[161/00163] train_loss: 0.017699\n",
      "[161/00213] train_loss: 0.017534\n",
      "[161/00263] train_loss: 0.016504\n",
      "[161/00313] train_loss: 0.017052\n",
      "[161/00363] train_loss: 0.017179\n",
      "[161/00413] train_loss: 0.017225\n",
      "[161/00463] train_loss: 0.016649\n",
      "[161/00513] train_loss: 0.016014\n",
      "[161/00563] train_loss: 0.016384\n",
      "[161/00613] train_loss: 0.016277\n",
      "[161/00663] train_loss: 0.016164\n",
      "[161/00713] train_loss: 0.015943\n",
      "[161/00763] train_loss: 0.016518\n",
      "[161/00813] train_loss: 0.016566\n",
      "[161/00863] train_loss: 0.017174\n",
      "[161/00913] train_loss: 0.017170\n",
      "[161/00963] train_loss: 0.016487\n",
      "[161/01013] train_loss: 0.017596\n",
      "[161/01063] train_loss: 0.017016\n",
      "[161/01113] train_loss: 0.017349\n",
      "[161/01163] train_loss: 0.016834\n",
      "[161/01213] train_loss: 0.016664\n",
      "[162/00037] train_loss: 0.022849\n",
      "[162/00087] train_loss: 0.021853\n",
      "[162/00137] train_loss: 0.018944\n",
      "[162/00187] train_loss: 0.018277\n",
      "[162/00237] train_loss: 0.017156\n",
      "[162/00287] train_loss: 0.016474\n",
      "[162/00337] train_loss: 0.017014\n",
      "[162/00387] train_loss: 0.016257\n",
      "[162/00437] train_loss: 0.016340\n",
      "[162/00487] train_loss: 0.016885\n",
      "[162/00537] train_loss: 0.017989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162/00587] train_loss: 0.016039\n",
      "[162/00637] train_loss: 0.016360\n",
      "[162/00687] train_loss: 0.017022\n",
      "[162/00737] train_loss: 0.017481\n",
      "[162/00787] train_loss: 0.016490\n",
      "[162/00837] train_loss: 0.015921\n",
      "[162/00887] train_loss: 0.015226\n",
      "[162/00937] train_loss: 0.016631\n",
      "[162/00987] train_loss: 0.016961\n",
      "[162/01037] train_loss: 0.016624\n",
      "[162/01087] train_loss: 0.017496\n",
      "[162/01137] train_loss: 0.017629\n",
      "[162/01187] train_loss: 0.017259\n",
      "[163/00011] train_loss: 0.019507\n",
      "[163/00061] train_loss: 0.023184\n",
      "[163/00111] train_loss: 0.019010\n",
      "[163/00161] train_loss: 0.017408\n",
      "[163/00211] train_loss: 0.017889\n",
      "[163/00261] train_loss: 0.016830\n",
      "[163/00311] train_loss: 0.017672\n",
      "[163/00361] train_loss: 0.016255\n",
      "[163/00411] train_loss: 0.016898\n",
      "[163/00461] train_loss: 0.016853\n",
      "[163/00511] train_loss: 0.016183\n",
      "[163/00561] train_loss: 0.016848\n",
      "[163/00611] train_loss: 0.016180\n",
      "[163/00661] train_loss: 0.016412\n",
      "[163/00711] train_loss: 0.015666\n",
      "[163/00761] train_loss: 0.015649\n",
      "[163/00811] train_loss: 0.016338\n",
      "[163/00861] train_loss: 0.017833\n",
      "[163/00911] train_loss: 0.017016\n",
      "[163/00961] train_loss: 0.015903\n",
      "[163/01011] train_loss: 0.016532\n",
      "[163/01061] train_loss: 0.017028\n",
      "[163/01111] train_loss: 0.016317\n",
      "[163/01161] train_loss: 0.016977\n",
      "[163/01211] train_loss: 0.016980\n",
      "[164/00035] train_loss: 0.023343\n",
      "[164/00085] train_loss: 0.022151\n",
      "[164/00135] train_loss: 0.017610\n",
      "[164/00185] train_loss: 0.018008\n",
      "[164/00235] train_loss: 0.017621\n",
      "[164/00285] train_loss: 0.017141\n",
      "[164/00335] train_loss: 0.016810\n",
      "[164/00385] train_loss: 0.016654\n",
      "[164/00435] train_loss: 0.016615\n",
      "[164/00485] train_loss: 0.016718\n",
      "[164/00535] train_loss: 0.016597\n",
      "[164/00585] train_loss: 0.017238\n",
      "[164/00635] train_loss: 0.015610\n",
      "[164/00685] train_loss: 0.016661\n",
      "[164/00735] train_loss: 0.016129\n",
      "[164/00785] train_loss: 0.016546\n",
      "[164/00835] train_loss: 0.016587\n",
      "[164/00885] train_loss: 0.016129\n",
      "[164/00935] train_loss: 0.016797\n",
      "[164/00985] train_loss: 0.016272\n",
      "[164/01035] train_loss: 0.016040\n",
      "[164/01085] train_loss: 0.016690\n",
      "[164/01135] train_loss: 0.017171\n",
      "[164/01185] train_loss: 0.016880\n",
      "[165/00009] train_loss: 0.018444\n",
      "[165/00059] train_loss: 0.024892\n",
      "[165/00109] train_loss: 0.021268\n",
      "[165/00159] train_loss: 0.018411\n",
      "[165/00209] train_loss: 0.017203\n",
      "[165/00259] train_loss: 0.016998\n",
      "[165/00309] train_loss: 0.016908\n",
      "[165/00359] train_loss: 0.016719\n",
      "[165/00409] train_loss: 0.016611\n",
      "[165/00459] train_loss: 0.015941\n",
      "[165/00509] train_loss: 0.016797\n",
      "[165/00559] train_loss: 0.016426\n",
      "[165/00609] train_loss: 0.016334\n",
      "[165/00659] train_loss: 0.016830\n",
      "[165/00709] train_loss: 0.015761\n",
      "[165/00759] train_loss: 0.016293\n",
      "[165/00809] train_loss: 0.016390\n",
      "[165/00859] train_loss: 0.015971\n",
      "[165/00909] train_loss: 0.016419\n",
      "[165/00959] train_loss: 0.016839\n",
      "[165/01009] train_loss: 0.016131\n",
      "[165/01059] train_loss: 0.016661\n",
      "[165/01109] train_loss: 0.017634\n",
      "[165/01159] train_loss: 0.017421\n",
      "[165/01209] train_loss: 0.016676\n",
      "[166/00033] train_loss: 0.022391\n",
      "[166/00083] train_loss: 0.022222\n",
      "[166/00133] train_loss: 0.020180\n",
      "[166/00183] train_loss: 0.017004\n",
      "[166/00233] train_loss: 0.017663\n",
      "[166/00283] train_loss: 0.016772\n",
      "[166/00333] train_loss: 0.016347\n",
      "[166/00383] train_loss: 0.016089\n",
      "[166/00433] train_loss: 0.018486\n",
      "[166/00483] train_loss: 0.017220\n",
      "[166/00533] train_loss: 0.016543\n",
      "[166/00583] train_loss: 0.015854\n",
      "[166/00633] train_loss: 0.016437\n",
      "[166/00683] train_loss: 0.015746\n",
      "[166/00733] train_loss: 0.017293\n",
      "[166/00783] train_loss: 0.016803\n",
      "[166/00833] train_loss: 0.016509\n",
      "[166/00883] train_loss: 0.017053\n",
      "[166/00933] train_loss: 0.016069\n",
      "[166/00983] train_loss: 0.017791\n",
      "[166/01033] train_loss: 0.016369\n",
      "[166/01083] train_loss: 0.016486\n",
      "[166/01133] train_loss: 0.017724\n",
      "[166/01183] train_loss: 0.017070\n",
      "[167/00007] train_loss: 0.019449\n",
      "[167/00057] train_loss: 0.023950\n",
      "[167/00107] train_loss: 0.020111\n",
      "[167/00157] train_loss: 0.017670\n",
      "[167/00207] train_loss: 0.017697\n",
      "[167/00257] train_loss: 0.016282\n",
      "[167/00307] train_loss: 0.017497\n",
      "[167/00357] train_loss: 0.015888\n",
      "[167/00407] train_loss: 0.017330\n",
      "[167/00457] train_loss: 0.016682\n",
      "[167/00507] train_loss: 0.016258\n",
      "[167/00557] train_loss: 0.016821\n",
      "[167/00607] train_loss: 0.017043\n",
      "[167/00657] train_loss: 0.016474\n",
      "[167/00707] train_loss: 0.015769\n",
      "[167/00757] train_loss: 0.016622\n",
      "[167/00807] train_loss: 0.016564\n",
      "[167/00857] train_loss: 0.016854\n",
      "[167/00907] train_loss: 0.016541\n",
      "[167/00957] train_loss: 0.018280\n",
      "[167/01007] train_loss: 0.017165\n",
      "[167/01057] train_loss: 0.016794\n",
      "[167/01107] train_loss: 0.016879\n",
      "[167/01157] train_loss: 0.017266\n",
      "[167/01207] train_loss: 0.015731\n",
      "[168/00031] train_loss: 0.023266\n",
      "[168/00081] train_loss: 0.022016\n",
      "[168/00131] train_loss: 0.019011\n",
      "[168/00181] train_loss: 0.017140\n",
      "[168/00231] train_loss: 0.017326\n",
      "[168/00281] train_loss: 0.017310\n",
      "[168/00331] train_loss: 0.016336\n",
      "[168/00381] train_loss: 0.017450\n",
      "[168/00431] train_loss: 0.017510\n",
      "[168/00481] train_loss: 0.016177\n",
      "[168/00531] train_loss: 0.016516\n",
      "[168/00581] train_loss: 0.016086\n",
      "[168/00631] train_loss: 0.016073\n",
      "[168/00681] train_loss: 0.016410\n",
      "[168/00731] train_loss: 0.015984\n",
      "[168/00781] train_loss: 0.017116\n",
      "[168/00831] train_loss: 0.015953\n",
      "[168/00881] train_loss: 0.016659\n",
      "[168/00931] train_loss: 0.016120\n",
      "[168/00981] train_loss: 0.016626\n",
      "[168/01031] train_loss: 0.015787\n",
      "[168/01081] train_loss: 0.015775\n",
      "[168/01131] train_loss: 0.016352\n",
      "[168/01181] train_loss: 0.017251\n",
      "[169/00005] train_loss: 0.017217\n",
      "[169/00055] train_loss: 0.025500\n",
      "[169/00105] train_loss: 0.020139\n",
      "[169/00155] train_loss: 0.017278\n",
      "[169/00205] train_loss: 0.016775\n",
      "[169/00255] train_loss: 0.017110\n",
      "[169/00305] train_loss: 0.016866\n",
      "[169/00355] train_loss: 0.016619\n",
      "[169/00405] train_loss: 0.016944\n",
      "[169/00455] train_loss: 0.015932\n",
      "[169/00505] train_loss: 0.017041\n",
      "[169/00555] train_loss: 0.016941\n",
      "[169/00605] train_loss: 0.015821\n",
      "[169/00655] train_loss: 0.016993\n",
      "[169/00705] train_loss: 0.016700\n",
      "[169/00755] train_loss: 0.016851\n",
      "[169/00805] train_loss: 0.015946\n",
      "[169/00855] train_loss: 0.017160\n",
      "[169/00905] train_loss: 0.016655\n",
      "[169/00955] train_loss: 0.016847\n",
      "[169/01005] train_loss: 0.017030\n",
      "[169/01055] train_loss: 0.015951\n",
      "[169/01105] train_loss: 0.016591\n",
      "[169/01155] train_loss: 0.017362\n",
      "[169/01205] train_loss: 0.016740\n",
      "[170/00029] train_loss: 0.022325\n",
      "[170/00079] train_loss: 0.022449\n",
      "[170/00129] train_loss: 0.018359\n",
      "[170/00179] train_loss: 0.017431\n",
      "[170/00229] train_loss: 0.016683\n",
      "[170/00279] train_loss: 0.017479\n",
      "[170/00329] train_loss: 0.016765\n",
      "[170/00379] train_loss: 0.016644\n",
      "[170/00429] train_loss: 0.016627\n",
      "[170/00479] train_loss: 0.016139\n",
      "[170/00529] train_loss: 0.016350\n",
      "[170/00579] train_loss: 0.016469\n",
      "[170/00629] train_loss: 0.016607\n",
      "[170/00679] train_loss: 0.015815\n",
      "[170/00729] train_loss: 0.016364\n",
      "[170/00779] train_loss: 0.015898\n",
      "[170/00829] train_loss: 0.016261\n",
      "[170/00879] train_loss: 0.017109\n",
      "[170/00929] train_loss: 0.016553\n",
      "[170/00979] train_loss: 0.016556\n",
      "[170/01029] train_loss: 0.017212\n",
      "[170/01079] train_loss: 0.017041\n",
      "[170/01129] train_loss: 0.017375\n",
      "[170/01179] train_loss: 0.017421\n",
      "[171/00003] train_loss: 0.018670\n",
      "[171/00053] train_loss: 0.023500\n",
      "[171/00103] train_loss: 0.020299\n",
      "[171/00153] train_loss: 0.017562\n",
      "[171/00203] train_loss: 0.016966\n",
      "[171/00253] train_loss: 0.016936\n",
      "[171/00303] train_loss: 0.016946\n",
      "[171/00353] train_loss: 0.017022\n",
      "[171/00403] train_loss: 0.017093\n",
      "[171/00453] train_loss: 0.016397\n",
      "[171/00503] train_loss: 0.015987\n",
      "[171/00553] train_loss: 0.016448\n",
      "[171/00603] train_loss: 0.015723\n",
      "[171/00653] train_loss: 0.016208\n",
      "[171/00703] train_loss: 0.016356\n",
      "[171/00753] train_loss: 0.016725\n",
      "[171/00803] train_loss: 0.016242\n",
      "[171/00853] train_loss: 0.016580\n",
      "[171/00903] train_loss: 0.016182\n",
      "[171/00953] train_loss: 0.016006\n",
      "[171/01003] train_loss: 0.017392\n",
      "[171/01053] train_loss: 0.016343\n",
      "[171/01103] train_loss: 0.016439\n",
      "[171/01153] train_loss: 0.017111\n",
      "[171/01203] train_loss: 0.016807\n",
      "[172/00027] train_loss: 0.021679\n",
      "[172/00077] train_loss: 0.022020\n",
      "[172/00127] train_loss: 0.019542\n",
      "[172/00177] train_loss: 0.017733\n",
      "[172/00227] train_loss: 0.016717\n",
      "[172/00277] train_loss: 0.017178\n",
      "[172/00327] train_loss: 0.016845\n",
      "[172/00377] train_loss: 0.016364\n",
      "[172/00427] train_loss: 0.016442\n",
      "[172/00477] train_loss: 0.016372\n",
      "[172/00527] train_loss: 0.016765\n",
      "[172/00577] train_loss: 0.016013\n",
      "[172/00627] train_loss: 0.015766\n",
      "[172/00677] train_loss: 0.016584\n",
      "[172/00727] train_loss: 0.016760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172/00777] train_loss: 0.016903\n",
      "[172/00827] train_loss: 0.016188\n",
      "[172/00877] train_loss: 0.015954\n",
      "[172/00927] train_loss: 0.016697\n",
      "[172/00977] train_loss: 0.016758\n",
      "[172/01027] train_loss: 0.016122\n",
      "[172/01077] train_loss: 0.016790\n",
      "[172/01127] train_loss: 0.016763\n",
      "[172/01177] train_loss: 0.015858\n",
      "[173/00001] train_loss: 0.017385\n",
      "[173/00051] train_loss: 0.024008\n",
      "[173/00101] train_loss: 0.020910\n",
      "[173/00151] train_loss: 0.018452\n",
      "[173/00201] train_loss: 0.016809\n",
      "[173/00251] train_loss: 0.017476\n",
      "[173/00301] train_loss: 0.017286\n",
      "[173/00351] train_loss: 0.016035\n",
      "[173/00401] train_loss: 0.016218\n",
      "[173/00451] train_loss: 0.016617\n",
      "[173/00501] train_loss: 0.016630\n",
      "[173/00551] train_loss: 0.016473\n",
      "[173/00601] train_loss: 0.015938\n",
      "[173/00651] train_loss: 0.017815\n",
      "[173/00701] train_loss: 0.016172\n",
      "[173/00751] train_loss: 0.016617\n",
      "[173/00801] train_loss: 0.016138\n",
      "[173/00851] train_loss: 0.017395\n",
      "[173/00901] train_loss: 0.016200\n",
      "[173/00951] train_loss: 0.016059\n",
      "[173/01001] train_loss: 0.016739\n",
      "[173/01051] train_loss: 0.017065\n",
      "[173/01101] train_loss: 0.016464\n",
      "[173/01151] train_loss: 0.017424\n",
      "[173/01201] train_loss: 0.015821\n",
      "[174/00025] train_loss: 0.021698\n",
      "[174/00075] train_loss: 0.022365\n",
      "[174/00125] train_loss: 0.019268\n",
      "[174/00175] train_loss: 0.017549\n",
      "[174/00225] train_loss: 0.017525\n",
      "[174/00275] train_loss: 0.016154\n",
      "[174/00325] train_loss: 0.017023\n",
      "[174/00375] train_loss: 0.016736\n",
      "[174/00425] train_loss: 0.016896\n",
      "[174/00475] train_loss: 0.015610\n",
      "[174/00525] train_loss: 0.016722\n",
      "[174/00575] train_loss: 0.016963\n",
      "[174/00625] train_loss: 0.015669\n",
      "[174/00675] train_loss: 0.016694\n",
      "[174/00725] train_loss: 0.016666\n",
      "[174/00775] train_loss: 0.016412\n",
      "[174/00825] train_loss: 0.015843\n",
      "[174/00875] train_loss: 0.016581\n",
      "[174/00925] train_loss: 0.016884\n",
      "[174/00975] train_loss: 0.016584\n",
      "[174/01025] train_loss: 0.017078\n",
      "[174/01075] train_loss: 0.016709\n",
      "[174/01125] train_loss: 0.016675\n",
      "[174/01175] train_loss: 0.017218\n",
      "[174/01225] train_loss: 0.017065\n",
      "[175/00049] train_loss: 0.026463\n",
      "[175/00099] train_loss: 0.020845\n",
      "[175/00149] train_loss: 0.018578\n",
      "[175/00199] train_loss: 0.017552\n",
      "[175/00249] train_loss: 0.016588\n",
      "[175/00299] train_loss: 0.017092\n",
      "[175/00349] train_loss: 0.016679\n",
      "[175/00399] train_loss: 0.017268\n",
      "[175/00449] train_loss: 0.016465\n",
      "[175/00499] train_loss: 0.016525\n",
      "[175/00549] train_loss: 0.016147\n",
      "[175/00599] train_loss: 0.016369\n",
      "[175/00649] train_loss: 0.016661\n",
      "[175/00699] train_loss: 0.016828\n",
      "[175/00749] train_loss: 0.015741\n",
      "[175/00799] train_loss: 0.016288\n",
      "[175/00849] train_loss: 0.016695\n",
      "[175/00899] train_loss: 0.017654\n",
      "[175/00949] train_loss: 0.017449\n",
      "[175/00999] train_loss: 0.016512\n",
      "[175/01049] train_loss: 0.016951\n",
      "[175/01099] train_loss: 0.016645\n",
      "[175/01149] train_loss: 0.016582\n",
      "[175/01199] train_loss: 0.017025\n",
      "[176/00023] train_loss: 0.021083\n",
      "[176/00073] train_loss: 0.022795\n",
      "[176/00123] train_loss: 0.018795\n",
      "[176/00173] train_loss: 0.017056\n",
      "[176/00223] train_loss: 0.016594\n",
      "[176/00273] train_loss: 0.016519\n",
      "[176/00323] train_loss: 0.017150\n",
      "[176/00373] train_loss: 0.016700\n",
      "[176/00423] train_loss: 0.016614\n",
      "[176/00473] train_loss: 0.016823\n",
      "[176/00523] train_loss: 0.016411\n",
      "[176/00573] train_loss: 0.015946\n",
      "[176/00623] train_loss: 0.017051\n",
      "[176/00673] train_loss: 0.015564\n",
      "[176/00723] train_loss: 0.017182\n",
      "[176/00773] train_loss: 0.016099\n",
      "[176/00823] train_loss: 0.016526\n",
      "[176/00873] train_loss: 0.016356\n",
      "[176/00923] train_loss: 0.016096\n",
      "[176/00973] train_loss: 0.016276\n",
      "[176/01023] train_loss: 0.017336\n",
      "[176/01073] train_loss: 0.016925\n",
      "[176/01123] train_loss: 0.016996\n",
      "[176/01173] train_loss: 0.017219\n",
      "[176/01223] train_loss: 0.017218\n",
      "[177/00047] train_loss: 0.025483\n",
      "[177/00097] train_loss: 0.020348\n",
      "[177/00147] train_loss: 0.019030\n",
      "[177/00197] train_loss: 0.016567\n",
      "[177/00247] train_loss: 0.016419\n",
      "[177/00297] train_loss: 0.016474\n",
      "[177/00347] train_loss: 0.016561\n",
      "[177/00397] train_loss: 0.015845\n",
      "[177/00447] train_loss: 0.016949\n",
      "[177/00497] train_loss: 0.015596\n",
      "[177/00547] train_loss: 0.016452\n",
      "[177/00597] train_loss: 0.016672\n",
      "[177/00647] train_loss: 0.017326\n",
      "[177/00697] train_loss: 0.017086\n",
      "[177/00747] train_loss: 0.016696\n",
      "[177/00797] train_loss: 0.015850\n",
      "[177/00847] train_loss: 0.017519\n",
      "[177/00897] train_loss: 0.017115\n",
      "[177/00947] train_loss: 0.017159\n",
      "[177/00997] train_loss: 0.017036\n",
      "[177/01047] train_loss: 0.017091\n",
      "[177/01097] train_loss: 0.016459\n",
      "[177/01147] train_loss: 0.016296\n",
      "[177/01197] train_loss: 0.016882\n",
      "[178/00021] train_loss: 0.020914\n",
      "[178/00071] train_loss: 0.021278\n",
      "[178/00121] train_loss: 0.018154\n",
      "[178/00171] train_loss: 0.017381\n",
      "[178/00221] train_loss: 0.017509\n",
      "[178/00271] train_loss: 0.016148\n",
      "[178/00321] train_loss: 0.016663\n",
      "[178/00371] train_loss: 0.016873\n",
      "[178/00421] train_loss: 0.016666\n",
      "[178/00471] train_loss: 0.016375\n",
      "[178/00521] train_loss: 0.016615\n",
      "[178/00571] train_loss: 0.016466\n",
      "[178/00621] train_loss: 0.016326\n",
      "[178/00671] train_loss: 0.017153\n",
      "[178/00721] train_loss: 0.016185\n",
      "[178/00771] train_loss: 0.016853\n",
      "[178/00821] train_loss: 0.016305\n",
      "[178/00871] train_loss: 0.017691\n",
      "[178/00921] train_loss: 0.016549\n",
      "[178/00971] train_loss: 0.015864\n",
      "[178/01021] train_loss: 0.016411\n",
      "[178/01071] train_loss: 0.016379\n",
      "[178/01121] train_loss: 0.017341\n",
      "[178/01171] train_loss: 0.016172\n",
      "[178/01221] train_loss: 0.016977\n",
      "[179/00045] train_loss: 0.025062\n",
      "[179/00095] train_loss: 0.019866\n",
      "[179/00145] train_loss: 0.018213\n",
      "[179/00195] train_loss: 0.017791\n",
      "[179/00245] train_loss: 0.017394\n",
      "[179/00295] train_loss: 0.017251\n",
      "[179/00345] train_loss: 0.017460\n",
      "[179/00395] train_loss: 0.017128\n",
      "[179/00445] train_loss: 0.016238\n",
      "[179/00495] train_loss: 0.016163\n",
      "[179/00545] train_loss: 0.016733\n",
      "[179/00595] train_loss: 0.016701\n",
      "[179/00645] train_loss: 0.015789\n",
      "[179/00695] train_loss: 0.016739\n",
      "[179/00745] train_loss: 0.016421\n",
      "[179/00795] train_loss: 0.017103\n",
      "[179/00845] train_loss: 0.016062\n",
      "[179/00895] train_loss: 0.016646\n",
      "[179/00945] train_loss: 0.016642\n",
      "[179/00995] train_loss: 0.016057\n",
      "[179/01045] train_loss: 0.017109\n",
      "[179/01095] train_loss: 0.016485\n",
      "[179/01145] train_loss: 0.017009\n",
      "[179/01195] train_loss: 0.016294\n",
      "[180/00019] train_loss: 0.019879\n",
      "[180/00069] train_loss: 0.022249\n",
      "[180/00119] train_loss: 0.018217\n",
      "[180/00169] train_loss: 0.018202\n",
      "[180/00219] train_loss: 0.017343\n",
      "[180/00269] train_loss: 0.015792\n",
      "[180/00319] train_loss: 0.016818\n",
      "[180/00369] train_loss: 0.017001\n",
      "[180/00419] train_loss: 0.016352\n",
      "[180/00469] train_loss: 0.016355\n",
      "[180/00519] train_loss: 0.016473\n",
      "[180/00569] train_loss: 0.016425\n",
      "[180/00619] train_loss: 0.016713\n",
      "[180/00669] train_loss: 0.015716\n",
      "[180/00719] train_loss: 0.017003\n",
      "[180/00769] train_loss: 0.016140\n",
      "[180/00819] train_loss: 0.016523\n",
      "[180/00869] train_loss: 0.016603\n",
      "[180/00919] train_loss: 0.016862\n",
      "[180/00969] train_loss: 0.016056\n",
      "[180/01019] train_loss: 0.016699\n",
      "[180/01069] train_loss: 0.016517\n",
      "[180/01119] train_loss: 0.016696\n",
      "[180/01169] train_loss: 0.016998\n",
      "[180/01219] train_loss: 0.016984\n",
      "[181/00043] train_loss: 0.023540\n",
      "[181/00093] train_loss: 0.020525\n",
      "[181/00143] train_loss: 0.017336\n",
      "[181/00193] train_loss: 0.016790\n",
      "[181/00243] train_loss: 0.016245\n",
      "[181/00293] train_loss: 0.017342\n",
      "[181/00343] train_loss: 0.016946\n",
      "[181/00393] train_loss: 0.015942\n",
      "[181/00443] train_loss: 0.016765\n",
      "[181/00493] train_loss: 0.016351\n",
      "[181/00543] train_loss: 0.016939\n",
      "[181/00593] train_loss: 0.016615\n",
      "[181/00643] train_loss: 0.017317\n",
      "[181/00693] train_loss: 0.016401\n",
      "[181/00743] train_loss: 0.015409\n",
      "[181/00793] train_loss: 0.016745\n",
      "[181/00843] train_loss: 0.017594\n",
      "[181/00893] train_loss: 0.016626\n",
      "[181/00943] train_loss: 0.016858\n",
      "[181/00993] train_loss: 0.016397\n",
      "[181/01043] train_loss: 0.016976\n",
      "[181/01093] train_loss: 0.016467\n",
      "[181/01143] train_loss: 0.016361\n",
      "[181/01193] train_loss: 0.016855\n",
      "[182/00017] train_loss: 0.020637\n",
      "[182/00067] train_loss: 0.023077\n",
      "[182/00117] train_loss: 0.018923\n",
      "[182/00167] train_loss: 0.017533\n",
      "[182/00217] train_loss: 0.016000\n",
      "[182/00267] train_loss: 0.017195\n",
      "[182/00317] train_loss: 0.016442\n",
      "[182/00367] train_loss: 0.016283\n",
      "[182/00417] train_loss: 0.016703\n",
      "[182/00467] train_loss: 0.015477\n",
      "[182/00517] train_loss: 0.016223\n",
      "[182/00567] train_loss: 0.017231\n",
      "[182/00617] train_loss: 0.015839\n",
      "[182/00667] train_loss: 0.016525\n",
      "[182/00717] train_loss: 0.016817\n",
      "[182/00767] train_loss: 0.017644\n",
      "[182/00817] train_loss: 0.016039\n",
      "[182/00867] train_loss: 0.015835\n",
      "[182/00917] train_loss: 0.016244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/00967] train_loss: 0.016923\n",
      "[182/01017] train_loss: 0.016375\n",
      "[182/01067] train_loss: 0.017306\n",
      "[182/01117] train_loss: 0.016149\n",
      "[182/01167] train_loss: 0.017043\n",
      "[182/01217] train_loss: 0.016756\n",
      "[183/00041] train_loss: 0.024376\n",
      "[183/00091] train_loss: 0.021800\n",
      "[183/00141] train_loss: 0.018765\n",
      "[183/00191] train_loss: 0.016623\n",
      "[183/00241] train_loss: 0.016090\n",
      "[183/00291] train_loss: 0.016831\n",
      "[183/00341] train_loss: 0.016056\n",
      "[183/00391] train_loss: 0.016733\n",
      "[183/00441] train_loss: 0.016614\n",
      "[183/00491] train_loss: 0.016340\n",
      "[183/00541] train_loss: 0.015719\n",
      "[183/00591] train_loss: 0.016808\n",
      "[183/00641] train_loss: 0.015651\n",
      "[183/00691] train_loss: 0.016090\n",
      "[183/00741] train_loss: 0.016139\n",
      "[183/00791] train_loss: 0.016546\n",
      "[183/00841] train_loss: 0.016691\n",
      "[183/00891] train_loss: 0.015838\n",
      "[183/00941] train_loss: 0.017552\n",
      "[183/00991] train_loss: 0.016337\n",
      "[183/01041] train_loss: 0.017214\n",
      "[183/01091] train_loss: 0.016997\n",
      "[183/01141] train_loss: 0.016703\n",
      "[183/01191] train_loss: 0.017031\n",
      "[184/00015] train_loss: 0.021963\n",
      "[184/00065] train_loss: 0.024678\n",
      "[184/00115] train_loss: 0.020027\n",
      "[184/00165] train_loss: 0.019035\n",
      "[184/00215] train_loss: 0.016755\n",
      "[184/00265] train_loss: 0.016857\n",
      "[184/00315] train_loss: 0.016745\n",
      "[184/00365] train_loss: 0.016028\n",
      "[184/00415] train_loss: 0.016740\n",
      "[184/00465] train_loss: 0.016504\n",
      "[184/00515] train_loss: 0.015889\n",
      "[184/00565] train_loss: 0.016017\n",
      "[184/00615] train_loss: 0.016579\n",
      "[184/00665] train_loss: 0.016177\n",
      "[184/00715] train_loss: 0.016828\n",
      "[184/00765] train_loss: 0.016078\n",
      "[184/00815] train_loss: 0.016961\n",
      "[184/00865] train_loss: 0.015957\n",
      "[184/00915] train_loss: 0.016521\n",
      "[184/00965] train_loss: 0.017091\n",
      "[184/01015] train_loss: 0.015925\n",
      "[184/01065] train_loss: 0.018185\n",
      "[184/01115] train_loss: 0.016366\n",
      "[184/01165] train_loss: 0.016213\n",
      "[184/01215] train_loss: 0.015715\n",
      "[185/00039] train_loss: 0.023029\n",
      "[185/00089] train_loss: 0.021535\n",
      "[185/00139] train_loss: 0.017808\n",
      "[185/00189] train_loss: 0.017405\n",
      "[185/00239] train_loss: 0.016604\n",
      "[185/00289] train_loss: 0.017687\n",
      "[185/00339] train_loss: 0.016939\n",
      "[185/00389] train_loss: 0.016464\n",
      "[185/00439] train_loss: 0.016219\n",
      "[185/00489] train_loss: 0.017273\n",
      "[185/00539] train_loss: 0.016930\n",
      "[185/00589] train_loss: 0.017061\n",
      "[185/00639] train_loss: 0.017247\n",
      "[185/00689] train_loss: 0.016514\n",
      "[185/00739] train_loss: 0.017036\n",
      "[185/00789] train_loss: 0.015628\n",
      "[185/00839] train_loss: 0.016388\n",
      "[185/00889] train_loss: 0.016418\n",
      "[185/00939] train_loss: 0.017034\n",
      "[185/00989] train_loss: 0.016730\n",
      "[185/01039] train_loss: 0.015899\n",
      "[185/01089] train_loss: 0.016833\n",
      "[185/01139] train_loss: 0.016394\n",
      "[185/01189] train_loss: 0.016660\n",
      "[186/00013] train_loss: 0.020469\n",
      "[186/00063] train_loss: 0.025193\n",
      "[186/00113] train_loss: 0.019807\n",
      "[186/00163] train_loss: 0.017772\n",
      "[186/00213] train_loss: 0.016821\n",
      "[186/00263] train_loss: 0.016843\n",
      "[186/00313] train_loss: 0.016430\n",
      "[186/00363] train_loss: 0.016599\n",
      "[186/00413] train_loss: 0.016351\n",
      "[186/00463] train_loss: 0.016338\n",
      "[186/00513] train_loss: 0.016099\n",
      "[186/00563] train_loss: 0.016657\n",
      "[186/00613] train_loss: 0.016419\n",
      "[186/00663] train_loss: 0.016293\n",
      "[186/00713] train_loss: 0.016298\n",
      "[186/00763] train_loss: 0.017533\n",
      "[186/00813] train_loss: 0.015711\n",
      "[186/00863] train_loss: 0.016449\n",
      "[186/00913] train_loss: 0.015931\n",
      "[186/00963] train_loss: 0.017370\n",
      "[186/01013] train_loss: 0.016369\n",
      "[186/01063] train_loss: 0.017172\n",
      "[186/01113] train_loss: 0.017413\n",
      "[186/01163] train_loss: 0.017853\n",
      "[186/01213] train_loss: 0.016610\n",
      "[187/00037] train_loss: 0.022208\n",
      "[187/00087] train_loss: 0.020683\n",
      "[187/00137] train_loss: 0.018267\n",
      "[187/00187] train_loss: 0.016258\n",
      "[187/00237] train_loss: 0.017096\n",
      "[187/00287] train_loss: 0.016507\n",
      "[187/00337] train_loss: 0.016633\n",
      "[187/00387] train_loss: 0.016592\n",
      "[187/00437] train_loss: 0.015852\n",
      "[187/00487] train_loss: 0.016231\n",
      "[187/00537] train_loss: 0.016047\n",
      "[187/00587] train_loss: 0.016017\n",
      "[187/00637] train_loss: 0.016807\n",
      "[187/00687] train_loss: 0.016081\n",
      "[187/00737] train_loss: 0.017372\n",
      "[187/00787] train_loss: 0.016779\n",
      "[187/00837] train_loss: 0.015853\n",
      "[187/00887] train_loss: 0.016626\n",
      "[187/00937] train_loss: 0.016721\n",
      "[187/00987] train_loss: 0.016681\n",
      "[187/01037] train_loss: 0.015840\n",
      "[187/01087] train_loss: 0.016980\n",
      "[187/01137] train_loss: 0.016213\n",
      "[187/01187] train_loss: 0.015987\n",
      "[188/00011] train_loss: 0.018644\n",
      "[188/00061] train_loss: 0.022580\n",
      "[188/00111] train_loss: 0.020742\n",
      "[188/00161] train_loss: 0.017156\n",
      "[188/00211] train_loss: 0.016832\n",
      "[188/00261] train_loss: 0.016801\n",
      "[188/00311] train_loss: 0.016957\n",
      "[188/00361] train_loss: 0.016843\n",
      "[188/00411] train_loss: 0.017289\n",
      "[188/00461] train_loss: 0.017325\n",
      "[188/00511] train_loss: 0.015625\n",
      "[188/00561] train_loss: 0.016191\n",
      "[188/00611] train_loss: 0.017148\n",
      "[188/00661] train_loss: 0.016928\n",
      "[188/00711] train_loss: 0.016356\n",
      "[188/00761] train_loss: 0.016195\n",
      "[188/00811] train_loss: 0.016724\n",
      "[188/00861] train_loss: 0.016352\n",
      "[188/00911] train_loss: 0.016254\n",
      "[188/00961] train_loss: 0.017110\n",
      "[188/01011] train_loss: 0.015674\n",
      "[188/01061] train_loss: 0.017212\n",
      "[188/01111] train_loss: 0.016680\n",
      "[188/01161] train_loss: 0.016720\n",
      "[188/01211] train_loss: 0.016162\n",
      "[189/00035] train_loss: 0.021814\n",
      "[189/00085] train_loss: 0.019804\n",
      "[189/00135] train_loss: 0.017745\n",
      "[189/00185] train_loss: 0.016346\n",
      "[189/00235] train_loss: 0.016818\n",
      "[189/00285] train_loss: 0.017007\n",
      "[189/00335] train_loss: 0.016131\n",
      "[189/00385] train_loss: 0.015703\n",
      "[189/00435] train_loss: 0.015866\n",
      "[189/00485] train_loss: 0.015645\n",
      "[189/00535] train_loss: 0.016349\n",
      "[189/00585] train_loss: 0.016373\n",
      "[189/00635] train_loss: 0.015873\n",
      "[189/00685] train_loss: 0.016493\n",
      "[189/00735] train_loss: 0.016763\n",
      "[189/00785] train_loss: 0.016248\n",
      "[189/00835] train_loss: 0.018287\n",
      "[189/00885] train_loss: 0.016361\n",
      "[189/00935] train_loss: 0.016022\n",
      "[189/00985] train_loss: 0.016941\n",
      "[189/01035] train_loss: 0.016381\n",
      "[189/01085] train_loss: 0.017805\n",
      "[189/01135] train_loss: 0.017608\n",
      "[189/01185] train_loss: 0.017343\n",
      "[190/00009] train_loss: 0.019701\n",
      "[190/00059] train_loss: 0.023094\n",
      "[190/00109] train_loss: 0.019845\n",
      "[190/00159] train_loss: 0.017192\n",
      "[190/00209] train_loss: 0.017167\n",
      "[190/00259] train_loss: 0.016918\n",
      "[190/00309] train_loss: 0.017595\n",
      "[190/00359] train_loss: 0.016614\n",
      "[190/00409] train_loss: 0.017087\n",
      "[190/00459] train_loss: 0.016162\n",
      "[190/00509] train_loss: 0.015871\n",
      "[190/00559] train_loss: 0.015713\n",
      "[190/00609] train_loss: 0.015761\n",
      "[190/00659] train_loss: 0.016384\n",
      "[190/00709] train_loss: 0.016110\n",
      "[190/00759] train_loss: 0.016445\n",
      "[190/00809] train_loss: 0.016602\n",
      "[190/00859] train_loss: 0.017820\n",
      "[190/00909] train_loss: 0.015931\n",
      "[190/00959] train_loss: 0.017252\n",
      "[190/01009] train_loss: 0.016754\n",
      "[190/01059] train_loss: 0.016894\n",
      "[190/01109] train_loss: 0.016364\n",
      "[190/01159] train_loss: 0.017544\n",
      "[190/01209] train_loss: 0.015559\n",
      "[191/00033] train_loss: 0.022679\n",
      "[191/00083] train_loss: 0.021680\n",
      "[191/00133] train_loss: 0.018147\n",
      "[191/00183] train_loss: 0.017090\n",
      "[191/00233] train_loss: 0.017212\n",
      "[191/00283] train_loss: 0.016370\n",
      "[191/00333] train_loss: 0.017064\n",
      "[191/00383] train_loss: 0.016473\n",
      "[191/00433] train_loss: 0.016538\n",
      "[191/00483] train_loss: 0.016312\n",
      "[191/00533] train_loss: 0.016632\n",
      "[191/00583] train_loss: 0.015594\n",
      "[191/00633] train_loss: 0.016356\n",
      "[191/00683] train_loss: 0.015878\n",
      "[191/00733] train_loss: 0.017222\n",
      "[191/00783] train_loss: 0.016540\n",
      "[191/00833] train_loss: 0.015938\n",
      "[191/00883] train_loss: 0.016968\n",
      "[191/00933] train_loss: 0.016304\n",
      "[191/00983] train_loss: 0.016472\n",
      "[191/01033] train_loss: 0.016930\n",
      "[191/01083] train_loss: 0.016567\n",
      "[191/01133] train_loss: 0.018047\n",
      "[191/01183] train_loss: 0.015986\n",
      "[192/00007] train_loss: 0.018342\n",
      "[192/00057] train_loss: 0.023867\n",
      "[192/00107] train_loss: 0.019631\n",
      "[192/00157] train_loss: 0.018263\n",
      "[192/00207] train_loss: 0.016802\n",
      "[192/00257] train_loss: 0.016223\n",
      "[192/00307] train_loss: 0.017280\n",
      "[192/00357] train_loss: 0.016631\n",
      "[192/00407] train_loss: 0.016252\n",
      "[192/00457] train_loss: 0.016956\n",
      "[192/00507] train_loss: 0.016689\n",
      "[192/00557] train_loss: 0.016381\n",
      "[192/00607] train_loss: 0.015752\n",
      "[192/00657] train_loss: 0.016562\n",
      "[192/00707] train_loss: 0.016290\n",
      "[192/00757] train_loss: 0.016230\n",
      "[192/00807] train_loss: 0.017160\n",
      "[192/00857] train_loss: 0.016943\n",
      "[192/00907] train_loss: 0.017318\n",
      "[192/00957] train_loss: 0.017411\n",
      "[192/01007] train_loss: 0.016563\n",
      "[192/01057] train_loss: 0.016961\n",
      "[192/01107] train_loss: 0.016336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192/01157] train_loss: 0.015520\n",
      "[192/01207] train_loss: 0.016280\n",
      "[193/00031] train_loss: 0.022324\n",
      "[193/00081] train_loss: 0.021364\n",
      "[193/00131] train_loss: 0.018410\n",
      "[193/00181] train_loss: 0.016401\n",
      "[193/00231] train_loss: 0.016254\n",
      "[193/00281] train_loss: 0.016513\n",
      "[193/00331] train_loss: 0.015945\n",
      "[193/00381] train_loss: 0.016767\n",
      "[193/00431] train_loss: 0.016238\n",
      "[193/00481] train_loss: 0.016864\n",
      "[193/00531] train_loss: 0.016840\n",
      "[193/00581] train_loss: 0.016591\n",
      "[193/00631] train_loss: 0.016887\n",
      "[193/00681] train_loss: 0.015377\n",
      "[193/00731] train_loss: 0.016516\n",
      "[193/00781] train_loss: 0.016363\n",
      "[193/00831] train_loss: 0.016499\n",
      "[193/00881] train_loss: 0.016072\n",
      "[193/00931] train_loss: 0.016479\n",
      "[193/00981] train_loss: 0.016935\n",
      "[193/01031] train_loss: 0.016496\n",
      "[193/01081] train_loss: 0.017127\n",
      "[193/01131] train_loss: 0.015700\n",
      "[193/01181] train_loss: 0.017069\n",
      "[194/00005] train_loss: 0.018208\n",
      "[194/00055] train_loss: 0.023244\n",
      "[194/00105] train_loss: 0.019174\n",
      "[194/00155] train_loss: 0.017708\n",
      "[194/00205] train_loss: 0.017733\n",
      "[194/00255] train_loss: 0.016327\n",
      "[194/00305] train_loss: 0.015745\n",
      "[194/00355] train_loss: 0.017827\n",
      "[194/00405] train_loss: 0.016859\n",
      "[194/00455] train_loss: 0.015707\n",
      "[194/00505] train_loss: 0.016593\n",
      "[194/00555] train_loss: 0.017065\n",
      "[194/00605] train_loss: 0.015452\n",
      "[194/00655] train_loss: 0.016032\n",
      "[194/00705] train_loss: 0.016618\n",
      "[194/00755] train_loss: 0.016067\n",
      "[194/00805] train_loss: 0.017087\n",
      "[194/00855] train_loss: 0.017608\n",
      "[194/00905] train_loss: 0.016235\n",
      "[194/00955] train_loss: 0.015502\n",
      "[194/01005] train_loss: 0.016558\n",
      "[194/01055] train_loss: 0.017207\n",
      "[194/01105] train_loss: 0.016515\n",
      "[194/01155] train_loss: 0.016693\n",
      "[194/01205] train_loss: 0.016558\n",
      "[195/00029] train_loss: 0.022968\n",
      "[195/00079] train_loss: 0.022115\n",
      "[195/00129] train_loss: 0.018322\n",
      "[195/00179] train_loss: 0.017983\n",
      "[195/00229] train_loss: 0.016876\n",
      "[195/00279] train_loss: 0.016516\n",
      "[195/00329] train_loss: 0.017513\n",
      "[195/00379] train_loss: 0.016042\n",
      "[195/00429] train_loss: 0.015673\n",
      "[195/00479] train_loss: 0.016799\n",
      "[195/00529] train_loss: 0.016397\n",
      "[195/00579] train_loss: 0.016500\n",
      "[195/00629] train_loss: 0.015973\n",
      "[195/00679] train_loss: 0.016249\n",
      "[195/00729] train_loss: 0.016181\n",
      "[195/00779] train_loss: 0.016569\n",
      "[195/00829] train_loss: 0.016927\n",
      "[195/00879] train_loss: 0.016563\n",
      "[195/00929] train_loss: 0.017428\n",
      "[195/00979] train_loss: 0.017418\n",
      "[195/01029] train_loss: 0.016983\n",
      "[195/01079] train_loss: 0.016117\n",
      "[195/01129] train_loss: 0.016432\n",
      "[195/01179] train_loss: 0.016910\n",
      "[196/00003] train_loss: 0.018042\n",
      "[196/00053] train_loss: 0.025261\n",
      "[196/00103] train_loss: 0.020100\n",
      "[196/00153] train_loss: 0.018492\n",
      "[196/00203] train_loss: 0.017275\n",
      "[196/00253] train_loss: 0.016002\n",
      "[196/00303] train_loss: 0.017113\n",
      "[196/00353] train_loss: 0.016661\n",
      "[196/00403] train_loss: 0.016465\n",
      "[196/00453] train_loss: 0.016102\n",
      "[196/00503] train_loss: 0.016035\n",
      "[196/00553] train_loss: 0.017074\n",
      "[196/00603] train_loss: 0.015644\n",
      "[196/00653] train_loss: 0.016381\n",
      "[196/00703] train_loss: 0.016048\n",
      "[196/00753] train_loss: 0.016414\n",
      "[196/00803] train_loss: 0.016448\n",
      "[196/00853] train_loss: 0.016269\n",
      "[196/00903] train_loss: 0.016411\n",
      "[196/00953] train_loss: 0.016693\n",
      "[196/01003] train_loss: 0.015883\n",
      "[196/01053] train_loss: 0.016382\n",
      "[196/01103] train_loss: 0.017548\n",
      "[196/01153] train_loss: 0.016402\n",
      "[196/01203] train_loss: 0.016279\n",
      "[197/00027] train_loss: 0.022021\n",
      "[197/00077] train_loss: 0.021209\n",
      "[197/00127] train_loss: 0.018897\n",
      "[197/00177] train_loss: 0.017752\n",
      "[197/00227] train_loss: 0.015675\n",
      "[197/00277] train_loss: 0.017070\n",
      "[197/00327] train_loss: 0.016766\n",
      "[197/00377] train_loss: 0.016190\n",
      "[197/00427] train_loss: 0.015670\n",
      "[197/00477] train_loss: 0.017154\n",
      "[197/00527] train_loss: 0.015912\n",
      "[197/00577] train_loss: 0.016334\n",
      "[197/00627] train_loss: 0.017155\n",
      "[197/00677] train_loss: 0.016323\n",
      "[197/00727] train_loss: 0.015605\n",
      "[197/00777] train_loss: 0.016964\n",
      "[197/00827] train_loss: 0.016409\n",
      "[197/00877] train_loss: 0.016200\n",
      "[197/00927] train_loss: 0.016799\n",
      "[197/00977] train_loss: 0.016223\n",
      "[197/01027] train_loss: 0.016016\n",
      "[197/01077] train_loss: 0.016910\n",
      "[197/01127] train_loss: 0.015596\n",
      "[197/01177] train_loss: 0.016092\n",
      "[198/00001] train_loss: 0.016749\n",
      "[198/00051] train_loss: 0.024999\n",
      "[198/00101] train_loss: 0.020354\n",
      "[198/00151] train_loss: 0.016573\n",
      "[198/00201] train_loss: 0.017910\n",
      "[198/00251] train_loss: 0.017002\n",
      "[198/00301] train_loss: 0.016450\n",
      "[198/00351] train_loss: 0.016237\n",
      "[198/00401] train_loss: 0.015659\n",
      "[198/00451] train_loss: 0.015845\n",
      "[198/00501] train_loss: 0.017003\n",
      "[198/00551] train_loss: 0.016956\n",
      "[198/00601] train_loss: 0.017182\n",
      "[198/00651] train_loss: 0.015563\n",
      "[198/00701] train_loss: 0.016727\n",
      "[198/00751] train_loss: 0.015632\n",
      "[198/00801] train_loss: 0.016492\n",
      "[198/00851] train_loss: 0.016704\n",
      "[198/00901] train_loss: 0.016638\n",
      "[198/00951] train_loss: 0.016926\n",
      "[198/01001] train_loss: 0.016486\n",
      "[198/01051] train_loss: 0.016507\n",
      "[198/01101] train_loss: 0.017470\n",
      "[198/01151] train_loss: 0.016057\n",
      "[198/01201] train_loss: 0.017806\n",
      "[199/00025] train_loss: 0.021617\n",
      "[199/00075] train_loss: 0.022115\n",
      "[199/00125] train_loss: 0.018381\n",
      "[199/00175] train_loss: 0.017362\n",
      "[199/00225] train_loss: 0.016839\n",
      "[199/00275] train_loss: 0.016893\n",
      "[199/00325] train_loss: 0.016764\n",
      "[199/00375] train_loss: 0.016107\n",
      "[199/00425] train_loss: 0.015350\n",
      "[199/00475] train_loss: 0.016947\n",
      "[199/00525] train_loss: 0.016066\n",
      "[199/00575] train_loss: 0.015944\n",
      "[199/00625] train_loss: 0.016247\n",
      "[199/00675] train_loss: 0.017455\n",
      "[199/00725] train_loss: 0.017170\n",
      "[199/00775] train_loss: 0.016326\n",
      "[199/00825] train_loss: 0.015567\n",
      "[199/00875] train_loss: 0.016433\n",
      "[199/00925] train_loss: 0.016345\n",
      "[199/00975] train_loss: 0.017544\n",
      "[199/01025] train_loss: 0.016641\n",
      "[199/01075] train_loss: 0.016976\n",
      "[199/01125] train_loss: 0.016766\n",
      "[199/01175] train_loss: 0.016101\n",
      "[199/01225] train_loss: 0.016318\n",
      "[200/00049] train_loss: 0.025055\n",
      "[200/00099] train_loss: 0.019419\n",
      "[200/00149] train_loss: 0.017272\n",
      "[200/00199] train_loss: 0.018202\n",
      "[200/00249] train_loss: 0.017116\n",
      "[200/00299] train_loss: 0.017525\n",
      "[200/00349] train_loss: 0.016473\n",
      "[200/00399] train_loss: 0.017130\n",
      "[200/00449] train_loss: 0.016443\n",
      "[200/00499] train_loss: 0.016480\n",
      "[200/00549] train_loss: 0.015834\n",
      "[200/00599] train_loss: 0.016139\n",
      "[200/00649] train_loss: 0.015562\n",
      "[200/00699] train_loss: 0.016203\n",
      "[200/00749] train_loss: 0.015835\n",
      "[200/00799] train_loss: 0.016591\n",
      "[200/00849] train_loss: 0.016679\n",
      "[200/00899] train_loss: 0.016553\n",
      "[200/00949] train_loss: 0.016031\n",
      "[200/00999] train_loss: 0.016386\n",
      "[200/01049] train_loss: 0.016946\n",
      "[200/01099] train_loss: 0.015259\n",
      "[200/01149] train_loss: 0.016453\n",
      "[200/01199] train_loss: 0.016380\n",
      "[201/00023] train_loss: 0.021999\n",
      "[201/00073] train_loss: 0.022031\n",
      "[201/00123] train_loss: 0.018275\n",
      "[201/00173] train_loss: 0.017863\n",
      "[201/00223] train_loss: 0.017322\n",
      "[201/00273] train_loss: 0.017017\n",
      "[201/00323] train_loss: 0.016929\n",
      "[201/00373] train_loss: 0.016118\n",
      "[201/00423] train_loss: 0.016616\n",
      "[201/00473] train_loss: 0.015500\n",
      "[201/00523] train_loss: 0.016596\n",
      "[201/00573] train_loss: 0.016543\n",
      "[201/00623] train_loss: 0.016160\n",
      "[201/00673] train_loss: 0.016886\n",
      "[201/00723] train_loss: 0.016481\n",
      "[201/00773] train_loss: 0.015833\n",
      "[201/00823] train_loss: 0.015420\n",
      "[201/00873] train_loss: 0.015877\n",
      "[201/00923] train_loss: 0.016480\n",
      "[201/00973] train_loss: 0.016816\n",
      "[201/01023] train_loss: 0.016929\n",
      "[201/01073] train_loss: 0.017641\n",
      "[201/01123] train_loss: 0.017560\n",
      "[201/01173] train_loss: 0.016572\n",
      "[201/01223] train_loss: 0.016218\n",
      "[202/00047] train_loss: 0.024110\n",
      "[202/00097] train_loss: 0.020268\n",
      "[202/00147] train_loss: 0.018629\n",
      "[202/00197] train_loss: 0.017159\n",
      "[202/00247] train_loss: 0.017162\n",
      "[202/00297] train_loss: 0.016752\n",
      "[202/00347] train_loss: 0.015244\n",
      "[202/00397] train_loss: 0.016281\n",
      "[202/00447] train_loss: 0.016053\n",
      "[202/00497] train_loss: 0.016179\n",
      "[202/00547] train_loss: 0.015906\n",
      "[202/00597] train_loss: 0.016703\n",
      "[202/00647] train_loss: 0.016422\n",
      "[202/00697] train_loss: 0.016678\n",
      "[202/00747] train_loss: 0.016369\n",
      "[202/00797] train_loss: 0.016267\n",
      "[202/00847] train_loss: 0.016413\n",
      "[202/00897] train_loss: 0.016542\n",
      "[202/00947] train_loss: 0.015632\n",
      "[202/00997] train_loss: 0.016358\n",
      "[202/01047] train_loss: 0.017432\n",
      "[202/01097] train_loss: 0.014980\n",
      "[202/01147] train_loss: 0.016415\n",
      "[202/01197] train_loss: 0.017646\n",
      "[203/00021] train_loss: 0.019294\n",
      "[203/00071] train_loss: 0.023639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203/00121] train_loss: 0.018257\n",
      "[203/00171] train_loss: 0.016993\n",
      "[203/00221] train_loss: 0.016623\n",
      "[203/00271] train_loss: 0.015843\n",
      "[203/00321] train_loss: 0.017419\n",
      "[203/00371] train_loss: 0.016644\n",
      "[203/00421] train_loss: 0.015953\n",
      "[203/00471] train_loss: 0.016270\n",
      "[203/00521] train_loss: 0.015623\n",
      "[203/00571] train_loss: 0.016171\n",
      "[203/00621] train_loss: 0.016489\n",
      "[203/00671] train_loss: 0.016992\n",
      "[203/00721] train_loss: 0.016217\n",
      "[203/00771] train_loss: 0.016666\n",
      "[203/00821] train_loss: 0.016336\n",
      "[203/00871] train_loss: 0.016401\n",
      "[203/00921] train_loss: 0.016806\n",
      "[203/00971] train_loss: 0.016177\n",
      "[203/01021] train_loss: 0.015859\n",
      "[203/01071] train_loss: 0.016992\n",
      "[203/01121] train_loss: 0.017847\n",
      "[203/01171] train_loss: 0.016707\n",
      "[203/01221] train_loss: 0.016281\n",
      "[204/00045] train_loss: 0.024369\n",
      "[204/00095] train_loss: 0.020671\n",
      "[204/00145] train_loss: 0.018070\n",
      "[204/00195] train_loss: 0.016346\n",
      "[204/00245] train_loss: 0.016953\n",
      "[204/00295] train_loss: 0.016426\n",
      "[204/00345] train_loss: 0.016677\n",
      "[204/00395] train_loss: 0.015861\n",
      "[204/00445] train_loss: 0.016457\n",
      "[204/00495] train_loss: 0.015771\n",
      "[204/00545] train_loss: 0.016494\n",
      "[204/00595] train_loss: 0.016552\n",
      "[204/00645] train_loss: 0.016466\n",
      "[204/00695] train_loss: 0.015929\n",
      "[204/00745] train_loss: 0.016642\n",
      "[204/00795] train_loss: 0.018028\n",
      "[204/00845] train_loss: 0.016180\n",
      "[204/00895] train_loss: 0.016934\n",
      "[204/00945] train_loss: 0.015903\n",
      "[204/00995] train_loss: 0.016007\n",
      "[204/01045] train_loss: 0.017000\n",
      "[204/01095] train_loss: 0.016562\n",
      "[204/01145] train_loss: 0.016257\n",
      "[204/01195] train_loss: 0.016963\n",
      "[205/00019] train_loss: 0.021088\n",
      "[205/00069] train_loss: 0.021613\n",
      "[205/00119] train_loss: 0.017544\n",
      "[205/00169] train_loss: 0.017163\n",
      "[205/00219] train_loss: 0.017217\n",
      "[205/00269] train_loss: 0.017715\n",
      "[205/00319] train_loss: 0.015941\n",
      "[205/00369] train_loss: 0.016802\n",
      "[205/00419] train_loss: 0.016405\n",
      "[205/00469] train_loss: 0.016954\n",
      "[205/00519] train_loss: 0.015768\n",
      "[205/00569] train_loss: 0.015706\n",
      "[205/00619] train_loss: 0.016480\n",
      "[205/00669] train_loss: 0.016023\n",
      "[205/00719] train_loss: 0.015845\n",
      "[205/00769] train_loss: 0.017299\n",
      "[205/00819] train_loss: 0.016610\n",
      "[205/00869] train_loss: 0.016075\n",
      "[205/00919] train_loss: 0.016463\n",
      "[205/00969] train_loss: 0.016768\n",
      "[205/01019] train_loss: 0.016491\n",
      "[205/01069] train_loss: 0.015943\n",
      "[205/01119] train_loss: 0.017216\n",
      "[205/01169] train_loss: 0.017055\n",
      "[205/01219] train_loss: 0.016406\n",
      "[206/00043] train_loss: 0.023701\n",
      "[206/00093] train_loss: 0.021793\n",
      "[206/00143] train_loss: 0.018398\n",
      "[206/00193] train_loss: 0.017049\n",
      "[206/00243] train_loss: 0.017882\n",
      "[206/00293] train_loss: 0.016356\n",
      "[206/00343] train_loss: 0.016694\n",
      "[206/00393] train_loss: 0.016806\n",
      "[206/00443] train_loss: 0.016781\n",
      "[206/00493] train_loss: 0.016526\n",
      "[206/00543] train_loss: 0.016735\n",
      "[206/00593] train_loss: 0.016840\n",
      "[206/00643] train_loss: 0.015960\n",
      "[206/00693] train_loss: 0.016718\n",
      "[206/00743] train_loss: 0.016050\n",
      "[206/00793] train_loss: 0.016332\n",
      "[206/00843] train_loss: 0.016709\n",
      "[206/00893] train_loss: 0.016509\n",
      "[206/00943] train_loss: 0.015920\n",
      "[206/00993] train_loss: 0.016710\n",
      "[206/01043] train_loss: 0.016679\n",
      "[206/01093] train_loss: 0.017009\n",
      "[206/01143] train_loss: 0.016763\n",
      "[206/01193] train_loss: 0.016369\n",
      "[207/00017] train_loss: 0.019180\n",
      "[207/00067] train_loss: 0.022613\n",
      "[207/00117] train_loss: 0.019433\n",
      "[207/00167] train_loss: 0.016989\n",
      "[207/00217] train_loss: 0.017631\n",
      "[207/00267] train_loss: 0.017455\n",
      "[207/00317] train_loss: 0.015577\n",
      "[207/00367] train_loss: 0.016938\n",
      "[207/00417] train_loss: 0.016750\n",
      "[207/00467] train_loss: 0.015732\n",
      "[207/00517] train_loss: 0.016660\n",
      "[207/00567] train_loss: 0.016059\n",
      "[207/00617] train_loss: 0.015540\n",
      "[207/00667] train_loss: 0.017229\n",
      "[207/00717] train_loss: 0.016046\n",
      "[207/00767] train_loss: 0.016672\n",
      "[207/00817] train_loss: 0.016262\n",
      "[207/00867] train_loss: 0.016446\n",
      "[207/00917] train_loss: 0.015836\n",
      "[207/00967] train_loss: 0.016886\n",
      "[207/01017] train_loss: 0.016844\n",
      "[207/01067] train_loss: 0.016466\n",
      "[207/01117] train_loss: 0.016472\n",
      "[207/01167] train_loss: 0.016541\n",
      "[207/01217] train_loss: 0.016528\n",
      "[208/00041] train_loss: 0.023690\n",
      "[208/00091] train_loss: 0.020649\n",
      "[208/00141] train_loss: 0.018501\n",
      "[208/00191] train_loss: 0.016225\n",
      "[208/00241] train_loss: 0.016817\n",
      "[208/00291] train_loss: 0.016971\n",
      "[208/00341] train_loss: 0.016673\n",
      "[208/00391] train_loss: 0.016647\n",
      "[208/00441] train_loss: 0.016275\n",
      "[208/00491] train_loss: 0.015918\n",
      "[208/00541] train_loss: 0.016703\n",
      "[208/00591] train_loss: 0.016375\n",
      "[208/00641] train_loss: 0.015873\n",
      "[208/00691] train_loss: 0.016486\n",
      "[208/00741] train_loss: 0.016715\n",
      "[208/00791] train_loss: 0.017177\n",
      "[208/00841] train_loss: 0.015755\n",
      "[208/00891] train_loss: 0.015765\n",
      "[208/00941] train_loss: 0.016244\n",
      "[208/00991] train_loss: 0.017094\n",
      "[208/01041] train_loss: 0.015829\n",
      "[208/01091] train_loss: 0.016281\n",
      "[208/01141] train_loss: 0.016269\n",
      "[208/01191] train_loss: 0.016735\n",
      "[209/00015] train_loss: 0.020538\n",
      "[209/00065] train_loss: 0.022637\n",
      "[209/00115] train_loss: 0.019660\n",
      "[209/00165] train_loss: 0.017136\n",
      "[209/00215] train_loss: 0.017218\n",
      "[209/00265] train_loss: 0.016077\n",
      "[209/00315] train_loss: 0.017106\n",
      "[209/00365] train_loss: 0.016117\n",
      "[209/00415] train_loss: 0.015824\n",
      "[209/00465] train_loss: 0.016517\n",
      "[209/00515] train_loss: 0.015355\n",
      "[209/00565] train_loss: 0.016878\n",
      "[209/00615] train_loss: 0.017659\n",
      "[209/00665] train_loss: 0.016961\n",
      "[209/00715] train_loss: 0.016486\n",
      "[209/00765] train_loss: 0.015814\n",
      "[209/00815] train_loss: 0.016752\n",
      "[209/00865] train_loss: 0.016527\n",
      "[209/00915] train_loss: 0.017434\n",
      "[209/00965] train_loss: 0.016256\n",
      "[209/01015] train_loss: 0.016278\n",
      "[209/01065] train_loss: 0.015599\n",
      "[209/01115] train_loss: 0.016724\n",
      "[209/01165] train_loss: 0.015681\n",
      "[209/01215] train_loss: 0.016039\n",
      "[210/00039] train_loss: 0.022905\n",
      "[210/00089] train_loss: 0.020151\n",
      "[210/00139] train_loss: 0.018598\n",
      "[210/00189] train_loss: 0.016965\n",
      "[210/00239] train_loss: 0.016100\n",
      "[210/00289] train_loss: 0.017458\n",
      "[210/00339] train_loss: 0.016448\n",
      "[210/00389] train_loss: 0.016383\n",
      "[210/00439] train_loss: 0.016472\n",
      "[210/00489] train_loss: 0.016355\n",
      "[210/00539] train_loss: 0.015994\n",
      "[210/00589] train_loss: 0.016395\n",
      "[210/00639] train_loss: 0.016359\n",
      "[210/00689] train_loss: 0.016400\n",
      "[210/00739] train_loss: 0.016159\n",
      "[210/00789] train_loss: 0.016623\n",
      "[210/00839] train_loss: 0.016132\n",
      "[210/00889] train_loss: 0.016691\n",
      "[210/00939] train_loss: 0.016020\n",
      "[210/00989] train_loss: 0.016825\n",
      "[210/01039] train_loss: 0.016526\n",
      "[210/01089] train_loss: 0.016769\n",
      "[210/01139] train_loss: 0.017507\n",
      "[210/01189] train_loss: 0.015896\n",
      "[211/00013] train_loss: 0.019854\n",
      "[211/00063] train_loss: 0.023469\n",
      "[211/00113] train_loss: 0.019198\n",
      "[211/00163] train_loss: 0.017148\n",
      "[211/00213] train_loss: 0.016406\n",
      "[211/00263] train_loss: 0.017405\n",
      "[211/00313] train_loss: 0.016534\n",
      "[211/00363] train_loss: 0.016588\n",
      "[211/00413] train_loss: 0.016204\n",
      "[211/00463] train_loss: 0.016214\n",
      "[211/00513] train_loss: 0.016078\n",
      "[211/00563] train_loss: 0.016282\n",
      "[211/00613] train_loss: 0.017006\n",
      "[211/00663] train_loss: 0.016647\n",
      "[211/00713] train_loss: 0.015767\n",
      "[211/00763] train_loss: 0.016598\n",
      "[211/00813] train_loss: 0.016861\n",
      "[211/00863] train_loss: 0.016209\n",
      "[211/00913] train_loss: 0.016401\n",
      "[211/00963] train_loss: 0.016604\n",
      "[211/01013] train_loss: 0.016371\n",
      "[211/01063] train_loss: 0.015629\n",
      "[211/01113] train_loss: 0.016971\n",
      "[211/01163] train_loss: 0.017565\n",
      "[211/01213] train_loss: 0.016331\n",
      "[212/00037] train_loss: 0.022670\n",
      "[212/00087] train_loss: 0.020583\n",
      "[212/00137] train_loss: 0.018951\n",
      "[212/00187] train_loss: 0.016699\n",
      "[212/00237] train_loss: 0.016570\n",
      "[212/00287] train_loss: 0.016227\n",
      "[212/00337] train_loss: 0.016104\n",
      "[212/00387] train_loss: 0.016218\n",
      "[212/00437] train_loss: 0.016022\n",
      "[212/00487] train_loss: 0.016390\n",
      "[212/00537] train_loss: 0.016012\n",
      "[212/00587] train_loss: 0.016996\n",
      "[212/00637] train_loss: 0.016337\n",
      "[212/00687] train_loss: 0.016447\n",
      "[212/00737] train_loss: 0.016997\n",
      "[212/00787] train_loss: 0.016698\n",
      "[212/00837] train_loss: 0.016069\n",
      "[212/00887] train_loss: 0.016571\n",
      "[212/00937] train_loss: 0.016667\n",
      "[212/00987] train_loss: 0.016185\n",
      "[212/01037] train_loss: 0.015964\n",
      "[212/01087] train_loss: 0.014866\n",
      "[212/01137] train_loss: 0.016430\n",
      "[212/01187] train_loss: 0.017113\n",
      "[213/00011] train_loss: 0.019827\n",
      "[213/00061] train_loss: 0.022358\n",
      "[213/00111] train_loss: 0.020044\n",
      "[213/00161] train_loss: 0.017061\n",
      "[213/00211] train_loss: 0.017115\n",
      "[213/00261] train_loss: 0.017227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213/00311] train_loss: 0.017144\n",
      "[213/00361] train_loss: 0.017665\n",
      "[213/00411] train_loss: 0.015131\n",
      "[213/00461] train_loss: 0.015629\n",
      "[213/00511] train_loss: 0.016837\n",
      "[213/00561] train_loss: 0.016553\n",
      "[213/00611] train_loss: 0.016494\n",
      "[213/00661] train_loss: 0.015276\n",
      "[213/00711] train_loss: 0.016389\n",
      "[213/00761] train_loss: 0.017138\n",
      "[213/00811] train_loss: 0.016336\n",
      "[213/00861] train_loss: 0.016342\n",
      "[213/00911] train_loss: 0.016644\n",
      "[213/00961] train_loss: 0.015412\n",
      "[213/01011] train_loss: 0.016606\n",
      "[213/01061] train_loss: 0.016736\n",
      "[213/01111] train_loss: 0.016287\n",
      "[213/01161] train_loss: 0.016768\n",
      "[213/01211] train_loss: 0.016588\n",
      "[214/00035] train_loss: 0.022970\n",
      "[214/00085] train_loss: 0.021291\n",
      "[214/00135] train_loss: 0.018003\n",
      "[214/00185] train_loss: 0.017471\n",
      "[214/00235] train_loss: 0.016482\n",
      "[214/00285] train_loss: 0.017424\n",
      "[214/00335] train_loss: 0.016775\n",
      "[214/00385] train_loss: 0.016464\n",
      "[214/00435] train_loss: 0.015777\n",
      "[214/00485] train_loss: 0.015312\n",
      "[214/00535] train_loss: 0.017194\n",
      "[214/00585] train_loss: 0.016411\n",
      "[214/00635] train_loss: 0.015276\n",
      "[214/00685] train_loss: 0.016037\n",
      "[214/00735] train_loss: 0.016261\n",
      "[214/00785] train_loss: 0.016467\n",
      "[214/00835] train_loss: 0.017627\n",
      "[214/00885] train_loss: 0.016354\n",
      "[214/00935] train_loss: 0.016190\n",
      "[214/00985] train_loss: 0.016298\n",
      "[214/01035] train_loss: 0.016174\n",
      "[214/01085] train_loss: 0.017125\n",
      "[214/01135] train_loss: 0.015857\n",
      "[214/01185] train_loss: 0.016345\n",
      "[215/00009] train_loss: 0.017375\n",
      "[215/00059] train_loss: 0.022168\n",
      "[215/00109] train_loss: 0.020013\n",
      "[215/00159] train_loss: 0.018633\n",
      "[215/00209] train_loss: 0.016649\n",
      "[215/00259] train_loss: 0.016413\n",
      "[215/00309] train_loss: 0.016360\n",
      "[215/00359] train_loss: 0.015999\n",
      "[215/00409] train_loss: 0.016369\n",
      "[215/00459] train_loss: 0.016310\n",
      "[215/00509] train_loss: 0.016021\n",
      "[215/00559] train_loss: 0.017143\n",
      "[215/00609] train_loss: 0.016236\n",
      "[215/00659] train_loss: 0.016504\n",
      "[215/00709] train_loss: 0.016533\n",
      "[215/00759] train_loss: 0.016637\n",
      "[215/00809] train_loss: 0.016225\n",
      "[215/00859] train_loss: 0.016402\n",
      "[215/00909] train_loss: 0.015695\n",
      "[215/00959] train_loss: 0.016090\n",
      "[215/01009] train_loss: 0.016387\n",
      "[215/01059] train_loss: 0.016306\n",
      "[215/01109] train_loss: 0.016195\n",
      "[215/01159] train_loss: 0.016750\n",
      "[215/01209] train_loss: 0.017687\n",
      "[216/00033] train_loss: 0.022727\n",
      "[216/00083] train_loss: 0.019003\n",
      "[216/00133] train_loss: 0.017759\n",
      "[216/00183] train_loss: 0.016207\n",
      "[216/00233] train_loss: 0.017116\n",
      "[216/00283] train_loss: 0.016567\n",
      "[216/00333] train_loss: 0.017417\n",
      "[216/00383] train_loss: 0.015973\n",
      "[216/00433] train_loss: 0.016790\n",
      "[216/00483] train_loss: 0.015921\n",
      "[216/00533] train_loss: 0.016323\n",
      "[216/00583] train_loss: 0.016028\n",
      "[216/00633] train_loss: 0.016638\n",
      "[216/00683] train_loss: 0.016526\n",
      "[216/00733] train_loss: 0.016147\n",
      "[216/00783] train_loss: 0.015133\n",
      "[216/00833] train_loss: 0.015694\n",
      "[216/00883] train_loss: 0.016519\n",
      "[216/00933] train_loss: 0.016408\n",
      "[216/00983] train_loss: 0.017808\n",
      "[216/01033] train_loss: 0.017381\n",
      "[216/01083] train_loss: 0.017135\n",
      "[216/01133] train_loss: 0.016734\n",
      "[216/01183] train_loss: 0.016787\n",
      "[217/00007] train_loss: 0.018116\n",
      "[217/00057] train_loss: 0.022824\n",
      "[217/00107] train_loss: 0.018810\n",
      "[217/00157] train_loss: 0.017064\n",
      "[217/00207] train_loss: 0.016702\n",
      "[217/00257] train_loss: 0.015857\n",
      "[217/00307] train_loss: 0.016489\n",
      "[217/00357] train_loss: 0.016562\n",
      "[217/00407] train_loss: 0.017119\n",
      "[217/00457] train_loss: 0.016232\n",
      "[217/00507] train_loss: 0.016796\n",
      "[217/00557] train_loss: 0.016243\n",
      "[217/00607] train_loss: 0.016866\n",
      "[217/00657] train_loss: 0.016504\n",
      "[217/00707] train_loss: 0.017121\n",
      "[217/00757] train_loss: 0.016075\n",
      "[217/00807] train_loss: 0.016301\n",
      "[217/00857] train_loss: 0.016337\n",
      "[217/00907] train_loss: 0.016875\n",
      "[217/00957] train_loss: 0.016359\n",
      "[217/01007] train_loss: 0.015074\n",
      "[217/01057] train_loss: 0.016433\n",
      "[217/01107] train_loss: 0.015556\n",
      "[217/01157] train_loss: 0.015849\n",
      "[217/01207] train_loss: 0.017635\n",
      "[218/00031] train_loss: 0.023633\n",
      "[218/00081] train_loss: 0.021560\n",
      "[218/00131] train_loss: 0.017937\n",
      "[218/00181] train_loss: 0.017194\n",
      "[218/00231] train_loss: 0.017240\n",
      "[218/00281] train_loss: 0.017540\n",
      "[218/00331] train_loss: 0.017041\n",
      "[218/00381] train_loss: 0.016137\n",
      "[218/00431] train_loss: 0.016906\n",
      "[218/00481] train_loss: 0.016804\n",
      "[218/00531] train_loss: 0.015984\n",
      "[218/00581] train_loss: 0.016528\n",
      "[218/00631] train_loss: 0.016441\n",
      "[218/00681] train_loss: 0.016715\n",
      "[218/00731] train_loss: 0.015760\n",
      "[218/00781] train_loss: 0.016867\n",
      "[218/00831] train_loss: 0.015617\n",
      "[218/00881] train_loss: 0.016182\n",
      "[218/00931] train_loss: 0.015857\n",
      "[218/00981] train_loss: 0.015611\n",
      "[218/01031] train_loss: 0.016098\n",
      "[218/01081] train_loss: 0.016063\n",
      "[218/01131] train_loss: 0.016717\n",
      "[218/01181] train_loss: 0.017248\n",
      "[219/00005] train_loss: 0.018277\n",
      "[219/00055] train_loss: 0.022593\n",
      "[219/00105] train_loss: 0.019452\n",
      "[219/00155] train_loss: 0.017643\n",
      "[219/00205] train_loss: 0.017134\n",
      "[219/00255] train_loss: 0.017102\n",
      "[219/00305] train_loss: 0.016735\n",
      "[219/00355] train_loss: 0.015984\n",
      "[219/00405] train_loss: 0.017107\n",
      "[219/00455] train_loss: 0.016177\n",
      "[219/00505] train_loss: 0.016790\n",
      "[219/00555] train_loss: 0.016421\n",
      "[219/00605] train_loss: 0.016136\n",
      "[219/00655] train_loss: 0.016328\n",
      "[219/00705] train_loss: 0.017429\n",
      "[219/00755] train_loss: 0.016621\n",
      "[219/00805] train_loss: 0.016192\n",
      "[219/00855] train_loss: 0.016523\n",
      "[219/00905] train_loss: 0.017266\n",
      "[219/00955] train_loss: 0.015601\n",
      "[219/01005] train_loss: 0.016344\n",
      "[219/01055] train_loss: 0.017100\n",
      "[219/01105] train_loss: 0.016250\n",
      "[219/01155] train_loss: 0.015653\n",
      "[219/01205] train_loss: 0.015111\n",
      "[220/00029] train_loss: 0.021997\n",
      "[220/00079] train_loss: 0.021174\n",
      "[220/00129] train_loss: 0.018237\n",
      "[220/00179] train_loss: 0.017103\n",
      "[220/00229] train_loss: 0.016554\n",
      "[220/00279] train_loss: 0.016321\n",
      "[220/00329] train_loss: 0.016451\n",
      "[220/00379] train_loss: 0.016319\n",
      "[220/00429] train_loss: 0.016526\n",
      "[220/00479] train_loss: 0.017534\n",
      "[220/00529] train_loss: 0.015905\n",
      "[220/00579] train_loss: 0.016013\n",
      "[220/00629] train_loss: 0.016649\n",
      "[220/00679] train_loss: 0.017292\n",
      "[220/00729] train_loss: 0.016581\n",
      "[220/00779] train_loss: 0.017250\n",
      "[220/00829] train_loss: 0.016303\n",
      "[220/00879] train_loss: 0.016884\n",
      "[220/00929] train_loss: 0.016017\n",
      "[220/00979] train_loss: 0.016502\n",
      "[220/01029] train_loss: 0.016859\n",
      "[220/01079] train_loss: 0.016208\n",
      "[220/01129] train_loss: 0.016498\n",
      "[220/01179] train_loss: 0.016962\n",
      "[221/00003] train_loss: 0.017132\n",
      "[221/00053] train_loss: 0.022543\n",
      "[221/00103] train_loss: 0.019824\n",
      "[221/00153] train_loss: 0.017373\n",
      "[221/00203] train_loss: 0.016594\n",
      "[221/00253] train_loss: 0.017332\n",
      "[221/00303] train_loss: 0.016236\n",
      "[221/00353] train_loss: 0.016522\n",
      "[221/00403] train_loss: 0.016567\n",
      "[221/00453] train_loss: 0.016086\n",
      "[221/00503] train_loss: 0.017133\n",
      "[221/00553] train_loss: 0.016153\n",
      "[221/00603] train_loss: 0.015386\n",
      "[221/00653] train_loss: 0.016310\n",
      "[221/00703] train_loss: 0.017306\n",
      "[221/00753] train_loss: 0.016228\n",
      "[221/00803] train_loss: 0.017134\n",
      "[221/00853] train_loss: 0.015908\n",
      "[221/00903] train_loss: 0.016017\n",
      "[221/00953] train_loss: 0.017064\n",
      "[221/01003] train_loss: 0.016583\n",
      "[221/01053] train_loss: 0.016679\n",
      "[221/01103] train_loss: 0.015943\n",
      "[221/01153] train_loss: 0.016342\n",
      "[221/01203] train_loss: 0.016502\n",
      "[222/00027] train_loss: 0.022371\n",
      "[222/00077] train_loss: 0.020233\n",
      "[222/00127] train_loss: 0.017873\n",
      "[222/00177] train_loss: 0.018003\n",
      "[222/00227] train_loss: 0.016407\n",
      "[222/00277] train_loss: 0.016486\n",
      "[222/00327] train_loss: 0.016319\n",
      "[222/00377] train_loss: 0.016464\n",
      "[222/00427] train_loss: 0.016575\n",
      "[222/00477] train_loss: 0.016040\n",
      "[222/00527] train_loss: 0.016182\n",
      "[222/00577] train_loss: 0.017264\n",
      "[222/00627] train_loss: 0.017114\n",
      "[222/00677] train_loss: 0.016060\n",
      "[222/00727] train_loss: 0.017572\n",
      "[222/00777] train_loss: 0.015706\n",
      "[222/00827] train_loss: 0.016207\n",
      "[222/00877] train_loss: 0.015812\n",
      "[222/00927] train_loss: 0.015942\n",
      "[222/00977] train_loss: 0.016039\n",
      "[222/01027] train_loss: 0.016413\n",
      "[222/01077] train_loss: 0.016697\n",
      "[222/01127] train_loss: 0.016159\n",
      "[222/01177] train_loss: 0.017303\n",
      "[223/00001] train_loss: 0.017352\n",
      "[223/00051] train_loss: 0.023424\n",
      "[223/00101] train_loss: 0.019848\n",
      "[223/00151] train_loss: 0.017375\n",
      "[223/00201] train_loss: 0.016774\n",
      "[223/00251] train_loss: 0.016724\n",
      "[223/00301] train_loss: 0.015808\n",
      "[223/00351] train_loss: 0.016341\n",
      "[223/00401] train_loss: 0.016378\n",
      "[223/00451] train_loss: 0.016833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223/00501] train_loss: 0.015910\n",
      "[223/00551] train_loss: 0.016459\n",
      "[223/00601] train_loss: 0.016550\n",
      "[223/00651] train_loss: 0.015665\n",
      "[223/00701] train_loss: 0.017235\n",
      "[223/00751] train_loss: 0.017511\n",
      "[223/00801] train_loss: 0.015571\n",
      "[223/00851] train_loss: 0.016513\n",
      "[223/00901] train_loss: 0.016190\n",
      "[223/00951] train_loss: 0.016725\n",
      "[223/01001] train_loss: 0.016070\n",
      "[223/01051] train_loss: 0.016312\n",
      "[223/01101] train_loss: 0.017002\n",
      "[223/01151] train_loss: 0.016324\n",
      "[223/01201] train_loss: 0.018244\n",
      "[224/00025] train_loss: 0.021254\n",
      "[224/00075] train_loss: 0.021916\n",
      "[224/00125] train_loss: 0.018391\n",
      "[224/00175] train_loss: 0.016503\n",
      "[224/00225] train_loss: 0.016309\n",
      "[224/00275] train_loss: 0.017302\n",
      "[224/00325] train_loss: 0.016239\n",
      "[224/00375] train_loss: 0.016316\n",
      "[224/00425] train_loss: 0.016626\n",
      "[224/00475] train_loss: 0.017058\n",
      "[224/00525] train_loss: 0.016720\n",
      "[224/00575] train_loss: 0.016248\n",
      "[224/00625] train_loss: 0.016113\n",
      "[224/00675] train_loss: 0.016688\n",
      "[224/00725] train_loss: 0.015864\n",
      "[224/00775] train_loss: 0.015883\n",
      "[224/00825] train_loss: 0.015512\n",
      "[224/00875] train_loss: 0.016954\n",
      "[224/00925] train_loss: 0.015927\n",
      "[224/00975] train_loss: 0.016744\n",
      "[224/01025] train_loss: 0.016314\n",
      "[224/01075] train_loss: 0.016643\n",
      "[224/01125] train_loss: 0.016939\n",
      "[224/01175] train_loss: 0.017422\n",
      "[224/01225] train_loss: 0.016769\n",
      "[225/00049] train_loss: 0.023657\n",
      "[225/00099] train_loss: 0.018780\n",
      "[225/00149] train_loss: 0.017330\n",
      "[225/00199] train_loss: 0.017332\n",
      "[225/00249] train_loss: 0.016371\n",
      "[225/00299] train_loss: 0.016183\n",
      "[225/00349] train_loss: 0.015963\n",
      "[225/00399] train_loss: 0.015847\n",
      "[225/00449] train_loss: 0.016511\n",
      "[225/00499] train_loss: 0.015675\n",
      "[225/00549] train_loss: 0.017421\n",
      "[225/00599] train_loss: 0.016611\n",
      "[225/00649] train_loss: 0.015224\n",
      "[225/00699] train_loss: 0.016994\n",
      "[225/00749] train_loss: 0.016162\n",
      "[225/00799] train_loss: 0.016739\n",
      "[225/00849] train_loss: 0.016394\n",
      "[225/00899] train_loss: 0.017052\n",
      "[225/00949] train_loss: 0.016789\n",
      "[225/00999] train_loss: 0.016545\n",
      "[225/01049] train_loss: 0.016300\n",
      "[225/01099] train_loss: 0.016694\n",
      "[225/01149] train_loss: 0.016362\n",
      "[225/01199] train_loss: 0.016773\n",
      "[226/00023] train_loss: 0.020076\n",
      "[226/00073] train_loss: 0.021097\n",
      "[226/00123] train_loss: 0.018323\n",
      "[226/00173] train_loss: 0.017027\n",
      "[226/00223] train_loss: 0.017157\n",
      "[226/00273] train_loss: 0.015696\n",
      "[226/00323] train_loss: 0.015763\n",
      "[226/00373] train_loss: 0.016394\n",
      "[226/00423] train_loss: 0.016883\n",
      "[226/00473] train_loss: 0.017106\n",
      "[226/00523] train_loss: 0.016420\n",
      "[226/00573] train_loss: 0.016518\n",
      "[226/00623] train_loss: 0.016325\n",
      "[226/00673] train_loss: 0.016101\n",
      "[226/00723] train_loss: 0.015800\n",
      "[226/00773] train_loss: 0.016421\n",
      "[226/00823] train_loss: 0.015758\n",
      "[226/00873] train_loss: 0.016509\n",
      "[226/00923] train_loss: 0.016638\n",
      "[226/00973] train_loss: 0.016725\n",
      "[226/01023] train_loss: 0.016008\n",
      "[226/01073] train_loss: 0.016547\n",
      "[226/01123] train_loss: 0.017427\n",
      "[226/01173] train_loss: 0.017301\n",
      "[226/01223] train_loss: 0.016205\n",
      "[227/00047] train_loss: 0.022284\n",
      "[227/00097] train_loss: 0.019782\n",
      "[227/00147] train_loss: 0.018153\n",
      "[227/00197] train_loss: 0.017263\n",
      "[227/00247] train_loss: 0.015564\n",
      "[227/00297] train_loss: 0.016120\n",
      "[227/00347] train_loss: 0.017508\n",
      "[227/00397] train_loss: 0.017119\n",
      "[227/00447] train_loss: 0.016259\n",
      "[227/00497] train_loss: 0.016415\n",
      "[227/00547] train_loss: 0.016639\n",
      "[227/00597] train_loss: 0.015885\n",
      "[227/00647] train_loss: 0.015992\n",
      "[227/00697] train_loss: 0.015873\n",
      "[227/00747] train_loss: 0.017181\n",
      "[227/00797] train_loss: 0.015664\n",
      "[227/00847] train_loss: 0.016422\n",
      "[227/00897] train_loss: 0.016405\n",
      "[227/00947] train_loss: 0.017644\n",
      "[227/00997] train_loss: 0.016799\n",
      "[227/01047] train_loss: 0.015994\n",
      "[227/01097] train_loss: 0.016508\n",
      "[227/01147] train_loss: 0.017009\n",
      "[227/01197] train_loss: 0.017127\n",
      "[228/00021] train_loss: 0.019571\n",
      "[228/00071] train_loss: 0.020934\n",
      "[228/00121] train_loss: 0.018702\n",
      "[228/00171] train_loss: 0.016603\n",
      "[228/00221] train_loss: 0.017162\n",
      "[228/00271] train_loss: 0.016287\n",
      "[228/00321] train_loss: 0.015375\n",
      "[228/00371] train_loss: 0.015698\n",
      "[228/00421] train_loss: 0.016268\n",
      "[228/00471] train_loss: 0.016027\n",
      "[228/00521] train_loss: 0.015565\n",
      "[228/00571] train_loss: 0.016247\n",
      "[228/00621] train_loss: 0.016378\n",
      "[228/00671] train_loss: 0.015910\n",
      "[228/00721] train_loss: 0.015682\n",
      "[228/00771] train_loss: 0.016460\n",
      "[228/00821] train_loss: 0.016648\n",
      "[228/00871] train_loss: 0.016151\n",
      "[228/00921] train_loss: 0.015433\n",
      "[228/00971] train_loss: 0.016892\n",
      "[228/01021] train_loss: 0.016140\n",
      "[228/01071] train_loss: 0.016623\n",
      "[228/01121] train_loss: 0.016336\n",
      "[228/01171] train_loss: 0.017646\n",
      "[228/01221] train_loss: 0.016877\n",
      "[229/00045] train_loss: 0.023498\n",
      "[229/00095] train_loss: 0.021001\n",
      "[229/00145] train_loss: 0.018847\n",
      "[229/00195] train_loss: 0.017580\n",
      "[229/00245] train_loss: 0.016705\n",
      "[229/00295] train_loss: 0.017134\n",
      "[229/00345] train_loss: 0.016161\n",
      "[229/00395] train_loss: 0.015989\n",
      "[229/00445] train_loss: 0.016152\n",
      "[229/00495] train_loss: 0.016704\n",
      "[229/00545] train_loss: 0.016613\n",
      "[229/00595] train_loss: 0.015059\n",
      "[229/00645] train_loss: 0.016385\n",
      "[229/00695] train_loss: 0.016546\n",
      "[229/00745] train_loss: 0.015918\n",
      "[229/00795] train_loss: 0.016448\n",
      "[229/00845] train_loss: 0.016700\n",
      "[229/00895] train_loss: 0.015213\n",
      "[229/00945] train_loss: 0.016359\n",
      "[229/00995] train_loss: 0.016973\n",
      "[229/01045] train_loss: 0.016681\n",
      "[229/01095] train_loss: 0.016562\n",
      "[229/01145] train_loss: 0.016269\n",
      "[229/01195] train_loss: 0.016899\n",
      "[230/00019] train_loss: 0.019977\n",
      "[230/00069] train_loss: 0.021896\n",
      "[230/00119] train_loss: 0.017971\n",
      "[230/00169] train_loss: 0.017008\n",
      "[230/00219] train_loss: 0.015967\n",
      "[230/00269] train_loss: 0.016762\n",
      "[230/00319] train_loss: 0.016636\n",
      "[230/00369] train_loss: 0.015959\n",
      "[230/00419] train_loss: 0.016909\n",
      "[230/00469] train_loss: 0.015644\n",
      "[230/00519] train_loss: 0.015532\n",
      "[230/00569] train_loss: 0.015603\n",
      "[230/00619] train_loss: 0.016230\n",
      "[230/00669] train_loss: 0.016338\n",
      "[230/00719] train_loss: 0.016277\n",
      "[230/00769] train_loss: 0.016534\n",
      "[230/00819] train_loss: 0.016420\n",
      "[230/00869] train_loss: 0.016153\n",
      "[230/00919] train_loss: 0.016476\n",
      "[230/00969] train_loss: 0.016891\n",
      "[230/01019] train_loss: 0.016531\n",
      "[230/01069] train_loss: 0.017392\n",
      "[230/01119] train_loss: 0.016596\n",
      "[230/01169] train_loss: 0.015993\n",
      "[230/01219] train_loss: 0.016855\n",
      "[231/00043] train_loss: 0.023021\n",
      "[231/00093] train_loss: 0.021064\n",
      "[231/00143] train_loss: 0.018451\n",
      "[231/00193] train_loss: 0.017047\n",
      "[231/00243] train_loss: 0.015719\n",
      "[231/00293] train_loss: 0.018306\n",
      "[231/00343] train_loss: 0.016221\n",
      "[231/00393] train_loss: 0.016544\n",
      "[231/00443] train_loss: 0.016447\n",
      "[231/00493] train_loss: 0.016115\n",
      "[231/00543] train_loss: 0.015860\n",
      "[231/00593] train_loss: 0.016368\n",
      "[231/00643] train_loss: 0.015829\n",
      "[231/00693] train_loss: 0.015920\n",
      "[231/00743] train_loss: 0.016330\n",
      "[231/00793] train_loss: 0.016991\n",
      "[231/00843] train_loss: 0.016466\n",
      "[231/00893] train_loss: 0.016567\n",
      "[231/00943] train_loss: 0.016593\n",
      "[231/00993] train_loss: 0.016996\n",
      "[231/01043] train_loss: 0.015586\n",
      "[231/01093] train_loss: 0.016219\n",
      "[231/01143] train_loss: 0.015687\n",
      "[231/01193] train_loss: 0.016340\n",
      "[232/00017] train_loss: 0.019253\n",
      "[232/00067] train_loss: 0.022220\n",
      "[232/00117] train_loss: 0.018515\n",
      "[232/00167] train_loss: 0.017747\n",
      "[232/00217] train_loss: 0.016299\n",
      "[232/00267] train_loss: 0.016362\n",
      "[232/00317] train_loss: 0.015932\n",
      "[232/00367] train_loss: 0.016540\n",
      "[232/00417] train_loss: 0.016393\n",
      "[232/00467] train_loss: 0.016238\n",
      "[232/00517] train_loss: 0.016231\n",
      "[232/00567] train_loss: 0.015539\n",
      "[232/00617] train_loss: 0.016100\n",
      "[232/00667] train_loss: 0.015707\n",
      "[232/00717] train_loss: 0.016436\n",
      "[232/00767] train_loss: 0.016669\n",
      "[232/00817] train_loss: 0.015628\n",
      "[232/00867] train_loss: 0.016728\n",
      "[232/00917] train_loss: 0.016156\n",
      "[232/00967] train_loss: 0.016810\n",
      "[232/01017] train_loss: 0.016825\n",
      "[232/01067] train_loss: 0.016229\n",
      "[232/01117] train_loss: 0.017395\n",
      "[232/01167] train_loss: 0.017195\n",
      "[232/01217] train_loss: 0.017603\n",
      "[233/00041] train_loss: 0.023035\n",
      "[233/00091] train_loss: 0.019928\n",
      "[233/00141] train_loss: 0.016800\n",
      "[233/00191] train_loss: 0.017380\n",
      "[233/00241] train_loss: 0.016455\n",
      "[233/00291] train_loss: 0.016463\n",
      "[233/00341] train_loss: 0.016175\n",
      "[233/00391] train_loss: 0.017034\n",
      "[233/00441] train_loss: 0.016270\n",
      "[233/00491] train_loss: 0.015588\n",
      "[233/00541] train_loss: 0.016401\n",
      "[233/00591] train_loss: 0.016619\n",
      "[233/00641] train_loss: 0.015954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233/00691] train_loss: 0.016434\n",
      "[233/00741] train_loss: 0.017119\n",
      "[233/00791] train_loss: 0.016536\n",
      "[233/00841] train_loss: 0.015635\n",
      "[233/00891] train_loss: 0.015833\n",
      "[233/00941] train_loss: 0.015673\n",
      "[233/00991] train_loss: 0.015852\n",
      "[233/01041] train_loss: 0.017989\n",
      "[233/01091] train_loss: 0.016067\n",
      "[233/01141] train_loss: 0.017519\n",
      "[233/01191] train_loss: 0.016397\n",
      "[234/00015] train_loss: 0.020579\n",
      "[234/00065] train_loss: 0.021067\n",
      "[234/00115] train_loss: 0.019518\n",
      "[234/00165] train_loss: 0.018120\n",
      "[234/00215] train_loss: 0.017526\n",
      "[234/00265] train_loss: 0.016126\n",
      "[234/00315] train_loss: 0.017046\n",
      "[234/00365] train_loss: 0.015829\n",
      "[234/00415] train_loss: 0.017036\n",
      "[234/00465] train_loss: 0.016530\n",
      "[234/00515] train_loss: 0.016843\n",
      "[234/00565] train_loss: 0.016116\n",
      "[234/00615] train_loss: 0.016301\n",
      "[234/00665] train_loss: 0.015822\n",
      "[234/00715] train_loss: 0.015381\n",
      "[234/00765] train_loss: 0.015919\n",
      "[234/00815] train_loss: 0.016653\n",
      "[234/00865] train_loss: 0.016662\n",
      "[234/00915] train_loss: 0.016476\n",
      "[234/00965] train_loss: 0.017405\n",
      "[234/01015] train_loss: 0.016905\n",
      "[234/01065] train_loss: 0.015802\n",
      "[234/01115] train_loss: 0.016432\n",
      "[234/01165] train_loss: 0.017339\n",
      "[234/01215] train_loss: 0.017166\n",
      "[235/00039] train_loss: 0.022052\n",
      "[235/00089] train_loss: 0.019560\n",
      "[235/00139] train_loss: 0.017969\n",
      "[235/00189] train_loss: 0.016432\n",
      "[235/00239] train_loss: 0.016828\n",
      "[235/00289] train_loss: 0.017039\n",
      "[235/00339] train_loss: 0.015939\n",
      "[235/00389] train_loss: 0.016300\n",
      "[235/00439] train_loss: 0.018051\n",
      "[235/00489] train_loss: 0.017666\n",
      "[235/00539] train_loss: 0.015637\n",
      "[235/00589] train_loss: 0.016701\n",
      "[235/00639] train_loss: 0.016452\n",
      "[235/00689] train_loss: 0.016150\n",
      "[235/00739] train_loss: 0.015698\n",
      "[235/00789] train_loss: 0.016799\n",
      "[235/00839] train_loss: 0.016528\n",
      "[235/00889] train_loss: 0.016340\n",
      "[235/00939] train_loss: 0.015921\n",
      "[235/00989] train_loss: 0.015480\n",
      "[235/01039] train_loss: 0.016547\n",
      "[235/01089] train_loss: 0.017170\n",
      "[235/01139] train_loss: 0.015905\n",
      "[235/01189] train_loss: 0.015633\n",
      "[236/00013] train_loss: 0.019463\n",
      "[236/00063] train_loss: 0.021922\n",
      "[236/00113] train_loss: 0.019067\n",
      "[236/00163] train_loss: 0.017584\n",
      "[236/00213] train_loss: 0.016267\n",
      "[236/00263] train_loss: 0.016557\n",
      "[236/00313] train_loss: 0.016181\n",
      "[236/00363] train_loss: 0.015799\n",
      "[236/00413] train_loss: 0.016565\n",
      "[236/00463] train_loss: 0.015795\n",
      "[236/00513] train_loss: 0.016147\n",
      "[236/00563] train_loss: 0.017100\n",
      "[236/00613] train_loss: 0.016555\n",
      "[236/00663] train_loss: 0.015752\n",
      "[236/00713] train_loss: 0.015986\n",
      "[236/00763] train_loss: 0.016331\n",
      "[236/00813] train_loss: 0.016544\n",
      "[236/00863] train_loss: 0.017223\n",
      "[236/00913] train_loss: 0.015663\n",
      "[236/00963] train_loss: 0.015924\n",
      "[236/01013] train_loss: 0.016490\n",
      "[236/01063] train_loss: 0.016988\n",
      "[236/01113] train_loss: 0.015561\n",
      "[236/01163] train_loss: 0.016970\n",
      "[236/01213] train_loss: 0.016735\n",
      "[237/00037] train_loss: 0.024246\n",
      "[237/00087] train_loss: 0.019394\n",
      "[237/00137] train_loss: 0.019516\n",
      "[237/00187] train_loss: 0.016651\n",
      "[237/00237] train_loss: 0.015703\n",
      "[237/00287] train_loss: 0.016744\n",
      "[237/00337] train_loss: 0.016132\n",
      "[237/00387] train_loss: 0.016396\n",
      "[237/00437] train_loss: 0.015522\n",
      "[237/00487] train_loss: 0.016383\n",
      "[237/00537] train_loss: 0.016960\n",
      "[237/00587] train_loss: 0.016011\n",
      "[237/00637] train_loss: 0.016823\n",
      "[237/00687] train_loss: 0.016165\n",
      "[237/00737] train_loss: 0.017271\n",
      "[237/00787] train_loss: 0.016448\n",
      "[237/00837] train_loss: 0.015734\n",
      "[237/00887] train_loss: 0.017088\n",
      "[237/00937] train_loss: 0.016374\n",
      "[237/00987] train_loss: 0.016312\n",
      "[237/01037] train_loss: 0.016544\n",
      "[237/01087] train_loss: 0.016695\n",
      "[237/01137] train_loss: 0.017100\n",
      "[237/01187] train_loss: 0.015916\n",
      "[238/00011] train_loss: 0.018436\n",
      "[238/00061] train_loss: 0.022800\n",
      "[238/00111] train_loss: 0.018694\n",
      "[238/00161] train_loss: 0.017187\n",
      "[238/00211] train_loss: 0.016171\n",
      "[238/00261] train_loss: 0.015911\n",
      "[238/00311] train_loss: 0.015785\n",
      "[238/00361] train_loss: 0.016855\n",
      "[238/00411] train_loss: 0.016231\n",
      "[238/00461] train_loss: 0.016209\n",
      "[238/00511] train_loss: 0.015928\n",
      "[238/00561] train_loss: 0.015195\n",
      "[238/00611] train_loss: 0.015555\n",
      "[238/00661] train_loss: 0.016166\n",
      "[238/00711] train_loss: 0.016449\n",
      "[238/00761] train_loss: 0.016493\n",
      "[238/00811] train_loss: 0.016544\n",
      "[238/00861] train_loss: 0.016581\n",
      "[238/00911] train_loss: 0.015500\n",
      "[238/00961] train_loss: 0.016796\n",
      "[238/01011] train_loss: 0.016620\n",
      "[238/01061] train_loss: 0.017240\n",
      "[238/01111] train_loss: 0.016406\n",
      "[238/01161] train_loss: 0.017434\n",
      "[238/01211] train_loss: 0.016662\n",
      "[239/00035] train_loss: 0.022768\n",
      "[239/00085] train_loss: 0.021213\n",
      "[239/00135] train_loss: 0.017942\n",
      "[239/00185] train_loss: 0.016775\n",
      "[239/00235] train_loss: 0.016080\n",
      "[239/00285] train_loss: 0.016909\n",
      "[239/00335] train_loss: 0.018042\n",
      "[239/00385] train_loss: 0.016567\n",
      "[239/00435] train_loss: 0.016826\n",
      "[239/00485] train_loss: 0.015808\n",
      "[239/00535] train_loss: 0.016432\n",
      "[239/00585] train_loss: 0.015443\n",
      "[239/00635] train_loss: 0.016341\n",
      "[239/00685] train_loss: 0.016777\n",
      "[239/00735] train_loss: 0.016124\n",
      "[239/00785] train_loss: 0.015800\n",
      "[239/00835] train_loss: 0.016504\n",
      "[239/00885] train_loss: 0.015616\n",
      "[239/00935] train_loss: 0.015620\n",
      "[239/00985] train_loss: 0.016515\n",
      "[239/01035] train_loss: 0.016294\n",
      "[239/01085] train_loss: 0.016056\n",
      "[239/01135] train_loss: 0.015843\n",
      "[239/01185] train_loss: 0.017092\n",
      "[240/00009] train_loss: 0.017935\n",
      "[240/00059] train_loss: 0.024447\n",
      "[240/00109] train_loss: 0.018740\n",
      "[240/00159] train_loss: 0.016875\n",
      "[240/00209] train_loss: 0.017193\n",
      "[240/00259] train_loss: 0.016883\n",
      "[240/00309] train_loss: 0.015966\n",
      "[240/00359] train_loss: 0.015944\n",
      "[240/00409] train_loss: 0.015744\n",
      "[240/00459] train_loss: 0.016655\n",
      "[240/00509] train_loss: 0.016092\n",
      "[240/00559] train_loss: 0.016116\n",
      "[240/00609] train_loss: 0.016692\n",
      "[240/00659] train_loss: 0.016709\n",
      "[240/00709] train_loss: 0.016405\n",
      "[240/00759] train_loss: 0.016014\n",
      "[240/00809] train_loss: 0.015959\n",
      "[240/00859] train_loss: 0.015518\n",
      "[240/00909] train_loss: 0.015935\n",
      "[240/00959] train_loss: 0.016682\n",
      "[240/01009] train_loss: 0.015676\n",
      "[240/01059] train_loss: 0.016556\n",
      "[240/01109] train_loss: 0.016432\n",
      "[240/01159] train_loss: 0.016393\n",
      "[240/01209] train_loss: 0.016438\n",
      "[241/00033] train_loss: 0.022763\n",
      "[241/00083] train_loss: 0.020770\n",
      "[241/00133] train_loss: 0.018132\n",
      "[241/00183] train_loss: 0.017614\n",
      "[241/00233] train_loss: 0.016768\n",
      "[241/00283] train_loss: 0.016097\n",
      "[241/00333] train_loss: 0.016442\n",
      "[241/00383] train_loss: 0.017273\n",
      "[241/00433] train_loss: 0.015784\n",
      "[241/00483] train_loss: 0.015794\n",
      "[241/00533] train_loss: 0.016511\n",
      "[241/00583] train_loss: 0.016886\n",
      "[241/00633] train_loss: 0.016535\n",
      "[241/00683] train_loss: 0.016531\n",
      "[241/00733] train_loss: 0.015988\n",
      "[241/00783] train_loss: 0.016389\n",
      "[241/00833] train_loss: 0.016303\n",
      "[241/00883] train_loss: 0.015939\n",
      "[241/00933] train_loss: 0.015992\n",
      "[241/00983] train_loss: 0.016692\n",
      "[241/01033] train_loss: 0.017262\n",
      "[241/01083] train_loss: 0.016251\n",
      "[241/01133] train_loss: 0.016298\n",
      "[241/01183] train_loss: 0.015951\n",
      "[242/00007] train_loss: 0.018091\n",
      "[242/00057] train_loss: 0.022303\n",
      "[242/00107] train_loss: 0.019187\n",
      "[242/00157] train_loss: 0.017785\n",
      "[242/00207] train_loss: 0.016996\n",
      "[242/00257] train_loss: 0.017384\n",
      "[242/00307] train_loss: 0.016544\n",
      "[242/00357] train_loss: 0.015044\n",
      "[242/00407] train_loss: 0.016349\n",
      "[242/00457] train_loss: 0.015322\n",
      "[242/00507] train_loss: 0.016495\n",
      "[242/00557] train_loss: 0.016095\n",
      "[242/00607] train_loss: 0.016772\n",
      "[242/00657] train_loss: 0.016270\n",
      "[242/00707] train_loss: 0.017214\n",
      "[242/00757] train_loss: 0.015938\n",
      "[242/00807] train_loss: 0.017071\n",
      "[242/00857] train_loss: 0.015853\n",
      "[242/00907] train_loss: 0.016610\n",
      "[242/00957] train_loss: 0.016194\n",
      "[242/01007] train_loss: 0.016605\n",
      "[242/01057] train_loss: 0.016434\n",
      "[242/01107] train_loss: 0.017104\n",
      "[242/01157] train_loss: 0.017432\n",
      "[242/01207] train_loss: 0.016774\n",
      "[243/00031] train_loss: 0.019445\n",
      "[243/00081] train_loss: 0.021293\n",
      "[243/00131] train_loss: 0.018740\n",
      "[243/00181] train_loss: 0.017606\n",
      "[243/00231] train_loss: 0.016797\n",
      "[243/00281] train_loss: 0.015751\n",
      "[243/00331] train_loss: 0.016151\n",
      "[243/00381] train_loss: 0.016204\n",
      "[243/00431] train_loss: 0.015510\n",
      "[243/00481] train_loss: 0.015707\n",
      "[243/00531] train_loss: 0.016822\n",
      "[243/00581] train_loss: 0.016392\n",
      "[243/00631] train_loss: 0.015723\n",
      "[243/00681] train_loss: 0.016278\n",
      "[243/00731] train_loss: 0.016120\n",
      "[243/00781] train_loss: 0.016382\n",
      "[243/00831] train_loss: 0.016950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243/00881] train_loss: 0.015604\n",
      "[243/00931] train_loss: 0.016011\n",
      "[243/00981] train_loss: 0.016495\n",
      "[243/01031] train_loss: 0.016781\n",
      "[243/01081] train_loss: 0.016636\n",
      "[243/01131] train_loss: 0.016445\n",
      "[243/01181] train_loss: 0.016528\n",
      "[244/00005] train_loss: 0.017202\n",
      "[244/00055] train_loss: 0.022604\n",
      "[244/00105] train_loss: 0.017982\n",
      "[244/00155] train_loss: 0.016444\n",
      "[244/00205] train_loss: 0.017036\n",
      "[244/00255] train_loss: 0.016330\n",
      "[244/00305] train_loss: 0.015921\n",
      "[244/00355] train_loss: 0.015545\n",
      "[244/00405] train_loss: 0.016728\n",
      "[244/00455] train_loss: 0.017186\n",
      "[244/00505] train_loss: 0.016058\n",
      "[244/00555] train_loss: 0.016012\n",
      "[244/00605] train_loss: 0.016174\n",
      "[244/00655] train_loss: 0.016343\n",
      "[244/00705] train_loss: 0.016166\n",
      "[244/00755] train_loss: 0.016308\n",
      "[244/00805] train_loss: 0.015989\n",
      "[244/00855] train_loss: 0.016410\n",
      "[244/00905] train_loss: 0.016529\n",
      "[244/00955] train_loss: 0.017223\n",
      "[244/01005] train_loss: 0.015832\n",
      "[244/01055] train_loss: 0.017075\n",
      "[244/01105] train_loss: 0.016269\n",
      "[244/01155] train_loss: 0.017182\n",
      "[244/01205] train_loss: 0.016458\n",
      "[245/00029] train_loss: 0.022728\n",
      "[245/00079] train_loss: 0.020320\n",
      "[245/00129] train_loss: 0.017928\n",
      "[245/00179] train_loss: 0.017587\n",
      "[245/00229] train_loss: 0.016134\n",
      "[245/00279] train_loss: 0.016367\n",
      "[245/00329] train_loss: 0.015954\n",
      "[245/00379] train_loss: 0.016659\n",
      "[245/00429] train_loss: 0.015974\n",
      "[245/00479] train_loss: 0.016401\n",
      "[245/00529] train_loss: 0.016277\n",
      "[245/00579] train_loss: 0.015844\n",
      "[245/00629] train_loss: 0.015783\n",
      "[245/00679] train_loss: 0.016848\n",
      "[245/00729] train_loss: 0.015884\n",
      "[245/00779] train_loss: 0.016463\n",
      "[245/00829] train_loss: 0.016267\n",
      "[245/00879] train_loss: 0.015785\n",
      "[245/00929] train_loss: 0.015938\n",
      "[245/00979] train_loss: 0.016616\n",
      "[245/01029] train_loss: 0.016168\n",
      "[245/01079] train_loss: 0.017197\n",
      "[245/01129] train_loss: 0.016117\n",
      "[245/01179] train_loss: 0.016544\n",
      "[246/00003] train_loss: 0.015396\n",
      "[246/00053] train_loss: 0.023191\n",
      "[246/00103] train_loss: 0.019495\n",
      "[246/00153] train_loss: 0.017227\n",
      "[246/00203] train_loss: 0.016986\n",
      "[246/00253] train_loss: 0.017316\n",
      "[246/00303] train_loss: 0.017850\n",
      "[246/00353] train_loss: 0.016239\n",
      "[246/00403] train_loss: 0.015891\n",
      "[246/00453] train_loss: 0.016037\n",
      "[246/00503] train_loss: 0.015786\n",
      "[246/00553] train_loss: 0.016684\n",
      "[246/00603] train_loss: 0.016755\n",
      "[246/00653] train_loss: 0.016497\n",
      "[246/00703] train_loss: 0.015810\n",
      "[246/00753] train_loss: 0.016367\n",
      "[246/00803] train_loss: 0.015266\n",
      "[246/00853] train_loss: 0.015035\n",
      "[246/00903] train_loss: 0.016853\n",
      "[246/00953] train_loss: 0.016223\n",
      "[246/01003] train_loss: 0.016013\n",
      "[246/01053] train_loss: 0.017019\n",
      "[246/01103] train_loss: 0.016990\n",
      "[246/01153] train_loss: 0.016300\n",
      "[246/01203] train_loss: 0.017114\n",
      "[247/00027] train_loss: 0.020935\n",
      "[247/00077] train_loss: 0.020626\n",
      "[247/00127] train_loss: 0.017291\n",
      "[247/00177] train_loss: 0.016902\n",
      "[247/00227] train_loss: 0.016334\n",
      "[247/00277] train_loss: 0.016562\n",
      "[247/00327] train_loss: 0.016722\n",
      "[247/00377] train_loss: 0.016086\n",
      "[247/00427] train_loss: 0.015289\n",
      "[247/00477] train_loss: 0.016632\n",
      "[247/00527] train_loss: 0.016034\n",
      "[247/00577] train_loss: 0.016545\n",
      "[247/00627] train_loss: 0.016455\n",
      "[247/00677] train_loss: 0.016763\n",
      "[247/00727] train_loss: 0.015124\n",
      "[247/00777] train_loss: 0.015498\n",
      "[247/00827] train_loss: 0.016437\n",
      "[247/00877] train_loss: 0.016141\n",
      "[247/00927] train_loss: 0.016207\n",
      "[247/00977] train_loss: 0.016361\n",
      "[247/01027] train_loss: 0.016290\n",
      "[247/01077] train_loss: 0.017499\n",
      "[247/01127] train_loss: 0.017129\n",
      "[247/01177] train_loss: 0.015693\n",
      "[248/00001] train_loss: 0.016667\n",
      "[248/00051] train_loss: 0.023652\n",
      "[248/00101] train_loss: 0.019404\n",
      "[248/00151] train_loss: 0.016722\n",
      "[248/00201] train_loss: 0.016947\n",
      "[248/00251] train_loss: 0.015362\n",
      "[248/00301] train_loss: 0.016712\n",
      "[248/00351] train_loss: 0.016563\n",
      "[248/00401] train_loss: 0.016126\n",
      "[248/00451] train_loss: 0.016308\n",
      "[248/00501] train_loss: 0.015790\n",
      "[248/00551] train_loss: 0.015130\n",
      "[248/00601] train_loss: 0.015792\n",
      "[248/00651] train_loss: 0.016946\n",
      "[248/00701] train_loss: 0.016036\n",
      "[248/00751] train_loss: 0.015708\n",
      "[248/00801] train_loss: 0.016714\n",
      "[248/00851] train_loss: 0.015565\n",
      "[248/00901] train_loss: 0.015945\n",
      "[248/00951] train_loss: 0.017005\n",
      "[248/01001] train_loss: 0.017039\n",
      "[248/01051] train_loss: 0.016995\n",
      "[248/01101] train_loss: 0.016330\n",
      "[248/01151] train_loss: 0.016470\n",
      "[248/01201] train_loss: 0.016485\n",
      "[249/00025] train_loss: 0.021663\n",
      "[249/00075] train_loss: 0.020142\n",
      "[249/00125] train_loss: 0.018102\n",
      "[249/00175] train_loss: 0.017455\n",
      "[249/00225] train_loss: 0.016681\n",
      "[249/00275] train_loss: 0.016327\n",
      "[249/00325] train_loss: 0.015976\n",
      "[249/00375] train_loss: 0.017016\n",
      "[249/00425] train_loss: 0.016880\n",
      "[249/00475] train_loss: 0.016920\n",
      "[249/00525] train_loss: 0.016508\n",
      "[249/00575] train_loss: 0.016148\n",
      "[249/00625] train_loss: 0.016439\n",
      "[249/00675] train_loss: 0.016347\n",
      "[249/00725] train_loss: 0.015672\n",
      "[249/00775] train_loss: 0.016751\n",
      "[249/00825] train_loss: 0.015940\n",
      "[249/00875] train_loss: 0.015644\n",
      "[249/00925] train_loss: 0.015686\n",
      "[249/00975] train_loss: 0.016004\n",
      "[249/01025] train_loss: 0.016964\n",
      "[249/01075] train_loss: 0.015675\n",
      "[249/01125] train_loss: 0.017523\n",
      "[249/01175] train_loss: 0.016626\n",
      "[249/01225] train_loss: 0.017077\n",
      "[250/00049] train_loss: 0.023033\n",
      "[250/00099] train_loss: 0.019569\n",
      "[250/00149] train_loss: 0.018072\n",
      "[250/00199] train_loss: 0.016183\n",
      "[250/00249] train_loss: 0.016651\n",
      "[250/00299] train_loss: 0.016520\n",
      "[250/00349] train_loss: 0.015553\n",
      "[250/00399] train_loss: 0.016406\n",
      "[250/00449] train_loss: 0.016403\n",
      "[250/00499] train_loss: 0.016267\n",
      "[250/00549] train_loss: 0.016019\n",
      "[250/00599] train_loss: 0.016240\n",
      "[250/00649] train_loss: 0.017176\n",
      "[250/00699] train_loss: 0.015525\n",
      "[250/00749] train_loss: 0.017167\n",
      "[250/00799] train_loss: 0.016365\n",
      "[250/00849] train_loss: 0.015732\n",
      "[250/00899] train_loss: 0.015460\n",
      "[250/00949] train_loss: 0.015971\n",
      "[250/00999] train_loss: 0.016478\n",
      "[250/01049] train_loss: 0.016597\n",
      "[250/01099] train_loss: 0.015606\n",
      "[250/01149] train_loss: 0.016042\n",
      "[250/01199] train_loss: 0.016677\n",
      "[251/00023] train_loss: 0.019823\n",
      "[251/00073] train_loss: 0.020238\n",
      "[251/00123] train_loss: 0.018735\n",
      "[251/00173] train_loss: 0.016702\n",
      "[251/00223] train_loss: 0.017350\n",
      "[251/00273] train_loss: 0.015956\n",
      "[251/00323] train_loss: 0.015885\n",
      "[251/00373] train_loss: 0.017247\n",
      "[251/00423] train_loss: 0.016842\n",
      "[251/00473] train_loss: 0.015607\n",
      "[251/00523] train_loss: 0.015870\n",
      "[251/00573] train_loss: 0.015863\n",
      "[251/00623] train_loss: 0.015771\n",
      "[251/00673] train_loss: 0.015995\n",
      "[251/00723] train_loss: 0.016944\n",
      "[251/00773] train_loss: 0.017070\n",
      "[251/00823] train_loss: 0.016305\n",
      "[251/00873] train_loss: 0.016246\n",
      "[251/00923] train_loss: 0.017327\n",
      "[251/00973] train_loss: 0.015838\n",
      "[251/01023] train_loss: 0.015624\n",
      "[251/01073] train_loss: 0.016254\n",
      "[251/01123] train_loss: 0.016235\n",
      "[251/01173] train_loss: 0.016332\n",
      "[251/01223] train_loss: 0.017837\n",
      "[252/00047] train_loss: 0.023498\n",
      "[252/00097] train_loss: 0.018143\n",
      "[252/00147] train_loss: 0.016437\n",
      "[252/00197] train_loss: 0.015775\n",
      "[252/00247] train_loss: 0.016320\n",
      "[252/00297] train_loss: 0.015593\n",
      "[252/00347] train_loss: 0.015895\n",
      "[252/00397] train_loss: 0.015558\n",
      "[252/00447] train_loss: 0.016854\n",
      "[252/00497] train_loss: 0.015732\n",
      "[252/00547] train_loss: 0.016787\n",
      "[252/00597] train_loss: 0.015957\n",
      "[252/00647] train_loss: 0.015702\n",
      "[252/00697] train_loss: 0.015892\n",
      "[252/00747] train_loss: 0.016607\n",
      "[252/00797] train_loss: 0.016315\n",
      "[252/00847] train_loss: 0.016386\n",
      "[252/00897] train_loss: 0.015768\n",
      "[252/00947] train_loss: 0.017465\n",
      "[252/00997] train_loss: 0.015627\n",
      "[252/01047] train_loss: 0.016353\n",
      "[252/01097] train_loss: 0.016838\n",
      "[252/01147] train_loss: 0.016731\n",
      "[252/01197] train_loss: 0.017554\n",
      "[253/00021] train_loss: 0.020181\n",
      "[253/00071] train_loss: 0.021002\n",
      "[253/00121] train_loss: 0.017690\n",
      "[253/00171] train_loss: 0.017347\n",
      "[253/00221] train_loss: 0.016154\n",
      "[253/00271] train_loss: 0.017960\n",
      "[253/00321] train_loss: 0.016858\n",
      "[253/00371] train_loss: 0.015749\n",
      "[253/00421] train_loss: 0.015504\n",
      "[253/00471] train_loss: 0.016092\n",
      "[253/00521] train_loss: 0.015334\n",
      "[253/00571] train_loss: 0.016633\n",
      "[253/00621] train_loss: 0.016706\n",
      "[253/00671] train_loss: 0.016757\n",
      "[253/00721] train_loss: 0.016134\n",
      "[253/00771] train_loss: 0.015329\n",
      "[253/00821] train_loss: 0.016024\n",
      "[253/00871] train_loss: 0.016802\n",
      "[253/00921] train_loss: 0.016297\n",
      "[253/00971] train_loss: 0.015917\n",
      "[253/01021] train_loss: 0.016384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253/01071] train_loss: 0.016153\n",
      "[253/01121] train_loss: 0.017134\n",
      "[253/01171] train_loss: 0.016233\n",
      "[253/01221] train_loss: 0.017235\n",
      "[254/00045] train_loss: 0.023425\n",
      "[254/00095] train_loss: 0.019626\n",
      "[254/00145] train_loss: 0.016532\n",
      "[254/00195] train_loss: 0.016697\n",
      "[254/00245] train_loss: 0.015872\n",
      "[254/00295] train_loss: 0.016581\n",
      "[254/00345] train_loss: 0.016508\n",
      "[254/00395] train_loss: 0.016111\n",
      "[254/00445] train_loss: 0.016233\n",
      "[254/00495] train_loss: 0.015841\n",
      "[254/00545] train_loss: 0.015997\n",
      "[254/00595] train_loss: 0.016454\n",
      "[254/00645] train_loss: 0.015544\n",
      "[254/00695] train_loss: 0.016759\n",
      "[254/00745] train_loss: 0.016014\n",
      "[254/00795] train_loss: 0.016251\n",
      "[254/00845] train_loss: 0.016557\n",
      "[254/00895] train_loss: 0.016120\n",
      "[254/00945] train_loss: 0.016236\n",
      "[254/00995] train_loss: 0.016155\n",
      "[254/01045] train_loss: 0.015573\n",
      "[254/01095] train_loss: 0.017243\n",
      "[254/01145] train_loss: 0.016194\n",
      "[254/01195] train_loss: 0.017206\n",
      "[255/00019] train_loss: 0.020425\n",
      "[255/00069] train_loss: 0.021982\n",
      "[255/00119] train_loss: 0.018532\n",
      "[255/00169] train_loss: 0.017960\n",
      "[255/00219] train_loss: 0.016984\n",
      "[255/00269] train_loss: 0.016526\n",
      "[255/00319] train_loss: 0.016422\n",
      "[255/00369] train_loss: 0.016388\n",
      "[255/00419] train_loss: 0.015859\n",
      "[255/00469] train_loss: 0.016162\n",
      "[255/00519] train_loss: 0.016431\n",
      "[255/00569] train_loss: 0.016615\n",
      "[255/00619] train_loss: 0.016338\n",
      "[255/00669] train_loss: 0.016373\n",
      "[255/00719] train_loss: 0.016205\n",
      "[255/00769] train_loss: 0.016647\n",
      "[255/00819] train_loss: 0.016182\n",
      "[255/00869] train_loss: 0.016683\n",
      "[255/00919] train_loss: 0.015407\n",
      "[255/00969] train_loss: 0.016922\n",
      "[255/01019] train_loss: 0.016380\n",
      "[255/01069] train_loss: 0.017127\n",
      "[255/01119] train_loss: 0.017052\n",
      "[255/01169] train_loss: 0.016318\n",
      "[255/01219] train_loss: 0.016182\n",
      "[256/00043] train_loss: 0.021839\n",
      "[256/00093] train_loss: 0.019257\n",
      "[256/00143] train_loss: 0.018028\n",
      "[256/00193] train_loss: 0.016223\n",
      "[256/00243] train_loss: 0.016599\n",
      "[256/00293] train_loss: 0.015177\n",
      "[256/00343] train_loss: 0.016255\n",
      "[256/00393] train_loss: 0.015994\n",
      "[256/00443] train_loss: 0.016314\n",
      "[256/00493] train_loss: 0.016094\n",
      "[256/00543] train_loss: 0.015662\n",
      "[256/00593] train_loss: 0.015511\n",
      "[256/00643] train_loss: 0.016078\n",
      "[256/00693] train_loss: 0.016195\n",
      "[256/00743] train_loss: 0.015465\n",
      "[256/00793] train_loss: 0.015384\n",
      "[256/00843] train_loss: 0.015725\n",
      "[256/00893] train_loss: 0.016372\n",
      "[256/00943] train_loss: 0.016493\n",
      "[256/00993] train_loss: 0.016644\n",
      "[256/01043] train_loss: 0.016113\n",
      "[256/01093] train_loss: 0.015442\n",
      "[256/01143] train_loss: 0.017511\n",
      "[256/01193] train_loss: 0.016353\n",
      "[257/00017] train_loss: 0.020963\n",
      "[257/00067] train_loss: 0.021681\n",
      "[257/00117] train_loss: 0.018250\n",
      "[257/00167] train_loss: 0.016735\n",
      "[257/00217] train_loss: 0.016697\n",
      "[257/00267] train_loss: 0.016278\n",
      "[257/00317] train_loss: 0.016368\n",
      "[257/00367] train_loss: 0.015594\n",
      "[257/00417] train_loss: 0.016388\n",
      "[257/00467] train_loss: 0.016128\n",
      "[257/00517] train_loss: 0.016248\n",
      "[257/00567] train_loss: 0.015775\n",
      "[257/00617] train_loss: 0.016190\n",
      "[257/00667] train_loss: 0.016382\n",
      "[257/00717] train_loss: 0.016848\n",
      "[257/00767] train_loss: 0.015549\n",
      "[257/00817] train_loss: 0.016275\n",
      "[257/00867] train_loss: 0.016691\n",
      "[257/00917] train_loss: 0.015471\n",
      "[257/00967] train_loss: 0.015992\n",
      "[257/01017] train_loss: 0.015846\n",
      "[257/01067] train_loss: 0.016026\n",
      "[257/01117] train_loss: 0.016389\n",
      "[257/01167] train_loss: 0.015547\n",
      "[257/01217] train_loss: 0.018045\n",
      "[258/00041] train_loss: 0.021740\n",
      "[258/00091] train_loss: 0.021288\n",
      "[258/00141] train_loss: 0.018103\n",
      "[258/00191] train_loss: 0.017167\n",
      "[258/00241] train_loss: 0.017109\n",
      "[258/00291] train_loss: 0.016324\n",
      "[258/00341] train_loss: 0.017450\n",
      "[258/00391] train_loss: 0.016900\n",
      "[258/00441] train_loss: 0.016718\n",
      "[258/00491] train_loss: 0.016088\n",
      "[258/00541] train_loss: 0.016197\n",
      "[258/00591] train_loss: 0.016060\n",
      "[258/00641] train_loss: 0.015213\n",
      "[258/00691] train_loss: 0.016124\n",
      "[258/00741] train_loss: 0.016304\n",
      "[258/00791] train_loss: 0.015930\n",
      "[258/00841] train_loss: 0.015724\n",
      "[258/00891] train_loss: 0.016328\n",
      "[258/00941] train_loss: 0.017290\n",
      "[258/00991] train_loss: 0.016394\n",
      "[258/01041] train_loss: 0.017026\n",
      "[258/01091] train_loss: 0.017546\n",
      "[258/01141] train_loss: 0.016375\n",
      "[258/01191] train_loss: 0.016598\n",
      "[259/00015] train_loss: 0.019122\n",
      "[259/00065] train_loss: 0.021844\n",
      "[259/00115] train_loss: 0.018514\n",
      "[259/00165] train_loss: 0.017143\n",
      "[259/00215] train_loss: 0.016504\n",
      "[259/00265] train_loss: 0.016440\n",
      "[259/00315] train_loss: 0.016304\n",
      "[259/00365] train_loss: 0.016752\n",
      "[259/00415] train_loss: 0.016251\n",
      "[259/00465] train_loss: 0.016546\n",
      "[259/00515] train_loss: 0.015320\n",
      "[259/00565] train_loss: 0.016406\n",
      "[259/00615] train_loss: 0.017929\n",
      "[259/00665] train_loss: 0.016528\n",
      "[259/00715] train_loss: 0.016619\n",
      "[259/00765] train_loss: 0.015575\n",
      "[259/00815] train_loss: 0.015888\n",
      "[259/00865] train_loss: 0.016718\n",
      "[259/00915] train_loss: 0.016680\n",
      "[259/00965] train_loss: 0.016157\n",
      "[259/01015] train_loss: 0.016166\n",
      "[259/01065] train_loss: 0.016682\n",
      "[259/01115] train_loss: 0.016714\n",
      "[259/01165] train_loss: 0.016124\n",
      "[259/01215] train_loss: 0.015490\n",
      "[260/00039] train_loss: 0.023747\n",
      "[260/00089] train_loss: 0.019914\n",
      "[260/00139] train_loss: 0.017571\n",
      "[260/00189] train_loss: 0.017817\n",
      "[260/00239] train_loss: 0.017471\n",
      "[260/00289] train_loss: 0.016508\n",
      "[260/00339] train_loss: 0.015988\n",
      "[260/00389] train_loss: 0.015977\n",
      "[260/00439] train_loss: 0.016433\n",
      "[260/00489] train_loss: 0.016611\n",
      "[260/00539] train_loss: 0.015593\n",
      "[260/00589] train_loss: 0.015515\n",
      "[260/00639] train_loss: 0.016728\n",
      "[260/00689] train_loss: 0.016425\n",
      "[260/00739] train_loss: 0.015251\n",
      "[260/00789] train_loss: 0.016264\n",
      "[260/00839] train_loss: 0.015957\n",
      "[260/00889] train_loss: 0.015758\n",
      "[260/00939] train_loss: 0.016355\n",
      "[260/00989] train_loss: 0.016326\n",
      "[260/01039] train_loss: 0.016192\n",
      "[260/01089] train_loss: 0.015624\n",
      "[260/01139] train_loss: 0.016215\n",
      "[260/01189] train_loss: 0.016852\n",
      "[261/00013] train_loss: 0.018753\n",
      "[261/00063] train_loss: 0.020871\n",
      "[261/00113] train_loss: 0.018109\n",
      "[261/00163] train_loss: 0.017887\n",
      "[261/00213] train_loss: 0.016655\n",
      "[261/00263] train_loss: 0.016650\n",
      "[261/00313] train_loss: 0.016825\n",
      "[261/00363] train_loss: 0.016457\n",
      "[261/00413] train_loss: 0.015566\n",
      "[261/00463] train_loss: 0.015849\n",
      "[261/00513] train_loss: 0.015732\n",
      "[261/00563] train_loss: 0.015818\n",
      "[261/00613] train_loss: 0.016099\n",
      "[261/00663] train_loss: 0.015949\n",
      "[261/00713] train_loss: 0.016339\n",
      "[261/00763] train_loss: 0.016001\n",
      "[261/00813] train_loss: 0.015554\n",
      "[261/00863] train_loss: 0.016145\n",
      "[261/00913] train_loss: 0.016889\n",
      "[261/00963] train_loss: 0.015604\n",
      "[261/01013] train_loss: 0.016908\n",
      "[261/01063] train_loss: 0.016745\n",
      "[261/01113] train_loss: 0.017192\n",
      "[261/01163] train_loss: 0.015729\n",
      "[261/01213] train_loss: 0.016370\n",
      "[262/00037] train_loss: 0.022324\n",
      "[262/00087] train_loss: 0.020289\n",
      "[262/00137] train_loss: 0.017767\n",
      "[262/00187] train_loss: 0.017172\n",
      "[262/00237] train_loss: 0.016148\n",
      "[262/00287] train_loss: 0.016525\n",
      "[262/00337] train_loss: 0.016912\n",
      "[262/00387] train_loss: 0.016225\n",
      "[262/00437] train_loss: 0.015817\n",
      "[262/00487] train_loss: 0.016428\n",
      "[262/00537] train_loss: 0.016844\n",
      "[262/00587] train_loss: 0.015765\n",
      "[262/00637] train_loss: 0.016594\n",
      "[262/00687] train_loss: 0.017123\n",
      "[262/00737] train_loss: 0.015833\n",
      "[262/00787] train_loss: 0.015968\n",
      "[262/00837] train_loss: 0.016714\n",
      "[262/00887] train_loss: 0.015949\n",
      "[262/00937] train_loss: 0.016217\n",
      "[262/00987] train_loss: 0.015146\n",
      "[262/01037] train_loss: 0.016656\n",
      "[262/01087] train_loss: 0.016336\n",
      "[262/01137] train_loss: 0.016322\n",
      "[262/01187] train_loss: 0.016728\n",
      "[263/00011] train_loss: 0.018661\n",
      "[263/00061] train_loss: 0.022185\n",
      "[263/00111] train_loss: 0.019356\n",
      "[263/00161] train_loss: 0.017525\n",
      "[263/00211] train_loss: 0.016778\n",
      "[263/00261] train_loss: 0.016694\n",
      "[263/00311] train_loss: 0.016316\n",
      "[263/00361] train_loss: 0.016720\n",
      "[263/00411] train_loss: 0.015853\n",
      "[263/00461] train_loss: 0.015988\n",
      "[263/00511] train_loss: 0.016644\n",
      "[263/00561] train_loss: 0.016874\n",
      "[263/00611] train_loss: 0.015983\n",
      "[263/00661] train_loss: 0.015910\n",
      "[263/00711] train_loss: 0.017104\n",
      "[263/00761] train_loss: 0.016288\n",
      "[263/00811] train_loss: 0.016119\n",
      "[263/00861] train_loss: 0.015324\n",
      "[263/00911] train_loss: 0.016497\n",
      "[263/00961] train_loss: 0.016211\n",
      "[263/01011] train_loss: 0.015497\n",
      "[263/01061] train_loss: 0.016010\n",
      "[263/01111] train_loss: 0.017284\n",
      "[263/01161] train_loss: 0.016507\n",
      "[263/01211] train_loss: 0.015881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264/00035] train_loss: 0.023466\n",
      "[264/00085] train_loss: 0.021041\n",
      "[264/00135] train_loss: 0.019099\n",
      "[264/00185] train_loss: 0.017778\n",
      "[264/00235] train_loss: 0.016352\n",
      "[264/00285] train_loss: 0.016044\n",
      "[264/00335] train_loss: 0.016243\n",
      "[264/00385] train_loss: 0.017033\n",
      "[264/00435] train_loss: 0.015278\n",
      "[264/00485] train_loss: 0.015304\n",
      "[264/00535] train_loss: 0.016354\n",
      "[264/00585] train_loss: 0.017350\n",
      "[264/00635] train_loss: 0.017113\n",
      "[264/00685] train_loss: 0.016236\n",
      "[264/00735] train_loss: 0.015419\n",
      "[264/00785] train_loss: 0.015499\n",
      "[264/00835] train_loss: 0.015944\n",
      "[264/00885] train_loss: 0.015742\n",
      "[264/00935] train_loss: 0.015620\n",
      "[264/00985] train_loss: 0.015956\n",
      "[264/01035] train_loss: 0.016521\n",
      "[264/01085] train_loss: 0.015766\n",
      "[264/01135] train_loss: 0.016120\n",
      "[264/01185] train_loss: 0.016233\n",
      "[265/00009] train_loss: 0.018655\n",
      "[265/00059] train_loss: 0.021251\n",
      "[265/00109] train_loss: 0.018898\n",
      "[265/00159] train_loss: 0.017307\n",
      "[265/00209] train_loss: 0.016516\n",
      "[265/00259] train_loss: 0.016189\n",
      "[265/00309] train_loss: 0.016328\n",
      "[265/00359] train_loss: 0.016112\n",
      "[265/00409] train_loss: 0.016179\n",
      "[265/00459] train_loss: 0.017054\n",
      "[265/00509] train_loss: 0.016780\n",
      "[265/00559] train_loss: 0.016549\n",
      "[265/00609] train_loss: 0.016117\n",
      "[265/00659] train_loss: 0.015850\n",
      "[265/00709] train_loss: 0.015993\n",
      "[265/00759] train_loss: 0.016265\n",
      "[265/00809] train_loss: 0.016658\n",
      "[265/00859] train_loss: 0.015183\n",
      "[265/00909] train_loss: 0.015238\n",
      "[265/00959] train_loss: 0.016394\n",
      "[265/01009] train_loss: 0.016159\n",
      "[265/01059] train_loss: 0.015831\n",
      "[265/01109] train_loss: 0.017060\n",
      "[265/01159] train_loss: 0.016876\n",
      "[265/01209] train_loss: 0.016563\n",
      "[266/00033] train_loss: 0.021151\n",
      "[266/00083] train_loss: 0.020178\n",
      "[266/00133] train_loss: 0.017820\n",
      "[266/00183] train_loss: 0.017182\n",
      "[266/00233] train_loss: 0.016509\n",
      "[266/00283] train_loss: 0.016621\n",
      "[266/00333] train_loss: 0.015783\n",
      "[266/00383] train_loss: 0.015861\n",
      "[266/00433] train_loss: 0.016055\n",
      "[266/00483] train_loss: 0.015371\n",
      "[266/00533] train_loss: 0.016550\n",
      "[266/00583] train_loss: 0.015065\n",
      "[266/00633] train_loss: 0.015844\n",
      "[266/00683] train_loss: 0.015652\n",
      "[266/00733] train_loss: 0.016493\n",
      "[266/00783] train_loss: 0.015929\n",
      "[266/00833] train_loss: 0.017180\n",
      "[266/00883] train_loss: 0.015702\n",
      "[266/00933] train_loss: 0.016758\n",
      "[266/00983] train_loss: 0.015986\n",
      "[266/01033] train_loss: 0.016651\n",
      "[266/01083] train_loss: 0.017729\n",
      "[266/01133] train_loss: 0.016603\n",
      "[266/01183] train_loss: 0.016945\n",
      "[267/00007] train_loss: 0.018301\n",
      "[267/00057] train_loss: 0.022514\n",
      "[267/00107] train_loss: 0.018862\n",
      "[267/00157] train_loss: 0.016628\n",
      "[267/00207] train_loss: 0.016520\n",
      "[267/00257] train_loss: 0.016020\n",
      "[267/00307] train_loss: 0.016274\n",
      "[267/00357] train_loss: 0.016291\n",
      "[267/00407] train_loss: 0.016187\n",
      "[267/00457] train_loss: 0.015475\n",
      "[267/00507] train_loss: 0.016113\n",
      "[267/00557] train_loss: 0.015901\n",
      "[267/00607] train_loss: 0.016441\n",
      "[267/00657] train_loss: 0.016103\n",
      "[267/00707] train_loss: 0.016751\n",
      "[267/00757] train_loss: 0.016175\n",
      "[267/00807] train_loss: 0.016960\n",
      "[267/00857] train_loss: 0.017074\n",
      "[267/00907] train_loss: 0.015857\n",
      "[267/00957] train_loss: 0.015536\n",
      "[267/01007] train_loss: 0.017060\n",
      "[267/01057] train_loss: 0.016168\n",
      "[267/01107] train_loss: 0.016716\n",
      "[267/01157] train_loss: 0.016903\n",
      "[267/01207] train_loss: 0.016297\n",
      "[268/00031] train_loss: 0.021508\n",
      "[268/00081] train_loss: 0.019377\n",
      "[268/00131] train_loss: 0.018634\n",
      "[268/00181] train_loss: 0.016774\n",
      "[268/00231] train_loss: 0.015737\n",
      "[268/00281] train_loss: 0.016127\n",
      "[268/00331] train_loss: 0.016649\n",
      "[268/00381] train_loss: 0.015364\n",
      "[268/00431] train_loss: 0.015659\n",
      "[268/00481] train_loss: 0.016691\n",
      "[268/00531] train_loss: 0.016833\n",
      "[268/00581] train_loss: 0.015471\n",
      "[268/00631] train_loss: 0.015787\n",
      "[268/00681] train_loss: 0.016379\n",
      "[268/00731] train_loss: 0.016686\n",
      "[268/00781] train_loss: 0.016227\n",
      "[268/00831] train_loss: 0.015688\n",
      "[268/00881] train_loss: 0.014705\n",
      "[268/00931] train_loss: 0.016849\n",
      "[268/00981] train_loss: 0.017629\n",
      "[268/01031] train_loss: 0.016753\n",
      "[268/01081] train_loss: 0.016523\n",
      "[268/01131] train_loss: 0.017728\n",
      "[268/01181] train_loss: 0.017360\n",
      "[269/00005] train_loss: 0.017243\n",
      "[269/00055] train_loss: 0.021596\n",
      "[269/00105] train_loss: 0.018213\n",
      "[269/00155] train_loss: 0.017733\n",
      "[269/00205] train_loss: 0.016418\n",
      "[269/00255] train_loss: 0.017470\n",
      "[269/00305] train_loss: 0.015851\n",
      "[269/00355] train_loss: 0.015707\n",
      "[269/00405] train_loss: 0.016330\n",
      "[269/00455] train_loss: 0.015358\n",
      "[269/00505] train_loss: 0.015588\n",
      "[269/00555] train_loss: 0.016159\n",
      "[269/00605] train_loss: 0.016057\n",
      "[269/00655] train_loss: 0.015810\n",
      "[269/00705] train_loss: 0.017020\n",
      "[269/00755] train_loss: 0.016706\n",
      "[269/00805] train_loss: 0.016669\n",
      "[269/00855] train_loss: 0.017367\n",
      "[269/00905] train_loss: 0.016759\n",
      "[269/00955] train_loss: 0.016820\n",
      "[269/01005] train_loss: 0.016308\n",
      "[269/01055] train_loss: 0.015455\n",
      "[269/01105] train_loss: 0.016130\n",
      "[269/01155] train_loss: 0.016245\n",
      "[269/01205] train_loss: 0.015880\n",
      "[270/00029] train_loss: 0.021502\n",
      "[270/00079] train_loss: 0.020988\n",
      "[270/00129] train_loss: 0.017953\n",
      "[270/00179] train_loss: 0.017186\n",
      "[270/00229] train_loss: 0.016868\n",
      "[270/00279] train_loss: 0.016711\n",
      "[270/00329] train_loss: 0.016023\n",
      "[270/00379] train_loss: 0.015143\n",
      "[270/00429] train_loss: 0.015144\n",
      "[270/00479] train_loss: 0.015343\n",
      "[270/00529] train_loss: 0.016593\n",
      "[270/00579] train_loss: 0.015192\n",
      "[270/00629] train_loss: 0.015329\n",
      "[270/00679] train_loss: 0.015956\n",
      "[270/00729] train_loss: 0.016587\n",
      "[270/00779] train_loss: 0.016066\n",
      "[270/00829] train_loss: 0.016191\n",
      "[270/00879] train_loss: 0.016742\n",
      "[270/00929] train_loss: 0.014899\n",
      "[270/00979] train_loss: 0.016523\n",
      "[270/01029] train_loss: 0.016672\n",
      "[270/01079] train_loss: 0.015199\n",
      "[270/01129] train_loss: 0.017705\n",
      "[270/01179] train_loss: 0.016788\n",
      "[271/00003] train_loss: 0.017441\n",
      "[271/00053] train_loss: 0.023568\n",
      "[271/00103] train_loss: 0.018477\n",
      "[271/00153] train_loss: 0.017908\n",
      "[271/00203] train_loss: 0.016664\n",
      "[271/00253] train_loss: 0.016579\n",
      "[271/00303] train_loss: 0.015563\n",
      "[271/00353] train_loss: 0.016899\n",
      "[271/00403] train_loss: 0.017213\n",
      "[271/00453] train_loss: 0.016560\n",
      "[271/00503] train_loss: 0.016375\n",
      "[271/00553] train_loss: 0.015870\n",
      "[271/00603] train_loss: 0.015706\n",
      "[271/00653] train_loss: 0.016327\n",
      "[271/00703] train_loss: 0.016809\n",
      "[271/00753] train_loss: 0.016461\n",
      "[271/00803] train_loss: 0.015076\n",
      "[271/00853] train_loss: 0.015668\n",
      "[271/00903] train_loss: 0.016612\n",
      "[271/00953] train_loss: 0.015361\n",
      "[271/01003] train_loss: 0.015329\n",
      "[271/01053] train_loss: 0.016197\n",
      "[271/01103] train_loss: 0.016568\n",
      "[271/01153] train_loss: 0.017104\n",
      "[271/01203] train_loss: 0.016313\n",
      "[272/00027] train_loss: 0.021256\n",
      "[272/00077] train_loss: 0.021372\n",
      "[272/00127] train_loss: 0.017045\n",
      "[272/00177] train_loss: 0.017252\n",
      "[272/00227] train_loss: 0.015713\n",
      "[272/00277] train_loss: 0.016644\n",
      "[272/00327] train_loss: 0.016330\n",
      "[272/00377] train_loss: 0.016166\n",
      "[272/00427] train_loss: 0.016781\n",
      "[272/00477] train_loss: 0.016315\n",
      "[272/00527] train_loss: 0.016551\n",
      "[272/00577] train_loss: 0.015960\n",
      "[272/00627] train_loss: 0.016108\n",
      "[272/00677] train_loss: 0.015829\n",
      "[272/00727] train_loss: 0.015948\n",
      "[272/00777] train_loss: 0.015596\n",
      "[272/00827] train_loss: 0.015818\n",
      "[272/00877] train_loss: 0.016305\n",
      "[272/00927] train_loss: 0.016422\n",
      "[272/00977] train_loss: 0.016422\n",
      "[272/01027] train_loss: 0.017147\n",
      "[272/01077] train_loss: 0.016968\n",
      "[272/01127] train_loss: 0.015390\n",
      "[272/01177] train_loss: 0.016883\n",
      "[273/00001] train_loss: 0.016784\n",
      "[273/00051] train_loss: 0.023515\n",
      "[273/00101] train_loss: 0.018545\n",
      "[273/00151] train_loss: 0.016830\n",
      "[273/00201] train_loss: 0.016207\n",
      "[273/00251] train_loss: 0.015953\n",
      "[273/00301] train_loss: 0.015377\n",
      "[273/00351] train_loss: 0.015886\n",
      "[273/00401] train_loss: 0.015852\n",
      "[273/00451] train_loss: 0.016299\n",
      "[273/00501] train_loss: 0.016514\n",
      "[273/00551] train_loss: 0.017385\n",
      "[273/00601] train_loss: 0.015861\n",
      "[273/00651] train_loss: 0.016080\n",
      "[273/00701] train_loss: 0.015692\n",
      "[273/00751] train_loss: 0.015781\n",
      "[273/00801] train_loss: 0.016441\n",
      "[273/00851] train_loss: 0.016051\n",
      "[273/00901] train_loss: 0.016202\n",
      "[273/00951] train_loss: 0.015822\n",
      "[273/01001] train_loss: 0.017027\n",
      "[273/01051] train_loss: 0.015330\n",
      "[273/01101] train_loss: 0.016988\n",
      "[273/01151] train_loss: 0.016497\n",
      "[273/01201] train_loss: 0.016831\n",
      "[274/00025] train_loss: 0.020049\n",
      "[274/00075] train_loss: 0.020402\n",
      "[274/00125] train_loss: 0.017486\n",
      "[274/00175] train_loss: 0.017134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274/00225] train_loss: 0.017806\n",
      "[274/00275] train_loss: 0.016032\n",
      "[274/00325] train_loss: 0.015820\n",
      "[274/00375] train_loss: 0.015703\n",
      "[274/00425] train_loss: 0.016636\n",
      "[274/00475] train_loss: 0.016009\n",
      "[274/00525] train_loss: 0.016049\n",
      "[274/00575] train_loss: 0.016043\n",
      "[274/00625] train_loss: 0.015522\n",
      "[274/00675] train_loss: 0.016418\n",
      "[274/00725] train_loss: 0.016722\n",
      "[274/00775] train_loss: 0.017086\n",
      "[274/00825] train_loss: 0.016096\n",
      "[274/00875] train_loss: 0.015819\n",
      "[274/00925] train_loss: 0.016257\n",
      "[274/00975] train_loss: 0.016906\n",
      "[274/01025] train_loss: 0.014943\n",
      "[274/01075] train_loss: 0.016298\n",
      "[274/01125] train_loss: 0.016657\n",
      "[274/01175] train_loss: 0.016682\n",
      "[274/01225] train_loss: 0.016525\n",
      "[275/00049] train_loss: 0.023430\n",
      "[275/00099] train_loss: 0.019749\n",
      "[275/00149] train_loss: 0.017221\n",
      "[275/00199] train_loss: 0.016846\n",
      "[275/00249] train_loss: 0.015059\n",
      "[275/00299] train_loss: 0.016187\n",
      "[275/00349] train_loss: 0.016691\n",
      "[275/00399] train_loss: 0.015438\n",
      "[275/00449] train_loss: 0.017211\n",
      "[275/00499] train_loss: 0.016419\n",
      "[275/00549] train_loss: 0.016057\n",
      "[275/00599] train_loss: 0.015241\n",
      "[275/00649] train_loss: 0.016158\n",
      "[275/00699] train_loss: 0.016336\n",
      "[275/00749] train_loss: 0.015983\n",
      "[275/00799] train_loss: 0.016700\n",
      "[275/00849] train_loss: 0.015897\n",
      "[275/00899] train_loss: 0.016674\n",
      "[275/00949] train_loss: 0.015866\n",
      "[275/00999] train_loss: 0.016497\n",
      "[275/01049] train_loss: 0.016055\n",
      "[275/01099] train_loss: 0.015696\n",
      "[275/01149] train_loss: 0.015816\n",
      "[275/01199] train_loss: 0.016731\n",
      "[276/00023] train_loss: 0.020032\n",
      "[276/00073] train_loss: 0.021278\n",
      "[276/00123] train_loss: 0.017807\n",
      "[276/00173] train_loss: 0.017195\n",
      "[276/00223] train_loss: 0.016904\n",
      "[276/00273] train_loss: 0.016644\n",
      "[276/00323] train_loss: 0.015748\n",
      "[276/00373] train_loss: 0.015275\n",
      "[276/00423] train_loss: 0.016294\n",
      "[276/00473] train_loss: 0.016137\n",
      "[276/00523] train_loss: 0.015791\n",
      "[276/00573] train_loss: 0.016116\n",
      "[276/00623] train_loss: 0.017535\n",
      "[276/00673] train_loss: 0.015861\n",
      "[276/00723] train_loss: 0.016015\n",
      "[276/00773] train_loss: 0.016044\n",
      "[276/00823] train_loss: 0.015360\n",
      "[276/00873] train_loss: 0.016378\n",
      "[276/00923] train_loss: 0.015509\n",
      "[276/00973] train_loss: 0.015911\n",
      "[276/01023] train_loss: 0.016593\n",
      "[276/01073] train_loss: 0.016476\n",
      "[276/01123] train_loss: 0.016256\n",
      "[276/01173] train_loss: 0.017185\n",
      "[276/01223] train_loss: 0.016437\n",
      "[277/00047] train_loss: 0.022105\n",
      "[277/00097] train_loss: 0.019157\n",
      "[277/00147] train_loss: 0.017449\n",
      "[277/00197] train_loss: 0.016290\n",
      "[277/00247] train_loss: 0.015753\n",
      "[277/00297] train_loss: 0.016388\n",
      "[277/00347] train_loss: 0.016158\n",
      "[277/00397] train_loss: 0.016400\n",
      "[277/00447] train_loss: 0.016456\n",
      "[277/00497] train_loss: 0.016049\n",
      "[277/00547] train_loss: 0.015669\n",
      "[277/00597] train_loss: 0.016463\n",
      "[277/00647] train_loss: 0.015137\n",
      "[277/00697] train_loss: 0.015709\n",
      "[277/00747] train_loss: 0.015725\n",
      "[277/00797] train_loss: 0.016232\n",
      "[277/00847] train_loss: 0.016952\n",
      "[277/00897] train_loss: 0.016227\n",
      "[277/00947] train_loss: 0.016765\n",
      "[277/00997] train_loss: 0.017018\n",
      "[277/01047] train_loss: 0.017204\n",
      "[277/01097] train_loss: 0.016695\n",
      "[277/01147] train_loss: 0.016279\n",
      "[277/01197] train_loss: 0.016375\n",
      "[278/00021] train_loss: 0.020551\n",
      "[278/00071] train_loss: 0.019624\n",
      "[278/00121] train_loss: 0.019135\n",
      "[278/00171] train_loss: 0.016561\n",
      "[278/00221] train_loss: 0.016488\n",
      "[278/00271] train_loss: 0.016324\n",
      "[278/00321] train_loss: 0.015973\n",
      "[278/00371] train_loss: 0.015520\n",
      "[278/00421] train_loss: 0.016037\n",
      "[278/00471] train_loss: 0.016272\n",
      "[278/00521] train_loss: 0.016330\n",
      "[278/00571] train_loss: 0.016271\n",
      "[278/00621] train_loss: 0.015617\n",
      "[278/00671] train_loss: 0.017392\n",
      "[278/00721] train_loss: 0.015621\n",
      "[278/00771] train_loss: 0.016193\n",
      "[278/00821] train_loss: 0.017267\n",
      "[278/00871] train_loss: 0.016105\n",
      "[278/00921] train_loss: 0.016220\n",
      "[278/00971] train_loss: 0.015669\n",
      "[278/01021] train_loss: 0.017077\n",
      "[278/01071] train_loss: 0.016724\n",
      "[278/01121] train_loss: 0.016313\n",
      "[278/01171] train_loss: 0.016281\n",
      "[278/01221] train_loss: 0.016620\n",
      "[279/00045] train_loss: 0.021700\n",
      "[279/00095] train_loss: 0.018821\n",
      "[279/00145] train_loss: 0.016948\n",
      "[279/00195] train_loss: 0.016455\n",
      "[279/00245] train_loss: 0.016130\n",
      "[279/00295] train_loss: 0.015756\n",
      "[279/00345] train_loss: 0.017318\n",
      "[279/00395] train_loss: 0.015897\n",
      "[279/00445] train_loss: 0.017255\n",
      "[279/00495] train_loss: 0.015364\n",
      "[279/00545] train_loss: 0.016095\n",
      "[279/00595] train_loss: 0.016645\n",
      "[279/00645] train_loss: 0.016420\n",
      "[279/00695] train_loss: 0.015664\n",
      "[279/00745] train_loss: 0.016769\n",
      "[279/00795] train_loss: 0.016200\n",
      "[279/00845] train_loss: 0.015718\n",
      "[279/00895] train_loss: 0.016623\n",
      "[279/00945] train_loss: 0.016462\n",
      "[279/00995] train_loss: 0.015792\n",
      "[279/01045] train_loss: 0.016364\n",
      "[279/01095] train_loss: 0.016452\n",
      "[279/01145] train_loss: 0.016431\n",
      "[279/01195] train_loss: 0.016380\n",
      "[280/00019] train_loss: 0.019116\n",
      "[280/00069] train_loss: 0.020997\n",
      "[280/00119] train_loss: 0.017073\n",
      "[280/00169] train_loss: 0.016287\n",
      "[280/00219] train_loss: 0.016590\n",
      "[280/00269] train_loss: 0.015972\n",
      "[280/00319] train_loss: 0.015815\n",
      "[280/00369] train_loss: 0.016624\n",
      "[280/00419] train_loss: 0.016855\n",
      "[280/00469] train_loss: 0.016479\n",
      "[280/00519] train_loss: 0.016032\n",
      "[280/00569] train_loss: 0.016034\n",
      "[280/00619] train_loss: 0.016129\n",
      "[280/00669] train_loss: 0.015775\n",
      "[280/00719] train_loss: 0.016440\n",
      "[280/00769] train_loss: 0.015615\n",
      "[280/00819] train_loss: 0.016659\n",
      "[280/00869] train_loss: 0.015724\n",
      "[280/00919] train_loss: 0.014960\n",
      "[280/00969] train_loss: 0.017359\n",
      "[280/01019] train_loss: 0.017094\n",
      "[280/01069] train_loss: 0.016190\n",
      "[280/01119] train_loss: 0.017021\n",
      "[280/01169] train_loss: 0.017197\n",
      "[280/01219] train_loss: 0.017141\n",
      "[281/00043] train_loss: 0.021960\n",
      "[281/00093] train_loss: 0.018813\n",
      "[281/00143] train_loss: 0.016875\n",
      "[281/00193] train_loss: 0.016256\n",
      "[281/00243] train_loss: 0.016595\n",
      "[281/00293] train_loss: 0.016154\n",
      "[281/00343] train_loss: 0.016283\n",
      "[281/00393] train_loss: 0.016679\n",
      "[281/00443] train_loss: 0.016366\n",
      "[281/00493] train_loss: 0.016093\n",
      "[281/00543] train_loss: 0.015883\n",
      "[281/00593] train_loss: 0.015304\n",
      "[281/00643] train_loss: 0.016248\n",
      "[281/00693] train_loss: 0.017105\n",
      "[281/00743] train_loss: 0.014837\n",
      "[281/00793] train_loss: 0.016453\n",
      "[281/00843] train_loss: 0.015166\n",
      "[281/00893] train_loss: 0.016426\n",
      "[281/00943] train_loss: 0.015814\n",
      "[281/00993] train_loss: 0.015930\n",
      "[281/01043] train_loss: 0.017785\n",
      "[281/01093] train_loss: 0.016345\n",
      "[281/01143] train_loss: 0.016281\n",
      "[281/01193] train_loss: 0.016236\n",
      "[282/00017] train_loss: 0.019391\n",
      "[282/00067] train_loss: 0.020607\n",
      "[282/00117] train_loss: 0.017748\n",
      "[282/00167] train_loss: 0.016734\n",
      "[282/00217] train_loss: 0.017018\n",
      "[282/00267] train_loss: 0.015673\n",
      "[282/00317] train_loss: 0.016299\n",
      "[282/00367] train_loss: 0.016301\n",
      "[282/00417] train_loss: 0.015706\n",
      "[282/00467] train_loss: 0.015919\n",
      "[282/00517] train_loss: 0.016222\n",
      "[282/00567] train_loss: 0.015627\n",
      "[282/00617] train_loss: 0.016135\n",
      "[282/00667] train_loss: 0.016500\n",
      "[282/00717] train_loss: 0.016607\n",
      "[282/00767] train_loss: 0.016775\n",
      "[282/00817] train_loss: 0.015881\n",
      "[282/00867] train_loss: 0.015552\n",
      "[282/00917] train_loss: 0.016230\n",
      "[282/00967] train_loss: 0.017357\n",
      "[282/01017] train_loss: 0.016359\n",
      "[282/01067] train_loss: 0.015619\n",
      "[282/01117] train_loss: 0.017331\n",
      "[282/01167] train_loss: 0.016752\n",
      "[282/01217] train_loss: 0.016070\n",
      "[283/00041] train_loss: 0.021725\n",
      "[283/00091] train_loss: 0.019694\n",
      "[283/00141] train_loss: 0.017360\n",
      "[283/00191] train_loss: 0.016126\n",
      "[283/00241] train_loss: 0.016977\n",
      "[283/00291] train_loss: 0.016839\n",
      "[283/00341] train_loss: 0.015738\n",
      "[283/00391] train_loss: 0.016317\n",
      "[283/00441] train_loss: 0.016784\n",
      "[283/00491] train_loss: 0.016434\n",
      "[283/00541] train_loss: 0.017093\n",
      "[283/00591] train_loss: 0.016245\n",
      "[283/00641] train_loss: 0.017088\n",
      "[283/00691] train_loss: 0.016243\n",
      "[283/00741] train_loss: 0.015070\n",
      "[283/00791] train_loss: 0.016664\n",
      "[283/00841] train_loss: 0.016422\n",
      "[283/00891] train_loss: 0.015611\n",
      "[283/00941] train_loss: 0.016262\n",
      "[283/00991] train_loss: 0.016197\n",
      "[283/01041] train_loss: 0.016534\n",
      "[283/01091] train_loss: 0.016607\n",
      "[283/01141] train_loss: 0.015480\n",
      "[283/01191] train_loss: 0.015694\n",
      "[284/00015] train_loss: 0.018489\n",
      "[284/00065] train_loss: 0.022532\n",
      "[284/00115] train_loss: 0.018385\n",
      "[284/00165] train_loss: 0.017639\n",
      "[284/00215] train_loss: 0.015982\n",
      "[284/00265] train_loss: 0.017043\n",
      "[284/00315] train_loss: 0.015785\n",
      "[284/00365] train_loss: 0.016245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284/00415] train_loss: 0.016234\n",
      "[284/00465] train_loss: 0.015456\n",
      "[284/00515] train_loss: 0.016934\n",
      "[284/00565] train_loss: 0.016456\n",
      "[284/00615] train_loss: 0.016412\n",
      "[284/00665] train_loss: 0.015562\n",
      "[284/00715] train_loss: 0.015826\n",
      "[284/00765] train_loss: 0.015778\n",
      "[284/00815] train_loss: 0.016450\n",
      "[284/00865] train_loss: 0.015680\n",
      "[284/00915] train_loss: 0.015400\n",
      "[284/00965] train_loss: 0.015563\n",
      "[284/01015] train_loss: 0.016837\n",
      "[284/01065] train_loss: 0.015907\n",
      "[284/01115] train_loss: 0.016105\n",
      "[284/01165] train_loss: 0.016689\n",
      "[284/01215] train_loss: 0.015624\n",
      "[285/00039] train_loss: 0.021583\n",
      "[285/00089] train_loss: 0.019691\n",
      "[285/00139] train_loss: 0.017199\n",
      "[285/00189] train_loss: 0.015723\n",
      "[285/00239] train_loss: 0.016269\n",
      "[285/00289] train_loss: 0.015961\n",
      "[285/00339] train_loss: 0.016308\n",
      "[285/00389] train_loss: 0.016122\n",
      "[285/00439] train_loss: 0.015650\n",
      "[285/00489] train_loss: 0.016015\n",
      "[285/00539] train_loss: 0.016660\n",
      "[285/00589] train_loss: 0.015478\n",
      "[285/00639] train_loss: 0.016376\n",
      "[285/00689] train_loss: 0.015863\n",
      "[285/00739] train_loss: 0.016964\n",
      "[285/00789] train_loss: 0.016443\n",
      "[285/00839] train_loss: 0.016129\n",
      "[285/00889] train_loss: 0.016339\n",
      "[285/00939] train_loss: 0.016282\n",
      "[285/00989] train_loss: 0.016673\n",
      "[285/01039] train_loss: 0.015655\n",
      "[285/01089] train_loss: 0.016175\n",
      "[285/01139] train_loss: 0.016861\n",
      "[285/01189] train_loss: 0.017017\n",
      "[286/00013] train_loss: 0.019025\n",
      "[286/00063] train_loss: 0.021434\n",
      "[286/00113] train_loss: 0.018271\n",
      "[286/00163] train_loss: 0.016874\n",
      "[286/00213] train_loss: 0.016188\n",
      "[286/00263] train_loss: 0.016334\n",
      "[286/00313] train_loss: 0.015911\n",
      "[286/00363] train_loss: 0.015457\n",
      "[286/00413] train_loss: 0.014807\n",
      "[286/00463] train_loss: 0.015754\n",
      "[286/00513] train_loss: 0.015579\n",
      "[286/00563] train_loss: 0.016541\n",
      "[286/00613] train_loss: 0.016093\n",
      "[286/00663] train_loss: 0.016635\n",
      "[286/00713] train_loss: 0.016479\n",
      "[286/00763] train_loss: 0.016688\n",
      "[286/00813] train_loss: 0.016217\n",
      "[286/00863] train_loss: 0.016763\n",
      "[286/00913] train_loss: 0.016138\n",
      "[286/00963] train_loss: 0.016180\n",
      "[286/01013] train_loss: 0.017289\n",
      "[286/01063] train_loss: 0.016537\n",
      "[286/01113] train_loss: 0.015661\n",
      "[286/01163] train_loss: 0.016659\n",
      "[286/01213] train_loss: 0.016199\n",
      "[287/00037] train_loss: 0.022309\n",
      "[287/00087] train_loss: 0.019962\n",
      "[287/00137] train_loss: 0.018223\n",
      "[287/00187] train_loss: 0.016572\n",
      "[287/00237] train_loss: 0.016731\n",
      "[287/00287] train_loss: 0.017528\n",
      "[287/00337] train_loss: 0.016479\n",
      "[287/00387] train_loss: 0.015822\n",
      "[287/00437] train_loss: 0.015608\n",
      "[287/00487] train_loss: 0.015727\n",
      "[287/00537] train_loss: 0.015697\n",
      "[287/00587] train_loss: 0.015966\n",
      "[287/00637] train_loss: 0.015267\n",
      "[287/00687] train_loss: 0.015502\n",
      "[287/00737] train_loss: 0.016729\n",
      "[287/00787] train_loss: 0.015351\n",
      "[287/00837] train_loss: 0.017183\n",
      "[287/00887] train_loss: 0.016573\n",
      "[287/00937] train_loss: 0.016712\n",
      "[287/00987] train_loss: 0.016581\n",
      "[287/01037] train_loss: 0.015698\n",
      "[287/01087] train_loss: 0.016261\n",
      "[287/01137] train_loss: 0.016531\n",
      "[287/01187] train_loss: 0.016478\n",
      "[288/00011] train_loss: 0.017912\n",
      "[288/00061] train_loss: 0.022448\n",
      "[288/00111] train_loss: 0.018958\n",
      "[288/00161] train_loss: 0.016355\n",
      "[288/00211] train_loss: 0.016152\n",
      "[288/00261] train_loss: 0.015378\n",
      "[288/00311] train_loss: 0.016021\n",
      "[288/00361] train_loss: 0.016510\n",
      "[288/00411] train_loss: 0.016224\n",
      "[288/00461] train_loss: 0.015923\n",
      "[288/00511] train_loss: 0.016315\n",
      "[288/00561] train_loss: 0.016405\n",
      "[288/00611] train_loss: 0.015999\n",
      "[288/00661] train_loss: 0.015655\n",
      "[288/00711] train_loss: 0.015948\n",
      "[288/00761] train_loss: 0.016859\n",
      "[288/00811] train_loss: 0.016322\n",
      "[288/00861] train_loss: 0.016336\n",
      "[288/00911] train_loss: 0.016311\n",
      "[288/00961] train_loss: 0.015852\n",
      "[288/01011] train_loss: 0.016221\n",
      "[288/01061] train_loss: 0.016022\n",
      "[288/01111] train_loss: 0.016477\n",
      "[288/01161] train_loss: 0.016222\n",
      "[288/01211] train_loss: 0.016422\n",
      "[289/00035] train_loss: 0.020786\n",
      "[289/00085] train_loss: 0.019850\n",
      "[289/00135] train_loss: 0.016870\n",
      "[289/00185] train_loss: 0.016936\n",
      "[289/00235] train_loss: 0.016500\n",
      "[289/00285] train_loss: 0.016491\n",
      "[289/00335] train_loss: 0.016124\n",
      "[289/00385] train_loss: 0.017222\n",
      "[289/00435] train_loss: 0.016715\n",
      "[289/00485] train_loss: 0.017036\n",
      "[289/00535] train_loss: 0.015698\n",
      "[289/00585] train_loss: 0.016019\n",
      "[289/00635] train_loss: 0.015263\n",
      "[289/00685] train_loss: 0.015203\n",
      "[289/00735] train_loss: 0.015472\n",
      "[289/00785] train_loss: 0.016066\n",
      "[289/00835] train_loss: 0.015918\n",
      "[289/00885] train_loss: 0.016850\n",
      "[289/00935] train_loss: 0.016019\n",
      "[289/00985] train_loss: 0.015862\n",
      "[289/01035] train_loss: 0.016040\n",
      "[289/01085] train_loss: 0.016868\n",
      "[289/01135] train_loss: 0.015337\n",
      "[289/01185] train_loss: 0.016796\n",
      "[290/00009] train_loss: 0.018897\n",
      "[290/00059] train_loss: 0.021316\n",
      "[290/00109] train_loss: 0.018457\n",
      "[290/00159] train_loss: 0.017074\n",
      "[290/00209] train_loss: 0.015918\n",
      "[290/00259] train_loss: 0.016209\n",
      "[290/00309] train_loss: 0.016244\n",
      "[290/00359] train_loss: 0.016232\n",
      "[290/00409] train_loss: 0.016317\n",
      "[290/00459] train_loss: 0.016017\n",
      "[290/00509] train_loss: 0.015964\n",
      "[290/00559] train_loss: 0.016936\n",
      "[290/00609] train_loss: 0.015874\n",
      "[290/00659] train_loss: 0.016856\n",
      "[290/00709] train_loss: 0.015773\n",
      "[290/00759] train_loss: 0.015506\n",
      "[290/00809] train_loss: 0.016360\n",
      "[290/00859] train_loss: 0.016222\n",
      "[290/00909] train_loss: 0.016301\n",
      "[290/00959] train_loss: 0.015461\n",
      "[290/01009] train_loss: 0.016263\n",
      "[290/01059] train_loss: 0.015801\n",
      "[290/01109] train_loss: 0.017447\n",
      "[290/01159] train_loss: 0.016413\n",
      "[290/01209] train_loss: 0.016421\n",
      "[291/00033] train_loss: 0.021415\n",
      "[291/00083] train_loss: 0.019693\n",
      "[291/00133] train_loss: 0.018035\n",
      "[291/00183] train_loss: 0.015943\n",
      "[291/00233] train_loss: 0.017619\n",
      "[291/00283] train_loss: 0.016266\n",
      "[291/00333] train_loss: 0.016450\n",
      "[291/00383] train_loss: 0.015426\n",
      "[291/00433] train_loss: 0.016841\n",
      "[291/00483] train_loss: 0.015352\n",
      "[291/00533] train_loss: 0.015287\n",
      "[291/00583] train_loss: 0.016318\n",
      "[291/00633] train_loss: 0.016501\n",
      "[291/00683] train_loss: 0.016576\n",
      "[291/00733] train_loss: 0.015241\n",
      "[291/00783] train_loss: 0.016675\n",
      "[291/00833] train_loss: 0.015894\n",
      "[291/00883] train_loss: 0.016381\n",
      "[291/00933] train_loss: 0.016789\n",
      "[291/00983] train_loss: 0.017591\n",
      "[291/01033] train_loss: 0.015669\n",
      "[291/01083] train_loss: 0.015853\n",
      "[291/01133] train_loss: 0.015728\n",
      "[291/01183] train_loss: 0.015627\n",
      "[292/00007] train_loss: 0.017523\n",
      "[292/00057] train_loss: 0.023055\n",
      "[292/00107] train_loss: 0.019330\n",
      "[292/00157] train_loss: 0.016670\n",
      "[292/00207] train_loss: 0.016151\n",
      "[292/00257] train_loss: 0.016167\n",
      "[292/00307] train_loss: 0.016155\n",
      "[292/00357] train_loss: 0.017611\n",
      "[292/00407] train_loss: 0.017004\n",
      "[292/00457] train_loss: 0.015318\n",
      "[292/00507] train_loss: 0.015550\n",
      "[292/00557] train_loss: 0.016029\n",
      "[292/00607] train_loss: 0.015462\n",
      "[292/00657] train_loss: 0.016683\n",
      "[292/00707] train_loss: 0.015076\n",
      "[292/00757] train_loss: 0.015660\n",
      "[292/00807] train_loss: 0.016624\n",
      "[292/00857] train_loss: 0.016437\n",
      "[292/00907] train_loss: 0.016521\n",
      "[292/00957] train_loss: 0.016437\n",
      "[292/01007] train_loss: 0.015873\n",
      "[292/01057] train_loss: 0.016842\n",
      "[292/01107] train_loss: 0.015762\n",
      "[292/01157] train_loss: 0.015965\n",
      "[292/01207] train_loss: 0.016633\n",
      "[293/00031] train_loss: 0.020950\n",
      "[293/00081] train_loss: 0.019676\n",
      "[293/00131] train_loss: 0.017396\n",
      "[293/00181] train_loss: 0.017556\n",
      "[293/00231] train_loss: 0.015984\n",
      "[293/00281] train_loss: 0.015483\n",
      "[293/00331] train_loss: 0.016521\n",
      "[293/00381] train_loss: 0.017302\n",
      "[293/00431] train_loss: 0.017656\n",
      "[293/00481] train_loss: 0.015611\n",
      "[293/00531] train_loss: 0.016218\n",
      "[293/00581] train_loss: 0.016225\n",
      "[293/00631] train_loss: 0.016081\n",
      "[293/00681] train_loss: 0.015963\n",
      "[293/00731] train_loss: 0.016155\n",
      "[293/00781] train_loss: 0.015194\n",
      "[293/00831] train_loss: 0.015875\n",
      "[293/00881] train_loss: 0.016045\n",
      "[293/00931] train_loss: 0.015375\n",
      "[293/00981] train_loss: 0.015422\n",
      "[293/01031] train_loss: 0.015754\n",
      "[293/01081] train_loss: 0.016734\n",
      "[293/01131] train_loss: 0.015494\n",
      "[293/01181] train_loss: 0.016270\n",
      "[294/00005] train_loss: 0.017445\n",
      "[294/00055] train_loss: 0.022566\n",
      "[294/00105] train_loss: 0.020016\n",
      "[294/00155] train_loss: 0.017135\n",
      "[294/00205] train_loss: 0.016221\n",
      "[294/00255] train_loss: 0.016437\n",
      "[294/00305] train_loss: 0.015631\n",
      "[294/00355] train_loss: 0.016685\n",
      "[294/00405] train_loss: 0.016446\n",
      "[294/00455] train_loss: 0.016040\n",
      "[294/00505] train_loss: 0.015946\n",
      "[294/00555] train_loss: 0.016363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[294/00605] train_loss: 0.015783\n",
      "[294/00655] train_loss: 0.015335\n",
      "[294/00705] train_loss: 0.016972\n",
      "[294/00755] train_loss: 0.016056\n",
      "[294/00805] train_loss: 0.016958\n",
      "[294/00855] train_loss: 0.016957\n",
      "[294/00905] train_loss: 0.016821\n",
      "[294/00955] train_loss: 0.016760\n",
      "[294/01005] train_loss: 0.015914\n",
      "[294/01055] train_loss: 0.016516\n",
      "[294/01105] train_loss: 0.016288\n",
      "[294/01155] train_loss: 0.015956\n",
      "[294/01205] train_loss: 0.015804\n",
      "[295/00029] train_loss: 0.019842\n",
      "[295/00079] train_loss: 0.020928\n",
      "[295/00129] train_loss: 0.018084\n",
      "[295/00179] train_loss: 0.016373\n",
      "[295/00229] train_loss: 0.016595\n",
      "[295/00279] train_loss: 0.016882\n",
      "[295/00329] train_loss: 0.016365\n",
      "[295/00379] train_loss: 0.016347\n",
      "[295/00429] train_loss: 0.016423\n",
      "[295/00479] train_loss: 0.016479\n",
      "[295/00529] train_loss: 0.015257\n",
      "[295/00579] train_loss: 0.016375\n",
      "[295/00629] train_loss: 0.016879\n",
      "[295/00679] train_loss: 0.016152\n",
      "[295/00729] train_loss: 0.015860\n",
      "[295/00779] train_loss: 0.015390\n",
      "[295/00829] train_loss: 0.015959\n",
      "[295/00879] train_loss: 0.016035\n",
      "[295/00929] train_loss: 0.016752\n",
      "[295/00979] train_loss: 0.017192\n",
      "[295/01029] train_loss: 0.017041\n",
      "[295/01079] train_loss: 0.015834\n",
      "[295/01129] train_loss: 0.016046\n",
      "[295/01179] train_loss: 0.016800\n",
      "[296/00003] train_loss: 0.016294\n",
      "[296/00053] train_loss: 0.022275\n",
      "[296/00103] train_loss: 0.018022\n",
      "[296/00153] train_loss: 0.016054\n",
      "[296/00203] train_loss: 0.016919\n",
      "[296/00253] train_loss: 0.016536\n",
      "[296/00303] train_loss: 0.016539\n",
      "[296/00353] train_loss: 0.015521\n",
      "[296/00403] train_loss: 0.016115\n",
      "[296/00453] train_loss: 0.016264\n",
      "[296/00503] train_loss: 0.017372\n",
      "[296/00553] train_loss: 0.015527\n",
      "[296/00603] train_loss: 0.015679\n",
      "[296/00653] train_loss: 0.016804\n",
      "[296/00703] train_loss: 0.016565\n",
      "[296/00753] train_loss: 0.016306\n",
      "[296/00803] train_loss: 0.016352\n",
      "[296/00853] train_loss: 0.016086\n",
      "[296/00903] train_loss: 0.015936\n",
      "[296/00953] train_loss: 0.017060\n",
      "[296/01003] train_loss: 0.015137\n",
      "[296/01053] train_loss: 0.016279\n",
      "[296/01103] train_loss: 0.015306\n",
      "[296/01153] train_loss: 0.016632\n",
      "[296/01203] train_loss: 0.015837\n",
      "[297/00027] train_loss: 0.021304\n",
      "[297/00077] train_loss: 0.020532\n",
      "[297/00127] train_loss: 0.017977\n",
      "[297/00177] train_loss: 0.017636\n",
      "[297/00227] train_loss: 0.016389\n",
      "[297/00277] train_loss: 0.016713\n",
      "[297/00327] train_loss: 0.015894\n",
      "[297/00377] train_loss: 0.015911\n",
      "[297/00427] train_loss: 0.015973\n",
      "[297/00477] train_loss: 0.015977\n",
      "[297/00527] train_loss: 0.016060\n",
      "[297/00577] train_loss: 0.016593\n",
      "[297/00627] train_loss: 0.016009\n",
      "[297/00677] train_loss: 0.016850\n",
      "[297/00727] train_loss: 0.016205\n",
      "[297/00777] train_loss: 0.015373\n",
      "[297/00827] train_loss: 0.016712\n",
      "[297/00877] train_loss: 0.016251\n",
      "[297/00927] train_loss: 0.016257\n",
      "[297/00977] train_loss: 0.017053\n",
      "[297/01027] train_loss: 0.016167\n",
      "[297/01077] train_loss: 0.016174\n",
      "[297/01127] train_loss: 0.015812\n",
      "[297/01177] train_loss: 0.016496\n",
      "[298/00001] train_loss: 0.017383\n",
      "[298/00051] train_loss: 0.023648\n",
      "[298/00101] train_loss: 0.018405\n",
      "[298/00151] train_loss: 0.016984\n",
      "[298/00201] train_loss: 0.016923\n",
      "[298/00251] train_loss: 0.016221\n",
      "[298/00301] train_loss: 0.016397\n",
      "[298/00351] train_loss: 0.015939\n",
      "[298/00401] train_loss: 0.016455\n",
      "[298/00451] train_loss: 0.016536\n",
      "[298/00501] train_loss: 0.015844\n",
      "[298/00551] train_loss: 0.016223\n",
      "[298/00601] train_loss: 0.016253\n",
      "[298/00651] train_loss: 0.015730\n",
      "[298/00701] train_loss: 0.016323\n",
      "[298/00751] train_loss: 0.016532\n",
      "[298/00801] train_loss: 0.015859\n",
      "[298/00851] train_loss: 0.016427\n",
      "[298/00901] train_loss: 0.015985\n",
      "[298/00951] train_loss: 0.016021\n",
      "[298/01001] train_loss: 0.016573\n",
      "[298/01051] train_loss: 0.015487\n",
      "[298/01101] train_loss: 0.015612\n",
      "[298/01151] train_loss: 0.015925\n",
      "[298/01201] train_loss: 0.016188\n",
      "[299/00025] train_loss: 0.019290\n",
      "[299/00075] train_loss: 0.019961\n",
      "[299/00125] train_loss: 0.017825\n",
      "[299/00175] train_loss: 0.016262\n",
      "[299/00225] train_loss: 0.016439\n",
      "[299/00275] train_loss: 0.016622\n",
      "[299/00325] train_loss: 0.017255\n",
      "[299/00375] train_loss: 0.016125\n",
      "[299/00425] train_loss: 0.016092\n",
      "[299/00475] train_loss: 0.016126\n",
      "[299/00525] train_loss: 0.016329\n",
      "[299/00575] train_loss: 0.016285\n",
      "[299/00625] train_loss: 0.014996\n",
      "[299/00675] train_loss: 0.016961\n",
      "[299/00725] train_loss: 0.015528\n",
      "[299/00775] train_loss: 0.017292\n",
      "[299/00825] train_loss: 0.016321\n",
      "[299/00875] train_loss: 0.015563\n",
      "[299/00925] train_loss: 0.016340\n",
      "[299/00975] train_loss: 0.016344\n",
      "[299/01025] train_loss: 0.016773\n",
      "[299/01075] train_loss: 0.016982\n",
      "[299/01125] train_loss: 0.015830\n",
      "[299/01175] train_loss: 0.016573\n",
      "[299/01225] train_loss: 0.015461\n",
      "[300/00049] train_loss: 0.022983\n",
      "[300/00099] train_loss: 0.019646\n",
      "[300/00149] train_loss: 0.017517\n",
      "[300/00199] train_loss: 0.016183\n",
      "[300/00249] train_loss: 0.016851\n",
      "[300/00299] train_loss: 0.015937\n",
      "[300/00349] train_loss: 0.015617\n",
      "[300/00399] train_loss: 0.016202\n",
      "[300/00449] train_loss: 0.015835\n",
      "[300/00499] train_loss: 0.016556\n",
      "[300/00549] train_loss: 0.015882\n",
      "[300/00599] train_loss: 0.015430\n",
      "[300/00649] train_loss: 0.016509\n",
      "[300/00699] train_loss: 0.016727\n",
      "[300/00749] train_loss: 0.015370\n",
      "[300/00799] train_loss: 0.015934\n",
      "[300/00849] train_loss: 0.015148\n",
      "[300/00899] train_loss: 0.016312\n",
      "[300/00949] train_loss: 0.016801\n",
      "[300/00999] train_loss: 0.015538\n",
      "[300/01049] train_loss: 0.016500\n",
      "[300/01099] train_loss: 0.016101\n",
      "[300/01149] train_loss: 0.016525\n",
      "[300/01199] train_loss: 0.017321\n",
      "[301/00023] train_loss: 0.021162\n",
      "[301/00073] train_loss: 0.021197\n",
      "[301/00123] train_loss: 0.017487\n",
      "[301/00173] train_loss: 0.016829\n",
      "[301/00223] train_loss: 0.016527\n",
      "[301/00273] train_loss: 0.016147\n",
      "[301/00323] train_loss: 0.016173\n",
      "[301/00373] train_loss: 0.015955\n",
      "[301/00423] train_loss: 0.016573\n",
      "[301/00473] train_loss: 0.016756\n",
      "[301/00523] train_loss: 0.015803\n",
      "[301/00573] train_loss: 0.016480\n",
      "[301/00623] train_loss: 0.015262\n",
      "[301/00673] train_loss: 0.015778\n",
      "[301/00723] train_loss: 0.016436\n",
      "[301/00773] train_loss: 0.016035\n",
      "[301/00823] train_loss: 0.016323\n",
      "[301/00873] train_loss: 0.016246\n",
      "[301/00923] train_loss: 0.016563\n",
      "[301/00973] train_loss: 0.015187\n",
      "[301/01023] train_loss: 0.016283\n",
      "[301/01073] train_loss: 0.016131\n",
      "[301/01123] train_loss: 0.017209\n",
      "[301/01173] train_loss: 0.016530\n",
      "[301/01223] train_loss: 0.016158\n",
      "[302/00047] train_loss: 0.021679\n",
      "[302/00097] train_loss: 0.018998\n",
      "[302/00147] train_loss: 0.018185\n",
      "[302/00197] train_loss: 0.016087\n",
      "[302/00247] train_loss: 0.015973\n",
      "[302/00297] train_loss: 0.016323\n",
      "[302/00347] train_loss: 0.015763\n",
      "[302/00397] train_loss: 0.016346\n",
      "[302/00447] train_loss: 0.016563\n",
      "[302/00497] train_loss: 0.014897\n",
      "[302/00547] train_loss: 0.015703\n",
      "[302/00597] train_loss: 0.017244\n",
      "[302/00647] train_loss: 0.015503\n",
      "[302/00697] train_loss: 0.016729\n",
      "[302/00747] train_loss: 0.016181\n",
      "[302/00797] train_loss: 0.015291\n",
      "[302/00847] train_loss: 0.016428\n",
      "[302/00897] train_loss: 0.016273\n",
      "[302/00947] train_loss: 0.016684\n",
      "[302/00997] train_loss: 0.015918\n",
      "[302/01047] train_loss: 0.015911\n",
      "[302/01097] train_loss: 0.016055\n",
      "[302/01147] train_loss: 0.016925\n",
      "[302/01197] train_loss: 0.017256\n",
      "[303/00021] train_loss: 0.019732\n",
      "[303/00071] train_loss: 0.021902\n",
      "[303/00121] train_loss: 0.017560\n",
      "[303/00171] train_loss: 0.017198\n",
      "[303/00221] train_loss: 0.016298\n",
      "[303/00271] train_loss: 0.016097\n",
      "[303/00321] train_loss: 0.016531\n",
      "[303/00371] train_loss: 0.016144\n",
      "[303/00421] train_loss: 0.016038\n",
      "[303/00471] train_loss: 0.015791\n",
      "[303/00521] train_loss: 0.015767\n",
      "[303/00571] train_loss: 0.016417\n",
      "[303/00621] train_loss: 0.015153\n",
      "[303/00671] train_loss: 0.016265\n",
      "[303/00721] train_loss: 0.016649\n",
      "[303/00771] train_loss: 0.015580\n",
      "[303/00821] train_loss: 0.017081\n",
      "[303/00871] train_loss: 0.015820\n",
      "[303/00921] train_loss: 0.016003\n",
      "[303/00971] train_loss: 0.015937\n",
      "[303/01021] train_loss: 0.015957\n",
      "[303/01071] train_loss: 0.015400\n",
      "[303/01121] train_loss: 0.016463\n",
      "[303/01171] train_loss: 0.017159\n",
      "[303/01221] train_loss: 0.017399\n",
      "[304/00045] train_loss: 0.021763\n",
      "[304/00095] train_loss: 0.020176\n",
      "[304/00145] train_loss: 0.016753\n",
      "[304/00195] train_loss: 0.016532\n",
      "[304/00245] train_loss: 0.016788\n",
      "[304/00295] train_loss: 0.016913\n",
      "[304/00345] train_loss: 0.015510\n",
      "[304/00395] train_loss: 0.015975\n",
      "[304/00445] train_loss: 0.015175\n",
      "[304/00495] train_loss: 0.015834\n",
      "[304/00545] train_loss: 0.015086\n",
      "[304/00595] train_loss: 0.016038\n",
      "[304/00645] train_loss: 0.015315\n",
      "[304/00695] train_loss: 0.016505\n",
      "[304/00745] train_loss: 0.015687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304/00795] train_loss: 0.015617\n",
      "[304/00845] train_loss: 0.015718\n",
      "[304/00895] train_loss: 0.015977\n",
      "[304/00945] train_loss: 0.016099\n",
      "[304/00995] train_loss: 0.016005\n",
      "[304/01045] train_loss: 0.016047\n",
      "[304/01095] train_loss: 0.016819\n",
      "[304/01145] train_loss: 0.015997\n",
      "[304/01195] train_loss: 0.016800\n",
      "[305/00019] train_loss: 0.019471\n",
      "[305/00069] train_loss: 0.021838\n",
      "[305/00119] train_loss: 0.017172\n",
      "[305/00169] train_loss: 0.016542\n",
      "[305/00219] train_loss: 0.016555\n",
      "[305/00269] train_loss: 0.015833\n",
      "[305/00319] train_loss: 0.016110\n",
      "[305/00369] train_loss: 0.015266\n",
      "[305/00419] train_loss: 0.015763\n",
      "[305/00469] train_loss: 0.015411\n",
      "[305/00519] train_loss: 0.016574\n",
      "[305/00569] train_loss: 0.016635\n",
      "[305/00619] train_loss: 0.016590\n",
      "[305/00669] train_loss: 0.016035\n",
      "[305/00719] train_loss: 0.015999\n",
      "[305/00769] train_loss: 0.017043\n",
      "[305/00819] train_loss: 0.016643\n",
      "[305/00869] train_loss: 0.016416\n",
      "[305/00919] train_loss: 0.016690\n",
      "[305/00969] train_loss: 0.016206\n",
      "[305/01019] train_loss: 0.016523\n",
      "[305/01069] train_loss: 0.015958\n",
      "[305/01119] train_loss: 0.016162\n",
      "[305/01169] train_loss: 0.015920\n",
      "[305/01219] train_loss: 0.016991\n",
      "[306/00043] train_loss: 0.023247\n",
      "[306/00093] train_loss: 0.019699\n",
      "[306/00143] train_loss: 0.017540\n",
      "[306/00193] train_loss: 0.016735\n",
      "[306/00243] train_loss: 0.016223\n",
      "[306/00293] train_loss: 0.016449\n",
      "[306/00343] train_loss: 0.015743\n",
      "[306/00393] train_loss: 0.015696\n",
      "[306/00443] train_loss: 0.016255\n",
      "[306/00493] train_loss: 0.015666\n",
      "[306/00543] train_loss: 0.016880\n",
      "[306/00593] train_loss: 0.016820\n",
      "[306/00643] train_loss: 0.016117\n",
      "[306/00693] train_loss: 0.015861\n",
      "[306/00743] train_loss: 0.014808\n",
      "[306/00793] train_loss: 0.016830\n",
      "[306/00843] train_loss: 0.015500\n",
      "[306/00893] train_loss: 0.016249\n",
      "[306/00943] train_loss: 0.015926\n",
      "[306/00993] train_loss: 0.016752\n",
      "[306/01043] train_loss: 0.016064\n",
      "[306/01093] train_loss: 0.016072\n",
      "[306/01143] train_loss: 0.016955\n",
      "[306/01193] train_loss: 0.015677\n",
      "[307/00017] train_loss: 0.018672\n",
      "[307/00067] train_loss: 0.020497\n",
      "[307/00117] train_loss: 0.019159\n",
      "[307/00167] train_loss: 0.016800\n",
      "[307/00217] train_loss: 0.015969\n",
      "[307/00267] train_loss: 0.015640\n",
      "[307/00317] train_loss: 0.015858\n",
      "[307/00367] train_loss: 0.016671\n",
      "[307/00417] train_loss: 0.016849\n",
      "[307/00467] train_loss: 0.015960\n",
      "[307/00517] train_loss: 0.016066\n",
      "[307/00567] train_loss: 0.016198\n",
      "[307/00617] train_loss: 0.016381\n",
      "[307/00667] train_loss: 0.016107\n",
      "[307/00717] train_loss: 0.016379\n",
      "[307/00767] train_loss: 0.015571\n",
      "[307/00817] train_loss: 0.015409\n",
      "[307/00867] train_loss: 0.015360\n",
      "[307/00917] train_loss: 0.015976\n",
      "[307/00967] train_loss: 0.016242\n",
      "[307/01017] train_loss: 0.015440\n",
      "[307/01067] train_loss: 0.016626\n",
      "[307/01117] train_loss: 0.015630\n",
      "[307/01167] train_loss: 0.017145\n",
      "[307/01217] train_loss: 0.016293\n",
      "[308/00041] train_loss: 0.021759\n",
      "[308/00091] train_loss: 0.018996\n",
      "[308/00141] train_loss: 0.017243\n",
      "[308/00191] train_loss: 0.016805\n",
      "[308/00241] train_loss: 0.016761\n",
      "[308/00291] train_loss: 0.016408\n",
      "[308/00341] train_loss: 0.016045\n",
      "[308/00391] train_loss: 0.016589\n",
      "[308/00441] train_loss: 0.015928\n",
      "[308/00491] train_loss: 0.016379\n",
      "[308/00541] train_loss: 0.016650\n",
      "[308/00591] train_loss: 0.016478\n",
      "[308/00641] train_loss: 0.015786\n",
      "[308/00691] train_loss: 0.016325\n",
      "[308/00741] train_loss: 0.016869\n",
      "[308/00791] train_loss: 0.017031\n",
      "[308/00841] train_loss: 0.016496\n",
      "[308/00891] train_loss: 0.015526\n",
      "[308/00941] train_loss: 0.015998\n",
      "[308/00991] train_loss: 0.016604\n",
      "[308/01041] train_loss: 0.016384\n",
      "[308/01091] train_loss: 0.015513\n",
      "[308/01141] train_loss: 0.015978\n",
      "[308/01191] train_loss: 0.016469\n",
      "[309/00015] train_loss: 0.018474\n",
      "[309/00065] train_loss: 0.020835\n",
      "[309/00115] train_loss: 0.018538\n",
      "[309/00165] train_loss: 0.017352\n",
      "[309/00215] train_loss: 0.015672\n",
      "[309/00265] train_loss: 0.016302\n",
      "[309/00315] train_loss: 0.015973\n",
      "[309/00365] train_loss: 0.016105\n",
      "[309/00415] train_loss: 0.016201\n",
      "[309/00465] train_loss: 0.015561\n",
      "[309/00515] train_loss: 0.016111\n",
      "[309/00565] train_loss: 0.016489\n",
      "[309/00615] train_loss: 0.015620\n",
      "[309/00665] train_loss: 0.015435\n",
      "[309/00715] train_loss: 0.015948\n",
      "[309/00765] train_loss: 0.016549\n",
      "[309/00815] train_loss: 0.016232\n",
      "[309/00865] train_loss: 0.016039\n",
      "[309/00915] train_loss: 0.015877\n",
      "[309/00965] train_loss: 0.016283\n",
      "[309/01015] train_loss: 0.014850\n",
      "[309/01065] train_loss: 0.016198\n",
      "[309/01115] train_loss: 0.017105\n",
      "[309/01165] train_loss: 0.016665\n",
      "[309/01215] train_loss: 0.016975\n",
      "[310/00039] train_loss: 0.020436\n",
      "[310/00089] train_loss: 0.018735\n",
      "[310/00139] train_loss: 0.017649\n",
      "[310/00189] train_loss: 0.016586\n",
      "[310/00239] train_loss: 0.016542\n",
      "[310/00289] train_loss: 0.015547\n",
      "[310/00339] train_loss: 0.015418\n",
      "[310/00389] train_loss: 0.016646\n",
      "[310/00439] train_loss: 0.015351\n",
      "[310/00489] train_loss: 0.015946\n",
      "[310/00539] train_loss: 0.016751\n",
      "[310/00589] train_loss: 0.016509\n",
      "[310/00639] train_loss: 0.016435\n",
      "[310/00689] train_loss: 0.016767\n",
      "[310/00739] train_loss: 0.016708\n",
      "[310/00789] train_loss: 0.015673\n",
      "[310/00839] train_loss: 0.015793\n",
      "[310/00889] train_loss: 0.016126\n",
      "[310/00939] train_loss: 0.015865\n",
      "[310/00989] train_loss: 0.016349\n",
      "[310/01039] train_loss: 0.015344\n",
      "[310/01089] train_loss: 0.016536\n",
      "[310/01139] train_loss: 0.015943\n",
      "[310/01189] train_loss: 0.015901\n",
      "[311/00013] train_loss: 0.018418\n",
      "[311/00063] train_loss: 0.020725\n",
      "[311/00113] train_loss: 0.018195\n",
      "[311/00163] train_loss: 0.017286\n",
      "[311/00213] train_loss: 0.016563\n",
      "[311/00263] train_loss: 0.017009\n",
      "[311/00313] train_loss: 0.016363\n",
      "[311/00363] train_loss: 0.015625\n",
      "[311/00413] train_loss: 0.015516\n",
      "[311/00463] train_loss: 0.015611\n",
      "[311/00513] train_loss: 0.016917\n",
      "[311/00563] train_loss: 0.015546\n",
      "[311/00613] train_loss: 0.015789\n",
      "[311/00663] train_loss: 0.015993\n",
      "[311/00713] train_loss: 0.015905\n",
      "[311/00763] train_loss: 0.016407\n",
      "[311/00813] train_loss: 0.016542\n",
      "[311/00863] train_loss: 0.016056\n",
      "[311/00913] train_loss: 0.016605\n",
      "[311/00963] train_loss: 0.016146\n",
      "[311/01013] train_loss: 0.015653\n",
      "[311/01063] train_loss: 0.015301\n",
      "[311/01113] train_loss: 0.017136\n",
      "[311/01163] train_loss: 0.015574\n",
      "[311/01213] train_loss: 0.016862\n",
      "[312/00037] train_loss: 0.021939\n",
      "[312/00087] train_loss: 0.019802\n",
      "[312/00137] train_loss: 0.017655\n",
      "[312/00187] train_loss: 0.017293\n",
      "[312/00237] train_loss: 0.015602\n",
      "[312/00287] train_loss: 0.015122\n",
      "[312/00337] train_loss: 0.015573\n",
      "[312/00387] train_loss: 0.015649\n",
      "[312/00437] train_loss: 0.016422\n",
      "[312/00487] train_loss: 0.016644\n",
      "[312/00537] train_loss: 0.016105\n",
      "[312/00587] train_loss: 0.016485\n",
      "[312/00637] train_loss: 0.015915\n",
      "[312/00687] train_loss: 0.016221\n",
      "[312/00737] train_loss: 0.016073\n",
      "[312/00787] train_loss: 0.017309\n",
      "[312/00837] train_loss: 0.016441\n",
      "[312/00887] train_loss: 0.016129\n",
      "[312/00937] train_loss: 0.016618\n",
      "[312/00987] train_loss: 0.015645\n",
      "[312/01037] train_loss: 0.016730\n",
      "[312/01087] train_loss: 0.016227\n",
      "[312/01137] train_loss: 0.017327\n",
      "[312/01187] train_loss: 0.017278\n",
      "[313/00011] train_loss: 0.019322\n",
      "[313/00061] train_loss: 0.021690\n",
      "[313/00111] train_loss: 0.018258\n",
      "[313/00161] train_loss: 0.016916\n",
      "[313/00211] train_loss: 0.016698\n",
      "[313/00261] train_loss: 0.015325\n",
      "[313/00311] train_loss: 0.015762\n",
      "[313/00361] train_loss: 0.016404\n",
      "[313/00411] train_loss: 0.016714\n",
      "[313/00461] train_loss: 0.015835\n",
      "[313/00511] train_loss: 0.015702\n",
      "[313/00561] train_loss: 0.016335\n",
      "[313/00611] train_loss: 0.016858\n",
      "[313/00661] train_loss: 0.015793\n",
      "[313/00711] train_loss: 0.015390\n",
      "[313/00761] train_loss: 0.015421\n",
      "[313/00811] train_loss: 0.015713\n",
      "[313/00861] train_loss: 0.016246\n",
      "[313/00911] train_loss: 0.017108\n",
      "[313/00961] train_loss: 0.015527\n",
      "[313/01011] train_loss: 0.015447\n",
      "[313/01061] train_loss: 0.016213\n",
      "[313/01111] train_loss: 0.015830\n",
      "[313/01161] train_loss: 0.016683\n",
      "[313/01211] train_loss: 0.015458\n",
      "[314/00035] train_loss: 0.021376\n",
      "[314/00085] train_loss: 0.019123\n",
      "[314/00135] train_loss: 0.018156\n",
      "[314/00185] train_loss: 0.015492\n",
      "[314/00235] train_loss: 0.016190\n",
      "[314/00285] train_loss: 0.015727\n",
      "[314/00335] train_loss: 0.016218\n",
      "[314/00385] train_loss: 0.016483\n",
      "[314/00435] train_loss: 0.015982\n",
      "[314/00485] train_loss: 0.015738\n",
      "[314/00535] train_loss: 0.015652\n",
      "[314/00585] train_loss: 0.016150\n",
      "[314/00635] train_loss: 0.016554\n",
      "[314/00685] train_loss: 0.017523\n",
      "[314/00735] train_loss: 0.015690\n",
      "[314/00785] train_loss: 0.016488\n",
      "[314/00835] train_loss: 0.014855\n",
      "[314/00885] train_loss: 0.016907\n",
      "[314/00935] train_loss: 0.016054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314/00985] train_loss: 0.016123\n",
      "[314/01035] train_loss: 0.016673\n",
      "[314/01085] train_loss: 0.015990\n",
      "[314/01135] train_loss: 0.016047\n",
      "[314/01185] train_loss: 0.016044\n",
      "[315/00009] train_loss: 0.018682\n",
      "[315/00059] train_loss: 0.020547\n",
      "[315/00109] train_loss: 0.018115\n",
      "[315/00159] train_loss: 0.016738\n",
      "[315/00209] train_loss: 0.015196\n",
      "[315/00259] train_loss: 0.016723\n",
      "[315/00309] train_loss: 0.016246\n",
      "[315/00359] train_loss: 0.016053\n",
      "[315/00409] train_loss: 0.015815\n",
      "[315/00459] train_loss: 0.016020\n",
      "[315/00509] train_loss: 0.015971\n",
      "[315/00559] train_loss: 0.015994\n",
      "[315/00609] train_loss: 0.015948\n",
      "[315/00659] train_loss: 0.015445\n",
      "[315/00709] train_loss: 0.016180\n",
      "[315/00759] train_loss: 0.016994\n",
      "[315/00809] train_loss: 0.015393\n",
      "[315/00859] train_loss: 0.016502\n",
      "[315/00909] train_loss: 0.015750\n",
      "[315/00959] train_loss: 0.015741\n",
      "[315/01009] train_loss: 0.015795\n",
      "[315/01059] train_loss: 0.016405\n",
      "[315/01109] train_loss: 0.016216\n",
      "[315/01159] train_loss: 0.016534\n",
      "[315/01209] train_loss: 0.016399\n",
      "[316/00033] train_loss: 0.021227\n",
      "[316/00083] train_loss: 0.021697\n",
      "[316/00133] train_loss: 0.019004\n",
      "[316/00183] train_loss: 0.016835\n",
      "[316/00233] train_loss: 0.015511\n",
      "[316/00283] train_loss: 0.015668\n",
      "[316/00333] train_loss: 0.016269\n",
      "[316/00383] train_loss: 0.015897\n",
      "[316/00433] train_loss: 0.015256\n",
      "[316/00483] train_loss: 0.015627\n",
      "[316/00533] train_loss: 0.016039\n",
      "[316/00583] train_loss: 0.015521\n",
      "[316/00633] train_loss: 0.016503\n",
      "[316/00683] train_loss: 0.015929\n",
      "[316/00733] train_loss: 0.015993\n",
      "[316/00783] train_loss: 0.016132\n",
      "[316/00833] train_loss: 0.015606\n",
      "[316/00883] train_loss: 0.016361\n",
      "[316/00933] train_loss: 0.015899\n",
      "[316/00983] train_loss: 0.015564\n",
      "[316/01033] train_loss: 0.016659\n",
      "[316/01083] train_loss: 0.016258\n",
      "[316/01133] train_loss: 0.016953\n",
      "[316/01183] train_loss: 0.017182\n",
      "[317/00007] train_loss: 0.017451\n",
      "[317/00057] train_loss: 0.021724\n",
      "[317/00107] train_loss: 0.017972\n",
      "[317/00157] train_loss: 0.016346\n",
      "[317/00207] train_loss: 0.016190\n",
      "[317/00257] train_loss: 0.015713\n",
      "[317/00307] train_loss: 0.016820\n",
      "[317/00357] train_loss: 0.016172\n",
      "[317/00407] train_loss: 0.015245\n",
      "[317/00457] train_loss: 0.015593\n",
      "[317/00507] train_loss: 0.015685\n",
      "[317/00557] train_loss: 0.016480\n",
      "[317/00607] train_loss: 0.015951\n",
      "[317/00657] train_loss: 0.016676\n",
      "[317/00707] train_loss: 0.016665\n",
      "[317/00757] train_loss: 0.015808\n",
      "[317/00807] train_loss: 0.015568\n",
      "[317/00857] train_loss: 0.016894\n",
      "[317/00907] train_loss: 0.015424\n",
      "[317/00957] train_loss: 0.015981\n",
      "[317/01007] train_loss: 0.015785\n",
      "[317/01057] train_loss: 0.015960\n",
      "[317/01107] train_loss: 0.017264\n",
      "[317/01157] train_loss: 0.016497\n",
      "[317/01207] train_loss: 0.016216\n",
      "[318/00031] train_loss: 0.021761\n",
      "[318/00081] train_loss: 0.019757\n",
      "[318/00131] train_loss: 0.017416\n",
      "[318/00181] train_loss: 0.017012\n",
      "[318/00231] train_loss: 0.016087\n",
      "[318/00281] train_loss: 0.015205\n",
      "[318/00331] train_loss: 0.016007\n",
      "[318/00381] train_loss: 0.016155\n",
      "[318/00431] train_loss: 0.015634\n",
      "[318/00481] train_loss: 0.016638\n",
      "[318/00531] train_loss: 0.016480\n",
      "[318/00581] train_loss: 0.015635\n",
      "[318/00631] train_loss: 0.015769\n",
      "[318/00681] train_loss: 0.015562\n",
      "[318/00731] train_loss: 0.015795\n",
      "[318/00781] train_loss: 0.015837\n",
      "[318/00831] train_loss: 0.016580\n",
      "[318/00881] train_loss: 0.016085\n",
      "[318/00931] train_loss: 0.015450\n",
      "[318/00981] train_loss: 0.016331\n",
      "[318/01031] train_loss: 0.016705\n",
      "[318/01081] train_loss: 0.016282\n",
      "[318/01131] train_loss: 0.016942\n",
      "[318/01181] train_loss: 0.017380\n",
      "[319/00005] train_loss: 0.017932\n",
      "[319/00055] train_loss: 0.020637\n",
      "[319/00105] train_loss: 0.018380\n",
      "[319/00155] train_loss: 0.016723\n",
      "[319/00205] train_loss: 0.016566\n",
      "[319/00255] train_loss: 0.016165\n",
      "[319/00305] train_loss: 0.015810\n",
      "[319/00355] train_loss: 0.016111\n",
      "[319/00405] train_loss: 0.016123\n",
      "[319/00455] train_loss: 0.015660\n",
      "[319/00505] train_loss: 0.015126\n",
      "[319/00555] train_loss: 0.015902\n",
      "[319/00605] train_loss: 0.016523\n",
      "[319/00655] train_loss: 0.016701\n",
      "[319/00705] train_loss: 0.015803\n",
      "[319/00755] train_loss: 0.016923\n",
      "[319/00805] train_loss: 0.016737\n",
      "[319/00855] train_loss: 0.015870\n",
      "[319/00905] train_loss: 0.015324\n",
      "[319/00955] train_loss: 0.016473\n",
      "[319/01005] train_loss: 0.016367\n",
      "[319/01055] train_loss: 0.015916\n",
      "[319/01105] train_loss: 0.015165\n",
      "[319/01155] train_loss: 0.016085\n",
      "[319/01205] train_loss: 0.016723\n",
      "[320/00029] train_loss: 0.020130\n",
      "[320/00079] train_loss: 0.020555\n",
      "[320/00129] train_loss: 0.017518\n",
      "[320/00179] train_loss: 0.016807\n",
      "[320/00229] train_loss: 0.016603\n",
      "[320/00279] train_loss: 0.016101\n",
      "[320/00329] train_loss: 0.015833\n",
      "[320/00379] train_loss: 0.015316\n",
      "[320/00429] train_loss: 0.015712\n",
      "[320/00479] train_loss: 0.015462\n",
      "[320/00529] train_loss: 0.016640\n",
      "[320/00579] train_loss: 0.015455\n",
      "[320/00629] train_loss: 0.016656\n",
      "[320/00679] train_loss: 0.015011\n",
      "[320/00729] train_loss: 0.015654\n",
      "[320/00779] train_loss: 0.016885\n",
      "[320/00829] train_loss: 0.016673\n",
      "[320/00879] train_loss: 0.015851\n",
      "[320/00929] train_loss: 0.017363\n",
      "[320/00979] train_loss: 0.016318\n",
      "[320/01029] train_loss: 0.015722\n",
      "[320/01079] train_loss: 0.015123\n",
      "[320/01129] train_loss: 0.016438\n",
      "[320/01179] train_loss: 0.016636\n",
      "[321/00003] train_loss: 0.018185\n",
      "[321/00053] train_loss: 0.022581\n",
      "[321/00103] train_loss: 0.018237\n",
      "[321/00153] train_loss: 0.016511\n",
      "[321/00203] train_loss: 0.016503\n",
      "[321/00253] train_loss: 0.016304\n",
      "[321/00303] train_loss: 0.016669\n",
      "[321/00353] train_loss: 0.015962\n",
      "[321/00403] train_loss: 0.015440\n",
      "[321/00453] train_loss: 0.016213\n",
      "[321/00503] train_loss: 0.015493\n",
      "[321/00553] train_loss: 0.015616\n",
      "[321/00603] train_loss: 0.016063\n",
      "[321/00653] train_loss: 0.015924\n",
      "[321/00703] train_loss: 0.015431\n",
      "[321/00753] train_loss: 0.015476\n",
      "[321/00803] train_loss: 0.016474\n",
      "[321/00853] train_loss: 0.016459\n",
      "[321/00903] train_loss: 0.015591\n",
      "[321/00953] train_loss: 0.015775\n",
      "[321/01003] train_loss: 0.016454\n",
      "[321/01053] train_loss: 0.014637\n",
      "[321/01103] train_loss: 0.015958\n",
      "[321/01153] train_loss: 0.016553\n",
      "[321/01203] train_loss: 0.016408\n",
      "[322/00027] train_loss: 0.019240\n",
      "[322/00077] train_loss: 0.020308\n",
      "[322/00127] train_loss: 0.017944\n",
      "[322/00177] train_loss: 0.015737\n",
      "[322/00227] train_loss: 0.016666\n",
      "[322/00277] train_loss: 0.015952\n",
      "[322/00327] train_loss: 0.015766\n",
      "[322/00377] train_loss: 0.015694\n",
      "[322/00427] train_loss: 0.015611\n",
      "[322/00477] train_loss: 0.015923\n",
      "[322/00527] train_loss: 0.016109\n",
      "[322/00577] train_loss: 0.014992\n",
      "[322/00627] train_loss: 0.017010\n",
      "[322/00677] train_loss: 0.015454\n",
      "[322/00727] train_loss: 0.015093\n",
      "[322/00777] train_loss: 0.015201\n",
      "[322/00827] train_loss: 0.015647\n",
      "[322/00877] train_loss: 0.016565\n",
      "[322/00927] train_loss: 0.016765\n",
      "[322/00977] train_loss: 0.016544\n",
      "[322/01027] train_loss: 0.016009\n",
      "[322/01077] train_loss: 0.015826\n",
      "[322/01127] train_loss: 0.016180\n",
      "[322/01177] train_loss: 0.017151\n",
      "[323/00001] train_loss: 0.015746\n",
      "[323/00051] train_loss: 0.023434\n",
      "[323/00101] train_loss: 0.018034\n",
      "[323/00151] train_loss: 0.017148\n",
      "[323/00201] train_loss: 0.015917\n",
      "[323/00251] train_loss: 0.017264\n",
      "[323/00301] train_loss: 0.015674\n",
      "[323/00351] train_loss: 0.016007\n",
      "[323/00401] train_loss: 0.016224\n",
      "[323/00451] train_loss: 0.015734\n",
      "[323/00501] train_loss: 0.016433\n",
      "[323/00551] train_loss: 0.015652\n",
      "[323/00601] train_loss: 0.016179\n",
      "[323/00651] train_loss: 0.015957\n",
      "[323/00701] train_loss: 0.016140\n",
      "[323/00751] train_loss: 0.015900\n",
      "[323/00801] train_loss: 0.016205\n",
      "[323/00851] train_loss: 0.016803\n",
      "[323/00901] train_loss: 0.015813\n",
      "[323/00951] train_loss: 0.016504\n",
      "[323/01001] train_loss: 0.016034\n",
      "[323/01051] train_loss: 0.016029\n",
      "[323/01101] train_loss: 0.016647\n",
      "[323/01151] train_loss: 0.015756\n",
      "[323/01201] train_loss: 0.016433\n",
      "[324/00025] train_loss: 0.018070\n",
      "[324/00075] train_loss: 0.020943\n",
      "[324/00125] train_loss: 0.017485\n",
      "[324/00175] train_loss: 0.017080\n",
      "[324/00225] train_loss: 0.016510\n",
      "[324/00275] train_loss: 0.016707\n",
      "[324/00325] train_loss: 0.015965\n",
      "[324/00375] train_loss: 0.015746\n",
      "[324/00425] train_loss: 0.016615\n",
      "[324/00475] train_loss: 0.015246\n",
      "[324/00525] train_loss: 0.015528\n",
      "[324/00575] train_loss: 0.015810\n",
      "[324/00625] train_loss: 0.015052\n",
      "[324/00675] train_loss: 0.015497\n",
      "[324/00725] train_loss: 0.015643\n",
      "[324/00775] train_loss: 0.016639\n",
      "[324/00825] train_loss: 0.016153\n",
      "[324/00875] train_loss: 0.015517\n",
      "[324/00925] train_loss: 0.016785\n",
      "[324/00975] train_loss: 0.016459\n",
      "[324/01025] train_loss: 0.015995\n",
      "[324/01075] train_loss: 0.017695\n",
      "[324/01125] train_loss: 0.016111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324/01175] train_loss: 0.016213\n",
      "[324/01225] train_loss: 0.016672\n",
      "[325/00049] train_loss: 0.022719\n",
      "[325/00099] train_loss: 0.019347\n",
      "[325/00149] train_loss: 0.017210\n",
      "[325/00199] train_loss: 0.015966\n",
      "[325/00249] train_loss: 0.017157\n",
      "[325/00299] train_loss: 0.016282\n",
      "[325/00349] train_loss: 0.015496\n",
      "[325/00399] train_loss: 0.015550\n",
      "[325/00449] train_loss: 0.016666\n",
      "[325/00499] train_loss: 0.016828\n",
      "[325/00549] train_loss: 0.015933\n",
      "[325/00599] train_loss: 0.016350\n",
      "[325/00649] train_loss: 0.016320\n",
      "[325/00699] train_loss: 0.015575\n",
      "[325/00749] train_loss: 0.016101\n",
      "[325/00799] train_loss: 0.015024\n",
      "[325/00849] train_loss: 0.014757\n",
      "[325/00899] train_loss: 0.016853\n",
      "[325/00949] train_loss: 0.015468\n",
      "[325/00999] train_loss: 0.015785\n",
      "[325/01049] train_loss: 0.014925\n",
      "[325/01099] train_loss: 0.015719\n",
      "[325/01149] train_loss: 0.016581\n",
      "[325/01199] train_loss: 0.017233\n",
      "[326/00023] train_loss: 0.019861\n",
      "[326/00073] train_loss: 0.019237\n",
      "[326/00123] train_loss: 0.017720\n",
      "[326/00173] train_loss: 0.016807\n",
      "[326/00223] train_loss: 0.015966\n",
      "[326/00273] train_loss: 0.016593\n",
      "[326/00323] train_loss: 0.016192\n",
      "[326/00373] train_loss: 0.016264\n",
      "[326/00423] train_loss: 0.015283\n",
      "[326/00473] train_loss: 0.015675\n",
      "[326/00523] train_loss: 0.015992\n",
      "[326/00573] train_loss: 0.016605\n",
      "[326/00623] train_loss: 0.015869\n",
      "[326/00673] train_loss: 0.016235\n",
      "[326/00723] train_loss: 0.016353\n",
      "[326/00773] train_loss: 0.016971\n",
      "[326/00823] train_loss: 0.015349\n",
      "[326/00873] train_loss: 0.015948\n",
      "[326/00923] train_loss: 0.016021\n",
      "[326/00973] train_loss: 0.015153\n",
      "[326/01023] train_loss: 0.016553\n",
      "[326/01073] train_loss: 0.015944\n",
      "[326/01123] train_loss: 0.016483\n",
      "[326/01173] train_loss: 0.016281\n",
      "[326/01223] train_loss: 0.016378\n",
      "[327/00047] train_loss: 0.022657\n",
      "[327/00097] train_loss: 0.018776\n",
      "[327/00147] train_loss: 0.018013\n",
      "[327/00197] train_loss: 0.016561\n",
      "[327/00247] train_loss: 0.016775\n",
      "[327/00297] train_loss: 0.016878\n",
      "[327/00347] train_loss: 0.016277\n",
      "[327/00397] train_loss: 0.015568\n",
      "[327/00447] train_loss: 0.015883\n",
      "[327/00497] train_loss: 0.016190\n",
      "[327/00547] train_loss: 0.016101\n",
      "[327/00597] train_loss: 0.016009\n",
      "[327/00647] train_loss: 0.016483\n",
      "[327/00697] train_loss: 0.016334\n",
      "[327/00747] train_loss: 0.016556\n",
      "[327/00797] train_loss: 0.015609\n",
      "[327/00847] train_loss: 0.015444\n",
      "[327/00897] train_loss: 0.016954\n",
      "[327/00947] train_loss: 0.015692\n",
      "[327/00997] train_loss: 0.015595\n",
      "[327/01047] train_loss: 0.015857\n",
      "[327/01097] train_loss: 0.016288\n",
      "[327/01147] train_loss: 0.016704\n",
      "[327/01197] train_loss: 0.016345\n",
      "[328/00021] train_loss: 0.019020\n",
      "[328/00071] train_loss: 0.021634\n",
      "[328/00121] train_loss: 0.017042\n",
      "[328/00171] train_loss: 0.017161\n",
      "[328/00221] train_loss: 0.016078\n",
      "[328/00271] train_loss: 0.015486\n",
      "[328/00321] train_loss: 0.015480\n",
      "[328/00371] train_loss: 0.016103\n",
      "[328/00421] train_loss: 0.014753\n",
      "[328/00471] train_loss: 0.016113\n",
      "[328/00521] train_loss: 0.016396\n",
      "[328/00571] train_loss: 0.015505\n",
      "[328/00621] train_loss: 0.016149\n",
      "[328/00671] train_loss: 0.016454\n",
      "[328/00721] train_loss: 0.016240\n",
      "[328/00771] train_loss: 0.015443\n",
      "[328/00821] train_loss: 0.015332\n",
      "[328/00871] train_loss: 0.016353\n",
      "[328/00921] train_loss: 0.016003\n",
      "[328/00971] train_loss: 0.016384\n",
      "[328/01021] train_loss: 0.016109\n",
      "[328/01071] train_loss: 0.016395\n",
      "[328/01121] train_loss: 0.016840\n",
      "[328/01171] train_loss: 0.016165\n",
      "[328/01221] train_loss: 0.016168\n",
      "[329/00045] train_loss: 0.021474\n",
      "[329/00095] train_loss: 0.018943\n",
      "[329/00145] train_loss: 0.016976\n",
      "[329/00195] train_loss: 0.017230\n",
      "[329/00245] train_loss: 0.016654\n",
      "[329/00295] train_loss: 0.015813\n",
      "[329/00345] train_loss: 0.015947\n",
      "[329/00395] train_loss: 0.016742\n",
      "[329/00445] train_loss: 0.016017\n",
      "[329/00495] train_loss: 0.016038\n",
      "[329/00545] train_loss: 0.015506\n",
      "[329/00595] train_loss: 0.015153\n",
      "[329/00645] train_loss: 0.015786\n",
      "[329/00695] train_loss: 0.015889\n",
      "[329/00745] train_loss: 0.016167\n",
      "[329/00795] train_loss: 0.015348\n",
      "[329/00845] train_loss: 0.016212\n",
      "[329/00895] train_loss: 0.016006\n",
      "[329/00945] train_loss: 0.015974\n",
      "[329/00995] train_loss: 0.016786\n",
      "[329/01045] train_loss: 0.015916\n",
      "[329/01095] train_loss: 0.015901\n",
      "[329/01145] train_loss: 0.016231\n",
      "[329/01195] train_loss: 0.016347\n",
      "[330/00019] train_loss: 0.020351\n",
      "[330/00069] train_loss: 0.020224\n",
      "[330/00119] train_loss: 0.017355\n",
      "[330/00169] train_loss: 0.016787\n",
      "[330/00219] train_loss: 0.016861\n",
      "[330/00269] train_loss: 0.014979\n",
      "[330/00319] train_loss: 0.016483\n",
      "[330/00369] train_loss: 0.016304\n",
      "[330/00419] train_loss: 0.015516\n",
      "[330/00469] train_loss: 0.015943\n",
      "[330/00519] train_loss: 0.016270\n",
      "[330/00569] train_loss: 0.016121\n",
      "[330/00619] train_loss: 0.015749\n",
      "[330/00669] train_loss: 0.016159\n",
      "[330/00719] train_loss: 0.015302\n",
      "[330/00769] train_loss: 0.015265\n",
      "[330/00819] train_loss: 0.015976\n",
      "[330/00869] train_loss: 0.016483\n",
      "[330/00919] train_loss: 0.016150\n",
      "[330/00969] train_loss: 0.016188\n",
      "[330/01019] train_loss: 0.016651\n",
      "[330/01069] train_loss: 0.016171\n",
      "[330/01119] train_loss: 0.017018\n",
      "[330/01169] train_loss: 0.016565\n",
      "[330/01219] train_loss: 0.015790\n",
      "[331/00043] train_loss: 0.021581\n",
      "[331/00093] train_loss: 0.018430\n",
      "[331/00143] train_loss: 0.018157\n",
      "[331/00193] train_loss: 0.015877\n",
      "[331/00243] train_loss: 0.016389\n",
      "[331/00293] train_loss: 0.015327\n",
      "[331/00343] train_loss: 0.016337\n",
      "[331/00393] train_loss: 0.016422\n",
      "[331/00443] train_loss: 0.015445\n",
      "[331/00493] train_loss: 0.016399\n",
      "[331/00543] train_loss: 0.015876\n",
      "[331/00593] train_loss: 0.015817\n",
      "[331/00643] train_loss: 0.015683\n",
      "[331/00693] train_loss: 0.016123\n",
      "[331/00743] train_loss: 0.015292\n",
      "[331/00793] train_loss: 0.016715\n",
      "[331/00843] train_loss: 0.016167\n",
      "[331/00893] train_loss: 0.015701\n",
      "[331/00943] train_loss: 0.016082\n",
      "[331/00993] train_loss: 0.015435\n",
      "[331/01043] train_loss: 0.015836\n",
      "[331/01093] train_loss: 0.015527\n",
      "[331/01143] train_loss: 0.016187\n",
      "[331/01193] train_loss: 0.016519\n",
      "[332/00017] train_loss: 0.019002\n",
      "[332/00067] train_loss: 0.021009\n",
      "[332/00117] train_loss: 0.018318\n",
      "[332/00167] train_loss: 0.016303\n",
      "[332/00217] train_loss: 0.016943\n",
      "[332/00267] train_loss: 0.016976\n",
      "[332/00317] train_loss: 0.015638\n",
      "[332/00367] train_loss: 0.015872\n",
      "[332/00417] train_loss: 0.014902\n",
      "[332/00467] train_loss: 0.015715\n",
      "[332/00517] train_loss: 0.016449\n",
      "[332/00567] train_loss: 0.015946\n",
      "[332/00617] train_loss: 0.014992\n",
      "[332/00667] train_loss: 0.017194\n",
      "[332/00717] train_loss: 0.015876\n",
      "[332/00767] train_loss: 0.016179\n",
      "[332/00817] train_loss: 0.016762\n",
      "[332/00867] train_loss: 0.015118\n",
      "[332/00917] train_loss: 0.015839\n",
      "[332/00967] train_loss: 0.015685\n",
      "[332/01017] train_loss: 0.016378\n",
      "[332/01067] train_loss: 0.015855\n",
      "[332/01117] train_loss: 0.016020\n",
      "[332/01167] train_loss: 0.016839\n",
      "[332/01217] train_loss: 0.016136\n",
      "[333/00041] train_loss: 0.021844\n",
      "[333/00091] train_loss: 0.019316\n",
      "[333/00141] train_loss: 0.018091\n",
      "[333/00191] train_loss: 0.016725\n",
      "[333/00241] train_loss: 0.015962\n",
      "[333/00291] train_loss: 0.016908\n",
      "[333/00341] train_loss: 0.016889\n",
      "[333/00391] train_loss: 0.015469\n",
      "[333/00441] train_loss: 0.015949\n",
      "[333/00491] train_loss: 0.015746\n",
      "[333/00541] train_loss: 0.014806\n",
      "[333/00591] train_loss: 0.015549\n",
      "[333/00641] train_loss: 0.015594\n",
      "[333/00691] train_loss: 0.016146\n",
      "[333/00741] train_loss: 0.016280\n",
      "[333/00791] train_loss: 0.015912\n",
      "[333/00841] train_loss: 0.015655\n",
      "[333/00891] train_loss: 0.016165\n",
      "[333/00941] train_loss: 0.016988\n",
      "[333/00991] train_loss: 0.016111\n",
      "[333/01041] train_loss: 0.016896\n",
      "[333/01091] train_loss: 0.015381\n",
      "[333/01141] train_loss: 0.016778\n",
      "[333/01191] train_loss: 0.016765\n",
      "[334/00015] train_loss: 0.019879\n",
      "[334/00065] train_loss: 0.020346\n",
      "[334/00115] train_loss: 0.016925\n",
      "[334/00165] train_loss: 0.016560\n",
      "[334/00215] train_loss: 0.015970\n",
      "[334/00265] train_loss: 0.016449\n",
      "[334/00315] train_loss: 0.016620\n",
      "[334/00365] train_loss: 0.015531\n",
      "[334/00415] train_loss: 0.015330\n",
      "[334/00465] train_loss: 0.015651\n",
      "[334/00515] train_loss: 0.016448\n",
      "[334/00565] train_loss: 0.015871\n",
      "[334/00615] train_loss: 0.015801\n",
      "[334/00665] train_loss: 0.016152\n",
      "[334/00715] train_loss: 0.016248\n",
      "[334/00765] train_loss: 0.016562\n",
      "[334/00815] train_loss: 0.015416\n",
      "[334/00865] train_loss: 0.017254\n",
      "[334/00915] train_loss: 0.016303\n",
      "[334/00965] train_loss: 0.016905\n",
      "[334/01015] train_loss: 0.016048\n",
      "[334/01065] train_loss: 0.015556\n",
      "[334/01115] train_loss: 0.016173\n",
      "[334/01165] train_loss: 0.015166\n",
      "[334/01215] train_loss: 0.016347\n",
      "[335/00039] train_loss: 0.022668\n",
      "[335/00089] train_loss: 0.019583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335/00139] train_loss: 0.017273\n",
      "[335/00189] train_loss: 0.015717\n",
      "[335/00239] train_loss: 0.016200\n",
      "[335/00289] train_loss: 0.016505\n",
      "[335/00339] train_loss: 0.016181\n",
      "[335/00389] train_loss: 0.015964\n",
      "[335/00439] train_loss: 0.016003\n",
      "[335/00489] train_loss: 0.016697\n",
      "[335/00539] train_loss: 0.015174\n",
      "[335/00589] train_loss: 0.016040\n",
      "[335/00639] train_loss: 0.016365\n",
      "[335/00689] train_loss: 0.016506\n",
      "[335/00739] train_loss: 0.016028\n",
      "[335/00789] train_loss: 0.016270\n",
      "[335/00839] train_loss: 0.015520\n",
      "[335/00889] train_loss: 0.016956\n",
      "[335/00939] train_loss: 0.015569\n",
      "[335/00989] train_loss: 0.015579\n",
      "[335/01039] train_loss: 0.016613\n",
      "[335/01089] train_loss: 0.016421\n",
      "[335/01139] train_loss: 0.016357\n",
      "[335/01189] train_loss: 0.015489\n",
      "[336/00013] train_loss: 0.016939\n",
      "[336/00063] train_loss: 0.021173\n",
      "[336/00113] train_loss: 0.017856\n",
      "[336/00163] train_loss: 0.016478\n",
      "[336/00213] train_loss: 0.016365\n",
      "[336/00263] train_loss: 0.015478\n",
      "[336/00313] train_loss: 0.016010\n",
      "[336/00363] train_loss: 0.015852\n",
      "[336/00413] train_loss: 0.015436\n",
      "[336/00463] train_loss: 0.015831\n",
      "[336/00513] train_loss: 0.016450\n",
      "[336/00563] train_loss: 0.016072\n",
      "[336/00613] train_loss: 0.015249\n",
      "[336/00663] train_loss: 0.015778\n",
      "[336/00713] train_loss: 0.016402\n",
      "[336/00763] train_loss: 0.016454\n",
      "[336/00813] train_loss: 0.016545\n",
      "[336/00863] train_loss: 0.017023\n",
      "[336/00913] train_loss: 0.015419\n",
      "[336/00963] train_loss: 0.016592\n",
      "[336/01013] train_loss: 0.015809\n",
      "[336/01063] train_loss: 0.015840\n",
      "[336/01113] train_loss: 0.016188\n",
      "[336/01163] train_loss: 0.016710\n",
      "[336/01213] train_loss: 0.016158\n",
      "[337/00037] train_loss: 0.020875\n",
      "[337/00087] train_loss: 0.019915\n",
      "[337/00137] train_loss: 0.017276\n",
      "[337/00187] train_loss: 0.016263\n",
      "[337/00237] train_loss: 0.015768\n",
      "[337/00287] train_loss: 0.016186\n",
      "[337/00337] train_loss: 0.015013\n",
      "[337/00387] train_loss: 0.016461\n",
      "[337/00437] train_loss: 0.015662\n",
      "[337/00487] train_loss: 0.016660\n",
      "[337/00537] train_loss: 0.016091\n",
      "[337/00587] train_loss: 0.015272\n",
      "[337/00637] train_loss: 0.016357\n",
      "[337/00687] train_loss: 0.015903\n",
      "[337/00737] train_loss: 0.016087\n",
      "[337/00787] train_loss: 0.015887\n",
      "[337/00837] train_loss: 0.016573\n",
      "[337/00887] train_loss: 0.016030\n",
      "[337/00937] train_loss: 0.015889\n",
      "[337/00987] train_loss: 0.016585\n",
      "[337/01037] train_loss: 0.016555\n",
      "[337/01087] train_loss: 0.017052\n",
      "[337/01137] train_loss: 0.015103\n",
      "[337/01187] train_loss: 0.015229\n",
      "[338/00011] train_loss: 0.017996\n",
      "[338/00061] train_loss: 0.021886\n",
      "[338/00111] train_loss: 0.018294\n",
      "[338/00161] train_loss: 0.017070\n",
      "[338/00211] train_loss: 0.015872\n",
      "[338/00261] train_loss: 0.016039\n",
      "[338/00311] train_loss: 0.015047\n",
      "[338/00361] train_loss: 0.016805\n",
      "[338/00411] train_loss: 0.015491\n",
      "[338/00461] train_loss: 0.016065\n",
      "[338/00511] train_loss: 0.015677\n",
      "[338/00561] train_loss: 0.015789\n",
      "[338/00611] train_loss: 0.015703\n",
      "[338/00661] train_loss: 0.015841\n",
      "[338/00711] train_loss: 0.015148\n",
      "[338/00761] train_loss: 0.016141\n",
      "[338/00811] train_loss: 0.016254\n",
      "[338/00861] train_loss: 0.016390\n",
      "[338/00911] train_loss: 0.015873\n",
      "[338/00961] train_loss: 0.016203\n",
      "[338/01011] train_loss: 0.015957\n",
      "[338/01061] train_loss: 0.016746\n",
      "[338/01111] train_loss: 0.016256\n",
      "[338/01161] train_loss: 0.016120\n",
      "[338/01211] train_loss: 0.016520\n",
      "[339/00035] train_loss: 0.022059\n",
      "[339/00085] train_loss: 0.018478\n",
      "[339/00135] train_loss: 0.017918\n",
      "[339/00185] train_loss: 0.015690\n",
      "[339/00235] train_loss: 0.016198\n",
      "[339/00285] train_loss: 0.016744\n",
      "[339/00335] train_loss: 0.015470\n",
      "[339/00385] train_loss: 0.015684\n",
      "[339/00435] train_loss: 0.015972\n",
      "[339/00485] train_loss: 0.016080\n",
      "[339/00535] train_loss: 0.015894\n",
      "[339/00585] train_loss: 0.015815\n",
      "[339/00635] train_loss: 0.016051\n",
      "[339/00685] train_loss: 0.015851\n",
      "[339/00735] train_loss: 0.015504\n",
      "[339/00785] train_loss: 0.016016\n",
      "[339/00835] train_loss: 0.015023\n",
      "[339/00885] train_loss: 0.015479\n",
      "[339/00935] train_loss: 0.015934\n",
      "[339/00985] train_loss: 0.015536\n",
      "[339/01035] train_loss: 0.016014\n",
      "[339/01085] train_loss: 0.015927\n",
      "[339/01135] train_loss: 0.017179\n",
      "[339/01185] train_loss: 0.017766\n",
      "[340/00009] train_loss: 0.018749\n",
      "[340/00059] train_loss: 0.021987\n",
      "[340/00109] train_loss: 0.016684\n",
      "[340/00159] train_loss: 0.016723\n",
      "[340/00209] train_loss: 0.016275\n",
      "[340/00259] train_loss: 0.016259\n",
      "[340/00309] train_loss: 0.016498\n",
      "[340/00359] train_loss: 0.014913\n",
      "[340/00409] train_loss: 0.015327\n",
      "[340/00459] train_loss: 0.015986\n",
      "[340/00509] train_loss: 0.015752\n",
      "[340/00559] train_loss: 0.016027\n",
      "[340/00609] train_loss: 0.015814\n",
      "[340/00659] train_loss: 0.016341\n",
      "[340/00709] train_loss: 0.015737\n",
      "[340/00759] train_loss: 0.016605\n",
      "[340/00809] train_loss: 0.016265\n",
      "[340/00859] train_loss: 0.016972\n",
      "[340/00909] train_loss: 0.016776\n",
      "[340/00959] train_loss: 0.015843\n",
      "[340/01009] train_loss: 0.016716\n",
      "[340/01059] train_loss: 0.016134\n",
      "[340/01109] train_loss: 0.016478\n",
      "[340/01159] train_loss: 0.015820\n",
      "[340/01209] train_loss: 0.016101\n",
      "[341/00033] train_loss: 0.020574\n",
      "[341/00083] train_loss: 0.018970\n",
      "[341/00133] train_loss: 0.016843\n",
      "[341/00183] train_loss: 0.016367\n",
      "[341/00233] train_loss: 0.015258\n",
      "[341/00283] train_loss: 0.016909\n",
      "[341/00333] train_loss: 0.016129\n",
      "[341/00383] train_loss: 0.015697\n",
      "[341/00433] train_loss: 0.016383\n",
      "[341/00483] train_loss: 0.015448\n",
      "[341/00533] train_loss: 0.015702\n",
      "[341/00583] train_loss: 0.016121\n",
      "[341/00633] train_loss: 0.016723\n",
      "[341/00683] train_loss: 0.016369\n",
      "[341/00733] train_loss: 0.016538\n",
      "[341/00783] train_loss: 0.015734\n",
      "[341/00833] train_loss: 0.015979\n",
      "[341/00883] train_loss: 0.015656\n",
      "[341/00933] train_loss: 0.016428\n",
      "[341/00983] train_loss: 0.016053\n",
      "[341/01033] train_loss: 0.016066\n",
      "[341/01083] train_loss: 0.016697\n",
      "[341/01133] train_loss: 0.017009\n",
      "[341/01183] train_loss: 0.016896\n",
      "[342/00007] train_loss: 0.016984\n",
      "[342/00057] train_loss: 0.021377\n",
      "[342/00107] train_loss: 0.018904\n",
      "[342/00157] train_loss: 0.016588\n",
      "[342/00207] train_loss: 0.015889\n",
      "[342/00257] train_loss: 0.016422\n",
      "[342/00307] train_loss: 0.016148\n",
      "[342/00357] train_loss: 0.016437\n",
      "[342/00407] train_loss: 0.015881\n",
      "[342/00457] train_loss: 0.015388\n",
      "[342/00507] train_loss: 0.015844\n",
      "[342/00557] train_loss: 0.016271\n",
      "[342/00607] train_loss: 0.015423\n",
      "[342/00657] train_loss: 0.016144\n",
      "[342/00707] train_loss: 0.016933\n",
      "[342/00757] train_loss: 0.017289\n",
      "[342/00807] train_loss: 0.016732\n",
      "[342/00857] train_loss: 0.015853\n",
      "[342/00907] train_loss: 0.015926\n",
      "[342/00957] train_loss: 0.016523\n",
      "[342/01007] train_loss: 0.016490\n",
      "[342/01057] train_loss: 0.015531\n",
      "[342/01107] train_loss: 0.016300\n",
      "[342/01157] train_loss: 0.015606\n",
      "[342/01207] train_loss: 0.016477\n",
      "[343/00031] train_loss: 0.020178\n",
      "[343/00081] train_loss: 0.020197\n",
      "[343/00131] train_loss: 0.016778\n",
      "[343/00181] train_loss: 0.016766\n",
      "[343/00231] train_loss: 0.015885\n",
      "[343/00281] train_loss: 0.016080\n",
      "[343/00331] train_loss: 0.015810\n",
      "[343/00381] train_loss: 0.016340\n",
      "[343/00431] train_loss: 0.015688\n",
      "[343/00481] train_loss: 0.016154\n",
      "[343/00531] train_loss: 0.015625\n",
      "[343/00581] train_loss: 0.015678\n",
      "[343/00631] train_loss: 0.015910\n",
      "[343/00681] train_loss: 0.016192\n",
      "[343/00731] train_loss: 0.015392\n",
      "[343/00781] train_loss: 0.015509\n",
      "[343/00831] train_loss: 0.016328\n",
      "[343/00881] train_loss: 0.017020\n",
      "[343/00931] train_loss: 0.015772\n",
      "[343/00981] train_loss: 0.016165\n",
      "[343/01031] train_loss: 0.015963\n",
      "[343/01081] train_loss: 0.015939\n",
      "[343/01131] train_loss: 0.015933\n",
      "[343/01181] train_loss: 0.015483\n",
      "[344/00005] train_loss: 0.017415\n",
      "[344/00055] train_loss: 0.020635\n",
      "[344/00105] train_loss: 0.019059\n",
      "[344/00155] train_loss: 0.017016\n",
      "[344/00205] train_loss: 0.016893\n",
      "[344/00255] train_loss: 0.015590\n",
      "[344/00305] train_loss: 0.016268\n",
      "[344/00355] train_loss: 0.015551\n",
      "[344/00405] train_loss: 0.015642\n",
      "[344/00455] train_loss: 0.016417\n",
      "[344/00505] train_loss: 0.016304\n",
      "[344/00555] train_loss: 0.014976\n",
      "[344/00605] train_loss: 0.015442\n",
      "[344/00655] train_loss: 0.016309\n",
      "[344/00705] train_loss: 0.015353\n",
      "[344/00755] train_loss: 0.016016\n",
      "[344/00805] train_loss: 0.016720\n",
      "[344/00855] train_loss: 0.017021\n",
      "[344/00905] train_loss: 0.015270\n",
      "[344/00955] train_loss: 0.015740\n",
      "[344/01005] train_loss: 0.015737\n",
      "[344/01055] train_loss: 0.016242\n",
      "[344/01105] train_loss: 0.016523\n",
      "[344/01155] train_loss: 0.015160\n",
      "[344/01205] train_loss: 0.016322\n",
      "[345/00029] train_loss: 0.018845\n",
      "[345/00079] train_loss: 0.019911\n",
      "[345/00129] train_loss: 0.017028\n",
      "[345/00179] train_loss: 0.016598\n",
      "[345/00229] train_loss: 0.016689\n",
      "[345/00279] train_loss: 0.015823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345/00329] train_loss: 0.015267\n",
      "[345/00379] train_loss: 0.016477\n",
      "[345/00429] train_loss: 0.016242\n",
      "[345/00479] train_loss: 0.015545\n",
      "[345/00529] train_loss: 0.016070\n",
      "[345/00579] train_loss: 0.016747\n",
      "[345/00629] train_loss: 0.016550\n",
      "[345/00679] train_loss: 0.015978\n",
      "[345/00729] train_loss: 0.014734\n",
      "[345/00779] train_loss: 0.016126\n",
      "[345/00829] train_loss: 0.016104\n",
      "[345/00879] train_loss: 0.015467\n",
      "[345/00929] train_loss: 0.015552\n",
      "[345/00979] train_loss: 0.016110\n",
      "[345/01029] train_loss: 0.017142\n",
      "[345/01079] train_loss: 0.016259\n",
      "[345/01129] train_loss: 0.016770\n",
      "[345/01179] train_loss: 0.016148\n",
      "[346/00003] train_loss: 0.017254\n",
      "[346/00053] train_loss: 0.021332\n",
      "[346/00103] train_loss: 0.017802\n",
      "[346/00153] train_loss: 0.016879\n",
      "[346/00203] train_loss: 0.015909\n",
      "[346/00253] train_loss: 0.017237\n",
      "[346/00303] train_loss: 0.016004\n",
      "[346/00353] train_loss: 0.014776\n",
      "[346/00403] train_loss: 0.016505\n",
      "[346/00453] train_loss: 0.016301\n",
      "[346/00503] train_loss: 0.015758\n",
      "[346/00553] train_loss: 0.016519\n",
      "[346/00603] train_loss: 0.015173\n",
      "[346/00653] train_loss: 0.016521\n",
      "[346/00703] train_loss: 0.016449\n",
      "[346/00753] train_loss: 0.015444\n",
      "[346/00803] train_loss: 0.015786\n",
      "[346/00853] train_loss: 0.017207\n",
      "[346/00903] train_loss: 0.016596\n",
      "[346/00953] train_loss: 0.015850\n",
      "[346/01003] train_loss: 0.016662\n",
      "[346/01053] train_loss: 0.016482\n",
      "[346/01103] train_loss: 0.017009\n",
      "[346/01153] train_loss: 0.015756\n",
      "[346/01203] train_loss: 0.016588\n",
      "[347/00027] train_loss: 0.019682\n",
      "[347/00077] train_loss: 0.021478\n",
      "[347/00127] train_loss: 0.018200\n",
      "[347/00177] train_loss: 0.016483\n",
      "[347/00227] train_loss: 0.016630\n",
      "[347/00277] train_loss: 0.015844\n",
      "[347/00327] train_loss: 0.015980\n",
      "[347/00377] train_loss: 0.015543\n",
      "[347/00427] train_loss: 0.015544\n",
      "[347/00477] train_loss: 0.016101\n",
      "[347/00527] train_loss: 0.015720\n",
      "[347/00577] train_loss: 0.015812\n",
      "[347/00627] train_loss: 0.016468\n",
      "[347/00677] train_loss: 0.015546\n",
      "[347/00727] train_loss: 0.014973\n",
      "[347/00777] train_loss: 0.016097\n",
      "[347/00827] train_loss: 0.015354\n",
      "[347/00877] train_loss: 0.014831\n",
      "[347/00927] train_loss: 0.015928\n",
      "[347/00977] train_loss: 0.016229\n",
      "[347/01027] train_loss: 0.017189\n",
      "[347/01077] train_loss: 0.017048\n",
      "[347/01127] train_loss: 0.016624\n",
      "[347/01177] train_loss: 0.016845\n",
      "[348/00001] train_loss: 0.016283\n",
      "[348/00051] train_loss: 0.021636\n",
      "[348/00101] train_loss: 0.018155\n",
      "[348/00151] train_loss: 0.017115\n",
      "[348/00201] train_loss: 0.015150\n",
      "[348/00251] train_loss: 0.015539\n",
      "[348/00301] train_loss: 0.015451\n",
      "[348/00351] train_loss: 0.015677\n",
      "[348/00401] train_loss: 0.016147\n",
      "[348/00451] train_loss: 0.015558\n",
      "[348/00501] train_loss: 0.015896\n",
      "[348/00551] train_loss: 0.015371\n",
      "[348/00601] train_loss: 0.016396\n",
      "[348/00651] train_loss: 0.015819\n",
      "[348/00701] train_loss: 0.016074\n",
      "[348/00751] train_loss: 0.015071\n",
      "[348/00801] train_loss: 0.016635\n",
      "[348/00851] train_loss: 0.016427\n",
      "[348/00901] train_loss: 0.015423\n",
      "[348/00951] train_loss: 0.016742\n",
      "[348/01001] train_loss: 0.015855\n",
      "[348/01051] train_loss: 0.016404\n",
      "[348/01101] train_loss: 0.015481\n",
      "[348/01151] train_loss: 0.015551\n",
      "[348/01201] train_loss: 0.016973\n",
      "[349/00025] train_loss: 0.020617\n",
      "[349/00075] train_loss: 0.020391\n",
      "[349/00125] train_loss: 0.018962\n",
      "[349/00175] train_loss: 0.016828\n",
      "[349/00225] train_loss: 0.015811\n",
      "[349/00275] train_loss: 0.016471\n",
      "[349/00325] train_loss: 0.016008\n",
      "[349/00375] train_loss: 0.015319\n",
      "[349/00425] train_loss: 0.016005\n",
      "[349/00475] train_loss: 0.014950\n",
      "[349/00525] train_loss: 0.015446\n",
      "[349/00575] train_loss: 0.015460\n",
      "[349/00625] train_loss: 0.015847\n",
      "[349/00675] train_loss: 0.015750\n",
      "[349/00725] train_loss: 0.015532\n",
      "[349/00775] train_loss: 0.016044\n",
      "[349/00825] train_loss: 0.015712\n",
      "[349/00875] train_loss: 0.015099\n",
      "[349/00925] train_loss: 0.015767\n",
      "[349/00975] train_loss: 0.015938\n",
      "[349/01025] train_loss: 0.016500\n",
      "[349/01075] train_loss: 0.016574\n",
      "[349/01125] train_loss: 0.017606\n",
      "[349/01175] train_loss: 0.015788\n",
      "[349/01225] train_loss: 0.015930\n",
      "[350/00049] train_loss: 0.021514\n",
      "[350/00099] train_loss: 0.019943\n",
      "[350/00149] train_loss: 0.017121\n",
      "[350/00199] train_loss: 0.016689\n",
      "[350/00249] train_loss: 0.015548\n",
      "[350/00299] train_loss: 0.015949\n",
      "[350/00349] train_loss: 0.016253\n",
      "[350/00399] train_loss: 0.015070\n",
      "[350/00449] train_loss: 0.016554\n",
      "[350/00499] train_loss: 0.015804\n",
      "[350/00549] train_loss: 0.016608\n",
      "[350/00599] train_loss: 0.015909\n",
      "[350/00649] train_loss: 0.015276\n",
      "[350/00699] train_loss: 0.015466\n",
      "[350/00749] train_loss: 0.016092\n",
      "[350/00799] train_loss: 0.016119\n",
      "[350/00849] train_loss: 0.016168\n",
      "[350/00899] train_loss: 0.015930\n",
      "[350/00949] train_loss: 0.015304\n",
      "[350/00999] train_loss: 0.016132\n",
      "[350/01049] train_loss: 0.016261\n",
      "[350/01099] train_loss: 0.015413\n",
      "[350/01149] train_loss: 0.016159\n",
      "[350/01199] train_loss: 0.016805\n",
      "[351/00023] train_loss: 0.021273\n",
      "[351/00073] train_loss: 0.019791\n",
      "[351/00123] train_loss: 0.017255\n",
      "[351/00173] train_loss: 0.017460\n",
      "[351/00223] train_loss: 0.016105\n",
      "[351/00273] train_loss: 0.016927\n",
      "[351/00323] train_loss: 0.015967\n",
      "[351/00373] train_loss: 0.015588\n",
      "[351/00423] train_loss: 0.015115\n",
      "[351/00473] train_loss: 0.015358\n",
      "[351/00523] train_loss: 0.016420\n",
      "[351/00573] train_loss: 0.015850\n",
      "[351/00623] train_loss: 0.016064\n",
      "[351/00673] train_loss: 0.014997\n",
      "[351/00723] train_loss: 0.016164\n",
      "[351/00773] train_loss: 0.015615\n",
      "[351/00823] train_loss: 0.016298\n",
      "[351/00873] train_loss: 0.015154\n",
      "[351/00923] train_loss: 0.016097\n",
      "[351/00973] train_loss: 0.016101\n",
      "[351/01023] train_loss: 0.015694\n",
      "[351/01073] train_loss: 0.016140\n",
      "[351/01123] train_loss: 0.016010\n",
      "[351/01173] train_loss: 0.015662\n",
      "[351/01223] train_loss: 0.016405\n",
      "[352/00047] train_loss: 0.022759\n",
      "[352/00097] train_loss: 0.018239\n",
      "[352/00147] train_loss: 0.016610\n",
      "[352/00197] train_loss: 0.015911\n",
      "[352/00247] train_loss: 0.016137\n",
      "[352/00297] train_loss: 0.016296\n",
      "[352/00347] train_loss: 0.015720\n",
      "[352/00397] train_loss: 0.015589\n",
      "[352/00447] train_loss: 0.016517\n",
      "[352/00497] train_loss: 0.015995\n",
      "[352/00547] train_loss: 0.015359\n",
      "[352/00597] train_loss: 0.015278\n",
      "[352/00647] train_loss: 0.015931\n",
      "[352/00697] train_loss: 0.016271\n",
      "[352/00747] train_loss: 0.015920\n",
      "[352/00797] train_loss: 0.016012\n",
      "[352/00847] train_loss: 0.016063\n",
      "[352/00897] train_loss: 0.016096\n",
      "[352/00947] train_loss: 0.016190\n",
      "[352/00997] train_loss: 0.016578\n",
      "[352/01047] train_loss: 0.016602\n",
      "[352/01097] train_loss: 0.016481\n",
      "[352/01147] train_loss: 0.016803\n",
      "[352/01197] train_loss: 0.017230\n",
      "[353/00021] train_loss: 0.020060\n",
      "[353/00071] train_loss: 0.020640\n",
      "[353/00121] train_loss: 0.017121\n",
      "[353/00171] train_loss: 0.016606\n",
      "[353/00221] train_loss: 0.015697\n",
      "[353/00271] train_loss: 0.015766\n",
      "[353/00321] train_loss: 0.016149\n",
      "[353/00371] train_loss: 0.016086\n",
      "[353/00421] train_loss: 0.015741\n",
      "[353/00471] train_loss: 0.015793\n",
      "[353/00521] train_loss: 0.015909\n",
      "[353/00571] train_loss: 0.015816\n",
      "[353/00621] train_loss: 0.016323\n",
      "[353/00671] train_loss: 0.016943\n",
      "[353/00721] train_loss: 0.016417\n",
      "[353/00771] train_loss: 0.016591\n",
      "[353/00821] train_loss: 0.015829\n",
      "[353/00871] train_loss: 0.016052\n",
      "[353/00921] train_loss: 0.015680\n",
      "[353/00971] train_loss: 0.017007\n",
      "[353/01021] train_loss: 0.015541\n",
      "[353/01071] train_loss: 0.016649\n",
      "[353/01121] train_loss: 0.015834\n",
      "[353/01171] train_loss: 0.016324\n",
      "[353/01221] train_loss: 0.017012\n",
      "[354/00045] train_loss: 0.022239\n",
      "[354/00095] train_loss: 0.019044\n",
      "[354/00145] train_loss: 0.016856\n",
      "[354/00195] train_loss: 0.016630\n",
      "[354/00245] train_loss: 0.015150\n",
      "[354/00295] train_loss: 0.015047\n",
      "[354/00345] train_loss: 0.015400\n",
      "[354/00395] train_loss: 0.015787\n",
      "[354/00445] train_loss: 0.015502\n",
      "[354/00495] train_loss: 0.016107\n",
      "[354/00545] train_loss: 0.015855\n",
      "[354/00595] train_loss: 0.016075\n",
      "[354/00645] train_loss: 0.015917\n",
      "[354/00695] train_loss: 0.015561\n",
      "[354/00745] train_loss: 0.016333\n",
      "[354/00795] train_loss: 0.015404\n",
      "[354/00845] train_loss: 0.017136\n",
      "[354/00895] train_loss: 0.016698\n",
      "[354/00945] train_loss: 0.016083\n",
      "[354/00995] train_loss: 0.015945\n",
      "[354/01045] train_loss: 0.015967\n",
      "[354/01095] train_loss: 0.015760\n",
      "[354/01145] train_loss: 0.015468\n",
      "[354/01195] train_loss: 0.016921\n",
      "[355/00019] train_loss: 0.019810\n",
      "[355/00069] train_loss: 0.020400\n",
      "[355/00119] train_loss: 0.017007\n",
      "[355/00169] train_loss: 0.017114\n",
      "[355/00219] train_loss: 0.015655\n",
      "[355/00269] train_loss: 0.015555\n",
      "[355/00319] train_loss: 0.016184\n",
      "[355/00369] train_loss: 0.015774\n",
      "[355/00419] train_loss: 0.016056\n",
      "[355/00469] train_loss: 0.015378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355/00519] train_loss: 0.016317\n",
      "[355/00569] train_loss: 0.015553\n",
      "[355/00619] train_loss: 0.015359\n",
      "[355/00669] train_loss: 0.016022\n",
      "[355/00719] train_loss: 0.016165\n",
      "[355/00769] train_loss: 0.015437\n",
      "[355/00819] train_loss: 0.016321\n",
      "[355/00869] train_loss: 0.015987\n",
      "[355/00919] train_loss: 0.016827\n",
      "[355/00969] train_loss: 0.016516\n",
      "[355/01019] train_loss: 0.016233\n",
      "[355/01069] train_loss: 0.016140\n",
      "[355/01119] train_loss: 0.015869\n",
      "[355/01169] train_loss: 0.016019\n",
      "[355/01219] train_loss: 0.015669\n",
      "[356/00043] train_loss: 0.021199\n",
      "[356/00093] train_loss: 0.019224\n",
      "[356/00143] train_loss: 0.017795\n",
      "[356/00193] train_loss: 0.016626\n",
      "[356/00243] train_loss: 0.016368\n",
      "[356/00293] train_loss: 0.015509\n",
      "[356/00343] train_loss: 0.016538\n",
      "[356/00393] train_loss: 0.016644\n",
      "[356/00443] train_loss: 0.016385\n",
      "[356/00493] train_loss: 0.015613\n",
      "[356/00543] train_loss: 0.016607\n",
      "[356/00593] train_loss: 0.015455\n",
      "[356/00643] train_loss: 0.015896\n",
      "[356/00693] train_loss: 0.015441\n",
      "[356/00743] train_loss: 0.015668\n",
      "[356/00793] train_loss: 0.015331\n",
      "[356/00843] train_loss: 0.015607\n",
      "[356/00893] train_loss: 0.015550\n",
      "[356/00943] train_loss: 0.015710\n",
      "[356/00993] train_loss: 0.016468\n",
      "[356/01043] train_loss: 0.016165\n",
      "[356/01093] train_loss: 0.015460\n",
      "[356/01143] train_loss: 0.015777\n",
      "[356/01193] train_loss: 0.016340\n",
      "[357/00017] train_loss: 0.018897\n",
      "[357/00067] train_loss: 0.020300\n",
      "[357/00117] train_loss: 0.017856\n",
      "[357/00167] train_loss: 0.016454\n",
      "[357/00217] train_loss: 0.015707\n",
      "[357/00267] train_loss: 0.015526\n",
      "[357/00317] train_loss: 0.016460\n",
      "[357/00367] train_loss: 0.015304\n",
      "[357/00417] train_loss: 0.015368\n",
      "[357/00467] train_loss: 0.016085\n",
      "[357/00517] train_loss: 0.015433\n",
      "[357/00567] train_loss: 0.016355\n",
      "[357/00617] train_loss: 0.015641\n",
      "[357/00667] train_loss: 0.015804\n",
      "[357/00717] train_loss: 0.015567\n",
      "[357/00767] train_loss: 0.016626\n",
      "[357/00817] train_loss: 0.015851\n",
      "[357/00867] train_loss: 0.016537\n",
      "[357/00917] train_loss: 0.016515\n",
      "[357/00967] train_loss: 0.016344\n",
      "[357/01017] train_loss: 0.016392\n",
      "[357/01067] train_loss: 0.015852\n",
      "[357/01117] train_loss: 0.016187\n",
      "[357/01167] train_loss: 0.015778\n",
      "[357/01217] train_loss: 0.016101\n",
      "[358/00041] train_loss: 0.020867\n",
      "[358/00091] train_loss: 0.018622\n",
      "[358/00141] train_loss: 0.017217\n",
      "[358/00191] train_loss: 0.016355\n",
      "[358/00241] train_loss: 0.016440\n",
      "[358/00291] train_loss: 0.016823\n",
      "[358/00341] train_loss: 0.016121\n",
      "[358/00391] train_loss: 0.015883\n",
      "[358/00441] train_loss: 0.015721\n",
      "[358/00491] train_loss: 0.015782\n",
      "[358/00541] train_loss: 0.016021\n",
      "[358/00591] train_loss: 0.016250\n",
      "[358/00641] train_loss: 0.015340\n",
      "[358/00691] train_loss: 0.015741\n",
      "[358/00741] train_loss: 0.015134\n",
      "[358/00791] train_loss: 0.016544\n",
      "[358/00841] train_loss: 0.016258\n",
      "[358/00891] train_loss: 0.016522\n",
      "[358/00941] train_loss: 0.016072\n",
      "[358/00991] train_loss: 0.015782\n",
      "[358/01041] train_loss: 0.016168\n",
      "[358/01091] train_loss: 0.016422\n",
      "[358/01141] train_loss: 0.016111\n",
      "[358/01191] train_loss: 0.015989\n",
      "[359/00015] train_loss: 0.019800\n",
      "[359/00065] train_loss: 0.020665\n",
      "[359/00115] train_loss: 0.017686\n",
      "[359/00165] train_loss: 0.016472\n",
      "[359/00215] train_loss: 0.016025\n",
      "[359/00265] train_loss: 0.016203\n",
      "[359/00315] train_loss: 0.016137\n",
      "[359/00365] train_loss: 0.015459\n",
      "[359/00415] train_loss: 0.016543\n",
      "[359/00465] train_loss: 0.014725\n",
      "[359/00515] train_loss: 0.014947\n",
      "[359/00565] train_loss: 0.015579\n",
      "[359/00615] train_loss: 0.016133\n",
      "[359/00665] train_loss: 0.016015\n",
      "[359/00715] train_loss: 0.016930\n",
      "[359/00765] train_loss: 0.015945\n",
      "[359/00815] train_loss: 0.015734\n",
      "[359/00865] train_loss: 0.016466\n",
      "[359/00915] train_loss: 0.016143\n",
      "[359/00965] train_loss: 0.015575\n",
      "[359/01015] train_loss: 0.015969\n",
      "[359/01065] train_loss: 0.016810\n",
      "[359/01115] train_loss: 0.016066\n",
      "[359/01165] train_loss: 0.015921\n",
      "[359/01215] train_loss: 0.016637\n",
      "[360/00039] train_loss: 0.020917\n",
      "[360/00089] train_loss: 0.018966\n",
      "[360/00139] train_loss: 0.017852\n",
      "[360/00189] train_loss: 0.016100\n",
      "[360/00239] train_loss: 0.016516\n",
      "[360/00289] train_loss: 0.015493\n",
      "[360/00339] train_loss: 0.015394\n",
      "[360/00389] train_loss: 0.015689\n",
      "[360/00439] train_loss: 0.015694\n",
      "[360/00489] train_loss: 0.016452\n",
      "[360/00539] train_loss: 0.016307\n",
      "[360/00589] train_loss: 0.015278\n",
      "[360/00639] train_loss: 0.015332\n",
      "[360/00689] train_loss: 0.016422\n",
      "[360/00739] train_loss: 0.016048\n",
      "[360/00789] train_loss: 0.015695\n",
      "[360/00839] train_loss: 0.015389\n",
      "[360/00889] train_loss: 0.016069\n",
      "[360/00939] train_loss: 0.016761\n",
      "[360/00989] train_loss: 0.015379\n",
      "[360/01039] train_loss: 0.016959\n",
      "[360/01089] train_loss: 0.015525\n",
      "[360/01139] train_loss: 0.016028\n",
      "[360/01189] train_loss: 0.016845\n",
      "[361/00013] train_loss: 0.018046\n",
      "[361/00063] train_loss: 0.020525\n",
      "[361/00113] train_loss: 0.017606\n",
      "[361/00163] train_loss: 0.017232\n",
      "[361/00213] train_loss: 0.015594\n",
      "[361/00263] train_loss: 0.016223\n",
      "[361/00313] train_loss: 0.017006\n",
      "[361/00363] train_loss: 0.015642\n",
      "[361/00413] train_loss: 0.016431\n",
      "[361/00463] train_loss: 0.015492\n",
      "[361/00513] train_loss: 0.015854\n",
      "[361/00563] train_loss: 0.016158\n",
      "[361/00613] train_loss: 0.015460\n",
      "[361/00663] train_loss: 0.016196\n",
      "[361/00713] train_loss: 0.015515\n",
      "[361/00763] train_loss: 0.015678\n",
      "[361/00813] train_loss: 0.016547\n",
      "[361/00863] train_loss: 0.016754\n",
      "[361/00913] train_loss: 0.015762\n",
      "[361/00963] train_loss: 0.015917\n",
      "[361/01013] train_loss: 0.016776\n",
      "[361/01063] train_loss: 0.015971\n",
      "[361/01113] train_loss: 0.016368\n",
      "[361/01163] train_loss: 0.016603\n",
      "[361/01213] train_loss: 0.015599\n",
      "[362/00037] train_loss: 0.021648\n",
      "[362/00087] train_loss: 0.018995\n",
      "[362/00137] train_loss: 0.017103\n",
      "[362/00187] train_loss: 0.016607\n",
      "[362/00237] train_loss: 0.015610\n",
      "[362/00287] train_loss: 0.015576\n",
      "[362/00337] train_loss: 0.016232\n",
      "[362/00387] train_loss: 0.015813\n",
      "[362/00437] train_loss: 0.016140\n",
      "[362/00487] train_loss: 0.015775\n",
      "[362/00537] train_loss: 0.015272\n",
      "[362/00587] train_loss: 0.015930\n",
      "[362/00637] train_loss: 0.015883\n",
      "[362/00687] train_loss: 0.015585\n",
      "[362/00737] train_loss: 0.014804\n",
      "[362/00787] train_loss: 0.015467\n",
      "[362/00837] train_loss: 0.016546\n",
      "[362/00887] train_loss: 0.015572\n",
      "[362/00937] train_loss: 0.015205\n",
      "[362/00987] train_loss: 0.016946\n",
      "[362/01037] train_loss: 0.017104\n",
      "[362/01087] train_loss: 0.017078\n",
      "[362/01137] train_loss: 0.016918\n",
      "[362/01187] train_loss: 0.016279\n",
      "[363/00011] train_loss: 0.017614\n",
      "[363/00061] train_loss: 0.021400\n",
      "[363/00111] train_loss: 0.018612\n",
      "[363/00161] train_loss: 0.016514\n",
      "[363/00211] train_loss: 0.016061\n",
      "[363/00261] train_loss: 0.016795\n",
      "[363/00311] train_loss: 0.016749\n",
      "[363/00361] train_loss: 0.015058\n",
      "[363/00411] train_loss: 0.016270\n",
      "[363/00461] train_loss: 0.015556\n",
      "[363/00511] train_loss: 0.015640\n",
      "[363/00561] train_loss: 0.016166\n",
      "[363/00611] train_loss: 0.015385\n",
      "[363/00661] train_loss: 0.014631\n",
      "[363/00711] train_loss: 0.015577\n",
      "[363/00761] train_loss: 0.015364\n",
      "[363/00811] train_loss: 0.015797\n",
      "[363/00861] train_loss: 0.016905\n",
      "[363/00911] train_loss: 0.015832\n",
      "[363/00961] train_loss: 0.016642\n",
      "[363/01011] train_loss: 0.016435\n",
      "[363/01061] train_loss: 0.016512\n",
      "[363/01111] train_loss: 0.015805\n",
      "[363/01161] train_loss: 0.016481\n",
      "[363/01211] train_loss: 0.016287\n",
      "[364/00035] train_loss: 0.019778\n",
      "[364/00085] train_loss: 0.019611\n",
      "[364/00135] train_loss: 0.017192\n",
      "[364/00185] train_loss: 0.016787\n",
      "[364/00235] train_loss: 0.016706\n",
      "[364/00285] train_loss: 0.015141\n",
      "[364/00335] train_loss: 0.016003\n",
      "[364/00385] train_loss: 0.015640\n",
      "[364/00435] train_loss: 0.016729\n",
      "[364/00485] train_loss: 0.016060\n",
      "[364/00535] train_loss: 0.015332\n",
      "[364/00585] train_loss: 0.015865\n",
      "[364/00635] train_loss: 0.014872\n",
      "[364/00685] train_loss: 0.015718\n",
      "[364/00735] train_loss: 0.015769\n",
      "[364/00785] train_loss: 0.015884\n",
      "[364/00835] train_loss: 0.014876\n",
      "[364/00885] train_loss: 0.015981\n",
      "[364/00935] train_loss: 0.015062\n",
      "[364/00985] train_loss: 0.016670\n",
      "[364/01035] train_loss: 0.016518\n",
      "[364/01085] train_loss: 0.016212\n",
      "[364/01135] train_loss: 0.017050\n",
      "[364/01185] train_loss: 0.016037\n",
      "[365/00009] train_loss: 0.017536\n",
      "[365/00059] train_loss: 0.021200\n",
      "[365/00109] train_loss: 0.018270\n",
      "[365/00159] train_loss: 0.017399\n",
      "[365/00209] train_loss: 0.015858\n",
      "[365/00259] train_loss: 0.016375\n",
      "[365/00309] train_loss: 0.015356\n",
      "[365/00359] train_loss: 0.015108\n",
      "[365/00409] train_loss: 0.016076\n",
      "[365/00459] train_loss: 0.015305\n",
      "[365/00509] train_loss: 0.015589\n",
      "[365/00559] train_loss: 0.015763\n",
      "[365/00609] train_loss: 0.015549\n",
      "[365/00659] train_loss: 0.015692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[365/00709] train_loss: 0.016276\n",
      "[365/00759] train_loss: 0.015682\n",
      "[365/00809] train_loss: 0.016735\n",
      "[365/00859] train_loss: 0.016229\n",
      "[365/00909] train_loss: 0.016142\n",
      "[365/00959] train_loss: 0.016001\n",
      "[365/01009] train_loss: 0.016422\n",
      "[365/01059] train_loss: 0.015753\n",
      "[365/01109] train_loss: 0.016002\n",
      "[365/01159] train_loss: 0.016260\n",
      "[365/01209] train_loss: 0.014904\n",
      "[366/00033] train_loss: 0.020935\n",
      "[366/00083] train_loss: 0.019635\n",
      "[366/00133] train_loss: 0.016773\n",
      "[366/00183] train_loss: 0.016026\n",
      "[366/00233] train_loss: 0.016214\n",
      "[366/00283] train_loss: 0.015613\n",
      "[366/00333] train_loss: 0.016473\n",
      "[366/00383] train_loss: 0.015512\n",
      "[366/00433] train_loss: 0.015468\n",
      "[366/00483] train_loss: 0.014897\n",
      "[366/00533] train_loss: 0.015720\n",
      "[366/00583] train_loss: 0.016394\n",
      "[366/00633] train_loss: 0.016487\n",
      "[366/00683] train_loss: 0.016370\n",
      "[366/00733] train_loss: 0.015819\n",
      "[366/00783] train_loss: 0.016005\n",
      "[366/00833] train_loss: 0.014872\n",
      "[366/00883] train_loss: 0.015857\n",
      "[366/00933] train_loss: 0.016034\n",
      "[366/00983] train_loss: 0.016328\n",
      "[366/01033] train_loss: 0.016694\n",
      "[366/01083] train_loss: 0.016457\n",
      "[366/01133] train_loss: 0.016439\n",
      "[366/01183] train_loss: 0.015951\n",
      "[367/00007] train_loss: 0.017145\n",
      "[367/00057] train_loss: 0.021312\n",
      "[367/00107] train_loss: 0.018063\n",
      "[367/00157] train_loss: 0.016909\n",
      "[367/00207] train_loss: 0.015943\n",
      "[367/00257] train_loss: 0.016764\n",
      "[367/00307] train_loss: 0.015611\n",
      "[367/00357] train_loss: 0.015659\n",
      "[367/00407] train_loss: 0.016348\n",
      "[367/00457] train_loss: 0.015842\n",
      "[367/00507] train_loss: 0.015384\n",
      "[367/00557] train_loss: 0.016635\n",
      "[367/00607] train_loss: 0.015995\n",
      "[367/00657] train_loss: 0.014549\n",
      "[367/00707] train_loss: 0.017408\n",
      "[367/00757] train_loss: 0.015613\n",
      "[367/00807] train_loss: 0.015585\n",
      "[367/00857] train_loss: 0.015964\n",
      "[367/00907] train_loss: 0.016069\n",
      "[367/00957] train_loss: 0.015629\n",
      "[367/01007] train_loss: 0.015539\n",
      "[367/01057] train_loss: 0.015540\n",
      "[367/01107] train_loss: 0.015938\n",
      "[367/01157] train_loss: 0.016218\n",
      "[367/01207] train_loss: 0.017627\n",
      "[368/00031] train_loss: 0.020517\n",
      "[368/00081] train_loss: 0.020242\n",
      "[368/00131] train_loss: 0.018050\n",
      "[368/00181] train_loss: 0.017246\n",
      "[368/00231] train_loss: 0.016504\n",
      "[368/00281] train_loss: 0.015913\n",
      "[368/00331] train_loss: 0.015046\n",
      "[368/00381] train_loss: 0.015679\n",
      "[368/00431] train_loss: 0.016550\n",
      "[368/00481] train_loss: 0.016091\n",
      "[368/00531] train_loss: 0.015590\n",
      "[368/00581] train_loss: 0.015603\n",
      "[368/00631] train_loss: 0.015791\n",
      "[368/00681] train_loss: 0.016242\n",
      "[368/00731] train_loss: 0.016412\n",
      "[368/00781] train_loss: 0.016690\n",
      "[368/00831] train_loss: 0.015380\n",
      "[368/00881] train_loss: 0.016810\n",
      "[368/00931] train_loss: 0.016934\n",
      "[368/00981] train_loss: 0.016225\n",
      "[368/01031] train_loss: 0.016048\n",
      "[368/01081] train_loss: 0.015327\n",
      "[368/01131] train_loss: 0.016161\n",
      "[368/01181] train_loss: 0.015469\n",
      "[369/00005] train_loss: 0.017789\n",
      "[369/00055] train_loss: 0.020348\n",
      "[369/00105] train_loss: 0.018348\n",
      "[369/00155] train_loss: 0.016711\n",
      "[369/00205] train_loss: 0.015507\n",
      "[369/00255] train_loss: 0.015563\n",
      "[369/00305] train_loss: 0.016403\n",
      "[369/00355] train_loss: 0.015180\n",
      "[369/00405] train_loss: 0.016375\n",
      "[369/00455] train_loss: 0.015263\n",
      "[369/00505] train_loss: 0.016623\n",
      "[369/00555] train_loss: 0.015833\n",
      "[369/00605] train_loss: 0.016281\n",
      "[369/00655] train_loss: 0.015947\n",
      "[369/00705] train_loss: 0.015742\n",
      "[369/00755] train_loss: 0.016302\n",
      "[369/00805] train_loss: 0.015557\n",
      "[369/00855] train_loss: 0.015068\n",
      "[369/00905] train_loss: 0.015688\n",
      "[369/00955] train_loss: 0.016890\n",
      "[369/01005] train_loss: 0.015973\n",
      "[369/01055] train_loss: 0.016806\n",
      "[369/01105] train_loss: 0.016276\n",
      "[369/01155] train_loss: 0.016061\n",
      "[369/01205] train_loss: 0.015796\n",
      "[370/00029] train_loss: 0.021357\n",
      "[370/00079] train_loss: 0.018558\n",
      "[370/00129] train_loss: 0.017173\n",
      "[370/00179] train_loss: 0.016312\n",
      "[370/00229] train_loss: 0.016416\n",
      "[370/00279] train_loss: 0.015775\n",
      "[370/00329] train_loss: 0.015987\n",
      "[370/00379] train_loss: 0.015461\n",
      "[370/00429] train_loss: 0.015792\n",
      "[370/00479] train_loss: 0.016872\n",
      "[370/00529] train_loss: 0.015557\n",
      "[370/00579] train_loss: 0.016612\n",
      "[370/00629] train_loss: 0.015811\n",
      "[370/00679] train_loss: 0.016329\n",
      "[370/00729] train_loss: 0.016034\n",
      "[370/00779] train_loss: 0.016422\n",
      "[370/00829] train_loss: 0.016468\n",
      "[370/00879] train_loss: 0.015856\n",
      "[370/00929] train_loss: 0.015802\n",
      "[370/00979] train_loss: 0.016140\n",
      "[370/01029] train_loss: 0.016170\n",
      "[370/01079] train_loss: 0.015610\n",
      "[370/01129] train_loss: 0.015927\n",
      "[370/01179] train_loss: 0.015815\n",
      "[371/00003] train_loss: 0.015351\n",
      "[371/00053] train_loss: 0.020247\n",
      "[371/00103] train_loss: 0.017432\n",
      "[371/00153] train_loss: 0.016306\n",
      "[371/00203] train_loss: 0.016578\n",
      "[371/00253] train_loss: 0.015902\n",
      "[371/00303] train_loss: 0.015879\n",
      "[371/00353] train_loss: 0.015898\n",
      "[371/00403] train_loss: 0.015903\n",
      "[371/00453] train_loss: 0.016128\n",
      "[371/00503] train_loss: 0.015689\n",
      "[371/00553] train_loss: 0.015452\n",
      "[371/00603] train_loss: 0.016286\n",
      "[371/00653] train_loss: 0.016439\n",
      "[371/00703] train_loss: 0.015683\n",
      "[371/00753] train_loss: 0.016844\n",
      "[371/00803] train_loss: 0.015999\n",
      "[371/00853] train_loss: 0.015195\n",
      "[371/00903] train_loss: 0.016988\n",
      "[371/00953] train_loss: 0.015976\n",
      "[371/01003] train_loss: 0.016203\n",
      "[371/01053] train_loss: 0.016258\n",
      "[371/01103] train_loss: 0.016373\n",
      "[371/01153] train_loss: 0.016094\n",
      "[371/01203] train_loss: 0.017430\n",
      "[372/00027] train_loss: 0.019646\n",
      "[372/00077] train_loss: 0.020016\n",
      "[372/00127] train_loss: 0.017518\n",
      "[372/00177] train_loss: 0.016882\n",
      "[372/00227] train_loss: 0.016202\n",
      "[372/00277] train_loss: 0.016386\n",
      "[372/00327] train_loss: 0.015994\n",
      "[372/00377] train_loss: 0.015864\n",
      "[372/00427] train_loss: 0.015955\n",
      "[372/00477] train_loss: 0.016126\n",
      "[372/00527] train_loss: 0.016430\n",
      "[372/00577] train_loss: 0.015563\n",
      "[372/00627] train_loss: 0.016912\n",
      "[372/00677] train_loss: 0.014907\n",
      "[372/00727] train_loss: 0.016037\n",
      "[372/00777] train_loss: 0.015479\n",
      "[372/00827] train_loss: 0.014538\n",
      "[372/00877] train_loss: 0.016312\n",
      "[372/00927] train_loss: 0.016315\n",
      "[372/00977] train_loss: 0.015080\n",
      "[372/01027] train_loss: 0.015868\n",
      "[372/01077] train_loss: 0.016048\n",
      "[372/01127] train_loss: 0.015576\n",
      "[372/01177] train_loss: 0.016193\n",
      "[373/00001] train_loss: 0.016852\n",
      "[373/00051] train_loss: 0.021119\n",
      "[373/00101] train_loss: 0.018014\n",
      "[373/00151] train_loss: 0.017038\n",
      "[373/00201] train_loss: 0.016774\n",
      "[373/00251] train_loss: 0.016356\n",
      "[373/00301] train_loss: 0.015681\n",
      "[373/00351] train_loss: 0.015693\n",
      "[373/00401] train_loss: 0.015620\n",
      "[373/00451] train_loss: 0.015526\n",
      "[373/00501] train_loss: 0.015711\n",
      "[373/00551] train_loss: 0.015407\n",
      "[373/00601] train_loss: 0.016621\n",
      "[373/00651] train_loss: 0.015805\n",
      "[373/00701] train_loss: 0.016016\n",
      "[373/00751] train_loss: 0.015843\n",
      "[373/00801] train_loss: 0.016332\n",
      "[373/00851] train_loss: 0.015875\n",
      "[373/00901] train_loss: 0.016643\n",
      "[373/00951] train_loss: 0.015065\n",
      "[373/01001] train_loss: 0.016612\n",
      "[373/01051] train_loss: 0.016517\n",
      "[373/01101] train_loss: 0.017424\n",
      "[373/01151] train_loss: 0.015121\n",
      "[373/01201] train_loss: 0.017433\n",
      "[374/00025] train_loss: 0.018388\n",
      "[374/00075] train_loss: 0.019806\n",
      "[374/00125] train_loss: 0.018418\n",
      "[374/00175] train_loss: 0.015989\n",
      "[374/00225] train_loss: 0.015689\n",
      "[374/00275] train_loss: 0.015887\n",
      "[374/00325] train_loss: 0.017025\n",
      "[374/00375] train_loss: 0.015254\n",
      "[374/00425] train_loss: 0.015115\n",
      "[374/00475] train_loss: 0.015694\n",
      "[374/00525] train_loss: 0.015880\n",
      "[374/00575] train_loss: 0.015508\n",
      "[374/00625] train_loss: 0.016101\n",
      "[374/00675] train_loss: 0.015454\n",
      "[374/00725] train_loss: 0.017014\n",
      "[374/00775] train_loss: 0.017088\n",
      "[374/00825] train_loss: 0.015637\n",
      "[374/00875] train_loss: 0.017549\n",
      "[374/00925] train_loss: 0.016287\n",
      "[374/00975] train_loss: 0.015837\n",
      "[374/01025] train_loss: 0.016312\n",
      "[374/01075] train_loss: 0.015926\n",
      "[374/01125] train_loss: 0.015274\n",
      "[374/01175] train_loss: 0.016815\n",
      "[374/01225] train_loss: 0.017803\n",
      "[375/00049] train_loss: 0.021825\n",
      "[375/00099] train_loss: 0.018225\n",
      "[375/00149] train_loss: 0.016640\n",
      "[375/00199] train_loss: 0.015904\n",
      "[375/00249] train_loss: 0.016258\n",
      "[375/00299] train_loss: 0.016030\n",
      "[375/00349] train_loss: 0.015707\n",
      "[375/00399] train_loss: 0.016661\n",
      "[375/00449] train_loss: 0.015393\n",
      "[375/00499] train_loss: 0.015620\n",
      "[375/00549] train_loss: 0.015779\n",
      "[375/00599] train_loss: 0.016677\n",
      "[375/00649] train_loss: 0.015407\n",
      "[375/00699] train_loss: 0.015180\n",
      "[375/00749] train_loss: 0.015733\n",
      "[375/00799] train_loss: 0.016363\n",
      "[375/00849] train_loss: 0.015460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375/00899] train_loss: 0.016247\n",
      "[375/00949] train_loss: 0.016438\n",
      "[375/00999] train_loss: 0.016486\n",
      "[375/01049] train_loss: 0.015728\n",
      "[375/01099] train_loss: 0.016459\n",
      "[375/01149] train_loss: 0.015986\n",
      "[375/01199] train_loss: 0.015236\n",
      "[376/00023] train_loss: 0.020450\n",
      "[376/00073] train_loss: 0.019746\n",
      "[376/00123] train_loss: 0.017530\n",
      "[376/00173] train_loss: 0.016454\n",
      "[376/00223] train_loss: 0.016639\n",
      "[376/00273] train_loss: 0.015455\n",
      "[376/00323] train_loss: 0.016087\n",
      "[376/00373] train_loss: 0.016027\n",
      "[376/00423] train_loss: 0.016152\n",
      "[376/00473] train_loss: 0.015234\n",
      "[376/00523] train_loss: 0.015297\n",
      "[376/00573] train_loss: 0.016211\n",
      "[376/00623] train_loss: 0.016163\n",
      "[376/00673] train_loss: 0.017147\n",
      "[376/00723] train_loss: 0.015291\n",
      "[376/00773] train_loss: 0.015739\n",
      "[376/00823] train_loss: 0.015948\n",
      "[376/00873] train_loss: 0.015522\n",
      "[376/00923] train_loss: 0.016209\n",
      "[376/00973] train_loss: 0.015554\n",
      "[376/01023] train_loss: 0.015772\n",
      "[376/01073] train_loss: 0.015971\n",
      "[376/01123] train_loss: 0.016189\n",
      "[376/01173] train_loss: 0.016882\n",
      "[376/01223] train_loss: 0.015413\n",
      "[377/00047] train_loss: 0.021201\n",
      "[377/00097] train_loss: 0.017302\n",
      "[377/00147] train_loss: 0.016928\n",
      "[377/00197] train_loss: 0.016015\n",
      "[377/00247] train_loss: 0.016836\n",
      "[377/00297] train_loss: 0.016668\n",
      "[377/00347] train_loss: 0.015393\n",
      "[377/00397] train_loss: 0.016111\n",
      "[377/00447] train_loss: 0.015143\n",
      "[377/00497] train_loss: 0.016002\n",
      "[377/00547] train_loss: 0.015762\n",
      "[377/00597] train_loss: 0.016287\n",
      "[377/00647] train_loss: 0.015695\n",
      "[377/00697] train_loss: 0.015624\n",
      "[377/00747] train_loss: 0.015367\n",
      "[377/00797] train_loss: 0.015837\n",
      "[377/00847] train_loss: 0.016098\n",
      "[377/00897] train_loss: 0.016474\n",
      "[377/00947] train_loss: 0.015370\n",
      "[377/00997] train_loss: 0.015798\n",
      "[377/01047] train_loss: 0.016269\n",
      "[377/01097] train_loss: 0.015465\n",
      "[377/01147] train_loss: 0.015639\n",
      "[377/01197] train_loss: 0.015655\n",
      "[378/00021] train_loss: 0.019757\n",
      "[378/00071] train_loss: 0.021134\n",
      "[378/00121] train_loss: 0.017224\n",
      "[378/00171] train_loss: 0.016905\n",
      "[378/00221] train_loss: 0.016190\n",
      "[378/00271] train_loss: 0.015371\n",
      "[378/00321] train_loss: 0.016229\n",
      "[378/00371] train_loss: 0.015902\n",
      "[378/00421] train_loss: 0.016330\n",
      "[378/00471] train_loss: 0.015052\n",
      "[378/00521] train_loss: 0.015751\n",
      "[378/00571] train_loss: 0.015698\n",
      "[378/00621] train_loss: 0.016718\n",
      "[378/00671] train_loss: 0.015215\n",
      "[378/00721] train_loss: 0.014952\n",
      "[378/00771] train_loss: 0.016364\n",
      "[378/00821] train_loss: 0.015876\n",
      "[378/00871] train_loss: 0.015899\n",
      "[378/00921] train_loss: 0.016046\n",
      "[378/00971] train_loss: 0.016625\n",
      "[378/01021] train_loss: 0.016393\n",
      "[378/01071] train_loss: 0.016257\n",
      "[378/01121] train_loss: 0.016106\n",
      "[378/01171] train_loss: 0.016233\n",
      "[378/01221] train_loss: 0.015903\n",
      "[379/00045] train_loss: 0.021502\n",
      "[379/00095] train_loss: 0.018449\n",
      "[379/00145] train_loss: 0.016770\n",
      "[379/00195] train_loss: 0.015703\n",
      "[379/00245] train_loss: 0.016403\n",
      "[379/00295] train_loss: 0.015962\n",
      "[379/00345] train_loss: 0.015079\n",
      "[379/00395] train_loss: 0.015275\n",
      "[379/00445] train_loss: 0.015455\n",
      "[379/00495] train_loss: 0.015892\n",
      "[379/00545] train_loss: 0.015465\n",
      "[379/00595] train_loss: 0.015683\n",
      "[379/00645] train_loss: 0.015526\n",
      "[379/00695] train_loss: 0.015381\n",
      "[379/00745] train_loss: 0.015591\n",
      "[379/00795] train_loss: 0.016695\n",
      "[379/00845] train_loss: 0.016674\n",
      "[379/00895] train_loss: 0.015861\n",
      "[379/00945] train_loss: 0.015791\n",
      "[379/00995] train_loss: 0.016445\n",
      "[379/01045] train_loss: 0.015425\n",
      "[379/01095] train_loss: 0.015665\n",
      "[379/01145] train_loss: 0.016500\n",
      "[379/01195] train_loss: 0.016016\n",
      "[380/00019] train_loss: 0.018721\n",
      "[380/00069] train_loss: 0.019099\n",
      "[380/00119] train_loss: 0.017488\n",
      "[380/00169] train_loss: 0.016590\n",
      "[380/00219] train_loss: 0.016898\n",
      "[380/00269] train_loss: 0.016016\n",
      "[380/00319] train_loss: 0.015092\n",
      "[380/00369] train_loss: 0.015921\n",
      "[380/00419] train_loss: 0.015685\n",
      "[380/00469] train_loss: 0.014862\n",
      "[380/00519] train_loss: 0.016476\n",
      "[380/00569] train_loss: 0.015408\n",
      "[380/00619] train_loss: 0.016239\n",
      "[380/00669] train_loss: 0.015733\n",
      "[380/00719] train_loss: 0.015658\n",
      "[380/00769] train_loss: 0.016137\n",
      "[380/00819] train_loss: 0.016627\n",
      "[380/00869] train_loss: 0.016328\n",
      "[380/00919] train_loss: 0.016379\n",
      "[380/00969] train_loss: 0.017012\n",
      "[380/01019] train_loss: 0.015867\n",
      "[380/01069] train_loss: 0.016078\n",
      "[380/01119] train_loss: 0.015340\n",
      "[380/01169] train_loss: 0.015872\n",
      "[380/01219] train_loss: 0.016609\n",
      "[381/00043] train_loss: 0.021259\n",
      "[381/00093] train_loss: 0.018565\n",
      "[381/00143] train_loss: 0.016166\n",
      "[381/00193] train_loss: 0.016671\n",
      "[381/00243] train_loss: 0.016521\n",
      "[381/00293] train_loss: 0.017405\n",
      "[381/00343] train_loss: 0.015978\n",
      "[381/00393] train_loss: 0.015750\n",
      "[381/00443] train_loss: 0.015089\n",
      "[381/00493] train_loss: 0.016823\n",
      "[381/00543] train_loss: 0.015884\n",
      "[381/00593] train_loss: 0.015453\n",
      "[381/00643] train_loss: 0.015657\n",
      "[381/00693] train_loss: 0.016288\n",
      "[381/00743] train_loss: 0.015109\n",
      "[381/00793] train_loss: 0.016475\n",
      "[381/00843] train_loss: 0.016110\n",
      "[381/00893] train_loss: 0.015534\n",
      "[381/00943] train_loss: 0.016035\n",
      "[381/00993] train_loss: 0.015973\n",
      "[381/01043] train_loss: 0.015652\n",
      "[381/01093] train_loss: 0.016514\n",
      "[381/01143] train_loss: 0.015755\n",
      "[381/01193] train_loss: 0.016100\n",
      "[382/00017] train_loss: 0.019263\n",
      "[382/00067] train_loss: 0.020047\n",
      "[382/00117] train_loss: 0.017362\n",
      "[382/00167] train_loss: 0.016639\n",
      "[382/00217] train_loss: 0.015713\n",
      "[382/00267] train_loss: 0.015511\n",
      "[382/00317] train_loss: 0.015830\n",
      "[382/00367] train_loss: 0.016296\n",
      "[382/00417] train_loss: 0.015418\n",
      "[382/00467] train_loss: 0.015947\n",
      "[382/00517] train_loss: 0.016410\n",
      "[382/00567] train_loss: 0.016021\n",
      "[382/00617] train_loss: 0.015832\n",
      "[382/00667] train_loss: 0.015417\n",
      "[382/00717] train_loss: 0.015538\n",
      "[382/00767] train_loss: 0.016043\n",
      "[382/00817] train_loss: 0.015658\n",
      "[382/00867] train_loss: 0.015719\n",
      "[382/00917] train_loss: 0.015311\n",
      "[382/00967] train_loss: 0.015877\n",
      "[382/01017] train_loss: 0.016635\n",
      "[382/01067] train_loss: 0.015650\n",
      "[382/01117] train_loss: 0.015510\n",
      "[382/01167] train_loss: 0.016511\n",
      "[382/01217] train_loss: 0.015811\n",
      "[383/00041] train_loss: 0.021808\n",
      "[383/00091] train_loss: 0.018657\n",
      "[383/00141] train_loss: 0.017108\n",
      "[383/00191] train_loss: 0.016277\n",
      "[383/00241] train_loss: 0.015255\n",
      "[383/00291] train_loss: 0.015337\n",
      "[383/00341] train_loss: 0.015769\n",
      "[383/00391] train_loss: 0.016257\n",
      "[383/00441] train_loss: 0.016399\n",
      "[383/00491] train_loss: 0.015229\n",
      "[383/00541] train_loss: 0.015613\n",
      "[383/00591] train_loss: 0.015914\n",
      "[383/00641] train_loss: 0.015707\n",
      "[383/00691] train_loss: 0.016002\n",
      "[383/00741] train_loss: 0.016407\n",
      "[383/00791] train_loss: 0.015007\n",
      "[383/00841] train_loss: 0.016724\n",
      "[383/00891] train_loss: 0.016585\n",
      "[383/00941] train_loss: 0.016359\n",
      "[383/00991] train_loss: 0.015998\n",
      "[383/01041] train_loss: 0.015613\n",
      "[383/01091] train_loss: 0.016576\n",
      "[383/01141] train_loss: 0.016465\n",
      "[383/01191] train_loss: 0.016612\n",
      "[384/00015] train_loss: 0.018779\n",
      "[384/00065] train_loss: 0.019586\n",
      "[384/00115] train_loss: 0.016761\n",
      "[384/00165] train_loss: 0.016854\n",
      "[384/00215] train_loss: 0.015718\n",
      "[384/00265] train_loss: 0.017262\n",
      "[384/00315] train_loss: 0.015776\n",
      "[384/00365] train_loss: 0.015324\n",
      "[384/00415] train_loss: 0.015790\n",
      "[384/00465] train_loss: 0.015747\n",
      "[384/00515] train_loss: 0.016594\n",
      "[384/00565] train_loss: 0.015096\n",
      "[384/00615] train_loss: 0.015600\n",
      "[384/00665] train_loss: 0.016428\n",
      "[384/00715] train_loss: 0.015925\n",
      "[384/00765] train_loss: 0.016172\n",
      "[384/00815] train_loss: 0.015627\n",
      "[384/00865] train_loss: 0.016394\n",
      "[384/00915] train_loss: 0.015753\n",
      "[384/00965] train_loss: 0.014998\n",
      "[384/01015] train_loss: 0.015632\n",
      "[384/01065] train_loss: 0.016618\n",
      "[384/01115] train_loss: 0.015989\n",
      "[384/01165] train_loss: 0.016280\n",
      "[384/01215] train_loss: 0.015852\n",
      "[385/00039] train_loss: 0.020066\n",
      "[385/00089] train_loss: 0.019442\n",
      "[385/00139] train_loss: 0.016886\n",
      "[385/00189] train_loss: 0.016500\n",
      "[385/00239] train_loss: 0.016876\n",
      "[385/00289] train_loss: 0.016139\n",
      "[385/00339] train_loss: 0.016127\n",
      "[385/00389] train_loss: 0.016441\n",
      "[385/00439] train_loss: 0.015599\n",
      "[385/00489] train_loss: 0.015729\n",
      "[385/00539] train_loss: 0.015271\n",
      "[385/00589] train_loss: 0.016310\n",
      "[385/00639] train_loss: 0.015595\n",
      "[385/00689] train_loss: 0.015520\n",
      "[385/00739] train_loss: 0.015638\n",
      "[385/00789] train_loss: 0.015536\n",
      "[385/00839] train_loss: 0.015426\n",
      "[385/00889] train_loss: 0.015915\n",
      "[385/00939] train_loss: 0.015787\n",
      "[385/00989] train_loss: 0.015325\n",
      "[385/01039] train_loss: 0.016787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[385/01089] train_loss: 0.015798\n",
      "[385/01139] train_loss: 0.016545\n",
      "[385/01189] train_loss: 0.017189\n",
      "[386/00013] train_loss: 0.019531\n",
      "[386/00063] train_loss: 0.022153\n",
      "[386/00113] train_loss: 0.017674\n",
      "[386/00163] train_loss: 0.016871\n",
      "[386/00213] train_loss: 0.015694\n",
      "[386/00263] train_loss: 0.015076\n",
      "[386/00313] train_loss: 0.016501\n",
      "[386/00363] train_loss: 0.015334\n",
      "[386/00413] train_loss: 0.016061\n",
      "[386/00463] train_loss: 0.015652\n",
      "[386/00513] train_loss: 0.016418\n",
      "[386/00563] train_loss: 0.015760\n",
      "[386/00613] train_loss: 0.016878\n",
      "[386/00663] train_loss: 0.015027\n",
      "[386/00713] train_loss: 0.015811\n",
      "[386/00763] train_loss: 0.016220\n",
      "[386/00813] train_loss: 0.015234\n",
      "[386/00863] train_loss: 0.015856\n",
      "[386/00913] train_loss: 0.016471\n",
      "[386/00963] train_loss: 0.016210\n",
      "[386/01013] train_loss: 0.015566\n",
      "[386/01063] train_loss: 0.015887\n",
      "[386/01113] train_loss: 0.016202\n",
      "[386/01163] train_loss: 0.016405\n",
      "[386/01213] train_loss: 0.016837\n",
      "[387/00037] train_loss: 0.020923\n",
      "[387/00087] train_loss: 0.019097\n",
      "[387/00137] train_loss: 0.017074\n",
      "[387/00187] train_loss: 0.016025\n",
      "[387/00237] train_loss: 0.015509\n",
      "[387/00287] train_loss: 0.015603\n",
      "[387/00337] train_loss: 0.015582\n",
      "[387/00387] train_loss: 0.016551\n",
      "[387/00437] train_loss: 0.016689\n",
      "[387/00487] train_loss: 0.015793\n",
      "[387/00537] train_loss: 0.015156\n",
      "[387/00587] train_loss: 0.016464\n",
      "[387/00637] train_loss: 0.014893\n",
      "[387/00687] train_loss: 0.015551\n",
      "[387/00737] train_loss: 0.016074\n",
      "[387/00787] train_loss: 0.016280\n",
      "[387/00837] train_loss: 0.015816\n",
      "[387/00887] train_loss: 0.015824\n",
      "[387/00937] train_loss: 0.015658\n",
      "[387/00987] train_loss: 0.015292\n",
      "[387/01037] train_loss: 0.015537\n",
      "[387/01087] train_loss: 0.016134\n",
      "[387/01137] train_loss: 0.015642\n",
      "[387/01187] train_loss: 0.016139\n",
      "[388/00011] train_loss: 0.019285\n",
      "[388/00061] train_loss: 0.020392\n",
      "[388/00111] train_loss: 0.018401\n",
      "[388/00161] train_loss: 0.016067\n",
      "[388/00211] train_loss: 0.016789\n",
      "[388/00261] train_loss: 0.016291\n",
      "[388/00311] train_loss: 0.016153\n",
      "[388/00361] train_loss: 0.016672\n",
      "[388/00411] train_loss: 0.015703\n",
      "[388/00461] train_loss: 0.015946\n",
      "[388/00511] train_loss: 0.016223\n",
      "[388/00561] train_loss: 0.015354\n",
      "[388/00611] train_loss: 0.015591\n",
      "[388/00661] train_loss: 0.015609\n",
      "[388/00711] train_loss: 0.016233\n",
      "[388/00761] train_loss: 0.015396\n",
      "[388/00811] train_loss: 0.015270\n",
      "[388/00861] train_loss: 0.015856\n",
      "[388/00911] train_loss: 0.015520\n",
      "[388/00961] train_loss: 0.015897\n",
      "[388/01011] train_loss: 0.015876\n",
      "[388/01061] train_loss: 0.015950\n",
      "[388/01111] train_loss: 0.016255\n",
      "[388/01161] train_loss: 0.016352\n",
      "[388/01211] train_loss: 0.016316\n",
      "[389/00035] train_loss: 0.021522\n",
      "[389/00085] train_loss: 0.019255\n",
      "[389/00135] train_loss: 0.018461\n",
      "[389/00185] train_loss: 0.016107\n",
      "[389/00235] train_loss: 0.016055\n",
      "[389/00285] train_loss: 0.015933\n",
      "[389/00335] train_loss: 0.015712\n",
      "[389/00385] train_loss: 0.016276\n",
      "[389/00435] train_loss: 0.016027\n",
      "[389/00485] train_loss: 0.015734\n",
      "[389/00535] train_loss: 0.016283\n",
      "[389/00585] train_loss: 0.015519\n",
      "[389/00635] train_loss: 0.014814\n",
      "[389/00685] train_loss: 0.015317\n",
      "[389/00735] train_loss: 0.015470\n",
      "[389/00785] train_loss: 0.016846\n",
      "[389/00835] train_loss: 0.015688\n",
      "[389/00885] train_loss: 0.016438\n",
      "[389/00935] train_loss: 0.015954\n",
      "[389/00985] train_loss: 0.015474\n",
      "[389/01035] train_loss: 0.016200\n",
      "[389/01085] train_loss: 0.016624\n",
      "[389/01135] train_loss: 0.015455\n",
      "[389/01185] train_loss: 0.015989\n",
      "[390/00009] train_loss: 0.016941\n",
      "[390/00059] train_loss: 0.020154\n",
      "[390/00109] train_loss: 0.018295\n",
      "[390/00159] train_loss: 0.016355\n",
      "[390/00209] train_loss: 0.016271\n",
      "[390/00259] train_loss: 0.015499\n",
      "[390/00309] train_loss: 0.016782\n",
      "[390/00359] train_loss: 0.015204\n",
      "[390/00409] train_loss: 0.016293\n",
      "[390/00459] train_loss: 0.015932\n",
      "[390/00509] train_loss: 0.016544\n",
      "[390/00559] train_loss: 0.016126\n",
      "[390/00609] train_loss: 0.016047\n",
      "[390/00659] train_loss: 0.014942\n",
      "[390/00709] train_loss: 0.015524\n",
      "[390/00759] train_loss: 0.015061\n",
      "[390/00809] train_loss: 0.016043\n",
      "[390/00859] train_loss: 0.015446\n",
      "[390/00909] train_loss: 0.016639\n",
      "[390/00959] train_loss: 0.016645\n",
      "[390/01009] train_loss: 0.016637\n",
      "[390/01059] train_loss: 0.015712\n",
      "[390/01109] train_loss: 0.015228\n",
      "[390/01159] train_loss: 0.016275\n",
      "[390/01209] train_loss: 0.015682\n",
      "[391/00033] train_loss: 0.020483\n",
      "[391/00083] train_loss: 0.019052\n",
      "[391/00133] train_loss: 0.018010\n",
      "[391/00183] train_loss: 0.016365\n",
      "[391/00233] train_loss: 0.015574\n",
      "[391/00283] train_loss: 0.015717\n",
      "[391/00333] train_loss: 0.015623\n",
      "[391/00383] train_loss: 0.015822\n",
      "[391/00433] train_loss: 0.015469\n",
      "[391/00483] train_loss: 0.015223\n",
      "[391/00533] train_loss: 0.016741\n",
      "[391/00583] train_loss: 0.015712\n",
      "[391/00633] train_loss: 0.016664\n",
      "[391/00683] train_loss: 0.014638\n",
      "[391/00733] train_loss: 0.015840\n",
      "[391/00783] train_loss: 0.015570\n",
      "[391/00833] train_loss: 0.015095\n",
      "[391/00883] train_loss: 0.016359\n",
      "[391/00933] train_loss: 0.016743\n",
      "[391/00983] train_loss: 0.015584\n",
      "[391/01033] train_loss: 0.016181\n",
      "[391/01083] train_loss: 0.015686\n",
      "[391/01133] train_loss: 0.016283\n",
      "[391/01183] train_loss: 0.016794\n",
      "[392/00007] train_loss: 0.017741\n",
      "[392/00057] train_loss: 0.021698\n",
      "[392/00107] train_loss: 0.018672\n",
      "[392/00157] train_loss: 0.016802\n",
      "[392/00207] train_loss: 0.016582\n",
      "[392/00257] train_loss: 0.016649\n",
      "[392/00307] train_loss: 0.016631\n",
      "[392/00357] train_loss: 0.015498\n",
      "[392/00407] train_loss: 0.015848\n",
      "[392/00457] train_loss: 0.015713\n",
      "[392/00507] train_loss: 0.016066\n",
      "[392/00557] train_loss: 0.015517\n",
      "[392/00607] train_loss: 0.014985\n",
      "[392/00657] train_loss: 0.014981\n",
      "[392/00707] train_loss: 0.015883\n",
      "[392/00757] train_loss: 0.016067\n",
      "[392/00807] train_loss: 0.016305\n",
      "[392/00857] train_loss: 0.015473\n",
      "[392/00907] train_loss: 0.017396\n",
      "[392/00957] train_loss: 0.016544\n",
      "[392/01007] train_loss: 0.015826\n",
      "[392/01057] train_loss: 0.015523\n",
      "[392/01107] train_loss: 0.015667\n",
      "[392/01157] train_loss: 0.015976\n",
      "[392/01207] train_loss: 0.016243\n",
      "[393/00031] train_loss: 0.021630\n",
      "[393/00081] train_loss: 0.018869\n",
      "[393/00131] train_loss: 0.017726\n",
      "[393/00181] train_loss: 0.016112\n",
      "[393/00231] train_loss: 0.016316\n",
      "[393/00281] train_loss: 0.017493\n",
      "[393/00331] train_loss: 0.015450\n",
      "[393/00381] train_loss: 0.015393\n",
      "[393/00431] train_loss: 0.015968\n",
      "[393/00481] train_loss: 0.015917\n",
      "[393/00531] train_loss: 0.015232\n",
      "[393/00581] train_loss: 0.015763\n",
      "[393/00631] train_loss: 0.016101\n",
      "[393/00681] train_loss: 0.014960\n",
      "[393/00731] train_loss: 0.016076\n",
      "[393/00781] train_loss: 0.016100\n",
      "[393/00831] train_loss: 0.014483\n",
      "[393/00881] train_loss: 0.015733\n",
      "[393/00931] train_loss: 0.015649\n",
      "[393/00981] train_loss: 0.016304\n",
      "[393/01031] train_loss: 0.016027\n",
      "[393/01081] train_loss: 0.015217\n",
      "[393/01131] train_loss: 0.016459\n",
      "[393/01181] train_loss: 0.017046\n",
      "[394/00005] train_loss: 0.016367\n",
      "[394/00055] train_loss: 0.021979\n",
      "[394/00105] train_loss: 0.019291\n",
      "[394/00155] train_loss: 0.016293\n",
      "[394/00205] train_loss: 0.015698\n",
      "[394/00255] train_loss: 0.016637\n",
      "[394/00305] train_loss: 0.015874\n",
      "[394/00355] train_loss: 0.015728\n",
      "[394/00405] train_loss: 0.016107\n",
      "[394/00455] train_loss: 0.016289\n",
      "[394/00505] train_loss: 0.015482\n",
      "[394/00555] train_loss: 0.015904\n",
      "[394/00605] train_loss: 0.016087\n",
      "[394/00655] train_loss: 0.015370\n",
      "[394/00705] train_loss: 0.015209\n",
      "[394/00755] train_loss: 0.016556\n",
      "[394/00805] train_loss: 0.016785\n",
      "[394/00855] train_loss: 0.015524\n",
      "[394/00905] train_loss: 0.016136\n",
      "[394/00955] train_loss: 0.015431\n",
      "[394/01005] train_loss: 0.015703\n",
      "[394/01055] train_loss: 0.016265\n",
      "[394/01105] train_loss: 0.015914\n",
      "[394/01155] train_loss: 0.016064\n",
      "[394/01205] train_loss: 0.016150\n",
      "[395/00029] train_loss: 0.018528\n",
      "[395/00079] train_loss: 0.020280\n",
      "[395/00129] train_loss: 0.016394\n",
      "[395/00179] train_loss: 0.016035\n",
      "[395/00229] train_loss: 0.016185\n",
      "[395/00279] train_loss: 0.014873\n",
      "[395/00329] train_loss: 0.016086\n",
      "[395/00379] train_loss: 0.016324\n",
      "[395/00429] train_loss: 0.016372\n",
      "[395/00479] train_loss: 0.016297\n",
      "[395/00529] train_loss: 0.015638\n",
      "[395/00579] train_loss: 0.015438\n",
      "[395/00629] train_loss: 0.015761\n",
      "[395/00679] train_loss: 0.015945\n",
      "[395/00729] train_loss: 0.014327\n",
      "[395/00779] train_loss: 0.016458\n",
      "[395/00829] train_loss: 0.015915\n",
      "[395/00879] train_loss: 0.016738\n",
      "[395/00929] train_loss: 0.015714\n",
      "[395/00979] train_loss: 0.014734\n",
      "[395/01029] train_loss: 0.016308\n",
      "[395/01079] train_loss: 0.015330\n",
      "[395/01129] train_loss: 0.016310\n",
      "[395/01179] train_loss: 0.016852\n",
      "[396/00003] train_loss: 0.017072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396/00053] train_loss: 0.020534\n",
      "[396/00103] train_loss: 0.018262\n",
      "[396/00153] train_loss: 0.016890\n",
      "[396/00203] train_loss: 0.015744\n",
      "[396/00253] train_loss: 0.016429\n",
      "[396/00303] train_loss: 0.015573\n",
      "[396/00353] train_loss: 0.015772\n",
      "[396/00403] train_loss: 0.015358\n",
      "[396/00453] train_loss: 0.015488\n",
      "[396/00503] train_loss: 0.014934\n",
      "[396/00553] train_loss: 0.015334\n",
      "[396/00603] train_loss: 0.015859\n",
      "[396/00653] train_loss: 0.015844\n",
      "[396/00703] train_loss: 0.016119\n",
      "[396/00753] train_loss: 0.015831\n",
      "[396/00803] train_loss: 0.016626\n",
      "[396/00853] train_loss: 0.016389\n",
      "[396/00903] train_loss: 0.015578\n",
      "[396/00953] train_loss: 0.015308\n",
      "[396/01003] train_loss: 0.016037\n",
      "[396/01053] train_loss: 0.015360\n",
      "[396/01103] train_loss: 0.016004\n",
      "[396/01153] train_loss: 0.016771\n",
      "[396/01203] train_loss: 0.016388\n",
      "[397/00027] train_loss: 0.018728\n",
      "[397/00077] train_loss: 0.019695\n",
      "[397/00127] train_loss: 0.017580\n",
      "[397/00177] train_loss: 0.016166\n",
      "[397/00227] train_loss: 0.016055\n",
      "[397/00277] train_loss: 0.016564\n",
      "[397/00327] train_loss: 0.015877\n",
      "[397/00377] train_loss: 0.016397\n",
      "[397/00427] train_loss: 0.014682\n",
      "[397/00477] train_loss: 0.015902\n",
      "[397/00527] train_loss: 0.015072\n",
      "[397/00577] train_loss: 0.015964\n",
      "[397/00627] train_loss: 0.015226\n",
      "[397/00677] train_loss: 0.015781\n",
      "[397/00727] train_loss: 0.015724\n",
      "[397/00777] train_loss: 0.015940\n",
      "[397/00827] train_loss: 0.016484\n",
      "[397/00877] train_loss: 0.015861\n",
      "[397/00927] train_loss: 0.015815\n",
      "[397/00977] train_loss: 0.015134\n",
      "[397/01027] train_loss: 0.015722\n",
      "[397/01077] train_loss: 0.015749\n",
      "[397/01127] train_loss: 0.015714\n",
      "[397/01177] train_loss: 0.016827\n",
      "[398/00001] train_loss: 0.016544\n",
      "[398/00051] train_loss: 0.023552\n",
      "[398/00101] train_loss: 0.018685\n",
      "[398/00151] train_loss: 0.017372\n",
      "[398/00201] train_loss: 0.015900\n",
      "[398/00251] train_loss: 0.016991\n",
      "[398/00301] train_loss: 0.015420\n",
      "[398/00351] train_loss: 0.015300\n",
      "[398/00401] train_loss: 0.016197\n",
      "[398/00451] train_loss: 0.015617\n",
      "[398/00501] train_loss: 0.015843\n",
      "[398/00551] train_loss: 0.015703\n",
      "[398/00601] train_loss: 0.014811\n",
      "[398/00651] train_loss: 0.016582\n",
      "[398/00701] train_loss: 0.015943\n",
      "[398/00751] train_loss: 0.015118\n",
      "[398/00801] train_loss: 0.015066\n",
      "[398/00851] train_loss: 0.015935\n",
      "[398/00901] train_loss: 0.015885\n",
      "[398/00951] train_loss: 0.015007\n",
      "[398/01001] train_loss: 0.015854\n",
      "[398/01051] train_loss: 0.016147\n",
      "[398/01101] train_loss: 0.016177\n",
      "[398/01151] train_loss: 0.015810\n",
      "[398/01201] train_loss: 0.015755\n",
      "[399/00025] train_loss: 0.020822\n",
      "[399/00075] train_loss: 0.019837\n",
      "[399/00125] train_loss: 0.016966\n",
      "[399/00175] train_loss: 0.015920\n",
      "[399/00225] train_loss: 0.016027\n",
      "[399/00275] train_loss: 0.015756\n",
      "[399/00325] train_loss: 0.015560\n",
      "[399/00375] train_loss: 0.015115\n",
      "[399/00425] train_loss: 0.015671\n",
      "[399/00475] train_loss: 0.016452\n",
      "[399/00525] train_loss: 0.016500\n",
      "[399/00575] train_loss: 0.016667\n",
      "[399/00625] train_loss: 0.016170\n",
      "[399/00675] train_loss: 0.015562\n",
      "[399/00725] train_loss: 0.015777\n",
      "[399/00775] train_loss: 0.016490\n",
      "[399/00825] train_loss: 0.015695\n",
      "[399/00875] train_loss: 0.015184\n",
      "[399/00925] train_loss: 0.015595\n",
      "[399/00975] train_loss: 0.015776\n",
      "[399/01025] train_loss: 0.016782\n",
      "[399/01075] train_loss: 0.016232\n",
      "[399/01125] train_loss: 0.016492\n",
      "[399/01175] train_loss: 0.015604\n",
      "[399/01225] train_loss: 0.016402\n",
      "[400/00049] train_loss: 0.020980\n",
      "[400/00099] train_loss: 0.019105\n",
      "[400/00149] train_loss: 0.017361\n",
      "[400/00199] train_loss: 0.016263\n",
      "[400/00249] train_loss: 0.016039\n",
      "[400/00299] train_loss: 0.015732\n",
      "[400/00349] train_loss: 0.016243\n",
      "[400/00399] train_loss: 0.015204\n",
      "[400/00449] train_loss: 0.015860\n",
      "[400/00499] train_loss: 0.015939\n",
      "[400/00549] train_loss: 0.016045\n",
      "[400/00599] train_loss: 0.015573\n",
      "[400/00649] train_loss: 0.015599\n",
      "[400/00699] train_loss: 0.015805\n",
      "[400/00749] train_loss: 0.015799\n",
      "[400/00799] train_loss: 0.015801\n",
      "[400/00849] train_loss: 0.016678\n",
      "[400/00899] train_loss: 0.015840\n",
      "[400/00949] train_loss: 0.015588\n",
      "[400/00999] train_loss: 0.016143\n",
      "[400/01049] train_loss: 0.016249\n",
      "[400/01099] train_loss: 0.015703\n",
      "[400/01149] train_loss: 0.016180\n",
      "[400/01199] train_loss: 0.016615\n",
      "[401/00023] train_loss: 0.019363\n",
      "[401/00073] train_loss: 0.019817\n",
      "[401/00123] train_loss: 0.016464\n",
      "[401/00173] train_loss: 0.015760\n",
      "[401/00223] train_loss: 0.016699\n",
      "[401/00273] train_loss: 0.015333\n",
      "[401/00323] train_loss: 0.016220\n",
      "[401/00373] train_loss: 0.015839\n",
      "[401/00423] train_loss: 0.015351\n",
      "[401/00473] train_loss: 0.014903\n",
      "[401/00523] train_loss: 0.014724\n",
      "[401/00573] train_loss: 0.015925\n",
      "[401/00623] train_loss: 0.015154\n",
      "[401/00673] train_loss: 0.015150\n",
      "[401/00723] train_loss: 0.015609\n",
      "[401/00773] train_loss: 0.016170\n",
      "[401/00823] train_loss: 0.015762\n",
      "[401/00873] train_loss: 0.016320\n",
      "[401/00923] train_loss: 0.014906\n",
      "[401/00973] train_loss: 0.015532\n",
      "[401/01023] train_loss: 0.015841\n",
      "[401/01073] train_loss: 0.015871\n",
      "[401/01123] train_loss: 0.016320\n",
      "[401/01173] train_loss: 0.016492\n",
      "[401/01223] train_loss: 0.015853\n",
      "[402/00047] train_loss: 0.021037\n",
      "[402/00097] train_loss: 0.018740\n",
      "[402/00147] train_loss: 0.016439\n",
      "[402/00197] train_loss: 0.015527\n",
      "[402/00247] train_loss: 0.016188\n",
      "[402/00297] train_loss: 0.015880\n",
      "[402/00347] train_loss: 0.016457\n",
      "[402/00397] train_loss: 0.017068\n",
      "[402/00447] train_loss: 0.015486\n",
      "[402/00497] train_loss: 0.014984\n",
      "[402/00547] train_loss: 0.015483\n",
      "[402/00597] train_loss: 0.015733\n",
      "[402/00647] train_loss: 0.015313\n",
      "[402/00697] train_loss: 0.015370\n",
      "[402/00747] train_loss: 0.015680\n",
      "[402/00797] train_loss: 0.015969\n",
      "[402/00847] train_loss: 0.016323\n",
      "[402/00897] train_loss: 0.016267\n",
      "[402/00947] train_loss: 0.015832\n",
      "[402/00997] train_loss: 0.016137\n",
      "[402/01047] train_loss: 0.016983\n",
      "[402/01097] train_loss: 0.015460\n",
      "[402/01147] train_loss: 0.016673\n",
      "[402/01197] train_loss: 0.015340\n",
      "[403/00021] train_loss: 0.019979\n",
      "[403/00071] train_loss: 0.019270\n",
      "[403/00121] train_loss: 0.016730\n",
      "[403/00171] train_loss: 0.016501\n",
      "[403/00221] train_loss: 0.015557\n",
      "[403/00271] train_loss: 0.016956\n",
      "[403/00321] train_loss: 0.015656\n",
      "[403/00371] train_loss: 0.016131\n",
      "[403/00421] train_loss: 0.014888\n",
      "[403/00471] train_loss: 0.015270\n",
      "[403/00521] train_loss: 0.016294\n",
      "[403/00571] train_loss: 0.015268\n",
      "[403/00621] train_loss: 0.015539\n",
      "[403/00671] train_loss: 0.014964\n",
      "[403/00721] train_loss: 0.016781\n",
      "[403/00771] train_loss: 0.015909\n",
      "[403/00821] train_loss: 0.016221\n",
      "[403/00871] train_loss: 0.016121\n",
      "[403/00921] train_loss: 0.015195\n",
      "[403/00971] train_loss: 0.015995\n",
      "[403/01021] train_loss: 0.015681\n",
      "[403/01071] train_loss: 0.016190\n",
      "[403/01121] train_loss: 0.016031\n",
      "[403/01171] train_loss: 0.016818\n",
      "[403/01221] train_loss: 0.016706\n",
      "[404/00045] train_loss: 0.021274\n",
      "[404/00095] train_loss: 0.018256\n",
      "[404/00145] train_loss: 0.016479\n",
      "[404/00195] train_loss: 0.016844\n",
      "[404/00245] train_loss: 0.016202\n",
      "[404/00295] train_loss: 0.015298\n",
      "[404/00345] train_loss: 0.015836\n",
      "[404/00395] train_loss: 0.015999\n",
      "[404/00445] train_loss: 0.017008\n",
      "[404/00495] train_loss: 0.015766\n",
      "[404/00545] train_loss: 0.015863\n",
      "[404/00595] train_loss: 0.015002\n",
      "[404/00645] train_loss: 0.015961\n",
      "[404/00695] train_loss: 0.015822\n",
      "[404/00745] train_loss: 0.016204\n",
      "[404/00795] train_loss: 0.015655\n",
      "[404/00845] train_loss: 0.015659\n",
      "[404/00895] train_loss: 0.016410\n",
      "[404/00945] train_loss: 0.015065\n",
      "[404/00995] train_loss: 0.016082\n",
      "[404/01045] train_loss: 0.015709\n",
      "[404/01095] train_loss: 0.016440\n",
      "[404/01145] train_loss: 0.016747\n",
      "[404/01195] train_loss: 0.016613\n",
      "[405/00019] train_loss: 0.018667\n",
      "[405/00069] train_loss: 0.019286\n",
      "[405/00119] train_loss: 0.016227\n",
      "[405/00169] train_loss: 0.015660\n",
      "[405/00219] train_loss: 0.016347\n",
      "[405/00269] train_loss: 0.015318\n",
      "[405/00319] train_loss: 0.015698\n",
      "[405/00369] train_loss: 0.016095\n",
      "[405/00419] train_loss: 0.015438\n",
      "[405/00469] train_loss: 0.015813\n",
      "[405/00519] train_loss: 0.015210\n",
      "[405/00569] train_loss: 0.015874\n",
      "[405/00619] train_loss: 0.015955\n",
      "[405/00669] train_loss: 0.015833\n",
      "[405/00719] train_loss: 0.016412\n",
      "[405/00769] train_loss: 0.016383\n",
      "[405/00819] train_loss: 0.014842\n",
      "[405/00869] train_loss: 0.016545\n",
      "[405/00919] train_loss: 0.015019\n",
      "[405/00969] train_loss: 0.015396\n",
      "[405/01019] train_loss: 0.016660\n",
      "[405/01069] train_loss: 0.016467\n",
      "[405/01119] train_loss: 0.016172\n",
      "[405/01169] train_loss: 0.015965\n",
      "[405/01219] train_loss: 0.016074\n",
      "[406/00043] train_loss: 0.021470\n",
      "[406/00093] train_loss: 0.018599\n",
      "[406/00143] train_loss: 0.016488\n",
      "[406/00193] train_loss: 0.015978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[406/00243] train_loss: 0.016206\n",
      "[406/00293] train_loss: 0.015220\n",
      "[406/00343] train_loss: 0.016671\n",
      "[406/00393] train_loss: 0.016088\n",
      "[406/00443] train_loss: 0.016201\n",
      "[406/00493] train_loss: 0.016003\n",
      "[406/00543] train_loss: 0.015517\n",
      "[406/00593] train_loss: 0.015774\n",
      "[406/00643] train_loss: 0.016148\n",
      "[406/00693] train_loss: 0.015525\n",
      "[406/00743] train_loss: 0.015649\n",
      "[406/00793] train_loss: 0.016726\n",
      "[406/00843] train_loss: 0.015454\n",
      "[406/00893] train_loss: 0.016534\n",
      "[406/00943] train_loss: 0.015151\n",
      "[406/00993] train_loss: 0.015481\n",
      "[406/01043] train_loss: 0.016539\n",
      "[406/01093] train_loss: 0.015471\n",
      "[406/01143] train_loss: 0.015454\n",
      "[406/01193] train_loss: 0.016382\n",
      "[407/00017] train_loss: 0.019003\n",
      "[407/00067] train_loss: 0.021506\n",
      "[407/00117] train_loss: 0.017881\n",
      "[407/00167] train_loss: 0.017137\n",
      "[407/00217] train_loss: 0.015030\n",
      "[407/00267] train_loss: 0.015953\n",
      "[407/00317] train_loss: 0.015302\n",
      "[407/00367] train_loss: 0.016528\n",
      "[407/00417] train_loss: 0.015387\n",
      "[407/00467] train_loss: 0.015411\n",
      "[407/00517] train_loss: 0.016488\n",
      "[407/00567] train_loss: 0.015402\n",
      "[407/00617] train_loss: 0.015140\n",
      "[407/00667] train_loss: 0.015570\n",
      "[407/00717] train_loss: 0.015401\n",
      "[407/00767] train_loss: 0.015795\n",
      "[407/00817] train_loss: 0.017217\n",
      "[407/00867] train_loss: 0.015960\n",
      "[407/00917] train_loss: 0.016111\n",
      "[407/00967] train_loss: 0.016131\n",
      "[407/01017] train_loss: 0.016264\n",
      "[407/01067] train_loss: 0.015284\n",
      "[407/01117] train_loss: 0.015178\n",
      "[407/01167] train_loss: 0.016270\n",
      "[407/01217] train_loss: 0.015466\n",
      "[408/00041] train_loss: 0.020788\n",
      "[408/00091] train_loss: 0.017344\n",
      "[408/00141] train_loss: 0.016079\n",
      "[408/00191] train_loss: 0.016709\n",
      "[408/00241] train_loss: 0.016097\n",
      "[408/00291] train_loss: 0.015481\n",
      "[408/00341] train_loss: 0.016747\n",
      "[408/00391] train_loss: 0.015698\n",
      "[408/00441] train_loss: 0.016366\n",
      "[408/00491] train_loss: 0.015740\n",
      "[408/00541] train_loss: 0.015846\n",
      "[408/00591] train_loss: 0.015221\n",
      "[408/00641] train_loss: 0.015930\n",
      "[408/00691] train_loss: 0.016504\n",
      "[408/00741] train_loss: 0.016806\n",
      "[408/00791] train_loss: 0.016061\n",
      "[408/00841] train_loss: 0.015720\n",
      "[408/00891] train_loss: 0.015781\n",
      "[408/00941] train_loss: 0.016502\n",
      "[408/00991] train_loss: 0.016158\n",
      "[408/01041] train_loss: 0.016417\n",
      "[408/01091] train_loss: 0.017133\n",
      "[408/01141] train_loss: 0.015615\n",
      "[408/01191] train_loss: 0.016381\n",
      "[409/00015] train_loss: 0.018118\n",
      "[409/00065] train_loss: 0.019921\n",
      "[409/00115] train_loss: 0.017662\n",
      "[409/00165] train_loss: 0.015806\n",
      "[409/00215] train_loss: 0.016850\n",
      "[409/00265] train_loss: 0.014972\n",
      "[409/00315] train_loss: 0.016048\n",
      "[409/00365] train_loss: 0.015813\n",
      "[409/00415] train_loss: 0.014782\n",
      "[409/00465] train_loss: 0.015988\n",
      "[409/00515] train_loss: 0.015639\n",
      "[409/00565] train_loss: 0.016422\n",
      "[409/00615] train_loss: 0.016747\n",
      "[409/00665] train_loss: 0.016244\n",
      "[409/00715] train_loss: 0.015322\n",
      "[409/00765] train_loss: 0.015657\n",
      "[409/00815] train_loss: 0.015770\n",
      "[409/00865] train_loss: 0.014974\n",
      "[409/00915] train_loss: 0.016357\n",
      "[409/00965] train_loss: 0.016465\n",
      "[409/01015] train_loss: 0.015892\n",
      "[409/01065] train_loss: 0.015812\n",
      "[409/01115] train_loss: 0.016228\n",
      "[409/01165] train_loss: 0.015366\n",
      "[409/01215] train_loss: 0.016264\n",
      "[410/00039] train_loss: 0.020766\n",
      "[410/00089] train_loss: 0.018891\n",
      "[410/00139] train_loss: 0.016312\n",
      "[410/00189] train_loss: 0.015870\n",
      "[410/00239] train_loss: 0.016398\n",
      "[410/00289] train_loss: 0.015355\n",
      "[410/00339] train_loss: 0.014729\n",
      "[410/00389] train_loss: 0.015149\n",
      "[410/00439] train_loss: 0.015691\n",
      "[410/00489] train_loss: 0.016256\n",
      "[410/00539] train_loss: 0.015793\n",
      "[410/00589] train_loss: 0.015259\n",
      "[410/00639] train_loss: 0.015544\n",
      "[410/00689] train_loss: 0.015748\n",
      "[410/00739] train_loss: 0.015813\n",
      "[410/00789] train_loss: 0.015664\n",
      "[410/00839] train_loss: 0.015905\n",
      "[410/00889] train_loss: 0.015841\n",
      "[410/00939] train_loss: 0.015905\n",
      "[410/00989] train_loss: 0.016017\n",
      "[410/01039] train_loss: 0.016563\n",
      "[410/01089] train_loss: 0.015341\n",
      "[410/01139] train_loss: 0.016214\n",
      "[410/01189] train_loss: 0.016397\n",
      "[411/00013] train_loss: 0.018660\n",
      "[411/00063] train_loss: 0.019814\n",
      "[411/00113] train_loss: 0.018073\n",
      "[411/00163] train_loss: 0.016594\n",
      "[411/00213] train_loss: 0.016130\n",
      "[411/00263] train_loss: 0.015278\n",
      "[411/00313] train_loss: 0.015448\n",
      "[411/00363] train_loss: 0.015367\n",
      "[411/00413] train_loss: 0.015654\n",
      "[411/00463] train_loss: 0.015376\n",
      "[411/00513] train_loss: 0.016138\n",
      "[411/00563] train_loss: 0.015786\n",
      "[411/00613] train_loss: 0.015514\n",
      "[411/00663] train_loss: 0.015334\n",
      "[411/00713] train_loss: 0.015170\n",
      "[411/00763] train_loss: 0.016907\n",
      "[411/00813] train_loss: 0.016004\n",
      "[411/00863] train_loss: 0.015352\n",
      "[411/00913] train_loss: 0.014899\n",
      "[411/00963] train_loss: 0.016291\n",
      "[411/01013] train_loss: 0.016913\n",
      "[411/01063] train_loss: 0.015771\n",
      "[411/01113] train_loss: 0.016759\n",
      "[411/01163] train_loss: 0.016024\n",
      "[411/01213] train_loss: 0.015606\n",
      "[412/00037] train_loss: 0.021971\n",
      "[412/00087] train_loss: 0.018274\n",
      "[412/00137] train_loss: 0.016607\n",
      "[412/00187] train_loss: 0.015404\n",
      "[412/00237] train_loss: 0.015525\n",
      "[412/00287] train_loss: 0.016031\n",
      "[412/00337] train_loss: 0.015778\n",
      "[412/00387] train_loss: 0.015783\n",
      "[412/00437] train_loss: 0.016196\n",
      "[412/00487] train_loss: 0.016309\n",
      "[412/00537] train_loss: 0.015950\n",
      "[412/00587] train_loss: 0.014664\n",
      "[412/00637] train_loss: 0.015564\n",
      "[412/00687] train_loss: 0.016994\n",
      "[412/00737] train_loss: 0.016038\n",
      "[412/00787] train_loss: 0.015942\n",
      "[412/00837] train_loss: 0.016363\n",
      "[412/00887] train_loss: 0.016435\n",
      "[412/00937] train_loss: 0.015654\n",
      "[412/00987] train_loss: 0.014787\n",
      "[412/01037] train_loss: 0.016450\n",
      "[412/01087] train_loss: 0.016199\n",
      "[412/01137] train_loss: 0.015499\n",
      "[412/01187] train_loss: 0.016398\n",
      "[413/00011] train_loss: 0.018241\n",
      "[413/00061] train_loss: 0.020092\n",
      "[413/00111] train_loss: 0.016773\n",
      "[413/00161] train_loss: 0.016763\n",
      "[413/00211] train_loss: 0.015578\n",
      "[413/00261] train_loss: 0.016242\n",
      "[413/00311] train_loss: 0.015576\n",
      "[413/00361] train_loss: 0.016452\n",
      "[413/00411] train_loss: 0.015364\n",
      "[413/00461] train_loss: 0.014804\n",
      "[413/00511] train_loss: 0.015692\n",
      "[413/00561] train_loss: 0.015544\n",
      "[413/00611] train_loss: 0.016139\n",
      "[413/00661] train_loss: 0.015049\n",
      "[413/00711] train_loss: 0.016256\n",
      "[413/00761] train_loss: 0.016445\n",
      "[413/00811] train_loss: 0.015730\n",
      "[413/00861] train_loss: 0.015628\n",
      "[413/00911] train_loss: 0.015827\n",
      "[413/00961] train_loss: 0.015858\n",
      "[413/01011] train_loss: 0.015435\n",
      "[413/01061] train_loss: 0.016432\n",
      "[413/01111] train_loss: 0.016420\n",
      "[413/01161] train_loss: 0.016768\n",
      "[413/01211] train_loss: 0.016867\n",
      "[414/00035] train_loss: 0.020266\n",
      "[414/00085] train_loss: 0.019786\n",
      "[414/00135] train_loss: 0.017785\n",
      "[414/00185] train_loss: 0.015204\n",
      "[414/00235] train_loss: 0.015921\n",
      "[414/00285] train_loss: 0.016487\n",
      "[414/00335] train_loss: 0.015339\n",
      "[414/00385] train_loss: 0.016209\n",
      "[414/00435] train_loss: 0.015481\n",
      "[414/00485] train_loss: 0.016381\n",
      "[414/00535] train_loss: 0.015493\n",
      "[414/00585] train_loss: 0.015638\n",
      "[414/00635] train_loss: 0.015604\n",
      "[414/00685] train_loss: 0.015130\n",
      "[414/00735] train_loss: 0.015930\n",
      "[414/00785] train_loss: 0.015905\n",
      "[414/00835] train_loss: 0.016225\n",
      "[414/00885] train_loss: 0.016242\n",
      "[414/00935] train_loss: 0.016695\n",
      "[414/00985] train_loss: 0.015377\n",
      "[414/01035] train_loss: 0.015939\n",
      "[414/01085] train_loss: 0.015807\n",
      "[414/01135] train_loss: 0.015992\n",
      "[414/01185] train_loss: 0.015568\n",
      "[415/00009] train_loss: 0.017620\n",
      "[415/00059] train_loss: 0.020308\n",
      "[415/00109] train_loss: 0.018131\n",
      "[415/00159] train_loss: 0.015744\n",
      "[415/00209] train_loss: 0.016308\n",
      "[415/00259] train_loss: 0.015613\n",
      "[415/00309] train_loss: 0.015682\n",
      "[415/00359] train_loss: 0.016317\n",
      "[415/00409] train_loss: 0.016271\n",
      "[415/00459] train_loss: 0.015471\n",
      "[415/00509] train_loss: 0.015028\n",
      "[415/00559] train_loss: 0.015973\n",
      "[415/00609] train_loss: 0.014529\n",
      "[415/00659] train_loss: 0.015505\n",
      "[415/00709] train_loss: 0.015469\n",
      "[415/00759] train_loss: 0.015815\n",
      "[415/00809] train_loss: 0.016951\n",
      "[415/00859] train_loss: 0.015321\n",
      "[415/00909] train_loss: 0.016005\n",
      "[415/00959] train_loss: 0.016123\n",
      "[415/01009] train_loss: 0.016491\n",
      "[415/01059] train_loss: 0.015341\n",
      "[415/01109] train_loss: 0.016577\n",
      "[415/01159] train_loss: 0.016199\n",
      "[415/01209] train_loss: 0.016242\n",
      "[416/00033] train_loss: 0.020126\n",
      "[416/00083] train_loss: 0.018313\n",
      "[416/00133] train_loss: 0.017389\n",
      "[416/00183] train_loss: 0.015751\n",
      "[416/00233] train_loss: 0.016681\n",
      "[416/00283] train_loss: 0.015769\n",
      "[416/00333] train_loss: 0.016232\n",
      "[416/00383] train_loss: 0.016594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416/00433] train_loss: 0.015038\n",
      "[416/00483] train_loss: 0.015313\n",
      "[416/00533] train_loss: 0.014754\n",
      "[416/00583] train_loss: 0.015492\n",
      "[416/00633] train_loss: 0.015140\n",
      "[416/00683] train_loss: 0.015332\n",
      "[416/00733] train_loss: 0.016211\n",
      "[416/00783] train_loss: 0.015553\n",
      "[416/00833] train_loss: 0.015778\n",
      "[416/00883] train_loss: 0.015935\n",
      "[416/00933] train_loss: 0.015996\n",
      "[416/00983] train_loss: 0.015184\n",
      "[416/01033] train_loss: 0.014786\n",
      "[416/01083] train_loss: 0.015912\n",
      "[416/01133] train_loss: 0.015594\n",
      "[416/01183] train_loss: 0.016344\n",
      "[417/00007] train_loss: 0.018909\n",
      "[417/00057] train_loss: 0.020017\n",
      "[417/00107] train_loss: 0.018275\n",
      "[417/00157] train_loss: 0.016896\n",
      "[417/00207] train_loss: 0.015632\n",
      "[417/00257] train_loss: 0.014861\n",
      "[417/00307] train_loss: 0.016093\n",
      "[417/00357] train_loss: 0.015297\n",
      "[417/00407] train_loss: 0.016293\n",
      "[417/00457] train_loss: 0.015709\n",
      "[417/00507] train_loss: 0.015419\n",
      "[417/00557] train_loss: 0.015592\n",
      "[417/00607] train_loss: 0.015666\n",
      "[417/00657] train_loss: 0.015251\n",
      "[417/00707] train_loss: 0.015449\n",
      "[417/00757] train_loss: 0.015265\n",
      "[417/00807] train_loss: 0.015229\n",
      "[417/00857] train_loss: 0.016907\n",
      "[417/00907] train_loss: 0.016677\n",
      "[417/00957] train_loss: 0.015835\n",
      "[417/01007] train_loss: 0.016015\n",
      "[417/01057] train_loss: 0.016064\n",
      "[417/01107] train_loss: 0.015222\n",
      "[417/01157] train_loss: 0.016576\n",
      "[417/01207] train_loss: 0.016057\n",
      "[418/00031] train_loss: 0.020439\n",
      "[418/00081] train_loss: 0.019634\n",
      "[418/00131] train_loss: 0.017219\n",
      "[418/00181] train_loss: 0.016075\n",
      "[418/00231] train_loss: 0.015497\n",
      "[418/00281] train_loss: 0.016714\n",
      "[418/00331] train_loss: 0.015378\n",
      "[418/00381] train_loss: 0.016290\n",
      "[418/00431] train_loss: 0.015489\n",
      "[418/00481] train_loss: 0.017096\n",
      "[418/00531] train_loss: 0.015654\n",
      "[418/00581] train_loss: 0.015823\n",
      "[418/00631] train_loss: 0.015822\n",
      "[418/00681] train_loss: 0.016752\n",
      "[418/00731] train_loss: 0.016187\n",
      "[418/00781] train_loss: 0.016391\n",
      "[418/00831] train_loss: 0.015642\n",
      "[418/00881] train_loss: 0.016198\n",
      "[418/00931] train_loss: 0.015618\n",
      "[418/00981] train_loss: 0.015727\n",
      "[418/01031] train_loss: 0.015573\n",
      "[418/01081] train_loss: 0.016431\n",
      "[418/01131] train_loss: 0.016550\n",
      "[418/01181] train_loss: 0.015987\n",
      "[419/00005] train_loss: 0.016746\n",
      "[419/00055] train_loss: 0.020261\n",
      "[419/00105] train_loss: 0.017449\n",
      "[419/00155] train_loss: 0.016127\n",
      "[419/00205] train_loss: 0.016251\n",
      "[419/00255] train_loss: 0.015762\n",
      "[419/00305] train_loss: 0.015940\n",
      "[419/00355] train_loss: 0.015132\n",
      "[419/00405] train_loss: 0.015310\n",
      "[419/00455] train_loss: 0.015932\n",
      "[419/00505] train_loss: 0.015470\n",
      "[419/00555] train_loss: 0.016440\n",
      "[419/00605] train_loss: 0.015466\n",
      "[419/00655] train_loss: 0.015783\n",
      "[419/00705] train_loss: 0.014844\n",
      "[419/00755] train_loss: 0.016249\n",
      "[419/00805] train_loss: 0.015283\n",
      "[419/00855] train_loss: 0.015449\n",
      "[419/00905] train_loss: 0.015273\n",
      "[419/00955] train_loss: 0.015354\n",
      "[419/01005] train_loss: 0.015533\n",
      "[419/01055] train_loss: 0.016364\n",
      "[419/01105] train_loss: 0.016122\n",
      "[419/01155] train_loss: 0.016859\n",
      "[419/01205] train_loss: 0.015445\n",
      "[420/00029] train_loss: 0.019750\n",
      "[420/00079] train_loss: 0.020165\n",
      "[420/00129] train_loss: 0.015831\n",
      "[420/00179] train_loss: 0.016159\n",
      "[420/00229] train_loss: 0.015570\n",
      "[420/00279] train_loss: 0.015706\n",
      "[420/00329] train_loss: 0.015645\n",
      "[420/00379] train_loss: 0.016137\n",
      "[420/00429] train_loss: 0.016058\n",
      "[420/00479] train_loss: 0.015258\n",
      "[420/00529] train_loss: 0.015641\n",
      "[420/00579] train_loss: 0.015360\n",
      "[420/00629] train_loss: 0.015390\n",
      "[420/00679] train_loss: 0.015800\n",
      "[420/00729] train_loss: 0.017104\n",
      "[420/00779] train_loss: 0.017309\n",
      "[420/00829] train_loss: 0.015610\n",
      "[420/00879] train_loss: 0.015869\n",
      "[420/00929] train_loss: 0.015786\n",
      "[420/00979] train_loss: 0.015456\n",
      "[420/01029] train_loss: 0.015762\n",
      "[420/01079] train_loss: 0.015173\n",
      "[420/01129] train_loss: 0.016826\n",
      "[420/01179] train_loss: 0.015336\n",
      "[421/00003] train_loss: 0.016116\n",
      "[421/00053] train_loss: 0.020809\n",
      "[421/00103] train_loss: 0.017953\n",
      "[421/00153] train_loss: 0.016903\n",
      "[421/00203] train_loss: 0.015349\n",
      "[421/00253] train_loss: 0.015904\n",
      "[421/00303] train_loss: 0.015859\n",
      "[421/00353] train_loss: 0.015631\n",
      "[421/00403] train_loss: 0.015868\n",
      "[421/00453] train_loss: 0.015779\n",
      "[421/00503] train_loss: 0.015840\n",
      "[421/00553] train_loss: 0.017403\n",
      "[421/00603] train_loss: 0.015555\n",
      "[421/00653] train_loss: 0.015230\n",
      "[421/00703] train_loss: 0.015809\n",
      "[421/00753] train_loss: 0.016556\n",
      "[421/00803] train_loss: 0.015014\n",
      "[421/00853] train_loss: 0.015600\n",
      "[421/00903] train_loss: 0.015533\n",
      "[421/00953] train_loss: 0.015680\n",
      "[421/01003] train_loss: 0.016238\n",
      "[421/01053] train_loss: 0.016330\n",
      "[421/01103] train_loss: 0.017067\n",
      "[421/01153] train_loss: 0.015998\n",
      "[421/01203] train_loss: 0.015947\n",
      "[422/00027] train_loss: 0.018362\n",
      "[422/00077] train_loss: 0.019195\n",
      "[422/00127] train_loss: 0.017022\n",
      "[422/00177] train_loss: 0.016486\n",
      "[422/00227] train_loss: 0.015926\n",
      "[422/00277] train_loss: 0.016226\n",
      "[422/00327] train_loss: 0.015675\n",
      "[422/00377] train_loss: 0.016872\n",
      "[422/00427] train_loss: 0.016264\n",
      "[422/00477] train_loss: 0.016103\n",
      "[422/00527] train_loss: 0.015285\n",
      "[422/00577] train_loss: 0.015227\n",
      "[422/00627] train_loss: 0.015501\n",
      "[422/00677] train_loss: 0.015381\n",
      "[422/00727] train_loss: 0.016203\n",
      "[422/00777] train_loss: 0.016309\n",
      "[422/00827] train_loss: 0.016219\n",
      "[422/00877] train_loss: 0.015776\n",
      "[422/00927] train_loss: 0.016405\n",
      "[422/00977] train_loss: 0.015892\n",
      "[422/01027] train_loss: 0.015980\n",
      "[422/01077] train_loss: 0.015617\n",
      "[422/01127] train_loss: 0.015925\n",
      "[422/01177] train_loss: 0.016129\n",
      "[423/00001] train_loss: 0.016348\n",
      "[423/00051] train_loss: 0.021152\n",
      "[423/00101] train_loss: 0.017855\n",
      "[423/00151] train_loss: 0.015700\n",
      "[423/00201] train_loss: 0.015742\n",
      "[423/00251] train_loss: 0.015190\n",
      "[423/00301] train_loss: 0.016353\n",
      "[423/00351] train_loss: 0.016501\n",
      "[423/00401] train_loss: 0.015962\n",
      "[423/00451] train_loss: 0.015497\n",
      "[423/00501] train_loss: 0.015985\n",
      "[423/00551] train_loss: 0.016008\n",
      "[423/00601] train_loss: 0.015940\n",
      "[423/00651] train_loss: 0.015838\n",
      "[423/00701] train_loss: 0.016195\n",
      "[423/00751] train_loss: 0.015063\n",
      "[423/00801] train_loss: 0.015581\n",
      "[423/00851] train_loss: 0.015781\n",
      "[423/00901] train_loss: 0.016369\n",
      "[423/00951] train_loss: 0.015373\n",
      "[423/01001] train_loss: 0.016468\n",
      "[423/01051] train_loss: 0.016722\n",
      "[423/01101] train_loss: 0.016321\n",
      "[423/01151] train_loss: 0.016499\n",
      "[423/01201] train_loss: 0.015710\n",
      "[424/00025] train_loss: 0.019990\n",
      "[424/00075] train_loss: 0.019079\n",
      "[424/00125] train_loss: 0.016106\n",
      "[424/00175] train_loss: 0.016481\n",
      "[424/00225] train_loss: 0.015092\n",
      "[424/00275] train_loss: 0.015338\n",
      "[424/00325] train_loss: 0.016091\n",
      "[424/00375] train_loss: 0.015777\n",
      "[424/00425] train_loss: 0.015669\n",
      "[424/00475] train_loss: 0.015585\n",
      "[424/00525] train_loss: 0.015905\n",
      "[424/00575] train_loss: 0.016075\n",
      "[424/00625] train_loss: 0.016452\n",
      "[424/00675] train_loss: 0.015125\n",
      "[424/00725] train_loss: 0.015744\n",
      "[424/00775] train_loss: 0.015073\n",
      "[424/00825] train_loss: 0.015193\n",
      "[424/00875] train_loss: 0.015558\n",
      "[424/00925] train_loss: 0.015599\n",
      "[424/00975] train_loss: 0.015986\n",
      "[424/01025] train_loss: 0.015788\n",
      "[424/01075] train_loss: 0.016440\n",
      "[424/01125] train_loss: 0.015148\n",
      "[424/01175] train_loss: 0.015954\n",
      "[424/01225] train_loss: 0.016430\n",
      "[425/00049] train_loss: 0.022624\n",
      "[425/00099] train_loss: 0.018193\n",
      "[425/00149] train_loss: 0.017391\n",
      "[425/00199] train_loss: 0.015523\n",
      "[425/00249] train_loss: 0.015691\n",
      "[425/00299] train_loss: 0.015531\n",
      "[425/00349] train_loss: 0.015000\n",
      "[425/00399] train_loss: 0.015235\n",
      "[425/00449] train_loss: 0.015609\n",
      "[425/00499] train_loss: 0.016415\n",
      "[425/00549] train_loss: 0.015784\n",
      "[425/00599] train_loss: 0.014719\n",
      "[425/00649] train_loss: 0.015510\n",
      "[425/00699] train_loss: 0.015601\n",
      "[425/00749] train_loss: 0.015942\n",
      "[425/00799] train_loss: 0.015873\n",
      "[425/00849] train_loss: 0.016081\n",
      "[425/00899] train_loss: 0.016235\n",
      "[425/00949] train_loss: 0.015895\n",
      "[425/00999] train_loss: 0.016067\n",
      "[425/01049] train_loss: 0.016004\n",
      "[425/01099] train_loss: 0.016128\n",
      "[425/01149] train_loss: 0.015572\n",
      "[425/01199] train_loss: 0.017725\n",
      "[426/00023] train_loss: 0.018770\n",
      "[426/00073] train_loss: 0.019276\n",
      "[426/00123] train_loss: 0.017273\n",
      "[426/00173] train_loss: 0.016353\n",
      "[426/00223] train_loss: 0.015748\n",
      "[426/00273] train_loss: 0.016128\n",
      "[426/00323] train_loss: 0.015761\n",
      "[426/00373] train_loss: 0.015431\n",
      "[426/00423] train_loss: 0.015381\n",
      "[426/00473] train_loss: 0.014850\n",
      "[426/00523] train_loss: 0.016107\n",
      "[426/00573] train_loss: 0.015709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426/00623] train_loss: 0.015247\n",
      "[426/00673] train_loss: 0.016153\n",
      "[426/00723] train_loss: 0.015906\n",
      "[426/00773] train_loss: 0.015973\n",
      "[426/00823] train_loss: 0.016432\n",
      "[426/00873] train_loss: 0.016901\n",
      "[426/00923] train_loss: 0.015506\n",
      "[426/00973] train_loss: 0.015584\n",
      "[426/01023] train_loss: 0.015777\n",
      "[426/01073] train_loss: 0.015485\n",
      "[426/01123] train_loss: 0.016483\n",
      "[426/01173] train_loss: 0.015435\n",
      "[426/01223] train_loss: 0.016374\n",
      "[427/00047] train_loss: 0.021320\n",
      "[427/00097] train_loss: 0.018902\n",
      "[427/00147] train_loss: 0.016790\n",
      "[427/00197] train_loss: 0.015487\n",
      "[427/00247] train_loss: 0.015644\n",
      "[427/00297] train_loss: 0.015926\n",
      "[427/00347] train_loss: 0.014910\n",
      "[427/00397] train_loss: 0.016560\n",
      "[427/00447] train_loss: 0.015907\n",
      "[427/00497] train_loss: 0.015895\n",
      "[427/00547] train_loss: 0.014984\n",
      "[427/00597] train_loss: 0.016019\n",
      "[427/00647] train_loss: 0.016276\n",
      "[427/00697] train_loss: 0.015612\n",
      "[427/00747] train_loss: 0.016055\n",
      "[427/00797] train_loss: 0.015410\n",
      "[427/00847] train_loss: 0.015405\n",
      "[427/00897] train_loss: 0.015632\n",
      "[427/00947] train_loss: 0.015751\n",
      "[427/00997] train_loss: 0.016025\n",
      "[427/01047] train_loss: 0.016298\n",
      "[427/01097] train_loss: 0.015600\n",
      "[427/01147] train_loss: 0.016333\n",
      "[427/01197] train_loss: 0.016392\n",
      "[428/00021] train_loss: 0.018602\n",
      "[428/00071] train_loss: 0.020036\n",
      "[428/00121] train_loss: 0.017342\n",
      "[428/00171] train_loss: 0.016414\n",
      "[428/00221] train_loss: 0.014984\n",
      "[428/00271] train_loss: 0.015768\n",
      "[428/00321] train_loss: 0.015855\n",
      "[428/00371] train_loss: 0.016370\n",
      "[428/00421] train_loss: 0.015039\n",
      "[428/00471] train_loss: 0.016672\n",
      "[428/00521] train_loss: 0.016008\n",
      "[428/00571] train_loss: 0.016166\n",
      "[428/00621] train_loss: 0.015560\n",
      "[428/00671] train_loss: 0.016118\n",
      "[428/00721] train_loss: 0.015315\n",
      "[428/00771] train_loss: 0.015259\n",
      "[428/00821] train_loss: 0.016398\n",
      "[428/00871] train_loss: 0.015976\n",
      "[428/00921] train_loss: 0.014361\n",
      "[428/00971] train_loss: 0.015075\n",
      "[428/01021] train_loss: 0.016516\n",
      "[428/01071] train_loss: 0.016408\n",
      "[428/01121] train_loss: 0.015872\n",
      "[428/01171] train_loss: 0.016514\n",
      "[428/01221] train_loss: 0.015036\n",
      "[429/00045] train_loss: 0.021696\n",
      "[429/00095] train_loss: 0.018954\n",
      "[429/00145] train_loss: 0.016935\n",
      "[429/00195] train_loss: 0.015647\n",
      "[429/00245] train_loss: 0.016235\n",
      "[429/00295] train_loss: 0.016576\n",
      "[429/00345] train_loss: 0.015255\n",
      "[429/00395] train_loss: 0.016217\n",
      "[429/00445] train_loss: 0.015630\n",
      "[429/00495] train_loss: 0.015544\n",
      "[429/00545] train_loss: 0.016079\n",
      "[429/00595] train_loss: 0.015548\n",
      "[429/00645] train_loss: 0.015561\n",
      "[429/00695] train_loss: 0.015312\n",
      "[429/00745] train_loss: 0.015888\n",
      "[429/00795] train_loss: 0.015994\n",
      "[429/00845] train_loss: 0.016042\n",
      "[429/00895] train_loss: 0.015995\n",
      "[429/00945] train_loss: 0.016186\n",
      "[429/00995] train_loss: 0.016009\n",
      "[429/01045] train_loss: 0.015572\n",
      "[429/01095] train_loss: 0.016280\n",
      "[429/01145] train_loss: 0.015807\n",
      "[429/01195] train_loss: 0.015809\n",
      "[430/00019] train_loss: 0.019161\n",
      "[430/00069] train_loss: 0.019534\n",
      "[430/00119] train_loss: 0.017782\n",
      "[430/00169] train_loss: 0.015727\n",
      "[430/00219] train_loss: 0.016463\n",
      "[430/00269] train_loss: 0.016577\n",
      "[430/00319] train_loss: 0.016213\n",
      "[430/00369] train_loss: 0.015359\n",
      "[430/00419] train_loss: 0.015579\n",
      "[430/00469] train_loss: 0.015138\n",
      "[430/00519] train_loss: 0.015663\n",
      "[430/00569] train_loss: 0.016645\n",
      "[430/00619] train_loss: 0.014731\n",
      "[430/00669] train_loss: 0.014999\n",
      "[430/00719] train_loss: 0.016425\n",
      "[430/00769] train_loss: 0.015342\n",
      "[430/00819] train_loss: 0.015119\n",
      "[430/00869] train_loss: 0.016227\n",
      "[430/00919] train_loss: 0.015967\n",
      "[430/00969] train_loss: 0.015648\n",
      "[430/01019] train_loss: 0.015871\n",
      "[430/01069] train_loss: 0.015387\n",
      "[430/01119] train_loss: 0.015831\n",
      "[430/01169] train_loss: 0.016073\n",
      "[430/01219] train_loss: 0.017215\n",
      "[431/00043] train_loss: 0.021867\n",
      "[431/00093] train_loss: 0.018190\n",
      "[431/00143] train_loss: 0.016562\n",
      "[431/00193] train_loss: 0.016377\n",
      "[431/00243] train_loss: 0.014905\n",
      "[431/00293] train_loss: 0.015242\n",
      "[431/00343] train_loss: 0.015320\n",
      "[431/00393] train_loss: 0.015322\n",
      "[431/00443] train_loss: 0.016585\n",
      "[431/00493] train_loss: 0.014928\n",
      "[431/00543] train_loss: 0.015373\n",
      "[431/00593] train_loss: 0.015839\n",
      "[431/00643] train_loss: 0.016545\n",
      "[431/00693] train_loss: 0.015852\n",
      "[431/00743] train_loss: 0.016601\n",
      "[431/00793] train_loss: 0.016388\n",
      "[431/00843] train_loss: 0.015712\n",
      "[431/00893] train_loss: 0.015993\n",
      "[431/00943] train_loss: 0.015885\n",
      "[431/00993] train_loss: 0.016119\n",
      "[431/01043] train_loss: 0.017008\n",
      "[431/01093] train_loss: 0.015612\n",
      "[431/01143] train_loss: 0.015703\n",
      "[431/01193] train_loss: 0.015474\n",
      "[432/00017] train_loss: 0.018936\n",
      "[432/00067] train_loss: 0.020630\n",
      "[432/00117] train_loss: 0.016985\n",
      "[432/00167] train_loss: 0.016329\n",
      "[432/00217] train_loss: 0.016184\n",
      "[432/00267] train_loss: 0.015982\n",
      "[432/00317] train_loss: 0.016545\n",
      "[432/00367] train_loss: 0.016132\n",
      "[432/00417] train_loss: 0.016211\n",
      "[432/00467] train_loss: 0.015523\n",
      "[432/00517] train_loss: 0.015639\n",
      "[432/00567] train_loss: 0.016325\n",
      "[432/00617] train_loss: 0.015812\n",
      "[432/00667] train_loss: 0.015026\n",
      "[432/00717] train_loss: 0.015610\n",
      "[432/00767] train_loss: 0.015986\n",
      "[432/00817] train_loss: 0.015827\n",
      "[432/00867] train_loss: 0.014965\n",
      "[432/00917] train_loss: 0.015985\n",
      "[432/00967] train_loss: 0.016161\n",
      "[432/01017] train_loss: 0.015240\n",
      "[432/01067] train_loss: 0.016183\n",
      "[432/01117] train_loss: 0.016213\n",
      "[432/01167] train_loss: 0.015950\n",
      "[432/01217] train_loss: 0.016243\n",
      "[433/00041] train_loss: 0.020440\n",
      "[433/00091] train_loss: 0.018200\n",
      "[433/00141] train_loss: 0.016386\n",
      "[433/00191] train_loss: 0.016684\n",
      "[433/00241] train_loss: 0.016304\n",
      "[433/00291] train_loss: 0.015243\n",
      "[433/00341] train_loss: 0.015567\n",
      "[433/00391] train_loss: 0.016062\n",
      "[433/00441] train_loss: 0.014723\n",
      "[433/00491] train_loss: 0.015782\n",
      "[433/00541] train_loss: 0.016018\n",
      "[433/00591] train_loss: 0.015442\n",
      "[433/00641] train_loss: 0.015282\n",
      "[433/00691] train_loss: 0.015923\n",
      "[433/00741] train_loss: 0.015935\n",
      "[433/00791] train_loss: 0.014911\n",
      "[433/00841] train_loss: 0.015134\n",
      "[433/00891] train_loss: 0.016254\n",
      "[433/00941] train_loss: 0.015787\n",
      "[433/00991] train_loss: 0.015420\n",
      "[433/01041] train_loss: 0.016851\n",
      "[433/01091] train_loss: 0.015441\n",
      "[433/01141] train_loss: 0.015197\n",
      "[433/01191] train_loss: 0.016208\n",
      "[434/00015] train_loss: 0.019467\n",
      "[434/00065] train_loss: 0.020104\n",
      "[434/00115] train_loss: 0.018206\n",
      "[434/00165] train_loss: 0.015933\n",
      "[434/00215] train_loss: 0.015772\n",
      "[434/00265] train_loss: 0.015665\n",
      "[434/00315] train_loss: 0.015740\n",
      "[434/00365] train_loss: 0.015663\n",
      "[434/00415] train_loss: 0.015923\n",
      "[434/00465] train_loss: 0.014870\n",
      "[434/00515] train_loss: 0.015722\n",
      "[434/00565] train_loss: 0.015833\n",
      "[434/00615] train_loss: 0.015874\n",
      "[434/00665] train_loss: 0.015633\n",
      "[434/00715] train_loss: 0.015989\n",
      "[434/00765] train_loss: 0.015373\n",
      "[434/00815] train_loss: 0.015773\n",
      "[434/00865] train_loss: 0.015648\n",
      "[434/00915] train_loss: 0.015599\n",
      "[434/00965] train_loss: 0.015836\n",
      "[434/01015] train_loss: 0.015960\n",
      "[434/01065] train_loss: 0.015335\n",
      "[434/01115] train_loss: 0.015866\n",
      "[434/01165] train_loss: 0.016336\n",
      "[434/01215] train_loss: 0.015226\n",
      "[435/00039] train_loss: 0.021841\n",
      "[435/00089] train_loss: 0.018604\n",
      "[435/00139] train_loss: 0.017196\n",
      "[435/00189] train_loss: 0.016202\n",
      "[435/00239] train_loss: 0.016446\n",
      "[435/00289] train_loss: 0.016056\n",
      "[435/00339] train_loss: 0.015943\n",
      "[435/00389] train_loss: 0.015326\n",
      "[435/00439] train_loss: 0.015705\n",
      "[435/00489] train_loss: 0.015305\n",
      "[435/00539] train_loss: 0.016119\n",
      "[435/00589] train_loss: 0.015226\n",
      "[435/00639] train_loss: 0.015525\n",
      "[435/00689] train_loss: 0.015999\n",
      "[435/00739] train_loss: 0.015416\n",
      "[435/00789] train_loss: 0.015175\n",
      "[435/00839] train_loss: 0.016604\n",
      "[435/00889] train_loss: 0.015270\n",
      "[435/00939] train_loss: 0.016700\n",
      "[435/00989] train_loss: 0.016833\n",
      "[435/01039] train_loss: 0.015138\n",
      "[435/01089] train_loss: 0.015221\n",
      "[435/01139] train_loss: 0.016144\n",
      "[435/01189] train_loss: 0.016174\n",
      "[436/00013] train_loss: 0.017624\n",
      "[436/00063] train_loss: 0.020036\n",
      "[436/00113] train_loss: 0.018599\n",
      "[436/00163] train_loss: 0.016740\n",
      "[436/00213] train_loss: 0.015918\n",
      "[436/00263] train_loss: 0.015357\n",
      "[436/00313] train_loss: 0.016334\n",
      "[436/00363] train_loss: 0.016169\n",
      "[436/00413] train_loss: 0.015461\n",
      "[436/00463] train_loss: 0.016265\n",
      "[436/00513] train_loss: 0.015595\n",
      "[436/00563] train_loss: 0.015289\n",
      "[436/00613] train_loss: 0.014857\n",
      "[436/00663] train_loss: 0.015902\n",
      "[436/00713] train_loss: 0.015651\n",
      "[436/00763] train_loss: 0.015486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436/00813] train_loss: 0.015704\n",
      "[436/00863] train_loss: 0.015159\n",
      "[436/00913] train_loss: 0.015589\n",
      "[436/00963] train_loss: 0.015860\n",
      "[436/01013] train_loss: 0.016134\n",
      "[436/01063] train_loss: 0.015132\n",
      "[436/01113] train_loss: 0.015135\n",
      "[436/01163] train_loss: 0.016047\n",
      "[436/01213] train_loss: 0.016200\n",
      "[437/00037] train_loss: 0.020218\n",
      "[437/00087] train_loss: 0.019202\n",
      "[437/00137] train_loss: 0.016991\n",
      "[437/00187] train_loss: 0.016401\n",
      "[437/00237] train_loss: 0.015200\n",
      "[437/00287] train_loss: 0.015965\n",
      "[437/00337] train_loss: 0.016241\n",
      "[437/00387] train_loss: 0.014891\n",
      "[437/00437] train_loss: 0.015183\n",
      "[437/00487] train_loss: 0.015499\n",
      "[437/00537] train_loss: 0.015949\n",
      "[437/00587] train_loss: 0.015945\n",
      "[437/00637] train_loss: 0.015303\n",
      "[437/00687] train_loss: 0.016343\n",
      "[437/00737] train_loss: 0.015916\n",
      "[437/00787] train_loss: 0.016042\n",
      "[437/00837] train_loss: 0.016610\n",
      "[437/00887] train_loss: 0.016189\n",
      "[437/00937] train_loss: 0.015963\n",
      "[437/00987] train_loss: 0.014896\n",
      "[437/01037] train_loss: 0.015526\n",
      "[437/01087] train_loss: 0.016058\n",
      "[437/01137] train_loss: 0.016016\n",
      "[437/01187] train_loss: 0.015882\n",
      "[438/00011] train_loss: 0.018222\n",
      "[438/00061] train_loss: 0.020737\n",
      "[438/00111] train_loss: 0.017695\n",
      "[438/00161] train_loss: 0.016586\n",
      "[438/00211] train_loss: 0.016323\n",
      "[438/00261] train_loss: 0.015996\n",
      "[438/00311] train_loss: 0.016056\n",
      "[438/00361] train_loss: 0.015651\n",
      "[438/00411] train_loss: 0.016113\n",
      "[438/00461] train_loss: 0.015931\n",
      "[438/00511] train_loss: 0.015133\n",
      "[438/00561] train_loss: 0.015156\n",
      "[438/00611] train_loss: 0.015765\n",
      "[438/00661] train_loss: 0.016228\n",
      "[438/00711] train_loss: 0.016123\n",
      "[438/00761] train_loss: 0.015304\n",
      "[438/00811] train_loss: 0.015402\n",
      "[438/00861] train_loss: 0.015946\n",
      "[438/00911] train_loss: 0.016177\n",
      "[438/00961] train_loss: 0.015798\n",
      "[438/01011] train_loss: 0.015473\n",
      "[438/01061] train_loss: 0.015513\n",
      "[438/01111] train_loss: 0.015759\n",
      "[438/01161] train_loss: 0.015699\n",
      "[438/01211] train_loss: 0.018148\n",
      "[439/00035] train_loss: 0.018939\n",
      "[439/00085] train_loss: 0.018575\n",
      "[439/00135] train_loss: 0.018349\n",
      "[439/00185] train_loss: 0.016312\n",
      "[439/00235] train_loss: 0.016785\n",
      "[439/00285] train_loss: 0.015409\n",
      "[439/00335] train_loss: 0.015565\n",
      "[439/00385] train_loss: 0.015695\n",
      "[439/00435] train_loss: 0.015829\n",
      "[439/00485] train_loss: 0.016158\n",
      "[439/00535] train_loss: 0.015027\n",
      "[439/00585] train_loss: 0.015747\n",
      "[439/00635] train_loss: 0.016181\n",
      "[439/00685] train_loss: 0.015248\n",
      "[439/00735] train_loss: 0.016813\n",
      "[439/00785] train_loss: 0.015641\n",
      "[439/00835] train_loss: 0.015741\n",
      "[439/00885] train_loss: 0.015317\n",
      "[439/00935] train_loss: 0.015225\n",
      "[439/00985] train_loss: 0.015449\n",
      "[439/01035] train_loss: 0.016488\n",
      "[439/01085] train_loss: 0.016483\n",
      "[439/01135] train_loss: 0.016010\n",
      "[439/01185] train_loss: 0.015374\n",
      "[440/00009] train_loss: 0.018182\n",
      "[440/00059] train_loss: 0.021376\n",
      "[440/00109] train_loss: 0.017410\n",
      "[440/00159] train_loss: 0.016685\n",
      "[440/00209] train_loss: 0.016139\n",
      "[440/00259] train_loss: 0.015557\n",
      "[440/00309] train_loss: 0.015397\n",
      "[440/00359] train_loss: 0.016874\n",
      "[440/00409] train_loss: 0.015451\n",
      "[440/00459] train_loss: 0.015744\n",
      "[440/00509] train_loss: 0.015889\n",
      "[440/00559] train_loss: 0.015417\n",
      "[440/00609] train_loss: 0.014903\n",
      "[440/00659] train_loss: 0.015324\n",
      "[440/00709] train_loss: 0.016614\n",
      "[440/00759] train_loss: 0.015284\n",
      "[440/00809] train_loss: 0.015998\n",
      "[440/00859] train_loss: 0.015737\n",
      "[440/00909] train_loss: 0.015162\n",
      "[440/00959] train_loss: 0.015936\n",
      "[440/01009] train_loss: 0.015723\n",
      "[440/01059] train_loss: 0.015218\n",
      "[440/01109] train_loss: 0.015526\n",
      "[440/01159] train_loss: 0.015836\n",
      "[440/01209] train_loss: 0.016286\n",
      "[441/00033] train_loss: 0.019526\n",
      "[441/00083] train_loss: 0.017383\n",
      "[441/00133] train_loss: 0.016889\n",
      "[441/00183] train_loss: 0.015913\n",
      "[441/00233] train_loss: 0.016927\n",
      "[441/00283] train_loss: 0.015897\n",
      "[441/00333] train_loss: 0.015878\n",
      "[441/00383] train_loss: 0.015618\n",
      "[441/00433] train_loss: 0.015810\n",
      "[441/00483] train_loss: 0.015637\n",
      "[441/00533] train_loss: 0.016844\n",
      "[441/00583] train_loss: 0.016469\n",
      "[441/00633] train_loss: 0.015884\n",
      "[441/00683] train_loss: 0.014558\n",
      "[441/00733] train_loss: 0.015874\n",
      "[441/00783] train_loss: 0.016990\n",
      "[441/00833] train_loss: 0.014993\n",
      "[441/00883] train_loss: 0.015861\n",
      "[441/00933] train_loss: 0.014979\n",
      "[441/00983] train_loss: 0.016577\n",
      "[441/01033] train_loss: 0.016740\n",
      "[441/01083] train_loss: 0.014844\n",
      "[441/01133] train_loss: 0.015804\n",
      "[441/01183] train_loss: 0.016055\n",
      "[442/00007] train_loss: 0.017160\n",
      "[442/00057] train_loss: 0.021458\n",
      "[442/00107] train_loss: 0.017945\n",
      "[442/00157] train_loss: 0.016115\n",
      "[442/00207] train_loss: 0.015866\n",
      "[442/00257] train_loss: 0.015186\n",
      "[442/00307] train_loss: 0.016693\n",
      "[442/00357] train_loss: 0.015930\n",
      "[442/00407] train_loss: 0.017427\n",
      "[442/00457] train_loss: 0.015174\n",
      "[442/00507] train_loss: 0.015695\n",
      "[442/00557] train_loss: 0.015162\n",
      "[442/00607] train_loss: 0.015184\n",
      "[442/00657] train_loss: 0.016070\n",
      "[442/00707] train_loss: 0.016333\n",
      "[442/00757] train_loss: 0.015456\n",
      "[442/00807] train_loss: 0.016286\n",
      "[442/00857] train_loss: 0.015696\n",
      "[442/00907] train_loss: 0.016533\n",
      "[442/00957] train_loss: 0.016870\n",
      "[442/01007] train_loss: 0.015505\n",
      "[442/01057] train_loss: 0.015482\n",
      "[442/01107] train_loss: 0.016398\n",
      "[442/01157] train_loss: 0.016402\n",
      "[442/01207] train_loss: 0.016056\n",
      "[443/00031] train_loss: 0.019514\n",
      "[443/00081] train_loss: 0.018679\n",
      "[443/00131] train_loss: 0.015997\n",
      "[443/00181] train_loss: 0.015965\n",
      "[443/00231] train_loss: 0.016305\n",
      "[443/00281] train_loss: 0.016166\n",
      "[443/00331] train_loss: 0.015451\n",
      "[443/00381] train_loss: 0.016596\n",
      "[443/00431] train_loss: 0.015620\n",
      "[443/00481] train_loss: 0.015683\n",
      "[443/00531] train_loss: 0.014739\n",
      "[443/00581] train_loss: 0.016071\n",
      "[443/00631] train_loss: 0.015203\n",
      "[443/00681] train_loss: 0.016066\n",
      "[443/00731] train_loss: 0.015430\n",
      "[443/00781] train_loss: 0.016458\n",
      "[443/00831] train_loss: 0.015364\n",
      "[443/00881] train_loss: 0.016290\n",
      "[443/00931] train_loss: 0.016379\n",
      "[443/00981] train_loss: 0.015522\n",
      "[443/01031] train_loss: 0.015152\n",
      "[443/01081] train_loss: 0.015432\n",
      "[443/01131] train_loss: 0.016266\n",
      "[443/01181] train_loss: 0.016300\n",
      "[444/00005] train_loss: 0.016264\n",
      "[444/00055] train_loss: 0.021654\n",
      "[444/00105] train_loss: 0.017711\n",
      "[444/00155] train_loss: 0.016093\n",
      "[444/00205] train_loss: 0.016309\n",
      "[444/00255] train_loss: 0.015727\n",
      "[444/00305] train_loss: 0.016169\n",
      "[444/00355] train_loss: 0.015888\n",
      "[444/00405] train_loss: 0.014942\n",
      "[444/00455] train_loss: 0.016134\n",
      "[444/00505] train_loss: 0.015140\n",
      "[444/00555] train_loss: 0.015981\n",
      "[444/00605] train_loss: 0.016349\n",
      "[444/00655] train_loss: 0.016018\n",
      "[444/00705] train_loss: 0.015641\n",
      "[444/00755] train_loss: 0.015580\n",
      "[444/00805] train_loss: 0.015157\n",
      "[444/00855] train_loss: 0.015657\n",
      "[444/00905] train_loss: 0.016039\n",
      "[444/00955] train_loss: 0.015873\n",
      "[444/01005] train_loss: 0.015443\n",
      "[444/01055] train_loss: 0.015282\n",
      "[444/01105] train_loss: 0.015920\n",
      "[444/01155] train_loss: 0.016206\n",
      "[444/01205] train_loss: 0.015219\n",
      "[445/00029] train_loss: 0.020384\n",
      "[445/00079] train_loss: 0.020115\n",
      "[445/00129] train_loss: 0.017459\n",
      "[445/00179] train_loss: 0.016604\n",
      "[445/00229] train_loss: 0.015919\n",
      "[445/00279] train_loss: 0.016251\n",
      "[445/00329] train_loss: 0.015319\n",
      "[445/00379] train_loss: 0.015093\n",
      "[445/00429] train_loss: 0.015408\n",
      "[445/00479] train_loss: 0.015756\n",
      "[445/00529] train_loss: 0.016215\n",
      "[445/00579] train_loss: 0.016020\n",
      "[445/00629] train_loss: 0.016166\n",
      "[445/00679] train_loss: 0.015488\n",
      "[445/00729] train_loss: 0.015816\n",
      "[445/00779] train_loss: 0.015139\n",
      "[445/00829] train_loss: 0.015908\n",
      "[445/00879] train_loss: 0.015506\n",
      "[445/00929] train_loss: 0.015272\n",
      "[445/00979] train_loss: 0.016808\n",
      "[445/01029] train_loss: 0.015441\n",
      "[445/01079] train_loss: 0.015864\n",
      "[445/01129] train_loss: 0.016403\n",
      "[445/01179] train_loss: 0.016651\n",
      "[446/00003] train_loss: 0.015986\n",
      "[446/00053] train_loss: 0.021463\n",
      "[446/00103] train_loss: 0.018282\n",
      "[446/00153] train_loss: 0.016763\n",
      "[446/00203] train_loss: 0.015580\n",
      "[446/00253] train_loss: 0.014857\n",
      "[446/00303] train_loss: 0.015658\n",
      "[446/00353] train_loss: 0.015290\n",
      "[446/00403] train_loss: 0.015282\n",
      "[446/00453] train_loss: 0.016525\n",
      "[446/00503] train_loss: 0.015948\n",
      "[446/00553] train_loss: 0.015643\n",
      "[446/00603] train_loss: 0.016207\n",
      "[446/00653] train_loss: 0.015001\n",
      "[446/00703] train_loss: 0.014838\n",
      "[446/00753] train_loss: 0.015816\n",
      "[446/00803] train_loss: 0.014852\n",
      "[446/00853] train_loss: 0.016379\n",
      "[446/00903] train_loss: 0.016252\n",
      "[446/00953] train_loss: 0.015406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446/01003] train_loss: 0.015861\n",
      "[446/01053] train_loss: 0.015746\n",
      "[446/01103] train_loss: 0.015732\n",
      "[446/01153] train_loss: 0.016130\n",
      "[446/01203] train_loss: 0.016611\n",
      "[447/00027] train_loss: 0.020139\n",
      "[447/00077] train_loss: 0.019094\n",
      "[447/00127] train_loss: 0.016992\n",
      "[447/00177] train_loss: 0.016490\n",
      "[447/00227] train_loss: 0.015450\n",
      "[447/00277] train_loss: 0.015594\n",
      "[447/00327] train_loss: 0.015362\n",
      "[447/00377] train_loss: 0.014765\n",
      "[447/00427] train_loss: 0.016210\n",
      "[447/00477] train_loss: 0.015451\n",
      "[447/00527] train_loss: 0.015761\n",
      "[447/00577] train_loss: 0.014914\n",
      "[447/00627] train_loss: 0.015630\n",
      "[447/00677] train_loss: 0.015784\n",
      "[447/00727] train_loss: 0.015637\n",
      "[447/00777] train_loss: 0.015562\n",
      "[447/00827] train_loss: 0.015366\n",
      "[447/00877] train_loss: 0.015892\n",
      "[447/00927] train_loss: 0.015964\n",
      "[447/00977] train_loss: 0.016624\n",
      "[447/01027] train_loss: 0.015587\n",
      "[447/01077] train_loss: 0.016301\n",
      "[447/01127] train_loss: 0.016864\n",
      "[447/01177] train_loss: 0.016347\n",
      "[448/00001] train_loss: 0.015762\n",
      "[448/00051] train_loss: 0.022121\n",
      "[448/00101] train_loss: 0.017895\n",
      "[448/00151] train_loss: 0.016027\n",
      "[448/00201] train_loss: 0.015723\n",
      "[448/00251] train_loss: 0.015600\n",
      "[448/00301] train_loss: 0.016567\n",
      "[448/00351] train_loss: 0.015693\n",
      "[448/00401] train_loss: 0.015456\n",
      "[448/00451] train_loss: 0.015497\n",
      "[448/00501] train_loss: 0.015776\n",
      "[448/00551] train_loss: 0.016020\n",
      "[448/00601] train_loss: 0.015784\n",
      "[448/00651] train_loss: 0.015111\n",
      "[448/00701] train_loss: 0.015717\n",
      "[448/00751] train_loss: 0.014295\n",
      "[448/00801] train_loss: 0.015300\n",
      "[448/00851] train_loss: 0.016503\n",
      "[448/00901] train_loss: 0.015102\n",
      "[448/00951] train_loss: 0.015163\n",
      "[448/01001] train_loss: 0.016609\n",
      "[448/01051] train_loss: 0.015857\n",
      "[448/01101] train_loss: 0.015554\n",
      "[448/01151] train_loss: 0.015512\n",
      "[448/01201] train_loss: 0.016389\n",
      "[449/00025] train_loss: 0.018821\n",
      "[449/00075] train_loss: 0.020646\n",
      "[449/00125] train_loss: 0.017020\n",
      "[449/00175] train_loss: 0.015865\n",
      "[449/00225] train_loss: 0.015556\n",
      "[449/00275] train_loss: 0.015924\n",
      "[449/00325] train_loss: 0.015662\n",
      "[449/00375] train_loss: 0.015812\n",
      "[449/00425] train_loss: 0.015742\n",
      "[449/00475] train_loss: 0.015613\n",
      "[449/00525] train_loss: 0.014714\n",
      "[449/00575] train_loss: 0.015388\n",
      "[449/00625] train_loss: 0.015629\n",
      "[449/00675] train_loss: 0.016051\n",
      "[449/00725] train_loss: 0.014641\n",
      "[449/00775] train_loss: 0.015731\n",
      "[449/00825] train_loss: 0.016210\n",
      "[449/00875] train_loss: 0.015019\n",
      "[449/00925] train_loss: 0.016788\n",
      "[449/00975] train_loss: 0.015991\n",
      "[449/01025] train_loss: 0.015823\n",
      "[449/01075] train_loss: 0.015704\n",
      "[449/01125] train_loss: 0.015788\n",
      "[449/01175] train_loss: 0.015935\n",
      "[449/01225] train_loss: 0.016087\n",
      "[450/00049] train_loss: 0.020391\n",
      "[450/00099] train_loss: 0.016914\n",
      "[450/00149] train_loss: 0.016712\n",
      "[450/00199] train_loss: 0.016085\n",
      "[450/00249] train_loss: 0.016002\n",
      "[450/00299] train_loss: 0.016298\n",
      "[450/00349] train_loss: 0.016190\n",
      "[450/00399] train_loss: 0.014786\n",
      "[450/00449] train_loss: 0.016276\n",
      "[450/00499] train_loss: 0.015840\n",
      "[450/00549] train_loss: 0.015494\n",
      "[450/00599] train_loss: 0.015563\n",
      "[450/00649] train_loss: 0.015606\n",
      "[450/00699] train_loss: 0.015027\n",
      "[450/00749] train_loss: 0.015297\n",
      "[450/00799] train_loss: 0.015496\n",
      "[450/00849] train_loss: 0.015150\n",
      "[450/00899] train_loss: 0.015917\n",
      "[450/00949] train_loss: 0.015533\n",
      "[450/00999] train_loss: 0.016618\n",
      "[450/01049] train_loss: 0.015986\n",
      "[450/01099] train_loss: 0.016881\n",
      "[450/01149] train_loss: 0.016342\n",
      "[450/01199] train_loss: 0.016391\n",
      "[451/00023] train_loss: 0.019406\n",
      "[451/00073] train_loss: 0.019199\n",
      "[451/00123] train_loss: 0.017716\n",
      "[451/00173] train_loss: 0.016913\n",
      "[451/00223] train_loss: 0.015776\n",
      "[451/00273] train_loss: 0.016038\n",
      "[451/00323] train_loss: 0.015881\n",
      "[451/00373] train_loss: 0.015696\n",
      "[451/00423] train_loss: 0.015548\n",
      "[451/00473] train_loss: 0.016373\n",
      "[451/00523] train_loss: 0.015690\n",
      "[451/00573] train_loss: 0.015263\n",
      "[451/00623] train_loss: 0.015893\n",
      "[451/00673] train_loss: 0.015758\n",
      "[451/00723] train_loss: 0.016097\n",
      "[451/00773] train_loss: 0.016357\n",
      "[451/00823] train_loss: 0.015558\n",
      "[451/00873] train_loss: 0.015979\n",
      "[451/00923] train_loss: 0.015723\n",
      "[451/00973] train_loss: 0.015230\n",
      "[451/01023] train_loss: 0.015983\n",
      "[451/01073] train_loss: 0.015867\n",
      "[451/01123] train_loss: 0.015679\n",
      "[451/01173] train_loss: 0.015684\n",
      "[451/01223] train_loss: 0.015730\n",
      "[452/00047] train_loss: 0.021842\n",
      "[452/00097] train_loss: 0.017039\n",
      "[452/00147] train_loss: 0.016608\n",
      "[452/00197] train_loss: 0.015525\n",
      "[452/00247] train_loss: 0.015975\n",
      "[452/00297] train_loss: 0.015761\n",
      "[452/00347] train_loss: 0.015401\n",
      "[452/00397] train_loss: 0.015690\n",
      "[452/00447] train_loss: 0.016849\n",
      "[452/00497] train_loss: 0.016483\n",
      "[452/00547] train_loss: 0.015958\n",
      "[452/00597] train_loss: 0.015010\n",
      "[452/00647] train_loss: 0.015823\n",
      "[452/00697] train_loss: 0.015620\n",
      "[452/00747] train_loss: 0.015575\n",
      "[452/00797] train_loss: 0.015231\n",
      "[452/00847] train_loss: 0.016074\n",
      "[452/00897] train_loss: 0.016210\n",
      "[452/00947] train_loss: 0.015724\n",
      "[452/00997] train_loss: 0.015628\n",
      "[452/01047] train_loss: 0.015466\n",
      "[452/01097] train_loss: 0.015780\n",
      "[452/01147] train_loss: 0.016346\n",
      "[452/01197] train_loss: 0.016256\n",
      "[453/00021] train_loss: 0.018602\n",
      "[453/00071] train_loss: 0.020131\n",
      "[453/00121] train_loss: 0.017238\n",
      "[453/00171] train_loss: 0.016373\n",
      "[453/00221] train_loss: 0.016033\n",
      "[453/00271] train_loss: 0.016549\n",
      "[453/00321] train_loss: 0.015984\n",
      "[453/00371] train_loss: 0.015567\n",
      "[453/00421] train_loss: 0.015422\n",
      "[453/00471] train_loss: 0.015858\n",
      "[453/00521] train_loss: 0.015419\n",
      "[453/00571] train_loss: 0.015134\n",
      "[453/00621] train_loss: 0.016101\n",
      "[453/00671] train_loss: 0.016000\n",
      "[453/00721] train_loss: 0.015865\n",
      "[453/00771] train_loss: 0.014706\n",
      "[453/00821] train_loss: 0.016014\n",
      "[453/00871] train_loss: 0.015382\n",
      "[453/00921] train_loss: 0.016774\n",
      "[453/00971] train_loss: 0.015797\n",
      "[453/01021] train_loss: 0.015162\n",
      "[453/01071] train_loss: 0.016712\n",
      "[453/01121] train_loss: 0.016317\n",
      "[453/01171] train_loss: 0.015341\n",
      "[453/01221] train_loss: 0.015567\n",
      "[454/00045] train_loss: 0.020486\n",
      "[454/00095] train_loss: 0.018278\n",
      "[454/00145] train_loss: 0.017744\n",
      "[454/00195] train_loss: 0.015303\n",
      "[454/00245] train_loss: 0.015600\n",
      "[454/00295] train_loss: 0.016630\n",
      "[454/00345] train_loss: 0.015727\n",
      "[454/00395] train_loss: 0.015416\n",
      "[454/00445] train_loss: 0.015547\n",
      "[454/00495] train_loss: 0.015574\n",
      "[454/00545] train_loss: 0.016285\n",
      "[454/00595] train_loss: 0.015173\n",
      "[454/00645] train_loss: 0.015804\n",
      "[454/00695] train_loss: 0.016506\n",
      "[454/00745] train_loss: 0.015681\n",
      "[454/00795] train_loss: 0.015746\n",
      "[454/00845] train_loss: 0.015721\n",
      "[454/00895] train_loss: 0.015885\n",
      "[454/00945] train_loss: 0.016078\n",
      "[454/00995] train_loss: 0.015931\n",
      "[454/01045] train_loss: 0.015366\n",
      "[454/01095] train_loss: 0.015579\n",
      "[454/01145] train_loss: 0.015231\n",
      "[454/01195] train_loss: 0.016122\n",
      "[455/00019] train_loss: 0.017984\n",
      "[455/00069] train_loss: 0.020362\n",
      "[455/00119] train_loss: 0.017565\n",
      "[455/00169] train_loss: 0.016902\n",
      "[455/00219] train_loss: 0.014937\n",
      "[455/00269] train_loss: 0.015353\n",
      "[455/00319] train_loss: 0.016711\n",
      "[455/00369] train_loss: 0.015407\n",
      "[455/00419] train_loss: 0.015467\n",
      "[455/00469] train_loss: 0.015101\n",
      "[455/00519] train_loss: 0.015291\n",
      "[455/00569] train_loss: 0.015380\n",
      "[455/00619] train_loss: 0.015830\n",
      "[455/00669] train_loss: 0.015591\n",
      "[455/00719] train_loss: 0.015445\n",
      "[455/00769] train_loss: 0.015484\n",
      "[455/00819] train_loss: 0.015385\n",
      "[455/00869] train_loss: 0.017172\n",
      "[455/00919] train_loss: 0.016148\n",
      "[455/00969] train_loss: 0.016627\n",
      "[455/01019] train_loss: 0.015553\n",
      "[455/01069] train_loss: 0.015748\n",
      "[455/01119] train_loss: 0.015049\n",
      "[455/01169] train_loss: 0.015535\n",
      "[455/01219] train_loss: 0.016736\n",
      "[456/00043] train_loss: 0.021876\n",
      "[456/00093] train_loss: 0.018572\n",
      "[456/00143] train_loss: 0.016291\n",
      "[456/00193] train_loss: 0.015092\n",
      "[456/00243] train_loss: 0.016139\n",
      "[456/00293] train_loss: 0.015830\n",
      "[456/00343] train_loss: 0.015635\n",
      "[456/00393] train_loss: 0.015649\n",
      "[456/00443] train_loss: 0.015606\n",
      "[456/00493] train_loss: 0.016252\n",
      "[456/00543] train_loss: 0.015751\n",
      "[456/00593] train_loss: 0.015267\n",
      "[456/00643] train_loss: 0.016623\n",
      "[456/00693] train_loss: 0.015530\n",
      "[456/00743] train_loss: 0.015877\n",
      "[456/00793] train_loss: 0.015585\n",
      "[456/00843] train_loss: 0.015582\n",
      "[456/00893] train_loss: 0.015658\n",
      "[456/00943] train_loss: 0.016062\n",
      "[456/00993] train_loss: 0.016666\n",
      "[456/01043] train_loss: 0.015782\n",
      "[456/01093] train_loss: 0.015591\n",
      "[456/01143] train_loss: 0.014533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[456/01193] train_loss: 0.015412\n",
      "[457/00017] train_loss: 0.018376\n",
      "[457/00067] train_loss: 0.020347\n",
      "[457/00117] train_loss: 0.017989\n",
      "[457/00167] train_loss: 0.016089\n",
      "[457/00217] train_loss: 0.015507\n",
      "[457/00267] train_loss: 0.015720\n",
      "[457/00317] train_loss: 0.015941\n",
      "[457/00367] train_loss: 0.015383\n",
      "[457/00417] train_loss: 0.015196\n",
      "[457/00467] train_loss: 0.016666\n",
      "[457/00517] train_loss: 0.016115\n",
      "[457/00567] train_loss: 0.015514\n",
      "[457/00617] train_loss: 0.015267\n",
      "[457/00667] train_loss: 0.016051\n",
      "[457/00717] train_loss: 0.015312\n",
      "[457/00767] train_loss: 0.017018\n",
      "[457/00817] train_loss: 0.016440\n",
      "[457/00867] train_loss: 0.016026\n",
      "[457/00917] train_loss: 0.014898\n",
      "[457/00967] train_loss: 0.016584\n",
      "[457/01017] train_loss: 0.015436\n",
      "[457/01067] train_loss: 0.016717\n",
      "[457/01117] train_loss: 0.014969\n",
      "[457/01167] train_loss: 0.015549\n",
      "[457/01217] train_loss: 0.016525\n",
      "[458/00041] train_loss: 0.020835\n",
      "[458/00091] train_loss: 0.019095\n",
      "[458/00141] train_loss: 0.016294\n",
      "[458/00191] train_loss: 0.016294\n",
      "[458/00241] train_loss: 0.015909\n",
      "[458/00291] train_loss: 0.016152\n",
      "[458/00341] train_loss: 0.015426\n",
      "[458/00391] train_loss: 0.015171\n",
      "[458/00441] train_loss: 0.015583\n",
      "[458/00491] train_loss: 0.015634\n",
      "[458/00541] train_loss: 0.015239\n",
      "[458/00591] train_loss: 0.015126\n",
      "[458/00641] train_loss: 0.015516\n",
      "[458/00691] train_loss: 0.015747\n",
      "[458/00741] train_loss: 0.015341\n",
      "[458/00791] train_loss: 0.015637\n",
      "[458/00841] train_loss: 0.015527\n",
      "[458/00891] train_loss: 0.015399\n",
      "[458/00941] train_loss: 0.015738\n",
      "[458/00991] train_loss: 0.015778\n",
      "[458/01041] train_loss: 0.016076\n",
      "[458/01091] train_loss: 0.016422\n",
      "[458/01141] train_loss: 0.016302\n",
      "[458/01191] train_loss: 0.016097\n",
      "[459/00015] train_loss: 0.018809\n",
      "[459/00065] train_loss: 0.019684\n",
      "[459/00115] train_loss: 0.017060\n",
      "[459/00165] train_loss: 0.016409\n",
      "[459/00215] train_loss: 0.015141\n",
      "[459/00265] train_loss: 0.017132\n",
      "[459/00315] train_loss: 0.015309\n",
      "[459/00365] train_loss: 0.015239\n",
      "[459/00415] train_loss: 0.015799\n",
      "[459/00465] train_loss: 0.016070\n",
      "[459/00515] train_loss: 0.015001\n",
      "[459/00565] train_loss: 0.016753\n",
      "[459/00615] train_loss: 0.014622\n",
      "[459/00665] train_loss: 0.016673\n",
      "[459/00715] train_loss: 0.016437\n",
      "[459/00765] train_loss: 0.014773\n",
      "[459/00815] train_loss: 0.014960\n",
      "[459/00865] train_loss: 0.016411\n",
      "[459/00915] train_loss: 0.014610\n",
      "[459/00965] train_loss: 0.015456\n",
      "[459/01015] train_loss: 0.015294\n",
      "[459/01065] train_loss: 0.015391\n",
      "[459/01115] train_loss: 0.016370\n",
      "[459/01165] train_loss: 0.015477\n",
      "[459/01215] train_loss: 0.016379\n",
      "[460/00039] train_loss: 0.021188\n",
      "[460/00089] train_loss: 0.018798\n",
      "[460/00139] train_loss: 0.017478\n",
      "[460/00189] train_loss: 0.014987\n",
      "[460/00239] train_loss: 0.015405\n",
      "[460/00289] train_loss: 0.015896\n",
      "[460/00339] train_loss: 0.016590\n",
      "[460/00389] train_loss: 0.015297\n",
      "[460/00439] train_loss: 0.015090\n",
      "[460/00489] train_loss: 0.015621\n",
      "[460/00539] train_loss: 0.015132\n",
      "[460/00589] train_loss: 0.015429\n",
      "[460/00639] train_loss: 0.015159\n",
      "[460/00689] train_loss: 0.016295\n",
      "[460/00739] train_loss: 0.014758\n",
      "[460/00789] train_loss: 0.015449\n",
      "[460/00839] train_loss: 0.015657\n",
      "[460/00889] train_loss: 0.016146\n",
      "[460/00939] train_loss: 0.015349\n",
      "[460/00989] train_loss: 0.014934\n",
      "[460/01039] train_loss: 0.015749\n",
      "[460/01089] train_loss: 0.017300\n",
      "[460/01139] train_loss: 0.015797\n",
      "[460/01189] train_loss: 0.016402\n",
      "[461/00013] train_loss: 0.017813\n",
      "[461/00063] train_loss: 0.019342\n",
      "[461/00113] train_loss: 0.016602\n",
      "[461/00163] train_loss: 0.016063\n",
      "[461/00213] train_loss: 0.016156\n",
      "[461/00263] train_loss: 0.016347\n",
      "[461/00313] train_loss: 0.015373\n",
      "[461/00363] train_loss: 0.016550\n",
      "[461/00413] train_loss: 0.015632\n",
      "[461/00463] train_loss: 0.015951\n",
      "[461/00513] train_loss: 0.015046\n",
      "[461/00563] train_loss: 0.015064\n",
      "[461/00613] train_loss: 0.015146\n",
      "[461/00663] train_loss: 0.016086\n",
      "[461/00713] train_loss: 0.016297\n",
      "[461/00763] train_loss: 0.015216\n",
      "[461/00813] train_loss: 0.015470\n",
      "[461/00863] train_loss: 0.014957\n",
      "[461/00913] train_loss: 0.015790\n",
      "[461/00963] train_loss: 0.015964\n",
      "[461/01013] train_loss: 0.015393\n",
      "[461/01063] train_loss: 0.015641\n",
      "[461/01113] train_loss: 0.016688\n",
      "[461/01163] train_loss: 0.016053\n",
      "[461/01213] train_loss: 0.016850\n",
      "[462/00037] train_loss: 0.020972\n",
      "[462/00087] train_loss: 0.018404\n",
      "[462/00137] train_loss: 0.016468\n",
      "[462/00187] train_loss: 0.015857\n",
      "[462/00237] train_loss: 0.015711\n",
      "[462/00287] train_loss: 0.016530\n",
      "[462/00337] train_loss: 0.016303\n",
      "[462/00387] train_loss: 0.015476\n",
      "[462/00437] train_loss: 0.015430\n",
      "[462/00487] train_loss: 0.014911\n",
      "[462/00537] train_loss: 0.015679\n",
      "[462/00587] train_loss: 0.015819\n",
      "[462/00637] train_loss: 0.015512\n",
      "[462/00687] train_loss: 0.015922\n",
      "[462/00737] train_loss: 0.016202\n",
      "[462/00787] train_loss: 0.015672\n",
      "[462/00837] train_loss: 0.015212\n",
      "[462/00887] train_loss: 0.016027\n",
      "[462/00937] train_loss: 0.015226\n",
      "[462/00987] train_loss: 0.017013\n",
      "[462/01037] train_loss: 0.015147\n",
      "[462/01087] train_loss: 0.015716\n",
      "[462/01137] train_loss: 0.015659\n",
      "[462/01187] train_loss: 0.015833\n",
      "[463/00011] train_loss: 0.018382\n",
      "[463/00061] train_loss: 0.020343\n",
      "[463/00111] train_loss: 0.017107\n",
      "[463/00161] train_loss: 0.015456\n",
      "[463/00211] train_loss: 0.015918\n",
      "[463/00261] train_loss: 0.015394\n",
      "[463/00311] train_loss: 0.014756\n",
      "[463/00361] train_loss: 0.015860\n",
      "[463/00411] train_loss: 0.015187\n",
      "[463/00461] train_loss: 0.015227\n",
      "[463/00511] train_loss: 0.016022\n",
      "[463/00561] train_loss: 0.014576\n",
      "[463/00611] train_loss: 0.015486\n",
      "[463/00661] train_loss: 0.016038\n",
      "[463/00711] train_loss: 0.015932\n",
      "[463/00761] train_loss: 0.015685\n",
      "[463/00811] train_loss: 0.016061\n",
      "[463/00861] train_loss: 0.016571\n",
      "[463/00911] train_loss: 0.016367\n",
      "[463/00961] train_loss: 0.015955\n",
      "[463/01011] train_loss: 0.015665\n",
      "[463/01061] train_loss: 0.015905\n",
      "[463/01111] train_loss: 0.016195\n",
      "[463/01161] train_loss: 0.015672\n",
      "[463/01211] train_loss: 0.016382\n",
      "[464/00035] train_loss: 0.019414\n",
      "[464/00085] train_loss: 0.017690\n",
      "[464/00135] train_loss: 0.015739\n",
      "[464/00185] train_loss: 0.015614\n",
      "[464/00235] train_loss: 0.015828\n",
      "[464/00285] train_loss: 0.016370\n",
      "[464/00335] train_loss: 0.016080\n",
      "[464/00385] train_loss: 0.015653\n",
      "[464/00435] train_loss: 0.015745\n",
      "[464/00485] train_loss: 0.016613\n",
      "[464/00535] train_loss: 0.016352\n",
      "[464/00585] train_loss: 0.015528\n",
      "[464/00635] train_loss: 0.016396\n",
      "[464/00685] train_loss: 0.015573\n",
      "[464/00735] train_loss: 0.016098\n",
      "[464/00785] train_loss: 0.015436\n",
      "[464/00835] train_loss: 0.016172\n",
      "[464/00885] train_loss: 0.015247\n",
      "[464/00935] train_loss: 0.015991\n",
      "[464/00985] train_loss: 0.016149\n",
      "[464/01035] train_loss: 0.015623\n",
      "[464/01085] train_loss: 0.015018\n",
      "[464/01135] train_loss: 0.016041\n",
      "[464/01185] train_loss: 0.015978\n",
      "[465/00009] train_loss: 0.017296\n",
      "[465/00059] train_loss: 0.020276\n",
      "[465/00109] train_loss: 0.016839\n",
      "[465/00159] train_loss: 0.015689\n",
      "[465/00209] train_loss: 0.015862\n",
      "[465/00259] train_loss: 0.016146\n",
      "[465/00309] train_loss: 0.015607\n",
      "[465/00359] train_loss: 0.016442\n",
      "[465/00409] train_loss: 0.016010\n",
      "[465/00459] train_loss: 0.015977\n",
      "[465/00509] train_loss: 0.015789\n",
      "[465/00559] train_loss: 0.015557\n",
      "[465/00609] train_loss: 0.015258\n",
      "[465/00659] train_loss: 0.015908\n",
      "[465/00709] train_loss: 0.015719\n",
      "[465/00759] train_loss: 0.014984\n",
      "[465/00809] train_loss: 0.015586\n",
      "[465/00859] train_loss: 0.016068\n",
      "[465/00909] train_loss: 0.015986\n",
      "[465/00959] train_loss: 0.015976\n",
      "[465/01009] train_loss: 0.016582\n",
      "[465/01059] train_loss: 0.015361\n",
      "[465/01109] train_loss: 0.015791\n",
      "[465/01159] train_loss: 0.016548\n",
      "[465/01209] train_loss: 0.016278\n",
      "[466/00033] train_loss: 0.018377\n",
      "[466/00083] train_loss: 0.018718\n",
      "[466/00133] train_loss: 0.016895\n",
      "[466/00183] train_loss: 0.015965\n",
      "[466/00233] train_loss: 0.015331\n",
      "[466/00283] train_loss: 0.015681\n",
      "[466/00333] train_loss: 0.015755\n",
      "[466/00383] train_loss: 0.015164\n",
      "[466/00433] train_loss: 0.015513\n",
      "[466/00483] train_loss: 0.015945\n",
      "[466/00533] train_loss: 0.015990\n",
      "[466/00583] train_loss: 0.014721\n",
      "[466/00633] train_loss: 0.015303\n",
      "[466/00683] train_loss: 0.015535\n",
      "[466/00733] train_loss: 0.016211\n",
      "[466/00783] train_loss: 0.015838\n",
      "[466/00833] train_loss: 0.015712\n",
      "[466/00883] train_loss: 0.015335\n",
      "[466/00933] train_loss: 0.015414\n",
      "[466/00983] train_loss: 0.016097\n",
      "[466/01033] train_loss: 0.016164\n",
      "[466/01083] train_loss: 0.016541\n",
      "[466/01133] train_loss: 0.015548\n",
      "[466/01183] train_loss: 0.016509\n",
      "[467/00007] train_loss: 0.018074\n",
      "[467/00057] train_loss: 0.020141\n",
      "[467/00107] train_loss: 0.017834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[467/00157] train_loss: 0.016229\n",
      "[467/00207] train_loss: 0.015389\n",
      "[467/00257] train_loss: 0.015925\n",
      "[467/00307] train_loss: 0.016265\n",
      "[467/00357] train_loss: 0.014516\n",
      "[467/00407] train_loss: 0.015353\n",
      "[467/00457] train_loss: 0.014886\n",
      "[467/00507] train_loss: 0.014903\n",
      "[467/00557] train_loss: 0.016367\n",
      "[467/00607] train_loss: 0.015368\n",
      "[467/00657] train_loss: 0.015901\n",
      "[467/00707] train_loss: 0.015377\n",
      "[467/00757] train_loss: 0.015485\n",
      "[467/00807] train_loss: 0.015305\n",
      "[467/00857] train_loss: 0.016580\n",
      "[467/00907] train_loss: 0.015757\n",
      "[467/00957] train_loss: 0.016302\n",
      "[467/01007] train_loss: 0.015571\n",
      "[467/01057] train_loss: 0.016522\n",
      "[467/01107] train_loss: 0.016572\n",
      "[467/01157] train_loss: 0.015003\n",
      "[467/01207] train_loss: 0.016673\n",
      "[468/00031] train_loss: 0.019417\n",
      "[468/00081] train_loss: 0.018103\n",
      "[468/00131] train_loss: 0.016609\n",
      "[468/00181] train_loss: 0.016361\n",
      "[468/00231] train_loss: 0.015714\n",
      "[468/00281] train_loss: 0.015771\n",
      "[468/00331] train_loss: 0.015650\n",
      "[468/00381] train_loss: 0.016388\n",
      "[468/00431] train_loss: 0.015640\n",
      "[468/00481] train_loss: 0.015445\n",
      "[468/00531] train_loss: 0.015067\n",
      "[468/00581] train_loss: 0.016071\n",
      "[468/00631] train_loss: 0.015137\n",
      "[468/00681] train_loss: 0.016047\n",
      "[468/00731] train_loss: 0.015292\n",
      "[468/00781] train_loss: 0.015618\n",
      "[468/00831] train_loss: 0.016474\n",
      "[468/00881] train_loss: 0.016168\n",
      "[468/00931] train_loss: 0.016549\n",
      "[468/00981] train_loss: 0.015247\n",
      "[468/01031] train_loss: 0.015879\n",
      "[468/01081] train_loss: 0.015734\n",
      "[468/01131] train_loss: 0.015960\n",
      "[468/01181] train_loss: 0.016082\n",
      "[469/00005] train_loss: 0.016649\n",
      "[469/00055] train_loss: 0.019964\n",
      "[469/00105] train_loss: 0.018151\n",
      "[469/00155] train_loss: 0.016535\n",
      "[469/00205] train_loss: 0.017002\n",
      "[469/00255] train_loss: 0.016179\n",
      "[469/00305] train_loss: 0.016418\n",
      "[469/00355] train_loss: 0.015550\n",
      "[469/00405] train_loss: 0.015365\n",
      "[469/00455] train_loss: 0.016064\n",
      "[469/00505] train_loss: 0.015786\n",
      "[469/00555] train_loss: 0.015534\n",
      "[469/00605] train_loss: 0.014879\n",
      "[469/00655] train_loss: 0.014982\n",
      "[469/00705] train_loss: 0.015772\n",
      "[469/00755] train_loss: 0.015824\n",
      "[469/00805] train_loss: 0.015557\n",
      "[469/00855] train_loss: 0.014939\n",
      "[469/00905] train_loss: 0.015941\n",
      "[469/00955] train_loss: 0.015495\n",
      "[469/01005] train_loss: 0.015303\n",
      "[469/01055] train_loss: 0.016087\n",
      "[469/01105] train_loss: 0.015944\n",
      "[469/01155] train_loss: 0.016451\n",
      "[469/01205] train_loss: 0.016585\n",
      "[470/00029] train_loss: 0.019807\n",
      "[470/00079] train_loss: 0.018733\n",
      "[470/00129] train_loss: 0.016922\n",
      "[470/00179] train_loss: 0.015674\n",
      "[470/00229] train_loss: 0.015100\n",
      "[470/00279] train_loss: 0.015439\n",
      "[470/00329] train_loss: 0.016021\n",
      "[470/00379] train_loss: 0.016302\n",
      "[470/00429] train_loss: 0.015539\n",
      "[470/00479] train_loss: 0.015586\n",
      "[470/00529] train_loss: 0.015823\n",
      "[470/00579] train_loss: 0.015522\n",
      "[470/00629] train_loss: 0.015528\n",
      "[470/00679] train_loss: 0.016669\n",
      "[470/00729] train_loss: 0.015449\n",
      "[470/00779] train_loss: 0.015227\n",
      "[470/00829] train_loss: 0.015420\n",
      "[470/00879] train_loss: 0.016034\n",
      "[470/00929] train_loss: 0.015984\n",
      "[470/00979] train_loss: 0.016270\n",
      "[470/01029] train_loss: 0.015565\n",
      "[470/01079] train_loss: 0.015494\n",
      "[470/01129] train_loss: 0.015539\n",
      "[470/01179] train_loss: 0.015961\n",
      "[471/00003] train_loss: 0.017524\n",
      "[471/00053] train_loss: 0.019458\n",
      "[471/00103] train_loss: 0.018715\n",
      "[471/00153] train_loss: 0.015998\n",
      "[471/00203] train_loss: 0.016626\n",
      "[471/00253] train_loss: 0.015312\n",
      "[471/00303] train_loss: 0.015515\n",
      "[471/00353] train_loss: 0.014897\n",
      "[471/00403] train_loss: 0.015787\n",
      "[471/00453] train_loss: 0.016100\n",
      "[471/00503] train_loss: 0.015192\n",
      "[471/00553] train_loss: 0.015993\n",
      "[471/00603] train_loss: 0.015444\n",
      "[471/00653] train_loss: 0.015402\n",
      "[471/00703] train_loss: 0.016114\n",
      "[471/00753] train_loss: 0.014832\n",
      "[471/00803] train_loss: 0.015227\n",
      "[471/00853] train_loss: 0.015691\n",
      "[471/00903] train_loss: 0.016119\n",
      "[471/00953] train_loss: 0.015253\n",
      "[471/01003] train_loss: 0.015088\n",
      "[471/01053] train_loss: 0.015443\n",
      "[471/01103] train_loss: 0.015796\n",
      "[471/01153] train_loss: 0.015405\n",
      "[471/01203] train_loss: 0.016224\n",
      "[472/00027] train_loss: 0.019584\n",
      "[472/00077] train_loss: 0.020110\n",
      "[472/00127] train_loss: 0.017165\n",
      "[472/00177] train_loss: 0.016642\n",
      "[472/00227] train_loss: 0.015516\n",
      "[472/00277] train_loss: 0.016064\n",
      "[472/00327] train_loss: 0.015757\n",
      "[472/00377] train_loss: 0.015928\n",
      "[472/00427] train_loss: 0.015800\n",
      "[472/00477] train_loss: 0.016489\n",
      "[472/00527] train_loss: 0.015086\n",
      "[472/00577] train_loss: 0.014729\n",
      "[472/00627] train_loss: 0.016209\n",
      "[472/00677] train_loss: 0.015577\n",
      "[472/00727] train_loss: 0.015883\n",
      "[472/00777] train_loss: 0.015639\n",
      "[472/00827] train_loss: 0.015995\n",
      "[472/00877] train_loss: 0.016204\n",
      "[472/00927] train_loss: 0.016158\n",
      "[472/00977] train_loss: 0.015691\n",
      "[472/01027] train_loss: 0.016275\n",
      "[472/01077] train_loss: 0.015632\n",
      "[472/01127] train_loss: 0.016345\n",
      "[472/01177] train_loss: 0.015056\n",
      "[473/00001] train_loss: 0.016570\n",
      "[473/00051] train_loss: 0.021304\n",
      "[473/00101] train_loss: 0.018361\n",
      "[473/00151] train_loss: 0.016061\n",
      "[473/00201] train_loss: 0.015687\n",
      "[473/00251] train_loss: 0.014734\n",
      "[473/00301] train_loss: 0.015475\n",
      "[473/00351] train_loss: 0.016211\n",
      "[473/00401] train_loss: 0.016545\n",
      "[473/00451] train_loss: 0.014719\n",
      "[473/00501] train_loss: 0.015924\n",
      "[473/00551] train_loss: 0.015776\n",
      "[473/00601] train_loss: 0.015912\n",
      "[473/00651] train_loss: 0.016045\n",
      "[473/00701] train_loss: 0.015640\n",
      "[473/00751] train_loss: 0.015560\n",
      "[473/00801] train_loss: 0.016210\n",
      "[473/00851] train_loss: 0.014732\n",
      "[473/00901] train_loss: 0.015759\n",
      "[473/00951] train_loss: 0.016091\n",
      "[473/01001] train_loss: 0.015207\n",
      "[473/01051] train_loss: 0.016350\n",
      "[473/01101] train_loss: 0.015966\n",
      "[473/01151] train_loss: 0.016496\n",
      "[473/01201] train_loss: 0.015859\n",
      "[474/00025] train_loss: 0.020235\n",
      "[474/00075] train_loss: 0.018663\n",
      "[474/00125] train_loss: 0.017130\n",
      "[474/00175] train_loss: 0.015959\n",
      "[474/00225] train_loss: 0.017119\n",
      "[474/00275] train_loss: 0.015956\n",
      "[474/00325] train_loss: 0.015453\n",
      "[474/00375] train_loss: 0.015160\n",
      "[474/00425] train_loss: 0.016097\n",
      "[474/00475] train_loss: 0.015469\n",
      "[474/00525] train_loss: 0.016192\n",
      "[474/00575] train_loss: 0.016438\n",
      "[474/00625] train_loss: 0.014706\n",
      "[474/00675] train_loss: 0.015520\n",
      "[474/00725] train_loss: 0.015531\n",
      "[474/00775] train_loss: 0.016029\n",
      "[474/00825] train_loss: 0.015580\n",
      "[474/00875] train_loss: 0.015954\n",
      "[474/00925] train_loss: 0.015537\n",
      "[474/00975] train_loss: 0.015958\n",
      "[474/01025] train_loss: 0.015237\n",
      "[474/01075] train_loss: 0.015872\n",
      "[474/01125] train_loss: 0.015336\n",
      "[474/01175] train_loss: 0.016300\n",
      "[474/01225] train_loss: 0.015901\n",
      "[475/00049] train_loss: 0.022148\n",
      "[475/00099] train_loss: 0.017229\n",
      "[475/00149] train_loss: 0.017108\n",
      "[475/00199] train_loss: 0.016884\n",
      "[475/00249] train_loss: 0.015895\n",
      "[475/00299] train_loss: 0.015773\n",
      "[475/00349] train_loss: 0.016118\n",
      "[475/00399] train_loss: 0.014820\n",
      "[475/00449] train_loss: 0.015997\n",
      "[475/00499] train_loss: 0.015703\n",
      "[475/00549] train_loss: 0.016359\n",
      "[475/00599] train_loss: 0.015979\n",
      "[475/00649] train_loss: 0.015806\n",
      "[475/00699] train_loss: 0.015329\n",
      "[475/00749] train_loss: 0.014982\n",
      "[475/00799] train_loss: 0.015966\n",
      "[475/00849] train_loss: 0.016334\n",
      "[475/00899] train_loss: 0.016215\n",
      "[475/00949] train_loss: 0.015523\n",
      "[475/00999] train_loss: 0.015932\n",
      "[475/01049] train_loss: 0.016193\n",
      "[475/01099] train_loss: 0.015073\n",
      "[475/01149] train_loss: 0.015717\n",
      "[475/01199] train_loss: 0.017069\n",
      "[476/00023] train_loss: 0.018291\n",
      "[476/00073] train_loss: 0.019053\n",
      "[476/00123] train_loss: 0.016822\n",
      "[476/00173] train_loss: 0.015983\n",
      "[476/00223] train_loss: 0.014382\n",
      "[476/00273] train_loss: 0.016480\n",
      "[476/00323] train_loss: 0.016273\n",
      "[476/00373] train_loss: 0.015011\n",
      "[476/00423] train_loss: 0.016787\n",
      "[476/00473] train_loss: 0.014638\n",
      "[476/00523] train_loss: 0.016006\n",
      "[476/00573] train_loss: 0.016543\n",
      "[476/00623] train_loss: 0.015690\n",
      "[476/00673] train_loss: 0.016595\n",
      "[476/00723] train_loss: 0.016144\n",
      "[476/00773] train_loss: 0.015741\n",
      "[476/00823] train_loss: 0.015082\n",
      "[476/00873] train_loss: 0.016534\n",
      "[476/00923] train_loss: 0.015942\n",
      "[476/00973] train_loss: 0.016087\n",
      "[476/01023] train_loss: 0.014812\n",
      "[476/01073] train_loss: 0.016390\n",
      "[476/01123] train_loss: 0.016361\n",
      "[476/01173] train_loss: 0.015960\n",
      "[476/01223] train_loss: 0.015301\n",
      "[477/00047] train_loss: 0.021050\n",
      "[477/00097] train_loss: 0.019103\n",
      "[477/00147] train_loss: 0.016150\n",
      "[477/00197] train_loss: 0.016515\n",
      "[477/00247] train_loss: 0.015741\n",
      "[477/00297] train_loss: 0.016682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477/00347] train_loss: 0.016158\n",
      "[477/00397] train_loss: 0.015330\n",
      "[477/00447] train_loss: 0.015777\n",
      "[477/00497] train_loss: 0.015396\n",
      "[477/00547] train_loss: 0.015817\n",
      "[477/00597] train_loss: 0.015741\n",
      "[477/00647] train_loss: 0.015680\n",
      "[477/00697] train_loss: 0.016114\n",
      "[477/00747] train_loss: 0.016226\n",
      "[477/00797] train_loss: 0.015526\n",
      "[477/00847] train_loss: 0.015120\n",
      "[477/00897] train_loss: 0.015605\n",
      "[477/00947] train_loss: 0.016338\n",
      "[477/00997] train_loss: 0.016455\n",
      "[477/01047] train_loss: 0.015497\n",
      "[477/01097] train_loss: 0.015578\n",
      "[477/01147] train_loss: 0.015461\n",
      "[477/01197] train_loss: 0.016222\n",
      "[478/00021] train_loss: 0.018525\n",
      "[478/00071] train_loss: 0.019506\n",
      "[478/00121] train_loss: 0.017273\n",
      "[478/00171] train_loss: 0.016868\n",
      "[478/00221] train_loss: 0.014672\n",
      "[478/00271] train_loss: 0.015922\n",
      "[478/00321] train_loss: 0.015592\n",
      "[478/00371] train_loss: 0.015237\n",
      "[478/00421] train_loss: 0.015579\n",
      "[478/00471] train_loss: 0.015767\n",
      "[478/00521] train_loss: 0.015548\n",
      "[478/00571] train_loss: 0.015503\n",
      "[478/00621] train_loss: 0.015056\n",
      "[478/00671] train_loss: 0.015545\n",
      "[478/00721] train_loss: 0.015099\n",
      "[478/00771] train_loss: 0.015424\n",
      "[478/00821] train_loss: 0.016022\n",
      "[478/00871] train_loss: 0.015272\n",
      "[478/00921] train_loss: 0.015678\n",
      "[478/00971] train_loss: 0.015725\n",
      "[478/01021] train_loss: 0.015343\n",
      "[478/01071] train_loss: 0.016121\n",
      "[478/01121] train_loss: 0.015422\n",
      "[478/01171] train_loss: 0.015331\n",
      "[478/01221] train_loss: 0.015995\n",
      "[479/00045] train_loss: 0.020649\n",
      "[479/00095] train_loss: 0.018021\n",
      "[479/00145] train_loss: 0.015861\n",
      "[479/00195] train_loss: 0.016578\n",
      "[479/00245] train_loss: 0.015917\n",
      "[479/00295] train_loss: 0.015262\n",
      "[479/00345] train_loss: 0.014946\n",
      "[479/00395] train_loss: 0.015457\n",
      "[479/00445] train_loss: 0.015752\n",
      "[479/00495] train_loss: 0.016187\n",
      "[479/00545] train_loss: 0.015618\n",
      "[479/00595] train_loss: 0.015356\n",
      "[479/00645] train_loss: 0.015708\n",
      "[479/00695] train_loss: 0.015823\n",
      "[479/00745] train_loss: 0.015335\n",
      "[479/00795] train_loss: 0.016921\n",
      "[479/00845] train_loss: 0.015210\n",
      "[479/00895] train_loss: 0.015135\n",
      "[479/00945] train_loss: 0.015804\n",
      "[479/00995] train_loss: 0.015666\n",
      "[479/01045] train_loss: 0.015753\n",
      "[479/01095] train_loss: 0.015778\n",
      "[479/01145] train_loss: 0.015914\n",
      "[479/01195] train_loss: 0.016274\n",
      "[480/00019] train_loss: 0.018316\n",
      "[480/00069] train_loss: 0.020457\n",
      "[480/00119] train_loss: 0.017421\n",
      "[480/00169] train_loss: 0.016233\n",
      "[480/00219] train_loss: 0.016779\n",
      "[480/00269] train_loss: 0.016433\n",
      "[480/00319] train_loss: 0.015040\n",
      "[480/00369] train_loss: 0.015677\n",
      "[480/00419] train_loss: 0.015742\n",
      "[480/00469] train_loss: 0.016025\n",
      "[480/00519] train_loss: 0.015161\n",
      "[480/00569] train_loss: 0.015564\n",
      "[480/00619] train_loss: 0.016005\n",
      "[480/00669] train_loss: 0.015099\n",
      "[480/00719] train_loss: 0.015817\n",
      "[480/00769] train_loss: 0.015847\n",
      "[480/00819] train_loss: 0.016227\n",
      "[480/00869] train_loss: 0.016286\n",
      "[480/00919] train_loss: 0.016004\n",
      "[480/00969] train_loss: 0.016357\n",
      "[480/01019] train_loss: 0.015798\n",
      "[480/01069] train_loss: 0.016113\n",
      "[480/01119] train_loss: 0.016162\n",
      "[480/01169] train_loss: 0.016985\n",
      "[480/01219] train_loss: 0.016195\n",
      "[481/00043] train_loss: 0.020672\n",
      "[481/00093] train_loss: 0.017891\n",
      "[481/00143] train_loss: 0.016559\n",
      "[481/00193] train_loss: 0.016019\n",
      "[481/00243] train_loss: 0.015883\n",
      "[481/00293] train_loss: 0.016035\n",
      "[481/00343] train_loss: 0.015704\n",
      "[481/00393] train_loss: 0.015437\n",
      "[481/00443] train_loss: 0.015697\n",
      "[481/00493] train_loss: 0.015430\n",
      "[481/00543] train_loss: 0.015092\n",
      "[481/00593] train_loss: 0.014583\n",
      "[481/00643] train_loss: 0.016064\n",
      "[481/00693] train_loss: 0.015578\n",
      "[481/00743] train_loss: 0.015438\n",
      "[481/00793] train_loss: 0.014382\n",
      "[481/00843] train_loss: 0.015504\n",
      "[481/00893] train_loss: 0.015263\n",
      "[481/00943] train_loss: 0.015971\n",
      "[481/00993] train_loss: 0.016083\n",
      "[481/01043] train_loss: 0.016066\n",
      "[481/01093] train_loss: 0.016029\n",
      "[481/01143] train_loss: 0.015569\n",
      "[481/01193] train_loss: 0.016008\n",
      "[482/00017] train_loss: 0.018079\n",
      "[482/00067] train_loss: 0.020568\n",
      "[482/00117] train_loss: 0.017808\n",
      "[482/00167] train_loss: 0.015627\n",
      "[482/00217] train_loss: 0.015692\n",
      "[482/00267] train_loss: 0.016177\n",
      "[482/00317] train_loss: 0.015779\n",
      "[482/00367] train_loss: 0.014942\n",
      "[482/00417] train_loss: 0.015611\n",
      "[482/00467] train_loss: 0.015478\n",
      "[482/00517] train_loss: 0.015070\n",
      "[482/00567] train_loss: 0.015420\n",
      "[482/00617] train_loss: 0.015476\n",
      "[482/00667] train_loss: 0.015596\n",
      "[482/00717] train_loss: 0.015252\n",
      "[482/00767] train_loss: 0.016475\n",
      "[482/00817] train_loss: 0.016080\n",
      "[482/00867] train_loss: 0.014621\n",
      "[482/00917] train_loss: 0.015107\n",
      "[482/00967] train_loss: 0.016632\n",
      "[482/01017] train_loss: 0.015648\n",
      "[482/01067] train_loss: 0.015822\n",
      "[482/01117] train_loss: 0.016174\n",
      "[482/01167] train_loss: 0.015751\n",
      "[482/01217] train_loss: 0.015409\n",
      "[483/00041] train_loss: 0.020605\n",
      "[483/00091] train_loss: 0.018122\n",
      "[483/00141] train_loss: 0.016161\n",
      "[483/00191] train_loss: 0.015826\n",
      "[483/00241] train_loss: 0.016025\n",
      "[483/00291] train_loss: 0.015768\n",
      "[483/00341] train_loss: 0.015660\n",
      "[483/00391] train_loss: 0.015413\n",
      "[483/00441] train_loss: 0.015111\n",
      "[483/00491] train_loss: 0.015640\n",
      "[483/00541] train_loss: 0.015469\n",
      "[483/00591] train_loss: 0.016352\n",
      "[483/00641] train_loss: 0.015880\n",
      "[483/00691] train_loss: 0.015965\n",
      "[483/00741] train_loss: 0.015016\n",
      "[483/00791] train_loss: 0.014897\n",
      "[483/00841] train_loss: 0.016552\n",
      "[483/00891] train_loss: 0.016375\n",
      "[483/00941] train_loss: 0.016494\n",
      "[483/00991] train_loss: 0.015547\n",
      "[483/01041] train_loss: 0.015627\n",
      "[483/01091] train_loss: 0.016255\n",
      "[483/01141] train_loss: 0.015700\n",
      "[483/01191] train_loss: 0.016042\n",
      "[484/00015] train_loss: 0.018393\n",
      "[484/00065] train_loss: 0.019030\n",
      "[484/00115] train_loss: 0.017170\n",
      "[484/00165] train_loss: 0.016748\n",
      "[484/00215] train_loss: 0.015883\n",
      "[484/00265] train_loss: 0.016367\n",
      "[484/00315] train_loss: 0.015256\n",
      "[484/00365] train_loss: 0.015500\n",
      "[484/00415] train_loss: 0.014689\n",
      "[484/00465] train_loss: 0.015214\n",
      "[484/00515] train_loss: 0.015119\n",
      "[484/00565] train_loss: 0.015247\n",
      "[484/00615] train_loss: 0.015041\n",
      "[484/00665] train_loss: 0.015990\n",
      "[484/00715] train_loss: 0.015510\n",
      "[484/00765] train_loss: 0.015703\n",
      "[484/00815] train_loss: 0.016173\n",
      "[484/00865] train_loss: 0.016639\n",
      "[484/00915] train_loss: 0.016086\n",
      "[484/00965] train_loss: 0.016052\n",
      "[484/01015] train_loss: 0.016174\n",
      "[484/01065] train_loss: 0.015165\n",
      "[484/01115] train_loss: 0.015947\n",
      "[484/01165] train_loss: 0.016230\n",
      "[484/01215] train_loss: 0.015988\n",
      "[485/00039] train_loss: 0.020248\n",
      "[485/00089] train_loss: 0.018652\n",
      "[485/00139] train_loss: 0.016034\n",
      "[485/00189] train_loss: 0.015653\n",
      "[485/00239] train_loss: 0.015602\n",
      "[485/00289] train_loss: 0.015073\n",
      "[485/00339] train_loss: 0.015222\n",
      "[485/00389] train_loss: 0.016433\n",
      "[485/00439] train_loss: 0.015013\n",
      "[485/00489] train_loss: 0.014799\n",
      "[485/00539] train_loss: 0.015303\n",
      "[485/00589] train_loss: 0.014489\n",
      "[485/00639] train_loss: 0.016768\n",
      "[485/00689] train_loss: 0.016369\n",
      "[485/00739] train_loss: 0.015216\n",
      "[485/00789] train_loss: 0.015464\n",
      "[485/00839] train_loss: 0.016531\n",
      "[485/00889] train_loss: 0.016352\n",
      "[485/00939] train_loss: 0.015843\n",
      "[485/00989] train_loss: 0.016413\n",
      "[485/01039] train_loss: 0.015984\n",
      "[485/01089] train_loss: 0.015859\n",
      "[485/01139] train_loss: 0.016476\n",
      "[485/01189] train_loss: 0.015410\n",
      "[486/00013] train_loss: 0.018560\n",
      "[486/00063] train_loss: 0.020158\n",
      "[486/00113] train_loss: 0.017279\n",
      "[486/00163] train_loss: 0.016082\n",
      "[486/00213] train_loss: 0.015989\n",
      "[486/00263] train_loss: 0.015029\n",
      "[486/00313] train_loss: 0.015198\n",
      "[486/00363] train_loss: 0.015483\n",
      "[486/00413] train_loss: 0.015696\n",
      "[486/00463] train_loss: 0.015371\n",
      "[486/00513] train_loss: 0.015862\n",
      "[486/00563] train_loss: 0.015677\n",
      "[486/00613] train_loss: 0.015480\n",
      "[486/00663] train_loss: 0.015343\n",
      "[486/00713] train_loss: 0.016637\n",
      "[486/00763] train_loss: 0.015898\n",
      "[486/00813] train_loss: 0.014686\n",
      "[486/00863] train_loss: 0.015441\n",
      "[486/00913] train_loss: 0.015388\n",
      "[486/00963] train_loss: 0.016306\n",
      "[486/01013] train_loss: 0.015670\n",
      "[486/01063] train_loss: 0.016333\n",
      "[486/01113] train_loss: 0.015701\n",
      "[486/01163] train_loss: 0.016122\n",
      "[486/01213] train_loss: 0.015903\n",
      "[487/00037] train_loss: 0.019569\n",
      "[487/00087] train_loss: 0.017167\n",
      "[487/00137] train_loss: 0.016076\n",
      "[487/00187] train_loss: 0.015870\n",
      "[487/00237] train_loss: 0.015441\n",
      "[487/00287] train_loss: 0.016121\n",
      "[487/00337] train_loss: 0.015470\n",
      "[487/00387] train_loss: 0.015545\n",
      "[487/00437] train_loss: 0.015888\n",
      "[487/00487] train_loss: 0.015623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487/00537] train_loss: 0.015510\n",
      "[487/00587] train_loss: 0.015548\n",
      "[487/00637] train_loss: 0.015757\n",
      "[487/00687] train_loss: 0.015921\n",
      "[487/00737] train_loss: 0.015774\n",
      "[487/00787] train_loss: 0.015947\n",
      "[487/00837] train_loss: 0.014891\n",
      "[487/00887] train_loss: 0.016077\n",
      "[487/00937] train_loss: 0.015032\n",
      "[487/00987] train_loss: 0.015250\n",
      "[487/01037] train_loss: 0.016247\n",
      "[487/01087] train_loss: 0.015993\n",
      "[487/01137] train_loss: 0.015957\n",
      "[487/01187] train_loss: 0.016123\n",
      "[488/00011] train_loss: 0.017860\n",
      "[488/00061] train_loss: 0.019603\n",
      "[488/00111] train_loss: 0.017730\n",
      "[488/00161] train_loss: 0.016874\n",
      "[488/00211] train_loss: 0.017059\n",
      "[488/00261] train_loss: 0.015131\n",
      "[488/00311] train_loss: 0.015492\n",
      "[488/00361] train_loss: 0.015567\n",
      "[488/00411] train_loss: 0.015062\n",
      "[488/00461] train_loss: 0.015144\n",
      "[488/00511] train_loss: 0.016264\n",
      "[488/00561] train_loss: 0.015246\n",
      "[488/00611] train_loss: 0.015265\n",
      "[488/00661] train_loss: 0.015663\n",
      "[488/00711] train_loss: 0.015585\n",
      "[488/00761] train_loss: 0.015874\n",
      "[488/00811] train_loss: 0.015555\n",
      "[488/00861] train_loss: 0.015762\n",
      "[488/00911] train_loss: 0.015170\n",
      "[488/00961] train_loss: 0.014687\n",
      "[488/01011] train_loss: 0.015819\n",
      "[488/01061] train_loss: 0.016773\n",
      "[488/01111] train_loss: 0.016264\n",
      "[488/01161] train_loss: 0.015815\n",
      "[488/01211] train_loss: 0.015977\n",
      "[489/00035] train_loss: 0.020056\n",
      "[489/00085] train_loss: 0.018536\n",
      "[489/00135] train_loss: 0.017043\n",
      "[489/00185] train_loss: 0.015197\n",
      "[489/00235] train_loss: 0.015632\n",
      "[489/00285] train_loss: 0.015169\n",
      "[489/00335] train_loss: 0.015290\n",
      "[489/00385] train_loss: 0.015929\n",
      "[489/00435] train_loss: 0.015703\n",
      "[489/00485] train_loss: 0.016110\n",
      "[489/00535] train_loss: 0.016232\n",
      "[489/00585] train_loss: 0.016006\n",
      "[489/00635] train_loss: 0.015564\n",
      "[489/00685] train_loss: 0.016138\n",
      "[489/00735] train_loss: 0.015113\n",
      "[489/00785] train_loss: 0.015294\n",
      "[489/00835] train_loss: 0.015371\n",
      "[489/00885] train_loss: 0.014855\n",
      "[489/00935] train_loss: 0.016839\n",
      "[489/00985] train_loss: 0.014961\n",
      "[489/01035] train_loss: 0.016151\n",
      "[489/01085] train_loss: 0.015299\n",
      "[489/01135] train_loss: 0.015847\n",
      "[489/01185] train_loss: 0.016767\n",
      "[490/00009] train_loss: 0.017634\n",
      "[490/00059] train_loss: 0.018990\n",
      "[490/00109] train_loss: 0.017409\n",
      "[490/00159] train_loss: 0.016450\n",
      "[490/00209] train_loss: 0.016338\n",
      "[490/00259] train_loss: 0.016052\n",
      "[490/00309] train_loss: 0.015379\n",
      "[490/00359] train_loss: 0.015614\n",
      "[490/00409] train_loss: 0.015598\n",
      "[490/00459] train_loss: 0.016309\n",
      "[490/00509] train_loss: 0.015259\n",
      "[490/00559] train_loss: 0.015394\n",
      "[490/00609] train_loss: 0.015721\n",
      "[490/00659] train_loss: 0.016161\n",
      "[490/00709] train_loss: 0.014513\n",
      "[490/00759] train_loss: 0.016114\n",
      "[490/00809] train_loss: 0.015868\n",
      "[490/00859] train_loss: 0.015955\n",
      "[490/00909] train_loss: 0.016162\n",
      "[490/00959] train_loss: 0.015605\n",
      "[490/01009] train_loss: 0.015315\n",
      "[490/01059] train_loss: 0.016261\n",
      "[490/01109] train_loss: 0.015343\n",
      "[490/01159] train_loss: 0.017301\n",
      "[490/01209] train_loss: 0.015744\n",
      "[491/00033] train_loss: 0.020798\n",
      "[491/00083] train_loss: 0.018466\n",
      "[491/00133] train_loss: 0.017276\n",
      "[491/00183] train_loss: 0.016072\n",
      "[491/00233] train_loss: 0.015967\n",
      "[491/00283] train_loss: 0.016166\n",
      "[491/00333] train_loss: 0.015229\n",
      "[491/00383] train_loss: 0.015698\n",
      "[491/00433] train_loss: 0.015863\n",
      "[491/00483] train_loss: 0.016225\n",
      "[491/00533] train_loss: 0.014607\n",
      "[491/00583] train_loss: 0.015738\n",
      "[491/00633] train_loss: 0.016398\n",
      "[491/00683] train_loss: 0.014545\n",
      "[491/00733] train_loss: 0.014874\n",
      "[491/00783] train_loss: 0.016220\n",
      "[491/00833] train_loss: 0.015496\n",
      "[491/00883] train_loss: 0.016436\n",
      "[491/00933] train_loss: 0.015581\n",
      "[491/00983] train_loss: 0.015027\n",
      "[491/01033] train_loss: 0.016776\n",
      "[491/01083] train_loss: 0.015111\n",
      "[491/01133] train_loss: 0.016146\n",
      "[491/01183] train_loss: 0.014689\n",
      "[492/00007] train_loss: 0.015726\n",
      "[492/00057] train_loss: 0.021020\n",
      "[492/00107] train_loss: 0.017090\n",
      "[492/00157] train_loss: 0.016065\n",
      "[492/00207] train_loss: 0.015386\n",
      "[492/00257] train_loss: 0.016627\n",
      "[492/00307] train_loss: 0.015441\n",
      "[492/00357] train_loss: 0.016751\n",
      "[492/00407] train_loss: 0.016017\n",
      "[492/00457] train_loss: 0.015211\n",
      "[492/00507] train_loss: 0.015090\n",
      "[492/00557] train_loss: 0.015974\n",
      "[492/00607] train_loss: 0.015145\n",
      "[492/00657] train_loss: 0.015113\n",
      "[492/00707] train_loss: 0.015021\n",
      "[492/00757] train_loss: 0.015766\n",
      "[492/00807] train_loss: 0.015710\n",
      "[492/00857] train_loss: 0.015944\n",
      "[492/00907] train_loss: 0.015419\n",
      "[492/00957] train_loss: 0.016394\n",
      "[492/01007] train_loss: 0.016277\n",
      "[492/01057] train_loss: 0.015680\n",
      "[492/01107] train_loss: 0.016079\n",
      "[492/01157] train_loss: 0.015388\n",
      "[492/01207] train_loss: 0.015643\n",
      "[493/00031] train_loss: 0.019209\n",
      "[493/00081] train_loss: 0.020203\n",
      "[493/00131] train_loss: 0.017556\n",
      "[493/00181] train_loss: 0.016322\n",
      "[493/00231] train_loss: 0.015607\n",
      "[493/00281] train_loss: 0.016123\n",
      "[493/00331] train_loss: 0.014887\n",
      "[493/00381] train_loss: 0.016028\n",
      "[493/00431] train_loss: 0.015490\n",
      "[493/00481] train_loss: 0.015145\n",
      "[493/00531] train_loss: 0.017050\n",
      "[493/00581] train_loss: 0.015763\n",
      "[493/00631] train_loss: 0.016480\n",
      "[493/00681] train_loss: 0.015257\n",
      "[493/00731] train_loss: 0.015732\n",
      "[493/00781] train_loss: 0.015670\n",
      "[493/00831] train_loss: 0.015672\n",
      "[493/00881] train_loss: 0.015526\n",
      "[493/00931] train_loss: 0.015438\n",
      "[493/00981] train_loss: 0.015735\n",
      "[493/01031] train_loss: 0.015638\n",
      "[493/01081] train_loss: 0.016113\n",
      "[493/01131] train_loss: 0.016340\n",
      "[493/01181] train_loss: 0.015807\n",
      "[494/00005] train_loss: 0.017189\n",
      "[494/00055] train_loss: 0.021001\n",
      "[494/00105] train_loss: 0.017897\n",
      "[494/00155] train_loss: 0.016102\n",
      "[494/00205] train_loss: 0.016202\n",
      "[494/00255] train_loss: 0.015728\n",
      "[494/00305] train_loss: 0.016639\n",
      "[494/00355] train_loss: 0.016430\n",
      "[494/00405] train_loss: 0.016298\n",
      "[494/00455] train_loss: 0.014976\n",
      "[494/00505] train_loss: 0.015270\n",
      "[494/00555] train_loss: 0.015342\n",
      "[494/00605] train_loss: 0.015820\n",
      "[494/00655] train_loss: 0.015419\n",
      "[494/00705] train_loss: 0.015479\n",
      "[494/00755] train_loss: 0.015542\n",
      "[494/00805] train_loss: 0.014690\n",
      "[494/00855] train_loss: 0.015924\n",
      "[494/00905] train_loss: 0.015920\n",
      "[494/00955] train_loss: 0.015977\n",
      "[494/01005] train_loss: 0.016312\n",
      "[494/01055] train_loss: 0.015540\n",
      "[494/01105] train_loss: 0.016305\n",
      "[494/01155] train_loss: 0.015559\n",
      "[494/01205] train_loss: 0.015227\n",
      "[495/00029] train_loss: 0.018745\n",
      "[495/00079] train_loss: 0.019158\n",
      "[495/00129] train_loss: 0.016375\n",
      "[495/00179] train_loss: 0.015812\n",
      "[495/00229] train_loss: 0.015384\n",
      "[495/00279] train_loss: 0.015510\n",
      "[495/00329] train_loss: 0.016075\n",
      "[495/00379] train_loss: 0.015244\n",
      "[495/00429] train_loss: 0.015803\n",
      "[495/00479] train_loss: 0.016408\n",
      "[495/00529] train_loss: 0.015885\n",
      "[495/00579] train_loss: 0.014991\n",
      "[495/00629] train_loss: 0.016209\n",
      "[495/00679] train_loss: 0.015316\n",
      "[495/00729] train_loss: 0.015615\n",
      "[495/00779] train_loss: 0.016074\n",
      "[495/00829] train_loss: 0.015864\n",
      "[495/00879] train_loss: 0.015027\n",
      "[495/00929] train_loss: 0.016055\n",
      "[495/00979] train_loss: 0.015477\n",
      "[495/01029] train_loss: 0.015465\n",
      "[495/01079] train_loss: 0.016544\n",
      "[495/01129] train_loss: 0.015213\n",
      "[495/01179] train_loss: 0.015673\n",
      "[496/00003] train_loss: 0.016569\n",
      "[496/00053] train_loss: 0.018793\n",
      "[496/00103] train_loss: 0.017708\n",
      "[496/00153] train_loss: 0.016315\n",
      "[496/00203] train_loss: 0.016635\n",
      "[496/00253] train_loss: 0.016358\n",
      "[496/00303] train_loss: 0.015250\n",
      "[496/00353] train_loss: 0.015808\n",
      "[496/00403] train_loss: 0.015763\n",
      "[496/00453] train_loss: 0.015652\n",
      "[496/00503] train_loss: 0.015818\n",
      "[496/00553] train_loss: 0.015652\n",
      "[496/00603] train_loss: 0.015690\n",
      "[496/00653] train_loss: 0.016191\n",
      "[496/00703] train_loss: 0.015545\n",
      "[496/00753] train_loss: 0.015384\n",
      "[496/00803] train_loss: 0.016121\n",
      "[496/00853] train_loss: 0.015299\n",
      "[496/00903] train_loss: 0.015507\n",
      "[496/00953] train_loss: 0.014930\n",
      "[496/01003] train_loss: 0.016055\n",
      "[496/01053] train_loss: 0.016503\n",
      "[496/01103] train_loss: 0.016361\n",
      "[496/01153] train_loss: 0.016921\n",
      "[496/01203] train_loss: 0.016247\n",
      "[497/00027] train_loss: 0.019071\n",
      "[497/00077] train_loss: 0.020442\n",
      "[497/00127] train_loss: 0.017103\n",
      "[497/00177] train_loss: 0.016013\n",
      "[497/00227] train_loss: 0.015746\n",
      "[497/00277] train_loss: 0.015570\n",
      "[497/00327] train_loss: 0.016079\n",
      "[497/00377] train_loss: 0.016142\n",
      "[497/00427] train_loss: 0.014456\n",
      "[497/00477] train_loss: 0.015440\n",
      "[497/00527] train_loss: 0.016140\n",
      "[497/00577] train_loss: 0.015944\n",
      "[497/00627] train_loss: 0.015157\n",
      "[497/00677] train_loss: 0.015362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[497/00727] train_loss: 0.015836\n",
      "[497/00777] train_loss: 0.015194\n",
      "[497/00827] train_loss: 0.014929\n",
      "[497/00877] train_loss: 0.014777\n",
      "[497/00927] train_loss: 0.015055\n",
      "[497/00977] train_loss: 0.015096\n",
      "[497/01027] train_loss: 0.015963\n",
      "[497/01077] train_loss: 0.016068\n",
      "[497/01127] train_loss: 0.015767\n",
      "[497/01177] train_loss: 0.016744\n",
      "[498/00001] train_loss: 0.016559\n",
      "[498/00051] train_loss: 0.021052\n",
      "[498/00101] train_loss: 0.017332\n",
      "[498/00151] train_loss: 0.016196\n",
      "[498/00201] train_loss: 0.015722\n",
      "[498/00251] train_loss: 0.015277\n",
      "[498/00301] train_loss: 0.015699\n",
      "[498/00351] train_loss: 0.016346\n",
      "[498/00401] train_loss: 0.015362\n",
      "[498/00451] train_loss: 0.015931\n",
      "[498/00501] train_loss: 0.016395\n",
      "[498/00551] train_loss: 0.015135\n",
      "[498/00601] train_loss: 0.015199\n",
      "[498/00651] train_loss: 0.016019\n",
      "[498/00701] train_loss: 0.015557\n",
      "[498/00751] train_loss: 0.015537\n",
      "[498/00801] train_loss: 0.015515\n",
      "[498/00851] train_loss: 0.015776\n",
      "[498/00901] train_loss: 0.015882\n",
      "[498/00951] train_loss: 0.015185\n",
      "[498/01001] train_loss: 0.015611\n",
      "[498/01051] train_loss: 0.015644\n",
      "[498/01101] train_loss: 0.015713\n",
      "[498/01151] train_loss: 0.015987\n",
      "[498/01201] train_loss: 0.015378\n",
      "[499/00025] train_loss: 0.017892\n",
      "[499/00075] train_loss: 0.019366\n",
      "[499/00125] train_loss: 0.018582\n",
      "[499/00175] train_loss: 0.016707\n",
      "[499/00225] train_loss: 0.015366\n",
      "[499/00275] train_loss: 0.015187\n",
      "[499/00325] train_loss: 0.015649\n",
      "[499/00375] train_loss: 0.015684\n",
      "[499/00425] train_loss: 0.014653\n",
      "[499/00475] train_loss: 0.016136\n",
      "[499/00525] train_loss: 0.016548\n",
      "[499/00575] train_loss: 0.015097\n",
      "[499/00625] train_loss: 0.015471\n",
      "[499/00675] train_loss: 0.016195\n",
      "[499/00725] train_loss: 0.015441\n",
      "[499/00775] train_loss: 0.015979\n",
      "[499/00825] train_loss: 0.015082\n",
      "[499/00875] train_loss: 0.015815\n",
      "[499/00925] train_loss: 0.015023\n",
      "[499/00975] train_loss: 0.016565\n",
      "[499/01025] train_loss: 0.016402\n",
      "[499/01075] train_loss: 0.015760\n",
      "[499/01125] train_loss: 0.015474\n",
      "[499/01175] train_loss: 0.015967\n",
      "[499/01225] train_loss: 0.015346\n",
      "[500/00049] train_loss: 0.021473\n",
      "[500/00099] train_loss: 0.019078\n",
      "[500/00149] train_loss: 0.017407\n",
      "[500/00199] train_loss: 0.016999\n",
      "[500/00249] train_loss: 0.016852\n",
      "[500/00299] train_loss: 0.015101\n",
      "[500/00349] train_loss: 0.016154\n",
      "[500/00399] train_loss: 0.016141\n",
      "[500/00449] train_loss: 0.015277\n",
      "[500/00499] train_loss: 0.015111\n",
      "[500/00549] train_loss: 0.015079\n",
      "[500/00599] train_loss: 0.014919\n",
      "[500/00649] train_loss: 0.015588\n",
      "[500/00699] train_loss: 0.015269\n",
      "[500/00749] train_loss: 0.014666\n",
      "[500/00799] train_loss: 0.015177\n",
      "[500/00849] train_loss: 0.015303\n",
      "[500/00899] train_loss: 0.015196\n",
      "[500/00949] train_loss: 0.015358\n",
      "[500/00999] train_loss: 0.016039\n",
      "[500/01049] train_loss: 0.015013\n",
      "[500/01099] train_loss: 0.014542\n",
      "[500/01149] train_loss: 0.014616\n",
      "[500/01199] train_loss: 0.015886\n",
      "[501/00023] train_loss: 0.015372\n",
      "[501/00073] train_loss: 0.014299\n",
      "[501/00123] train_loss: 0.013885\n",
      "[501/00173] train_loss: 0.013558\n",
      "[501/00223] train_loss: 0.013573\n",
      "[501/00273] train_loss: 0.012875\n",
      "[501/00323] train_loss: 0.013098\n",
      "[501/00373] train_loss: 0.012877\n",
      "[501/00423] train_loss: 0.013531\n",
      "[501/00473] train_loss: 0.013529\n",
      "[501/00523] train_loss: 0.013105\n",
      "[501/00573] train_loss: 0.013868\n",
      "[501/00623] train_loss: 0.012966\n",
      "[501/00673] train_loss: 0.013466\n",
      "[501/00723] train_loss: 0.012464\n",
      "[501/00773] train_loss: 0.012169\n",
      "[501/00823] train_loss: 0.013724\n",
      "[501/00873] train_loss: 0.012947\n",
      "[501/00923] train_loss: 0.012831\n",
      "[501/00973] train_loss: 0.013054\n",
      "[501/01023] train_loss: 0.012853\n",
      "[501/01073] train_loss: 0.013516\n",
      "[501/01123] train_loss: 0.012827\n",
      "[501/01173] train_loss: 0.013020\n",
      "[501/01223] train_loss: 0.013897\n",
      "[502/00047] train_loss: 0.013676\n",
      "[502/00097] train_loss: 0.013887\n",
      "[502/00147] train_loss: 0.014194\n",
      "[502/00197] train_loss: 0.013502\n",
      "[502/00247] train_loss: 0.012325\n",
      "[502/00297] train_loss: 0.012779\n",
      "[502/00347] train_loss: 0.013112\n",
      "[502/00397] train_loss: 0.013342\n",
      "[502/00447] train_loss: 0.013267\n",
      "[502/00497] train_loss: 0.012867\n",
      "[502/00547] train_loss: 0.012804\n",
      "[502/00597] train_loss: 0.013395\n",
      "[502/00647] train_loss: 0.013561\n",
      "[502/00697] train_loss: 0.013269\n",
      "[502/00747] train_loss: 0.013692\n",
      "[502/00797] train_loss: 0.012754\n",
      "[502/00847] train_loss: 0.012964\n",
      "[502/00897] train_loss: 0.012731\n",
      "[502/00947] train_loss: 0.013322\n",
      "[502/00997] train_loss: 0.012291\n",
      "[502/01047] train_loss: 0.013378\n",
      "[502/01097] train_loss: 0.013230\n",
      "[502/01147] train_loss: 0.012672\n",
      "[502/01197] train_loss: 0.013634\n",
      "[503/00021] train_loss: 0.014070\n",
      "[503/00071] train_loss: 0.013896\n",
      "[503/00121] train_loss: 0.012963\n",
      "[503/00171] train_loss: 0.012375\n",
      "[503/00221] train_loss: 0.013171\n",
      "[503/00271] train_loss: 0.013172\n",
      "[503/00321] train_loss: 0.013439\n",
      "[503/00371] train_loss: 0.012889\n",
      "[503/00421] train_loss: 0.012968\n",
      "[503/00471] train_loss: 0.013004\n",
      "[503/00521] train_loss: 0.013215\n",
      "[503/00571] train_loss: 0.012499\n",
      "[503/00621] train_loss: 0.012859\n",
      "[503/00671] train_loss: 0.013084\n",
      "[503/00721] train_loss: 0.011903\n",
      "[503/00771] train_loss: 0.013511\n",
      "[503/00821] train_loss: 0.012669\n",
      "[503/00871] train_loss: 0.012831\n",
      "[503/00921] train_loss: 0.011840\n",
      "[503/00971] train_loss: 0.012624\n",
      "[503/01021] train_loss: 0.013656\n",
      "[503/01071] train_loss: 0.012565\n",
      "[503/01121] train_loss: 0.013036\n",
      "[503/01171] train_loss: 0.012570\n",
      "[503/01221] train_loss: 0.012709\n",
      "[504/00045] train_loss: 0.014990\n",
      "[504/00095] train_loss: 0.014831\n",
      "[504/00145] train_loss: 0.013570\n",
      "[504/00195] train_loss: 0.013605\n",
      "[504/00245] train_loss: 0.013240\n",
      "[504/00295] train_loss: 0.012027\n",
      "[504/00345] train_loss: 0.012489\n",
      "[504/00395] train_loss: 0.012437\n",
      "[504/00445] train_loss: 0.012649\n",
      "[504/00495] train_loss: 0.012975\n",
      "[504/00545] train_loss: 0.012176\n",
      "[504/00595] train_loss: 0.012663\n",
      "[504/00645] train_loss: 0.012318\n",
      "[504/00695] train_loss: 0.012963\n",
      "[504/00745] train_loss: 0.012847\n",
      "[504/00795] train_loss: 0.012266\n",
      "[504/00845] train_loss: 0.012562\n",
      "[504/00895] train_loss: 0.012393\n",
      "[504/00945] train_loss: 0.013188\n",
      "[504/00995] train_loss: 0.012832\n",
      "[504/01045] train_loss: 0.013093\n",
      "[504/01095] train_loss: 0.013490\n",
      "[504/01145] train_loss: 0.013089\n",
      "[504/01195] train_loss: 0.012971\n",
      "[505/00019] train_loss: 0.014134\n",
      "[505/00069] train_loss: 0.014778\n",
      "[505/00119] train_loss: 0.013577\n",
      "[505/00169] train_loss: 0.013719\n",
      "[505/00219] train_loss: 0.012937\n",
      "[505/00269] train_loss: 0.011821\n",
      "[505/00319] train_loss: 0.013080\n",
      "[505/00369] train_loss: 0.012875\n",
      "[505/00419] train_loss: 0.013025\n",
      "[505/00469] train_loss: 0.013621\n",
      "[505/00519] train_loss: 0.013196\n",
      "[505/00569] train_loss: 0.012233\n",
      "[505/00619] train_loss: 0.012375\n",
      "[505/00669] train_loss: 0.012615\n",
      "[505/00719] train_loss: 0.013381\n",
      "[505/00769] train_loss: 0.012876\n",
      "[505/00819] train_loss: 0.012263\n",
      "[505/00869] train_loss: 0.013454\n",
      "[505/00919] train_loss: 0.012917\n",
      "[505/00969] train_loss: 0.012053\n",
      "[505/01019] train_loss: 0.014119\n",
      "[505/01069] train_loss: 0.013286\n",
      "[505/01119] train_loss: 0.013559\n",
      "[505/01169] train_loss: 0.012806\n",
      "[505/01219] train_loss: 0.013106\n",
      "[506/00043] train_loss: 0.014744\n",
      "[506/00093] train_loss: 0.016159\n",
      "[506/00143] train_loss: 0.013068\n",
      "[506/00193] train_loss: 0.012891\n",
      "[506/00243] train_loss: 0.012602\n",
      "[506/00293] train_loss: 0.013685\n",
      "[506/00343] train_loss: 0.013166\n",
      "[506/00393] train_loss: 0.012431\n",
      "[506/00443] train_loss: 0.012480\n",
      "[506/00493] train_loss: 0.013354\n",
      "[506/00543] train_loss: 0.012640\n",
      "[506/00593] train_loss: 0.012881\n",
      "[506/00643] train_loss: 0.012601\n",
      "[506/00693] train_loss: 0.012921\n",
      "[506/00743] train_loss: 0.013235\n",
      "[506/00793] train_loss: 0.012776\n",
      "[506/00843] train_loss: 0.012565\n",
      "[506/00893] train_loss: 0.013200\n",
      "[506/00943] train_loss: 0.012772\n",
      "[506/00993] train_loss: 0.013505\n",
      "[506/01043] train_loss: 0.012317\n",
      "[506/01093] train_loss: 0.013362\n",
      "[506/01143] train_loss: 0.013126\n",
      "[506/01193] train_loss: 0.013162\n",
      "[507/00017] train_loss: 0.013929\n",
      "[507/00067] train_loss: 0.015044\n",
      "[507/00117] train_loss: 0.013466\n",
      "[507/00167] train_loss: 0.013105\n",
      "[507/00217] train_loss: 0.013212\n",
      "[507/00267] train_loss: 0.012627\n",
      "[507/00317] train_loss: 0.013015\n",
      "[507/00367] train_loss: 0.012428\n",
      "[507/00417] train_loss: 0.012378\n",
      "[507/00467] train_loss: 0.013525\n",
      "[507/00517] train_loss: 0.012011\n",
      "[507/00567] train_loss: 0.014103\n",
      "[507/00617] train_loss: 0.013041\n",
      "[507/00667] train_loss: 0.012810\n",
      "[507/00717] train_loss: 0.012537\n",
      "[507/00767] train_loss: 0.012531\n",
      "[507/00817] train_loss: 0.012527\n",
      "[507/00867] train_loss: 0.013136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[507/00917] train_loss: 0.013730\n",
      "[507/00967] train_loss: 0.012724\n",
      "[507/01017] train_loss: 0.012177\n",
      "[507/01067] train_loss: 0.013218\n",
      "[507/01117] train_loss: 0.013139\n",
      "[507/01167] train_loss: 0.013425\n",
      "[507/01217] train_loss: 0.012828\n",
      "[508/00041] train_loss: 0.015046\n",
      "[508/00091] train_loss: 0.014662\n",
      "[508/00141] train_loss: 0.013868\n",
      "[508/00191] train_loss: 0.013823\n",
      "[508/00241] train_loss: 0.013053\n",
      "[508/00291] train_loss: 0.013511\n",
      "[508/00341] train_loss: 0.012971\n",
      "[508/00391] train_loss: 0.012957\n",
      "[508/00441] train_loss: 0.013275\n",
      "[508/00491] train_loss: 0.012576\n",
      "[508/00541] train_loss: 0.012109\n",
      "[508/00591] train_loss: 0.012839\n",
      "[508/00641] train_loss: 0.012294\n",
      "[508/00691] train_loss: 0.012124\n",
      "[508/00741] train_loss: 0.013369\n",
      "[508/00791] train_loss: 0.012337\n",
      "[508/00841] train_loss: 0.012338\n",
      "[508/00891] train_loss: 0.012670\n",
      "[508/00941] train_loss: 0.011807\n",
      "[508/00991] train_loss: 0.013338\n",
      "[508/01041] train_loss: 0.012592\n",
      "[508/01091] train_loss: 0.013551\n",
      "[508/01141] train_loss: 0.012649\n",
      "[508/01191] train_loss: 0.012431\n",
      "[509/00015] train_loss: 0.013335\n",
      "[509/00065] train_loss: 0.015178\n",
      "[509/00115] train_loss: 0.014132\n",
      "[509/00165] train_loss: 0.012717\n",
      "[509/00215] train_loss: 0.012479\n",
      "[509/00265] train_loss: 0.013238\n",
      "[509/00315] train_loss: 0.013539\n",
      "[509/00365] train_loss: 0.012696\n",
      "[509/00415] train_loss: 0.013018\n",
      "[509/00465] train_loss: 0.012716\n",
      "[509/00515] train_loss: 0.012030\n",
      "[509/00565] train_loss: 0.012773\n",
      "[509/00615] train_loss: 0.012452\n",
      "[509/00665] train_loss: 0.013386\n",
      "[509/00715] train_loss: 0.013233\n",
      "[509/00765] train_loss: 0.013891\n",
      "[509/00815] train_loss: 0.013602\n",
      "[509/00865] train_loss: 0.013023\n",
      "[509/00915] train_loss: 0.013246\n",
      "[509/00965] train_loss: 0.012875\n",
      "[509/01015] train_loss: 0.013045\n",
      "[509/01065] train_loss: 0.013335\n",
      "[509/01115] train_loss: 0.012307\n",
      "[509/01165] train_loss: 0.012647\n",
      "[509/01215] train_loss: 0.012702\n",
      "[510/00039] train_loss: 0.015427\n",
      "[510/00089] train_loss: 0.014549\n",
      "[510/00139] train_loss: 0.013639\n",
      "[510/00189] train_loss: 0.013200\n",
      "[510/00239] train_loss: 0.012289\n",
      "[510/00289] train_loss: 0.012626\n",
      "[510/00339] train_loss: 0.012474\n",
      "[510/00389] train_loss: 0.012020\n",
      "[510/00439] train_loss: 0.013006\n",
      "[510/00489] train_loss: 0.011407\n",
      "[510/00539] train_loss: 0.012196\n",
      "[510/00589] train_loss: 0.012725\n",
      "[510/00639] train_loss: 0.012956\n",
      "[510/00689] train_loss: 0.013491\n",
      "[510/00739] train_loss: 0.013045\n",
      "[510/00789] train_loss: 0.013269\n",
      "[510/00839] train_loss: 0.012736\n",
      "[510/00889] train_loss: 0.012737\n",
      "[510/00939] train_loss: 0.012938\n",
      "[510/00989] train_loss: 0.013111\n",
      "[510/01039] train_loss: 0.013219\n",
      "[510/01089] train_loss: 0.014085\n",
      "[510/01139] train_loss: 0.013321\n",
      "[510/01189] train_loss: 0.012857\n",
      "[511/00013] train_loss: 0.013711\n",
      "[511/00063] train_loss: 0.014867\n",
      "[511/00113] train_loss: 0.014449\n",
      "[511/00163] train_loss: 0.013177\n",
      "[511/00213] train_loss: 0.012992\n",
      "[511/00263] train_loss: 0.012255\n",
      "[511/00313] train_loss: 0.013215\n",
      "[511/00363] train_loss: 0.012909\n",
      "[511/00413] train_loss: 0.013433\n",
      "[511/00463] train_loss: 0.012523\n",
      "[511/00513] train_loss: 0.013230\n",
      "[511/00563] train_loss: 0.013114\n",
      "[511/00613] train_loss: 0.012878\n",
      "[511/00663] train_loss: 0.013147\n",
      "[511/00713] train_loss: 0.013290\n",
      "[511/00763] train_loss: 0.013429\n",
      "[511/00813] train_loss: 0.012584\n",
      "[511/00863] train_loss: 0.012889\n",
      "[511/00913] train_loss: 0.012247\n",
      "[511/00963] train_loss: 0.013156\n",
      "[511/01013] train_loss: 0.013254\n",
      "[511/01063] train_loss: 0.013011\n",
      "[511/01113] train_loss: 0.012876\n",
      "[511/01163] train_loss: 0.012737\n",
      "[511/01213] train_loss: 0.012318\n",
      "[512/00037] train_loss: 0.014391\n",
      "[512/00087] train_loss: 0.014656\n",
      "[512/00137] train_loss: 0.013089\n",
      "[512/00187] train_loss: 0.013314\n",
      "[512/00237] train_loss: 0.013207\n",
      "[512/00287] train_loss: 0.013489\n",
      "[512/00337] train_loss: 0.012924\n",
      "[512/00387] train_loss: 0.012260\n",
      "[512/00437] train_loss: 0.013093\n",
      "[512/00487] train_loss: 0.012810\n",
      "[512/00537] train_loss: 0.012138\n",
      "[512/00587] train_loss: 0.013203\n",
      "[512/00637] train_loss: 0.013177\n",
      "[512/00687] train_loss: 0.012768\n",
      "[512/00737] train_loss: 0.012751\n",
      "[512/00787] train_loss: 0.013693\n",
      "[512/00837] train_loss: 0.012329\n",
      "[512/00887] train_loss: 0.013003\n",
      "[512/00937] train_loss: 0.012898\n",
      "[512/00987] train_loss: 0.013599\n",
      "[512/01037] train_loss: 0.012976\n",
      "[512/01087] train_loss: 0.013202\n",
      "[512/01137] train_loss: 0.013054\n",
      "[512/01187] train_loss: 0.013552\n",
      "[513/00011] train_loss: 0.012721\n",
      "[513/00061] train_loss: 0.015342\n",
      "[513/00111] train_loss: 0.014299\n",
      "[513/00161] train_loss: 0.013143\n",
      "[513/00211] train_loss: 0.013304\n",
      "[513/00261] train_loss: 0.011608\n",
      "[513/00311] train_loss: 0.012924\n",
      "[513/00361] train_loss: 0.012825\n",
      "[513/00411] train_loss: 0.012629\n",
      "[513/00461] train_loss: 0.012895\n",
      "[513/00511] train_loss: 0.012412\n",
      "[513/00561] train_loss: 0.013038\n",
      "[513/00611] train_loss: 0.012514\n",
      "[513/00661] train_loss: 0.012595\n",
      "[513/00711] train_loss: 0.013011\n",
      "[513/00761] train_loss: 0.013145\n",
      "[513/00811] train_loss: 0.013312\n",
      "[513/00861] train_loss: 0.013450\n",
      "[513/00911] train_loss: 0.014104\n",
      "[513/00961] train_loss: 0.013842\n",
      "[513/01011] train_loss: 0.012256\n",
      "[513/01061] train_loss: 0.012875\n",
      "[513/01111] train_loss: 0.013171\n",
      "[513/01161] train_loss: 0.013259\n",
      "[513/01211] train_loss: 0.012386\n",
      "[514/00035] train_loss: 0.014712\n",
      "[514/00085] train_loss: 0.014324\n",
      "[514/00135] train_loss: 0.013456\n",
      "[514/00185] train_loss: 0.013305\n",
      "[514/00235] train_loss: 0.012637\n",
      "[514/00285] train_loss: 0.012903\n",
      "[514/00335] train_loss: 0.013352\n",
      "[514/00385] train_loss: 0.013080\n",
      "[514/00435] train_loss: 0.012762\n",
      "[514/00485] train_loss: 0.013494\n",
      "[514/00535] train_loss: 0.012199\n",
      "[514/00585] train_loss: 0.012637\n",
      "[514/00635] train_loss: 0.012254\n",
      "[514/00685] train_loss: 0.013246\n",
      "[514/00735] train_loss: 0.013353\n",
      "[514/00785] train_loss: 0.013397\n",
      "[514/00835] train_loss: 0.012553\n",
      "[514/00885] train_loss: 0.012907\n",
      "[514/00935] train_loss: 0.012526\n",
      "[514/00985] train_loss: 0.012624\n",
      "[514/01035] train_loss: 0.013551\n",
      "[514/01085] train_loss: 0.013759\n",
      "[514/01135] train_loss: 0.012754\n",
      "[514/01185] train_loss: 0.013243\n",
      "[515/00009] train_loss: 0.014464\n",
      "[515/00059] train_loss: 0.014872\n",
      "[515/00109] train_loss: 0.015091\n",
      "[515/00159] train_loss: 0.013346\n",
      "[515/00209] train_loss: 0.013122\n",
      "[515/00259] train_loss: 0.012758\n",
      "[515/00309] train_loss: 0.012834\n",
      "[515/00359] train_loss: 0.012588\n",
      "[515/00409] train_loss: 0.012849\n",
      "[515/00459] train_loss: 0.012499\n",
      "[515/00509] train_loss: 0.012847\n",
      "[515/00559] train_loss: 0.013398\n",
      "[515/00609] train_loss: 0.013010\n",
      "[515/00659] train_loss: 0.013545\n",
      "[515/00709] train_loss: 0.013629\n",
      "[515/00759] train_loss: 0.012361\n",
      "[515/00809] train_loss: 0.012632\n",
      "[515/00859] train_loss: 0.013174\n",
      "[515/00909] train_loss: 0.012514\n",
      "[515/00959] train_loss: 0.012633\n",
      "[515/01009] train_loss: 0.013078\n",
      "[515/01059] train_loss: 0.013565\n",
      "[515/01109] train_loss: 0.012759\n",
      "[515/01159] train_loss: 0.012931\n",
      "[515/01209] train_loss: 0.012608\n",
      "[516/00033] train_loss: 0.015144\n",
      "[516/00083] train_loss: 0.014950\n",
      "[516/00133] train_loss: 0.013892\n",
      "[516/00183] train_loss: 0.012532\n",
      "[516/00233] train_loss: 0.012978\n",
      "[516/00283] train_loss: 0.012960\n",
      "[516/00333] train_loss: 0.012638\n",
      "[516/00383] train_loss: 0.012954\n",
      "[516/00433] train_loss: 0.013336\n",
      "[516/00483] train_loss: 0.012467\n",
      "[516/00533] train_loss: 0.012174\n",
      "[516/00583] train_loss: 0.012328\n",
      "[516/00633] train_loss: 0.012300\n",
      "[516/00683] train_loss: 0.012764\n",
      "[516/00733] train_loss: 0.013265\n",
      "[516/00783] train_loss: 0.014049\n",
      "[516/00833] train_loss: 0.012204\n",
      "[516/00883] train_loss: 0.012965\n",
      "[516/00933] train_loss: 0.012965\n",
      "[516/00983] train_loss: 0.012352\n",
      "[516/01033] train_loss: 0.013466\n",
      "[516/01083] train_loss: 0.012880\n",
      "[516/01133] train_loss: 0.013825\n",
      "[516/01183] train_loss: 0.013051\n",
      "[517/00007] train_loss: 0.013244\n",
      "[517/00057] train_loss: 0.015752\n",
      "[517/00107] train_loss: 0.013570\n",
      "[517/00157] train_loss: 0.013128\n",
      "[517/00207] train_loss: 0.012648\n",
      "[517/00257] train_loss: 0.012849\n",
      "[517/00307] train_loss: 0.013085\n",
      "[517/00357] train_loss: 0.012771\n",
      "[517/00407] train_loss: 0.013125\n",
      "[517/00457] train_loss: 0.013182\n",
      "[517/00507] train_loss: 0.013225\n",
      "[517/00557] train_loss: 0.012482\n",
      "[517/00607] train_loss: 0.012768\n",
      "[517/00657] train_loss: 0.013358\n",
      "[517/00707] train_loss: 0.012159\n",
      "[517/00757] train_loss: 0.012981\n",
      "[517/00807] train_loss: 0.011801\n",
      "[517/00857] train_loss: 0.013076\n",
      "[517/00907] train_loss: 0.013349\n",
      "[517/00957] train_loss: 0.013090\n",
      "[517/01007] train_loss: 0.012635\n",
      "[517/01057] train_loss: 0.012811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[517/01107] train_loss: 0.013145\n",
      "[517/01157] train_loss: 0.013681\n",
      "[517/01207] train_loss: 0.013487\n",
      "[518/00031] train_loss: 0.014751\n",
      "[518/00081] train_loss: 0.014408\n",
      "[518/00131] train_loss: 0.014082\n",
      "[518/00181] train_loss: 0.012930\n",
      "[518/00231] train_loss: 0.013094\n",
      "[518/00281] train_loss: 0.012873\n",
      "[518/00331] train_loss: 0.012124\n",
      "[518/00381] train_loss: 0.012101\n",
      "[518/00431] train_loss: 0.013543\n",
      "[518/00481] train_loss: 0.013124\n",
      "[518/00531] train_loss: 0.013029\n",
      "[518/00581] train_loss: 0.012944\n",
      "[518/00631] train_loss: 0.012870\n",
      "[518/00681] train_loss: 0.012774\n",
      "[518/00731] train_loss: 0.012529\n",
      "[518/00781] train_loss: 0.013817\n",
      "[518/00831] train_loss: 0.012792\n",
      "[518/00881] train_loss: 0.012358\n",
      "[518/00931] train_loss: 0.012469\n",
      "[518/00981] train_loss: 0.012623\n",
      "[518/01031] train_loss: 0.013030\n",
      "[518/01081] train_loss: 0.012817\n",
      "[518/01131] train_loss: 0.013324\n",
      "[518/01181] train_loss: 0.013017\n",
      "[519/00005] train_loss: 0.013328\n",
      "[519/00055] train_loss: 0.015440\n",
      "[519/00105] train_loss: 0.014267\n",
      "[519/00155] train_loss: 0.013649\n",
      "[519/00205] train_loss: 0.013633\n",
      "[519/00255] train_loss: 0.012230\n",
      "[519/00305] train_loss: 0.012688\n",
      "[519/00355] train_loss: 0.012351\n",
      "[519/00405] train_loss: 0.012549\n",
      "[519/00455] train_loss: 0.013274\n",
      "[519/00505] train_loss: 0.012600\n",
      "[519/00555] train_loss: 0.012829\n",
      "[519/00605] train_loss: 0.012580\n",
      "[519/00655] train_loss: 0.013790\n",
      "[519/00705] train_loss: 0.012481\n",
      "[519/00755] train_loss: 0.013588\n",
      "[519/00805] train_loss: 0.013296\n",
      "[519/00855] train_loss: 0.013052\n",
      "[519/00905] train_loss: 0.012689\n",
      "[519/00955] train_loss: 0.012993\n",
      "[519/01005] train_loss: 0.013880\n",
      "[519/01055] train_loss: 0.012859\n",
      "[519/01105] train_loss: 0.013053\n",
      "[519/01155] train_loss: 0.012635\n",
      "[519/01205] train_loss: 0.013579\n",
      "[520/00029] train_loss: 0.014261\n",
      "[520/00079] train_loss: 0.014884\n",
      "[520/00129] train_loss: 0.014137\n",
      "[520/00179] train_loss: 0.013217\n",
      "[520/00229] train_loss: 0.013013\n",
      "[520/00279] train_loss: 0.013035\n",
      "[520/00329] train_loss: 0.013069\n",
      "[520/00379] train_loss: 0.012165\n",
      "[520/00429] train_loss: 0.013081\n",
      "[520/00479] train_loss: 0.013129\n",
      "[520/00529] train_loss: 0.012407\n",
      "[520/00579] train_loss: 0.013306\n",
      "[520/00629] train_loss: 0.012784\n",
      "[520/00679] train_loss: 0.012956\n",
      "[520/00729] train_loss: 0.012593\n",
      "[520/00779] train_loss: 0.013817\n",
      "[520/00829] train_loss: 0.013168\n",
      "[520/00879] train_loss: 0.013349\n",
      "[520/00929] train_loss: 0.012660\n",
      "[520/00979] train_loss: 0.012236\n",
      "[520/01029] train_loss: 0.012943\n",
      "[520/01079] train_loss: 0.013391\n",
      "[520/01129] train_loss: 0.012633\n",
      "[520/01179] train_loss: 0.013069\n",
      "[521/00003] train_loss: 0.013241\n",
      "[521/00053] train_loss: 0.014877\n",
      "[521/00103] train_loss: 0.014799\n",
      "[521/00153] train_loss: 0.014363\n",
      "[521/00203] train_loss: 0.013579\n",
      "[521/00253] train_loss: 0.013197\n",
      "[521/00303] train_loss: 0.012548\n",
      "[521/00353] train_loss: 0.013322\n",
      "[521/00403] train_loss: 0.012609\n",
      "[521/00453] train_loss: 0.013310\n",
      "[521/00503] train_loss: 0.012901\n",
      "[521/00553] train_loss: 0.013013\n",
      "[521/00603] train_loss: 0.012041\n",
      "[521/00653] train_loss: 0.012873\n",
      "[521/00703] train_loss: 0.013317\n",
      "[521/00753] train_loss: 0.013103\n",
      "[521/00803] train_loss: 0.012650\n",
      "[521/00853] train_loss: 0.012324\n",
      "[521/00903] train_loss: 0.013815\n",
      "[521/00953] train_loss: 0.012799\n",
      "[521/01003] train_loss: 0.012479\n",
      "[521/01053] train_loss: 0.012678\n",
      "[521/01103] train_loss: 0.012839\n",
      "[521/01153] train_loss: 0.012778\n",
      "[521/01203] train_loss: 0.013109\n",
      "[522/00027] train_loss: 0.015240\n",
      "[522/00077] train_loss: 0.015048\n",
      "[522/00127] train_loss: 0.015067\n",
      "[522/00177] train_loss: 0.013868\n",
      "[522/00227] train_loss: 0.013160\n",
      "[522/00277] train_loss: 0.012640\n",
      "[522/00327] train_loss: 0.013474\n",
      "[522/00377] train_loss: 0.012551\n",
      "[522/00427] train_loss: 0.012283\n",
      "[522/00477] train_loss: 0.012692\n",
      "[522/00527] train_loss: 0.013278\n",
      "[522/00577] train_loss: 0.012830\n",
      "[522/00627] train_loss: 0.012859\n",
      "[522/00677] train_loss: 0.012353\n",
      "[522/00727] train_loss: 0.012766\n",
      "[522/00777] train_loss: 0.012864\n",
      "[522/00827] train_loss: 0.012415\n",
      "[522/00877] train_loss: 0.012892\n",
      "[522/00927] train_loss: 0.012696\n",
      "[522/00977] train_loss: 0.013054\n",
      "[522/01027] train_loss: 0.013830\n",
      "[522/01077] train_loss: 0.013364\n",
      "[522/01127] train_loss: 0.012646\n",
      "[522/01177] train_loss: 0.012228\n",
      "[523/00001] train_loss: 0.012726\n",
      "[523/00051] train_loss: 0.016600\n",
      "[523/00101] train_loss: 0.013667\n",
      "[523/00151] train_loss: 0.013125\n",
      "[523/00201] train_loss: 0.012937\n",
      "[523/00251] train_loss: 0.013007\n",
      "[523/00301] train_loss: 0.012985\n",
      "[523/00351] train_loss: 0.012996\n",
      "[523/00401] train_loss: 0.013270\n",
      "[523/00451] train_loss: 0.012026\n",
      "[523/00501] train_loss: 0.012756\n",
      "[523/00551] train_loss: 0.013251\n",
      "[523/00601] train_loss: 0.012083\n",
      "[523/00651] train_loss: 0.012724\n",
      "[523/00701] train_loss: 0.013011\n",
      "[523/00751] train_loss: 0.012215\n",
      "[523/00801] train_loss: 0.012794\n",
      "[523/00851] train_loss: 0.013286\n",
      "[523/00901] train_loss: 0.013624\n",
      "[523/00951] train_loss: 0.012700\n",
      "[523/01001] train_loss: 0.013066\n",
      "[523/01051] train_loss: 0.013555\n",
      "[523/01101] train_loss: 0.012906\n",
      "[523/01151] train_loss: 0.013254\n",
      "[523/01201] train_loss: 0.013222\n",
      "[524/00025] train_loss: 0.014275\n",
      "[524/00075] train_loss: 0.015037\n",
      "[524/00125] train_loss: 0.013733\n",
      "[524/00175] train_loss: 0.014015\n",
      "[524/00225] train_loss: 0.013565\n",
      "[524/00275] train_loss: 0.013336\n",
      "[524/00325] train_loss: 0.013186\n",
      "[524/00375] train_loss: 0.013555\n",
      "[524/00425] train_loss: 0.012764\n",
      "[524/00475] train_loss: 0.012261\n",
      "[524/00525] train_loss: 0.012136\n",
      "[524/00575] train_loss: 0.012669\n",
      "[524/00625] train_loss: 0.013027\n",
      "[524/00675] train_loss: 0.012694\n",
      "[524/00725] train_loss: 0.012193\n",
      "[524/00775] train_loss: 0.012807\n",
      "[524/00825] train_loss: 0.013071\n",
      "[524/00875] train_loss: 0.012826\n",
      "[524/00925] train_loss: 0.013288\n",
      "[524/00975] train_loss: 0.012934\n",
      "[524/01025] train_loss: 0.013580\n",
      "[524/01075] train_loss: 0.013060\n",
      "[524/01125] train_loss: 0.013120\n",
      "[524/01175] train_loss: 0.012238\n",
      "[524/01225] train_loss: 0.012746\n",
      "[525/00049] train_loss: 0.015275\n",
      "[525/00099] train_loss: 0.013574\n",
      "[525/00149] train_loss: 0.013965\n",
      "[525/00199] train_loss: 0.013720\n",
      "[525/00249] train_loss: 0.012704\n",
      "[525/00299] train_loss: 0.013225\n",
      "[525/00349] train_loss: 0.013684\n",
      "[525/00399] train_loss: 0.013302\n",
      "[525/00449] train_loss: 0.012497\n",
      "[525/00499] train_loss: 0.012489\n",
      "[525/00549] train_loss: 0.013138\n",
      "[525/00599] train_loss: 0.013670\n",
      "[525/00649] train_loss: 0.013015\n",
      "[525/00699] train_loss: 0.012381\n",
      "[525/00749] train_loss: 0.013021\n",
      "[525/00799] train_loss: 0.012714\n",
      "[525/00849] train_loss: 0.012379\n",
      "[525/00899] train_loss: 0.012934\n",
      "[525/00949] train_loss: 0.013061\n",
      "[525/00999] train_loss: 0.012751\n",
      "[525/01049] train_loss: 0.013043\n",
      "[525/01099] train_loss: 0.012952\n",
      "[525/01149] train_loss: 0.011811\n",
      "[525/01199] train_loss: 0.013199\n",
      "[526/00023] train_loss: 0.014710\n",
      "[526/00073] train_loss: 0.015600\n",
      "[526/00123] train_loss: 0.013852\n",
      "[526/00173] train_loss: 0.013135\n",
      "[526/00223] train_loss: 0.013562\n",
      "[526/00273] train_loss: 0.012703\n",
      "[526/00323] train_loss: 0.013666\n",
      "[526/00373] train_loss: 0.013183\n",
      "[526/00423] train_loss: 0.012825\n",
      "[526/00473] train_loss: 0.012896\n",
      "[526/00523] train_loss: 0.011959\n",
      "[526/00573] train_loss: 0.013490\n",
      "[526/00623] train_loss: 0.012947\n",
      "[526/00673] train_loss: 0.013447\n",
      "[526/00723] train_loss: 0.012348\n",
      "[526/00773] train_loss: 0.012763\n",
      "[526/00823] train_loss: 0.012491\n",
      "[526/00873] train_loss: 0.012780\n",
      "[526/00923] train_loss: 0.012960\n",
      "[526/00973] train_loss: 0.013933\n",
      "[526/01023] train_loss: 0.013254\n",
      "[526/01073] train_loss: 0.013385\n",
      "[526/01123] train_loss: 0.012238\n",
      "[526/01173] train_loss: 0.013134\n",
      "[526/01223] train_loss: 0.012698\n",
      "[527/00047] train_loss: 0.014366\n",
      "[527/00097] train_loss: 0.014638\n",
      "[527/00147] train_loss: 0.013780\n",
      "[527/00197] train_loss: 0.013363\n",
      "[527/00247] train_loss: 0.012924\n",
      "[527/00297] train_loss: 0.012746\n",
      "[527/00347] train_loss: 0.012293\n",
      "[527/00397] train_loss: 0.013724\n",
      "[527/00447] train_loss: 0.012858\n",
      "[527/00497] train_loss: 0.012307\n",
      "[527/00547] train_loss: 0.012728\n",
      "[527/00597] train_loss: 0.011868\n",
      "[527/00647] train_loss: 0.012876\n",
      "[527/00697] train_loss: 0.013304\n",
      "[527/00747] train_loss: 0.013659\n",
      "[527/00797] train_loss: 0.013275\n",
      "[527/00847] train_loss: 0.013429\n",
      "[527/00897] train_loss: 0.013134\n",
      "[527/00947] train_loss: 0.012206\n",
      "[527/00997] train_loss: 0.013422\n",
      "[527/01047] train_loss: 0.013289\n",
      "[527/01097] train_loss: 0.012706\n",
      "[527/01147] train_loss: 0.013801\n",
      "[527/01197] train_loss: 0.013216\n",
      "[528/00021] train_loss: 0.014131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[528/00071] train_loss: 0.014735\n",
      "[528/00121] train_loss: 0.013385\n",
      "[528/00171] train_loss: 0.013469\n",
      "[528/00221] train_loss: 0.012829\n",
      "[528/00271] train_loss: 0.012841\n",
      "[528/00321] train_loss: 0.012773\n",
      "[528/00371] train_loss: 0.012188\n",
      "[528/00421] train_loss: 0.012182\n",
      "[528/00471] train_loss: 0.013507\n",
      "[528/00521] train_loss: 0.013532\n",
      "[528/00571] train_loss: 0.013535\n",
      "[528/00621] train_loss: 0.013280\n",
      "[528/00671] train_loss: 0.012988\n",
      "[528/00721] train_loss: 0.013503\n",
      "[528/00771] train_loss: 0.013331\n",
      "[528/00821] train_loss: 0.012318\n",
      "[528/00871] train_loss: 0.012593\n",
      "[528/00921] train_loss: 0.012807\n",
      "[528/00971] train_loss: 0.012604\n",
      "[528/01021] train_loss: 0.013122\n",
      "[528/01071] train_loss: 0.012748\n",
      "[528/01121] train_loss: 0.013175\n",
      "[528/01171] train_loss: 0.013383\n",
      "[528/01221] train_loss: 0.012983\n",
      "[529/00045] train_loss: 0.015602\n",
      "[529/00095] train_loss: 0.014847\n",
      "[529/00145] train_loss: 0.013882\n",
      "[529/00195] train_loss: 0.013474\n",
      "[529/00245] train_loss: 0.012402\n",
      "[529/00295] train_loss: 0.012461\n",
      "[529/00345] train_loss: 0.013176\n",
      "[529/00395] train_loss: 0.013341\n",
      "[529/00445] train_loss: 0.013348\n",
      "[529/00495] train_loss: 0.013148\n",
      "[529/00545] train_loss: 0.012527\n",
      "[529/00595] train_loss: 0.012206\n",
      "[529/00645] train_loss: 0.012100\n",
      "[529/00695] train_loss: 0.012546\n",
      "[529/00745] train_loss: 0.013744\n",
      "[529/00795] train_loss: 0.012420\n",
      "[529/00845] train_loss: 0.013277\n",
      "[529/00895] train_loss: 0.012671\n",
      "[529/00945] train_loss: 0.012854\n",
      "[529/00995] train_loss: 0.013021\n",
      "[529/01045] train_loss: 0.013022\n",
      "[529/01095] train_loss: 0.012419\n",
      "[529/01145] train_loss: 0.014093\n",
      "[529/01195] train_loss: 0.012767\n",
      "[530/00019] train_loss: 0.014898\n",
      "[530/00069] train_loss: 0.014469\n",
      "[530/00119] train_loss: 0.013524\n",
      "[530/00169] train_loss: 0.014082\n",
      "[530/00219] train_loss: 0.013959\n",
      "[530/00269] train_loss: 0.012850\n",
      "[530/00319] train_loss: 0.012457\n",
      "[530/00369] train_loss: 0.013380\n",
      "[530/00419] train_loss: 0.012572\n",
      "[530/00469] train_loss: 0.013144\n",
      "[530/00519] train_loss: 0.013369\n",
      "[530/00569] train_loss: 0.012963\n",
      "[530/00619] train_loss: 0.011815\n",
      "[530/00669] train_loss: 0.013064\n",
      "[530/00719] train_loss: 0.013394\n",
      "[530/00769] train_loss: 0.013299\n",
      "[530/00819] train_loss: 0.012212\n",
      "[530/00869] train_loss: 0.012894\n",
      "[530/00919] train_loss: 0.012804\n",
      "[530/00969] train_loss: 0.013171\n",
      "[530/01019] train_loss: 0.013161\n",
      "[530/01069] train_loss: 0.012680\n",
      "[530/01119] train_loss: 0.013751\n",
      "[530/01169] train_loss: 0.012758\n",
      "[530/01219] train_loss: 0.012655\n",
      "[531/00043] train_loss: 0.014349\n",
      "[531/00093] train_loss: 0.014237\n",
      "[531/00143] train_loss: 0.013074\n",
      "[531/00193] train_loss: 0.013562\n",
      "[531/00243] train_loss: 0.012681\n",
      "[531/00293] train_loss: 0.012763\n",
      "[531/00343] train_loss: 0.013073\n",
      "[531/00393] train_loss: 0.013214\n",
      "[531/00443] train_loss: 0.013272\n",
      "[531/00493] train_loss: 0.012514\n",
      "[531/00543] train_loss: 0.012144\n",
      "[531/00593] train_loss: 0.012828\n",
      "[531/00643] train_loss: 0.012436\n",
      "[531/00693] train_loss: 0.012930\n",
      "[531/00743] train_loss: 0.012914\n",
      "[531/00793] train_loss: 0.013399\n",
      "[531/00843] train_loss: 0.013010\n",
      "[531/00893] train_loss: 0.012773\n",
      "[531/00943] train_loss: 0.012688\n",
      "[531/00993] train_loss: 0.013743\n",
      "[531/01043] train_loss: 0.013015\n",
      "[531/01093] train_loss: 0.013352\n",
      "[531/01143] train_loss: 0.012966\n",
      "[531/01193] train_loss: 0.013110\n",
      "[532/00017] train_loss: 0.014574\n",
      "[532/00067] train_loss: 0.015368\n",
      "[532/00117] train_loss: 0.014173\n",
      "[532/00167] train_loss: 0.013099\n",
      "[532/00217] train_loss: 0.014179\n",
      "[532/00267] train_loss: 0.013521\n",
      "[532/00317] train_loss: 0.013466\n",
      "[532/00367] train_loss: 0.012692\n",
      "[532/00417] train_loss: 0.012766\n",
      "[532/00467] train_loss: 0.012816\n",
      "[532/00517] train_loss: 0.012838\n",
      "[532/00567] train_loss: 0.012635\n",
      "[532/00617] train_loss: 0.013423\n",
      "[532/00667] train_loss: 0.013098\n",
      "[532/00717] train_loss: 0.012813\n",
      "[532/00767] train_loss: 0.012778\n",
      "[532/00817] train_loss: 0.012349\n",
      "[532/00867] train_loss: 0.012779\n",
      "[532/00917] train_loss: 0.013178\n",
      "[532/00967] train_loss: 0.013191\n",
      "[532/01017] train_loss: 0.013175\n",
      "[532/01067] train_loss: 0.012806\n",
      "[532/01117] train_loss: 0.012948\n",
      "[532/01167] train_loss: 0.013222\n",
      "[532/01217] train_loss: 0.012727\n",
      "[533/00041] train_loss: 0.015327\n",
      "[533/00091] train_loss: 0.014591\n",
      "[533/00141] train_loss: 0.014186\n",
      "[533/00191] train_loss: 0.013094\n",
      "[533/00241] train_loss: 0.012767\n",
      "[533/00291] train_loss: 0.013771\n",
      "[533/00341] train_loss: 0.013029\n",
      "[533/00391] train_loss: 0.012983\n",
      "[533/00441] train_loss: 0.013401\n",
      "[533/00491] train_loss: 0.012600\n",
      "[533/00541] train_loss: 0.012989\n",
      "[533/00591] train_loss: 0.013096\n",
      "[533/00641] train_loss: 0.012259\n",
      "[533/00691] train_loss: 0.012718\n",
      "[533/00741] train_loss: 0.013137\n",
      "[533/00791] train_loss: 0.012941\n",
      "[533/00841] train_loss: 0.012063\n",
      "[533/00891] train_loss: 0.013468\n",
      "[533/00941] train_loss: 0.013584\n",
      "[533/00991] train_loss: 0.012619\n",
      "[533/01041] train_loss: 0.012342\n",
      "[533/01091] train_loss: 0.012983\n",
      "[533/01141] train_loss: 0.013309\n",
      "[533/01191] train_loss: 0.013106\n",
      "[534/00015] train_loss: 0.013812\n",
      "[534/00065] train_loss: 0.015201\n",
      "[534/00115] train_loss: 0.013544\n",
      "[534/00165] train_loss: 0.013468\n",
      "[534/00215] train_loss: 0.013440\n",
      "[534/00265] train_loss: 0.013266\n",
      "[534/00315] train_loss: 0.012890\n",
      "[534/00365] train_loss: 0.012645\n",
      "[534/00415] train_loss: 0.013083\n",
      "[534/00465] train_loss: 0.013300\n",
      "[534/00515] train_loss: 0.012444\n",
      "[534/00565] train_loss: 0.012874\n",
      "[534/00615] train_loss: 0.013156\n",
      "[534/00665] train_loss: 0.013265\n",
      "[534/00715] train_loss: 0.012395\n",
      "[534/00765] train_loss: 0.012667\n",
      "[534/00815] train_loss: 0.012705\n",
      "[534/00865] train_loss: 0.012732\n",
      "[534/00915] train_loss: 0.012602\n",
      "[534/00965] train_loss: 0.012868\n",
      "[534/01015] train_loss: 0.012802\n",
      "[534/01065] train_loss: 0.013600\n",
      "[534/01115] train_loss: 0.013868\n",
      "[534/01165] train_loss: 0.012459\n",
      "[534/01215] train_loss: 0.013232\n",
      "[535/00039] train_loss: 0.015169\n",
      "[535/00089] train_loss: 0.013918\n",
      "[535/00139] train_loss: 0.014079\n",
      "[535/00189] train_loss: 0.013642\n",
      "[535/00239] train_loss: 0.012868\n",
      "[535/00289] train_loss: 0.013196\n",
      "[535/00339] train_loss: 0.013024\n",
      "[535/00389] train_loss: 0.013529\n",
      "[535/00439] train_loss: 0.012870\n",
      "[535/00489] train_loss: 0.012852\n",
      "[535/00539] train_loss: 0.012778\n",
      "[535/00589] train_loss: 0.013059\n",
      "[535/00639] train_loss: 0.013302\n",
      "[535/00689] train_loss: 0.013640\n",
      "[535/00739] train_loss: 0.011898\n",
      "[535/00789] train_loss: 0.012668\n",
      "[535/00839] train_loss: 0.012528\n",
      "[535/00889] train_loss: 0.012568\n",
      "[535/00939] train_loss: 0.012495\n",
      "[535/00989] train_loss: 0.013189\n",
      "[535/01039] train_loss: 0.012714\n",
      "[535/01089] train_loss: 0.013632\n",
      "[535/01139] train_loss: 0.012651\n",
      "[535/01189] train_loss: 0.012254\n",
      "[536/00013] train_loss: 0.013844\n",
      "[536/00063] train_loss: 0.016115\n",
      "[536/00113] train_loss: 0.013927\n",
      "[536/00163] train_loss: 0.013893\n",
      "[536/00213] train_loss: 0.012805\n",
      "[536/00263] train_loss: 0.013434\n",
      "[536/00313] train_loss: 0.013179\n",
      "[536/00363] train_loss: 0.012590\n",
      "[536/00413] train_loss: 0.012622\n",
      "[536/00463] train_loss: 0.012645\n",
      "[536/00513] train_loss: 0.012787\n",
      "[536/00563] train_loss: 0.012933\n",
      "[536/00613] train_loss: 0.013595\n",
      "[536/00663] train_loss: 0.013225\n",
      "[536/00713] train_loss: 0.012845\n",
      "[536/00763] train_loss: 0.012738\n",
      "[536/00813] train_loss: 0.012734\n",
      "[536/00863] train_loss: 0.012573\n",
      "[536/00913] train_loss: 0.013111\n",
      "[536/00963] train_loss: 0.012784\n",
      "[536/01013] train_loss: 0.012620\n",
      "[536/01063] train_loss: 0.013141\n",
      "[536/01113] train_loss: 0.012972\n",
      "[536/01163] train_loss: 0.013038\n",
      "[536/01213] train_loss: 0.013338\n",
      "[537/00037] train_loss: 0.015390\n",
      "[537/00087] train_loss: 0.014487\n",
      "[537/00137] train_loss: 0.013191\n",
      "[537/00187] train_loss: 0.013761\n",
      "[537/00237] train_loss: 0.012765\n",
      "[537/00287] train_loss: 0.012775\n",
      "[537/00337] train_loss: 0.012889\n",
      "[537/00387] train_loss: 0.012369\n",
      "[537/00437] train_loss: 0.013102\n",
      "[537/00487] train_loss: 0.012801\n",
      "[537/00537] train_loss: 0.012851\n",
      "[537/00587] train_loss: 0.013425\n",
      "[537/00637] train_loss: 0.013544\n",
      "[537/00687] train_loss: 0.013798\n",
      "[537/00737] train_loss: 0.012195\n",
      "[537/00787] train_loss: 0.012829\n",
      "[537/00837] train_loss: 0.012391\n",
      "[537/00887] train_loss: 0.012801\n",
      "[537/00937] train_loss: 0.012949\n",
      "[537/00987] train_loss: 0.013362\n",
      "[537/01037] train_loss: 0.012318\n",
      "[537/01087] train_loss: 0.012186\n",
      "[537/01137] train_loss: 0.013264\n",
      "[537/01187] train_loss: 0.013548\n",
      "[538/00011] train_loss: 0.014423\n",
      "[538/00061] train_loss: 0.015390\n",
      "[538/00111] train_loss: 0.014518\n",
      "[538/00161] train_loss: 0.013025\n",
      "[538/00211] train_loss: 0.013022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[538/00261] train_loss: 0.014332\n",
      "[538/00311] train_loss: 0.013700\n",
      "[538/00361] train_loss: 0.012762\n",
      "[538/00411] train_loss: 0.012482\n",
      "[538/00461] train_loss: 0.013020\n",
      "[538/00511] train_loss: 0.012433\n",
      "[538/00561] train_loss: 0.012834\n",
      "[538/00611] train_loss: 0.012818\n",
      "[538/00661] train_loss: 0.012770\n",
      "[538/00711] train_loss: 0.013003\n",
      "[538/00761] train_loss: 0.013498\n",
      "[538/00811] train_loss: 0.012617\n",
      "[538/00861] train_loss: 0.012730\n",
      "[538/00911] train_loss: 0.013291\n",
      "[538/00961] train_loss: 0.013078\n",
      "[538/01011] train_loss: 0.012914\n",
      "[538/01061] train_loss: 0.013269\n",
      "[538/01111] train_loss: 0.013072\n",
      "[538/01161] train_loss: 0.012820\n",
      "[538/01211] train_loss: 0.012316\n",
      "[539/00035] train_loss: 0.014766\n",
      "[539/00085] train_loss: 0.014155\n",
      "[539/00135] train_loss: 0.013395\n",
      "[539/00185] train_loss: 0.013332\n",
      "[539/00235] train_loss: 0.013438\n",
      "[539/00285] train_loss: 0.012966\n",
      "[539/00335] train_loss: 0.012265\n",
      "[539/00385] train_loss: 0.013363\n",
      "[539/00435] train_loss: 0.013137\n",
      "[539/00485] train_loss: 0.013184\n",
      "[539/00535] train_loss: 0.012378\n",
      "[539/00585] train_loss: 0.012930\n",
      "[539/00635] train_loss: 0.013129\n",
      "[539/00685] train_loss: 0.013303\n",
      "[539/00735] train_loss: 0.012664\n",
      "[539/00785] train_loss: 0.013616\n",
      "[539/00835] train_loss: 0.012147\n",
      "[539/00885] train_loss: 0.012527\n",
      "[539/00935] train_loss: 0.012785\n",
      "[539/00985] train_loss: 0.012933\n",
      "[539/01035] train_loss: 0.012541\n",
      "[539/01085] train_loss: 0.012607\n",
      "[539/01135] train_loss: 0.013737\n",
      "[539/01185] train_loss: 0.013102\n",
      "[540/00009] train_loss: 0.013479\n",
      "[540/00059] train_loss: 0.015709\n",
      "[540/00109] train_loss: 0.014078\n",
      "[540/00159] train_loss: 0.013471\n",
      "[540/00209] train_loss: 0.014104\n",
      "[540/00259] train_loss: 0.012665\n",
      "[540/00309] train_loss: 0.012359\n",
      "[540/00359] train_loss: 0.013542\n",
      "[540/00409] train_loss: 0.013083\n",
      "[540/00459] train_loss: 0.012977\n",
      "[540/00509] train_loss: 0.012253\n",
      "[540/00559] train_loss: 0.013881\n",
      "[540/00609] train_loss: 0.012101\n",
      "[540/00659] train_loss: 0.012463\n",
      "[540/00709] train_loss: 0.012802\n",
      "[540/00759] train_loss: 0.013151\n",
      "[540/00809] train_loss: 0.013076\n",
      "[540/00859] train_loss: 0.012661\n",
      "[540/00909] train_loss: 0.012787\n",
      "[540/00959] train_loss: 0.013319\n",
      "[540/01009] train_loss: 0.013372\n",
      "[540/01059] train_loss: 0.013305\n",
      "[540/01109] train_loss: 0.012935\n",
      "[540/01159] train_loss: 0.012639\n",
      "[540/01209] train_loss: 0.012193\n",
      "[541/00033] train_loss: 0.015754\n",
      "[541/00083] train_loss: 0.014657\n",
      "[541/00133] train_loss: 0.013715\n",
      "[541/00183] train_loss: 0.013400\n",
      "[541/00233] train_loss: 0.013740\n",
      "[541/00283] train_loss: 0.012315\n",
      "[541/00333] train_loss: 0.012724\n",
      "[541/00383] train_loss: 0.012936\n",
      "[541/00433] train_loss: 0.012373\n",
      "[541/00483] train_loss: 0.013290\n",
      "[541/00533] train_loss: 0.012789\n",
      "[541/00583] train_loss: 0.013164\n",
      "[541/00633] train_loss: 0.013140\n",
      "[541/00683] train_loss: 0.012673\n",
      "[541/00733] train_loss: 0.013316\n",
      "[541/00783] train_loss: 0.013196\n",
      "[541/00833] train_loss: 0.012616\n",
      "[541/00883] train_loss: 0.012944\n",
      "[541/00933] train_loss: 0.012742\n",
      "[541/00983] train_loss: 0.013493\n",
      "[541/01033] train_loss: 0.012002\n",
      "[541/01083] train_loss: 0.012851\n",
      "[541/01133] train_loss: 0.012810\n",
      "[541/01183] train_loss: 0.013851\n",
      "[542/00007] train_loss: 0.012471\n",
      "[542/00057] train_loss: 0.016198\n",
      "[542/00107] train_loss: 0.014558\n",
      "[542/00157] train_loss: 0.014020\n",
      "[542/00207] train_loss: 0.013380\n",
      "[542/00257] train_loss: 0.012753\n",
      "[542/00307] train_loss: 0.013841\n",
      "[542/00357] train_loss: 0.012781\n",
      "[542/00407] train_loss: 0.012945\n",
      "[542/00457] train_loss: 0.012837\n",
      "[542/00507] train_loss: 0.013387\n",
      "[542/00557] train_loss: 0.013407\n",
      "[542/00607] train_loss: 0.012208\n",
      "[542/00657] train_loss: 0.012629\n",
      "[542/00707] train_loss: 0.012770\n",
      "[542/00757] train_loss: 0.011923\n",
      "[542/00807] train_loss: 0.012892\n",
      "[542/00857] train_loss: 0.013108\n",
      "[542/00907] train_loss: 0.013687\n",
      "[542/00957] train_loss: 0.013014\n",
      "[542/01007] train_loss: 0.012700\n",
      "[542/01057] train_loss: 0.013364\n",
      "[542/01107] train_loss: 0.013197\n",
      "[542/01157] train_loss: 0.012848\n",
      "[542/01207] train_loss: 0.012621\n",
      "[543/00031] train_loss: 0.014564\n",
      "[543/00081] train_loss: 0.014878\n",
      "[543/00131] train_loss: 0.013360\n",
      "[543/00181] train_loss: 0.013400\n",
      "[543/00231] train_loss: 0.012734\n",
      "[543/00281] train_loss: 0.013240\n",
      "[543/00331] train_loss: 0.012040\n",
      "[543/00381] train_loss: 0.012791\n",
      "[543/00431] train_loss: 0.013187\n",
      "[543/00481] train_loss: 0.013011\n",
      "[543/00531] train_loss: 0.012959\n",
      "[543/00581] train_loss: 0.013279\n",
      "[543/00631] train_loss: 0.013213\n",
      "[543/00681] train_loss: 0.012496\n",
      "[543/00731] train_loss: 0.012469\n",
      "[543/00781] train_loss: 0.012998\n",
      "[543/00831] train_loss: 0.013852\n",
      "[543/00881] train_loss: 0.012987\n",
      "[543/00931] train_loss: 0.013345\n",
      "[543/00981] train_loss: 0.013035\n",
      "[543/01031] train_loss: 0.013138\n",
      "[543/01081] train_loss: 0.013161\n",
      "[543/01131] train_loss: 0.013237\n",
      "[543/01181] train_loss: 0.013046\n",
      "[544/00005] train_loss: 0.013514\n",
      "[544/00055] train_loss: 0.015309\n",
      "[544/00105] train_loss: 0.015263\n",
      "[544/00155] train_loss: 0.014617\n",
      "[544/00205] train_loss: 0.012684\n",
      "[544/00255] train_loss: 0.013090\n",
      "[544/00305] train_loss: 0.013332\n",
      "[544/00355] train_loss: 0.013289\n",
      "[544/00405] train_loss: 0.012456\n",
      "[544/00455] train_loss: 0.013452\n",
      "[544/00505] train_loss: 0.012070\n",
      "[544/00555] train_loss: 0.012409\n",
      "[544/00605] train_loss: 0.012682\n",
      "[544/00655] train_loss: 0.013771\n",
      "[544/00705] train_loss: 0.013119\n",
      "[544/00755] train_loss: 0.012708\n",
      "[544/00805] train_loss: 0.012412\n",
      "[544/00855] train_loss: 0.011700\n",
      "[544/00905] train_loss: 0.013134\n",
      "[544/00955] train_loss: 0.013407\n",
      "[544/01005] train_loss: 0.012203\n",
      "[544/01055] train_loss: 0.012558\n",
      "[544/01105] train_loss: 0.012345\n",
      "[544/01155] train_loss: 0.013133\n",
      "[544/01205] train_loss: 0.012971\n",
      "[545/00029] train_loss: 0.015165\n",
      "[545/00079] train_loss: 0.015304\n",
      "[545/00129] train_loss: 0.014105\n",
      "[545/00179] train_loss: 0.013584\n",
      "[545/00229] train_loss: 0.012514\n",
      "[545/00279] train_loss: 0.012886\n",
      "[545/00329] train_loss: 0.012406\n",
      "[545/00379] train_loss: 0.012757\n",
      "[545/00429] train_loss: 0.011774\n",
      "[545/00479] train_loss: 0.013050\n",
      "[545/00529] train_loss: 0.012860\n",
      "[545/00579] train_loss: 0.012673\n",
      "[545/00629] train_loss: 0.012943\n",
      "[545/00679] train_loss: 0.012721\n",
      "[545/00729] train_loss: 0.012722\n",
      "[545/00779] train_loss: 0.013556\n",
      "[545/00829] train_loss: 0.013424\n",
      "[545/00879] train_loss: 0.013407\n",
      "[545/00929] train_loss: 0.013432\n",
      "[545/00979] train_loss: 0.013698\n",
      "[545/01029] train_loss: 0.012670\n",
      "[545/01079] train_loss: 0.012817\n",
      "[545/01129] train_loss: 0.012407\n",
      "[545/01179] train_loss: 0.012887\n",
      "[546/00003] train_loss: 0.013915\n",
      "[546/00053] train_loss: 0.016425\n",
      "[546/00103] train_loss: 0.014417\n",
      "[546/00153] train_loss: 0.013865\n",
      "[546/00203] train_loss: 0.013303\n",
      "[546/00253] train_loss: 0.012884\n",
      "[546/00303] train_loss: 0.012843\n",
      "[546/00353] train_loss: 0.012256\n",
      "[546/00403] train_loss: 0.012456\n",
      "[546/00453] train_loss: 0.013321\n",
      "[546/00503] train_loss: 0.012457\n",
      "[546/00553] train_loss: 0.013584\n",
      "[546/00603] train_loss: 0.012563\n",
      "[546/00653] train_loss: 0.012769\n",
      "[546/00703] train_loss: 0.012301\n",
      "[546/00753] train_loss: 0.013040\n",
      "[546/00803] train_loss: 0.012590\n",
      "[546/00853] train_loss: 0.013666\n",
      "[546/00903] train_loss: 0.012216\n",
      "[546/00953] train_loss: 0.012621\n",
      "[546/01003] train_loss: 0.012668\n",
      "[546/01053] train_loss: 0.013041\n",
      "[546/01103] train_loss: 0.013102\n",
      "[546/01153] train_loss: 0.013270\n",
      "[546/01203] train_loss: 0.012823\n",
      "[547/00027] train_loss: 0.015562\n",
      "[547/00077] train_loss: 0.014885\n",
      "[547/00127] train_loss: 0.013875\n",
      "[547/00177] train_loss: 0.013169\n",
      "[547/00227] train_loss: 0.012757\n",
      "[547/00277] train_loss: 0.012973\n",
      "[547/00327] train_loss: 0.012853\n",
      "[547/00377] train_loss: 0.012378\n",
      "[547/00427] train_loss: 0.012696\n",
      "[547/00477] train_loss: 0.013685\n",
      "[547/00527] train_loss: 0.013223\n",
      "[547/00577] train_loss: 0.012870\n",
      "[547/00627] train_loss: 0.013116\n",
      "[547/00677] train_loss: 0.013670\n",
      "[547/00727] train_loss: 0.012160\n",
      "[547/00777] train_loss: 0.013033\n",
      "[547/00827] train_loss: 0.014064\n",
      "[547/00877] train_loss: 0.012336\n",
      "[547/00927] train_loss: 0.012402\n",
      "[547/00977] train_loss: 0.012470\n",
      "[547/01027] train_loss: 0.012785\n",
      "[547/01077] train_loss: 0.012985\n",
      "[547/01127] train_loss: 0.013418\n",
      "[547/01177] train_loss: 0.012449\n",
      "[548/00001] train_loss: 0.013048\n",
      "[548/00051] train_loss: 0.016290\n",
      "[548/00101] train_loss: 0.013861\n",
      "[548/00151] train_loss: 0.013318\n",
      "[548/00201] train_loss: 0.012850\n",
      "[548/00251] train_loss: 0.013222\n",
      "[548/00301] train_loss: 0.013712\n",
      "[548/00351] train_loss: 0.013340\n",
      "[548/00401] train_loss: 0.012822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548/00451] train_loss: 0.012964\n",
      "[548/00501] train_loss: 0.012642\n",
      "[548/00551] train_loss: 0.011834\n",
      "[548/00601] train_loss: 0.013640\n",
      "[548/00651] train_loss: 0.013345\n",
      "[548/00701] train_loss: 0.012366\n",
      "[548/00751] train_loss: 0.012786\n",
      "[548/00801] train_loss: 0.012774\n",
      "[548/00851] train_loss: 0.013355\n",
      "[548/00901] train_loss: 0.012849\n",
      "[548/00951] train_loss: 0.013193\n",
      "[548/01001] train_loss: 0.013301\n",
      "[548/01051] train_loss: 0.013317\n",
      "[548/01101] train_loss: 0.013478\n",
      "[548/01151] train_loss: 0.012465\n",
      "[548/01201] train_loss: 0.012844\n",
      "[549/00025] train_loss: 0.013538\n",
      "[549/00075] train_loss: 0.015160\n",
      "[549/00125] train_loss: 0.014087\n",
      "[549/00175] train_loss: 0.013116\n",
      "[549/00225] train_loss: 0.012614\n",
      "[549/00275] train_loss: 0.012598\n",
      "[549/00325] train_loss: 0.013390\n",
      "[549/00375] train_loss: 0.012961\n",
      "[549/00425] train_loss: 0.012630\n",
      "[549/00475] train_loss: 0.013219\n",
      "[549/00525] train_loss: 0.013161\n",
      "[549/00575] train_loss: 0.012448\n",
      "[549/00625] train_loss: 0.012857\n",
      "[549/00675] train_loss: 0.013249\n",
      "[549/00725] train_loss: 0.012781\n",
      "[549/00775] train_loss: 0.013091\n",
      "[549/00825] train_loss: 0.013059\n",
      "[549/00875] train_loss: 0.012422\n",
      "[549/00925] train_loss: 0.012556\n",
      "[549/00975] train_loss: 0.013879\n",
      "[549/01025] train_loss: 0.013470\n",
      "[549/01075] train_loss: 0.012815\n",
      "[549/01125] train_loss: 0.013425\n",
      "[549/01175] train_loss: 0.013493\n",
      "[549/01225] train_loss: 0.012236\n",
      "[550/00049] train_loss: 0.015341\n",
      "[550/00099] train_loss: 0.014407\n",
      "[550/00149] train_loss: 0.014010\n",
      "[550/00199] train_loss: 0.014045\n",
      "[550/00249] train_loss: 0.013359\n",
      "[550/00299] train_loss: 0.012979\n",
      "[550/00349] train_loss: 0.013504\n",
      "[550/00399] train_loss: 0.012773\n",
      "[550/00449] train_loss: 0.012025\n",
      "[550/00499] train_loss: 0.012620\n",
      "[550/00549] train_loss: 0.013447\n",
      "[550/00599] train_loss: 0.012550\n",
      "[550/00649] train_loss: 0.013266\n",
      "[550/00699] train_loss: 0.012861\n",
      "[550/00749] train_loss: 0.012321\n",
      "[550/00799] train_loss: 0.012065\n",
      "[550/00849] train_loss: 0.012439\n",
      "[550/00899] train_loss: 0.012300\n",
      "[550/00949] train_loss: 0.012740\n",
      "[550/00999] train_loss: 0.013895\n",
      "[550/01049] train_loss: 0.012624\n",
      "[550/01099] train_loss: 0.012449\n",
      "[550/01149] train_loss: 0.013011\n",
      "[550/01199] train_loss: 0.013568\n",
      "[551/00023] train_loss: 0.014361\n",
      "[551/00073] train_loss: 0.014966\n",
      "[551/00123] train_loss: 0.014391\n",
      "[551/00173] train_loss: 0.013495\n",
      "[551/00223] train_loss: 0.012833\n",
      "[551/00273] train_loss: 0.012420\n",
      "[551/00323] train_loss: 0.014341\n",
      "[551/00373] train_loss: 0.012798\n",
      "[551/00423] train_loss: 0.012589\n",
      "[551/00473] train_loss: 0.012503\n",
      "[551/00523] train_loss: 0.012974\n",
      "[551/00573] train_loss: 0.013083\n",
      "[551/00623] train_loss: 0.013331\n",
      "[551/00673] train_loss: 0.012690\n",
      "[551/00723] train_loss: 0.013049\n",
      "[551/00773] train_loss: 0.012191\n",
      "[551/00823] train_loss: 0.012998\n",
      "[551/00873] train_loss: 0.013363\n",
      "[551/00923] train_loss: 0.012954\n",
      "[551/00973] train_loss: 0.012992\n",
      "[551/01023] train_loss: 0.013554\n",
      "[551/01073] train_loss: 0.012767\n",
      "[551/01123] train_loss: 0.013602\n",
      "[551/01173] train_loss: 0.012959\n",
      "[551/01223] train_loss: 0.012937\n",
      "[552/00047] train_loss: 0.015395\n",
      "[552/00097] train_loss: 0.013881\n",
      "[552/00147] train_loss: 0.013460\n",
      "[552/00197] train_loss: 0.012817\n",
      "[552/00247] train_loss: 0.013308\n",
      "[552/00297] train_loss: 0.013022\n",
      "[552/00347] train_loss: 0.012909\n",
      "[552/00397] train_loss: 0.013334\n",
      "[552/00447] train_loss: 0.012408\n",
      "[552/00497] train_loss: 0.013134\n",
      "[552/00547] train_loss: 0.012915\n",
      "[552/00597] train_loss: 0.012156\n",
      "[552/00647] train_loss: 0.012476\n",
      "[552/00697] train_loss: 0.012513\n",
      "[552/00747] train_loss: 0.012793\n",
      "[552/00797] train_loss: 0.012216\n",
      "[552/00847] train_loss: 0.012997\n",
      "[552/00897] train_loss: 0.013258\n",
      "[552/00947] train_loss: 0.013450\n",
      "[552/00997] train_loss: 0.013567\n",
      "[552/01047] train_loss: 0.012949\n",
      "[552/01097] train_loss: 0.013255\n",
      "[552/01147] train_loss: 0.013080\n",
      "[552/01197] train_loss: 0.012650\n",
      "[553/00021] train_loss: 0.014516\n",
      "[553/00071] train_loss: 0.015465\n",
      "[553/00121] train_loss: 0.013725\n",
      "[553/00171] train_loss: 0.013733\n",
      "[553/00221] train_loss: 0.012429\n",
      "[553/00271] train_loss: 0.012348\n",
      "[553/00321] train_loss: 0.012547\n",
      "[553/00371] train_loss: 0.013336\n",
      "[553/00421] train_loss: 0.012649\n",
      "[553/00471] train_loss: 0.013523\n",
      "[553/00521] train_loss: 0.013713\n",
      "[553/00571] train_loss: 0.012873\n",
      "[553/00621] train_loss: 0.013200\n",
      "[553/00671] train_loss: 0.013749\n",
      "[553/00721] train_loss: 0.012576\n",
      "[553/00771] train_loss: 0.013587\n",
      "[553/00821] train_loss: 0.012958\n",
      "[553/00871] train_loss: 0.013033\n",
      "[553/00921] train_loss: 0.012935\n",
      "[553/00971] train_loss: 0.012571\n",
      "[553/01021] train_loss: 0.012344\n",
      "[553/01071] train_loss: 0.012335\n",
      "[553/01121] train_loss: 0.013747\n",
      "[553/01171] train_loss: 0.012054\n",
      "[553/01221] train_loss: 0.012919\n",
      "[554/00045] train_loss: 0.015188\n",
      "[554/00095] train_loss: 0.014903\n",
      "[554/00145] train_loss: 0.013962\n",
      "[554/00195] train_loss: 0.013062\n",
      "[554/00245] train_loss: 0.012565\n",
      "[554/00295] train_loss: 0.012717\n",
      "[554/00345] train_loss: 0.012734\n",
      "[554/00395] train_loss: 0.012637\n",
      "[554/00445] train_loss: 0.012354\n",
      "[554/00495] train_loss: 0.012266\n",
      "[554/00545] train_loss: 0.013286\n",
      "[554/00595] train_loss: 0.012984\n",
      "[554/00645] train_loss: 0.012922\n",
      "[554/00695] train_loss: 0.012385\n",
      "[554/00745] train_loss: 0.012243\n",
      "[554/00795] train_loss: 0.012592\n",
      "[554/00845] train_loss: 0.013133\n",
      "[554/00895] train_loss: 0.013106\n",
      "[554/00945] train_loss: 0.013022\n",
      "[554/00995] train_loss: 0.012960\n",
      "[554/01045] train_loss: 0.013604\n",
      "[554/01095] train_loss: 0.013684\n",
      "[554/01145] train_loss: 0.013364\n",
      "[554/01195] train_loss: 0.012597\n",
      "[555/00019] train_loss: 0.014435\n",
      "[555/00069] train_loss: 0.014806\n",
      "[555/00119] train_loss: 0.014051\n",
      "[555/00169] train_loss: 0.013201\n",
      "[555/00219] train_loss: 0.013628\n",
      "[555/00269] train_loss: 0.013305\n",
      "[555/00319] train_loss: 0.012966\n",
      "[555/00369] train_loss: 0.013108\n",
      "[555/00419] train_loss: 0.013584\n",
      "[555/00469] train_loss: 0.012699\n",
      "[555/00519] train_loss: 0.012579\n",
      "[555/00569] train_loss: 0.012916\n",
      "[555/00619] train_loss: 0.012820\n",
      "[555/00669] train_loss: 0.012926\n",
      "[555/00719] train_loss: 0.012833\n",
      "[555/00769] train_loss: 0.012370\n",
      "[555/00819] train_loss: 0.013035\n",
      "[555/00869] train_loss: 0.012243\n",
      "[555/00919] train_loss: 0.012059\n",
      "[555/00969] train_loss: 0.013161\n",
      "[555/01019] train_loss: 0.013598\n",
      "[555/01069] train_loss: 0.013228\n",
      "[555/01119] train_loss: 0.013575\n",
      "[555/01169] train_loss: 0.012728\n",
      "[555/01219] train_loss: 0.013180\n",
      "[556/00043] train_loss: 0.015917\n",
      "[556/00093] train_loss: 0.014646\n",
      "[556/00143] train_loss: 0.014032\n",
      "[556/00193] train_loss: 0.012954\n",
      "[556/00243] train_loss: 0.013201\n",
      "[556/00293] train_loss: 0.013496\n",
      "[556/00343] train_loss: 0.012358\n",
      "[556/00393] train_loss: 0.013058\n",
      "[556/00443] train_loss: 0.013145\n",
      "[556/00493] train_loss: 0.012644\n",
      "[556/00543] train_loss: 0.012611\n",
      "[556/00593] train_loss: 0.013473\n",
      "[556/00643] train_loss: 0.013208\n",
      "[556/00693] train_loss: 0.012136\n",
      "[556/00743] train_loss: 0.012624\n",
      "[556/00793] train_loss: 0.012610\n",
      "[556/00843] train_loss: 0.013366\n",
      "[556/00893] train_loss: 0.012361\n",
      "[556/00943] train_loss: 0.012577\n",
      "[556/00993] train_loss: 0.012550\n",
      "[556/01043] train_loss: 0.013393\n",
      "[556/01093] train_loss: 0.012516\n",
      "[556/01143] train_loss: 0.012866\n",
      "[556/01193] train_loss: 0.014052\n",
      "[557/00017] train_loss: 0.013736\n",
      "[557/00067] train_loss: 0.015176\n",
      "[557/00117] train_loss: 0.014014\n",
      "[557/00167] train_loss: 0.013332\n",
      "[557/00217] train_loss: 0.013571\n",
      "[557/00267] train_loss: 0.012944\n",
      "[557/00317] train_loss: 0.012671\n",
      "[557/00367] train_loss: 0.013454\n",
      "[557/00417] train_loss: 0.012603\n",
      "[557/00467] train_loss: 0.012931\n",
      "[557/00517] train_loss: 0.013411\n",
      "[557/00567] train_loss: 0.012019\n",
      "[557/00617] train_loss: 0.013035\n",
      "[557/00667] train_loss: 0.012106\n",
      "[557/00717] train_loss: 0.012544\n",
      "[557/00767] train_loss: 0.012727\n",
      "[557/00817] train_loss: 0.012890\n",
      "[557/00867] train_loss: 0.013536\n",
      "[557/00917] train_loss: 0.012492\n",
      "[557/00967] train_loss: 0.013361\n",
      "[557/01017] train_loss: 0.013106\n",
      "[557/01067] train_loss: 0.013620\n",
      "[557/01117] train_loss: 0.012998\n",
      "[557/01167] train_loss: 0.012323\n",
      "[557/01217] train_loss: 0.013149\n",
      "[558/00041] train_loss: 0.016103\n",
      "[558/00091] train_loss: 0.014413\n",
      "[558/00141] train_loss: 0.013990\n",
      "[558/00191] train_loss: 0.013996\n",
      "[558/00241] train_loss: 0.012392\n",
      "[558/00291] train_loss: 0.012710\n",
      "[558/00341] train_loss: 0.013417\n",
      "[558/00391] train_loss: 0.013865\n",
      "[558/00441] train_loss: 0.013471\n",
      "[558/00491] train_loss: 0.012671\n",
      "[558/00541] train_loss: 0.012420\n",
      "[558/00591] train_loss: 0.012831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[558/00641] train_loss: 0.012863\n",
      "[558/00691] train_loss: 0.012903\n",
      "[558/00741] train_loss: 0.011595\n",
      "[558/00791] train_loss: 0.013132\n",
      "[558/00841] train_loss: 0.013105\n",
      "[558/00891] train_loss: 0.012793\n",
      "[558/00941] train_loss: 0.013179\n",
      "[558/00991] train_loss: 0.012407\n",
      "[558/01041] train_loss: 0.013618\n",
      "[558/01091] train_loss: 0.013005\n",
      "[558/01141] train_loss: 0.012853\n",
      "[558/01191] train_loss: 0.013119\n",
      "[559/00015] train_loss: 0.013110\n",
      "[559/00065] train_loss: 0.014864\n",
      "[559/00115] train_loss: 0.013976\n",
      "[559/00165] train_loss: 0.013424\n",
      "[559/00215] train_loss: 0.012770\n",
      "[559/00265] train_loss: 0.012920\n",
      "[559/00315] train_loss: 0.013027\n",
      "[559/00365] train_loss: 0.013341\n",
      "[559/00415] train_loss: 0.013145\n",
      "[559/00465] train_loss: 0.012998\n",
      "[559/00515] train_loss: 0.013384\n",
      "[559/00565] train_loss: 0.013142\n",
      "[559/00615] train_loss: 0.012487\n",
      "[559/00665] train_loss: 0.014022\n",
      "[559/00715] train_loss: 0.012543\n",
      "[559/00765] train_loss: 0.013652\n",
      "[559/00815] train_loss: 0.011959\n",
      "[559/00865] train_loss: 0.012969\n",
      "[559/00915] train_loss: 0.012705\n",
      "[559/00965] train_loss: 0.013336\n",
      "[559/01015] train_loss: 0.012420\n",
      "[559/01065] train_loss: 0.012956\n",
      "[559/01115] train_loss: 0.012883\n",
      "[559/01165] train_loss: 0.013260\n",
      "[559/01215] train_loss: 0.012914\n",
      "[560/00039] train_loss: 0.014660\n",
      "[560/00089] train_loss: 0.014353\n",
      "[560/00139] train_loss: 0.012999\n",
      "[560/00189] train_loss: 0.013625\n",
      "[560/00239] train_loss: 0.012661\n",
      "[560/00289] train_loss: 0.012900\n",
      "[560/00339] train_loss: 0.012872\n",
      "[560/00389] train_loss: 0.012804\n",
      "[560/00439] train_loss: 0.013726\n",
      "[560/00489] train_loss: 0.012738\n",
      "[560/00539] train_loss: 0.013191\n",
      "[560/00589] train_loss: 0.013556\n",
      "[560/00639] train_loss: 0.012532\n",
      "[560/00689] train_loss: 0.013397\n",
      "[560/00739] train_loss: 0.012948\n",
      "[560/00789] train_loss: 0.012971\n",
      "[560/00839] train_loss: 0.012616\n",
      "[560/00889] train_loss: 0.012859\n",
      "[560/00939] train_loss: 0.013013\n",
      "[560/00989] train_loss: 0.013038\n",
      "[560/01039] train_loss: 0.012721\n",
      "[560/01089] train_loss: 0.013954\n",
      "[560/01139] train_loss: 0.012694\n",
      "[560/01189] train_loss: 0.012136\n",
      "[561/00013] train_loss: 0.014550\n",
      "[561/00063] train_loss: 0.015077\n",
      "[561/00113] train_loss: 0.013618\n",
      "[561/00163] train_loss: 0.012860\n",
      "[561/00213] train_loss: 0.012913\n",
      "[561/00263] train_loss: 0.013931\n",
      "[561/00313] train_loss: 0.013169\n",
      "[561/00363] train_loss: 0.013422\n",
      "[561/00413] train_loss: 0.013393\n",
      "[561/00463] train_loss: 0.012484\n",
      "[561/00513] train_loss: 0.012245\n",
      "[561/00563] train_loss: 0.012992\n",
      "[561/00613] train_loss: 0.013280\n",
      "[561/00663] train_loss: 0.013452\n",
      "[561/00713] train_loss: 0.013383\n",
      "[561/00763] train_loss: 0.013753\n",
      "[561/00813] train_loss: 0.013390\n",
      "[561/00863] train_loss: 0.012537\n",
      "[561/00913] train_loss: 0.011986\n",
      "[561/00963] train_loss: 0.012552\n",
      "[561/01013] train_loss: 0.013084\n",
      "[561/01063] train_loss: 0.013383\n",
      "[561/01113] train_loss: 0.012920\n",
      "[561/01163] train_loss: 0.012852\n",
      "[561/01213] train_loss: 0.013157\n",
      "[562/00037] train_loss: 0.014405\n",
      "[562/00087] train_loss: 0.014413\n",
      "[562/00137] train_loss: 0.014219\n",
      "[562/00187] train_loss: 0.013152\n",
      "[562/00237] train_loss: 0.013084\n",
      "[562/00287] train_loss: 0.013331\n",
      "[562/00337] train_loss: 0.013032\n",
      "[562/00387] train_loss: 0.012194\n",
      "[562/00437] train_loss: 0.013087\n",
      "[562/00487] train_loss: 0.012775\n",
      "[562/00537] train_loss: 0.013276\n",
      "[562/00587] train_loss: 0.012830\n",
      "[562/00637] train_loss: 0.012247\n",
      "[562/00687] train_loss: 0.012886\n",
      "[562/00737] train_loss: 0.013057\n",
      "[562/00787] train_loss: 0.012943\n",
      "[562/00837] train_loss: 0.012882\n",
      "[562/00887] train_loss: 0.012727\n",
      "[562/00937] train_loss: 0.012803\n",
      "[562/00987] train_loss: 0.013299\n",
      "[562/01037] train_loss: 0.013817\n",
      "[562/01087] train_loss: 0.013539\n",
      "[562/01137] train_loss: 0.013338\n",
      "[562/01187] train_loss: 0.013389\n",
      "[563/00011] train_loss: 0.014244\n",
      "[563/00061] train_loss: 0.015282\n",
      "[563/00111] train_loss: 0.014054\n",
      "[563/00161] train_loss: 0.013189\n",
      "[563/00211] train_loss: 0.012709\n",
      "[563/00261] train_loss: 0.012497\n",
      "[563/00311] train_loss: 0.013380\n",
      "[563/00361] train_loss: 0.012868\n",
      "[563/00411] train_loss: 0.012803\n",
      "[563/00461] train_loss: 0.013085\n",
      "[563/00511] train_loss: 0.012451\n",
      "[563/00561] train_loss: 0.012931\n",
      "[563/00611] train_loss: 0.012169\n",
      "[563/00661] train_loss: 0.012330\n",
      "[563/00711] train_loss: 0.013146\n",
      "[563/00761] train_loss: 0.013100\n",
      "[563/00811] train_loss: 0.012928\n",
      "[563/00861] train_loss: 0.012598\n",
      "[563/00911] train_loss: 0.013053\n",
      "[563/00961] train_loss: 0.012907\n",
      "[563/01011] train_loss: 0.013209\n",
      "[563/01061] train_loss: 0.013042\n",
      "[563/01111] train_loss: 0.013654\n",
      "[563/01161] train_loss: 0.013752\n",
      "[563/01211] train_loss: 0.013288\n",
      "[564/00035] train_loss: 0.015636\n",
      "[564/00085] train_loss: 0.014510\n",
      "[564/00135] train_loss: 0.013184\n",
      "[564/00185] train_loss: 0.012977\n",
      "[564/00235] train_loss: 0.012664\n",
      "[564/00285] train_loss: 0.012334\n",
      "[564/00335] train_loss: 0.013239\n",
      "[564/00385] train_loss: 0.013090\n",
      "[564/00435] train_loss: 0.012669\n",
      "[564/00485] train_loss: 0.012713\n",
      "[564/00535] train_loss: 0.013218\n",
      "[564/00585] train_loss: 0.012434\n",
      "[564/00635] train_loss: 0.012696\n",
      "[564/00685] train_loss: 0.013033\n",
      "[564/00735] train_loss: 0.013088\n",
      "[564/00785] train_loss: 0.011912\n",
      "[564/00835] train_loss: 0.013267\n",
      "[564/00885] train_loss: 0.012869\n",
      "[564/00935] train_loss: 0.012885\n",
      "[564/00985] train_loss: 0.012992\n",
      "[564/01035] train_loss: 0.013368\n",
      "[564/01085] train_loss: 0.013677\n",
      "[564/01135] train_loss: 0.012692\n",
      "[564/01185] train_loss: 0.013022\n",
      "[565/00009] train_loss: 0.013580\n",
      "[565/00059] train_loss: 0.015103\n",
      "[565/00109] train_loss: 0.014501\n",
      "[565/00159] train_loss: 0.013192\n",
      "[565/00209] train_loss: 0.013688\n",
      "[565/00259] train_loss: 0.012972\n",
      "[565/00309] train_loss: 0.013683\n",
      "[565/00359] train_loss: 0.012404\n",
      "[565/00409] train_loss: 0.013480\n",
      "[565/00459] train_loss: 0.012364\n",
      "[565/00509] train_loss: 0.012339\n",
      "[565/00559] train_loss: 0.012803\n",
      "[565/00609] train_loss: 0.013940\n",
      "[565/00659] train_loss: 0.012915\n",
      "[565/00709] train_loss: 0.012532\n",
      "[565/00759] train_loss: 0.012975\n",
      "[565/00809] train_loss: 0.013205\n",
      "[565/00859] train_loss: 0.012607\n",
      "[565/00909] train_loss: 0.011843\n",
      "[565/00959] train_loss: 0.013071\n",
      "[565/01009] train_loss: 0.013102\n",
      "[565/01059] train_loss: 0.012992\n",
      "[565/01109] train_loss: 0.013714\n",
      "[565/01159] train_loss: 0.013616\n",
      "[565/01209] train_loss: 0.012936\n",
      "[566/00033] train_loss: 0.016085\n",
      "[566/00083] train_loss: 0.015246\n",
      "[566/00133] train_loss: 0.013876\n",
      "[566/00183] train_loss: 0.012920\n",
      "[566/00233] train_loss: 0.013675\n",
      "[566/00283] train_loss: 0.013072\n",
      "[566/00333] train_loss: 0.012886\n",
      "[566/00383] train_loss: 0.012212\n",
      "[566/00433] train_loss: 0.013173\n",
      "[566/00483] train_loss: 0.012606\n",
      "[566/00533] train_loss: 0.012568\n",
      "[566/00583] train_loss: 0.012462\n",
      "[566/00633] train_loss: 0.013062\n",
      "[566/00683] train_loss: 0.013244\n",
      "[566/00733] train_loss: 0.012637\n",
      "[566/00783] train_loss: 0.012545\n",
      "[566/00833] train_loss: 0.012235\n",
      "[566/00883] train_loss: 0.013013\n",
      "[566/00933] train_loss: 0.013464\n",
      "[566/00983] train_loss: 0.012313\n",
      "[566/01033] train_loss: 0.013969\n",
      "[566/01083] train_loss: 0.012559\n",
      "[566/01133] train_loss: 0.012284\n",
      "[566/01183] train_loss: 0.013097\n",
      "[567/00007] train_loss: 0.014233\n",
      "[567/00057] train_loss: 0.016269\n",
      "[567/00107] train_loss: 0.014402\n",
      "[567/00157] train_loss: 0.013480\n",
      "[567/00207] train_loss: 0.012579\n",
      "[567/00257] train_loss: 0.012159\n",
      "[567/00307] train_loss: 0.012347\n",
      "[567/00357] train_loss: 0.013255\n",
      "[567/00407] train_loss: 0.012835\n",
      "[567/00457] train_loss: 0.013410\n",
      "[567/00507] train_loss: 0.012939\n",
      "[567/00557] train_loss: 0.013171\n",
      "[567/00607] train_loss: 0.012610\n",
      "[567/00657] train_loss: 0.013320\n",
      "[567/00707] train_loss: 0.012509\n",
      "[567/00757] train_loss: 0.011975\n",
      "[567/00807] train_loss: 0.012910\n",
      "[567/00857] train_loss: 0.013581\n",
      "[567/00907] train_loss: 0.013690\n",
      "[567/00957] train_loss: 0.013770\n",
      "[567/01007] train_loss: 0.012296\n",
      "[567/01057] train_loss: 0.012532\n",
      "[567/01107] train_loss: 0.013949\n",
      "[567/01157] train_loss: 0.012503\n",
      "[567/01207] train_loss: 0.012714\n",
      "[568/00031] train_loss: 0.014381\n",
      "[568/00081] train_loss: 0.014345\n",
      "[568/00131] train_loss: 0.013854\n",
      "[568/00181] train_loss: 0.014621\n",
      "[568/00231] train_loss: 0.012572\n",
      "[568/00281] train_loss: 0.013645\n",
      "[568/00331] train_loss: 0.012776\n",
      "[568/00381] train_loss: 0.012312\n",
      "[568/00431] train_loss: 0.012920\n",
      "[568/00481] train_loss: 0.013659\n",
      "[568/00531] train_loss: 0.012105\n",
      "[568/00581] train_loss: 0.013744\n",
      "[568/00631] train_loss: 0.012844\n",
      "[568/00681] train_loss: 0.013055\n",
      "[568/00731] train_loss: 0.012328\n",
      "[568/00781] train_loss: 0.012359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[568/00831] train_loss: 0.013349\n",
      "[568/00881] train_loss: 0.012756\n",
      "[568/00931] train_loss: 0.013005\n",
      "[568/00981] train_loss: 0.012802\n",
      "[568/01031] train_loss: 0.013386\n",
      "[568/01081] train_loss: 0.012853\n",
      "[568/01131] train_loss: 0.013054\n",
      "[568/01181] train_loss: 0.013397\n",
      "[569/00005] train_loss: 0.012984\n",
      "[569/00055] train_loss: 0.016490\n",
      "[569/00105] train_loss: 0.015092\n",
      "[569/00155] train_loss: 0.013892\n",
      "[569/00205] train_loss: 0.013579\n",
      "[569/00255] train_loss: 0.013340\n",
      "[569/00305] train_loss: 0.012755\n",
      "[569/00355] train_loss: 0.012567\n",
      "[569/00405] train_loss: 0.012880\n",
      "[569/00455] train_loss: 0.013613\n",
      "[569/00505] train_loss: 0.012494\n",
      "[569/00555] train_loss: 0.013194\n",
      "[569/00605] train_loss: 0.012131\n",
      "[569/00655] train_loss: 0.013466\n",
      "[569/00705] train_loss: 0.013320\n",
      "[569/00755] train_loss: 0.012925\n",
      "[569/00805] train_loss: 0.013420\n",
      "[569/00855] train_loss: 0.012921\n",
      "[569/00905] train_loss: 0.013457\n",
      "[569/00955] train_loss: 0.012436\n",
      "[569/01005] train_loss: 0.012004\n",
      "[569/01055] train_loss: 0.012149\n",
      "[569/01105] train_loss: 0.013177\n",
      "[569/01155] train_loss: 0.012260\n",
      "[569/01205] train_loss: 0.012368\n",
      "[570/00029] train_loss: 0.014392\n",
      "[570/00079] train_loss: 0.015269\n",
      "[570/00129] train_loss: 0.014199\n",
      "[570/00179] train_loss: 0.012996\n",
      "[570/00229] train_loss: 0.013364\n",
      "[570/00279] train_loss: 0.012702\n",
      "[570/00329] train_loss: 0.013173\n",
      "[570/00379] train_loss: 0.012641\n",
      "[570/00429] train_loss: 0.013131\n",
      "[570/00479] train_loss: 0.012621\n",
      "[570/00529] train_loss: 0.013261\n",
      "[570/00579] train_loss: 0.012853\n",
      "[570/00629] train_loss: 0.012617\n",
      "[570/00679] train_loss: 0.013140\n",
      "[570/00729] train_loss: 0.012768\n",
      "[570/00779] train_loss: 0.012668\n",
      "[570/00829] train_loss: 0.012967\n",
      "[570/00879] train_loss: 0.013308\n",
      "[570/00929] train_loss: 0.012567\n",
      "[570/00979] train_loss: 0.012367\n",
      "[570/01029] train_loss: 0.012669\n",
      "[570/01079] train_loss: 0.013367\n",
      "[570/01129] train_loss: 0.012381\n",
      "[570/01179] train_loss: 0.013382\n",
      "[571/00003] train_loss: 0.012489\n",
      "[571/00053] train_loss: 0.015873\n",
      "[571/00103] train_loss: 0.015221\n",
      "[571/00153] train_loss: 0.013216\n",
      "[571/00203] train_loss: 0.013571\n",
      "[571/00253] train_loss: 0.012416\n",
      "[571/00303] train_loss: 0.013274\n",
      "[571/00353] train_loss: 0.013818\n",
      "[571/00403] train_loss: 0.013649\n",
      "[571/00453] train_loss: 0.012637\n",
      "[571/00503] train_loss: 0.013055\n",
      "[571/00553] train_loss: 0.013059\n",
      "[571/00603] train_loss: 0.012727\n",
      "[571/00653] train_loss: 0.012093\n",
      "[571/00703] train_loss: 0.012746\n",
      "[571/00753] train_loss: 0.012983\n",
      "[571/00803] train_loss: 0.012887\n",
      "[571/00853] train_loss: 0.013138\n",
      "[571/00903] train_loss: 0.012498\n",
      "[571/00953] train_loss: 0.012317\n",
      "[571/01003] train_loss: 0.013031\n",
      "[571/01053] train_loss: 0.012525\n",
      "[571/01103] train_loss: 0.013377\n",
      "[571/01153] train_loss: 0.013123\n",
      "[571/01203] train_loss: 0.012859\n",
      "[572/00027] train_loss: 0.014526\n",
      "[572/00077] train_loss: 0.015376\n",
      "[572/00127] train_loss: 0.013838\n",
      "[572/00177] train_loss: 0.012748\n",
      "[572/00227] train_loss: 0.012651\n",
      "[572/00277] train_loss: 0.013458\n",
      "[572/00327] train_loss: 0.013776\n",
      "[572/00377] train_loss: 0.013036\n",
      "[572/00427] train_loss: 0.012891\n",
      "[572/00477] train_loss: 0.012779\n",
      "[572/00527] train_loss: 0.012561\n",
      "[572/00577] train_loss: 0.012838\n",
      "[572/00627] train_loss: 0.011556\n",
      "[572/00677] train_loss: 0.012256\n",
      "[572/00727] train_loss: 0.014004\n",
      "[572/00777] train_loss: 0.012406\n",
      "[572/00827] train_loss: 0.012806\n",
      "[572/00877] train_loss: 0.013414\n",
      "[572/00927] train_loss: 0.013291\n",
      "[572/00977] train_loss: 0.014009\n",
      "[572/01027] train_loss: 0.012579\n",
      "[572/01077] train_loss: 0.012804\n",
      "[572/01127] train_loss: 0.013066\n",
      "[572/01177] train_loss: 0.013187\n",
      "[573/00001] train_loss: 0.013043\n",
      "[573/00051] train_loss: 0.016628\n",
      "[573/00101] train_loss: 0.013731\n",
      "[573/00151] train_loss: 0.013539\n",
      "[573/00201] train_loss: 0.013297\n",
      "[573/00251] train_loss: 0.012951\n",
      "[573/00301] train_loss: 0.012888\n",
      "[573/00351] train_loss: 0.013650\n",
      "[573/00401] train_loss: 0.012462\n",
      "[573/00451] train_loss: 0.012559\n",
      "[573/00501] train_loss: 0.012749\n",
      "[573/00551] train_loss: 0.012308\n",
      "[573/00601] train_loss: 0.013628\n",
      "[573/00651] train_loss: 0.013259\n",
      "[573/00701] train_loss: 0.013424\n",
      "[573/00751] train_loss: 0.013267\n",
      "[573/00801] train_loss: 0.012903\n",
      "[573/00851] train_loss: 0.012165\n",
      "[573/00901] train_loss: 0.012828\n",
      "[573/00951] train_loss: 0.012178\n",
      "[573/01001] train_loss: 0.012776\n",
      "[573/01051] train_loss: 0.013283\n",
      "[573/01101] train_loss: 0.013131\n",
      "[573/01151] train_loss: 0.013536\n",
      "[573/01201] train_loss: 0.011988\n",
      "[574/00025] train_loss: 0.014653\n",
      "[574/00075] train_loss: 0.014222\n",
      "[574/00125] train_loss: 0.014147\n",
      "[574/00175] train_loss: 0.013445\n",
      "[574/00225] train_loss: 0.013304\n",
      "[574/00275] train_loss: 0.013305\n",
      "[574/00325] train_loss: 0.012221\n",
      "[574/00375] train_loss: 0.012473\n",
      "[574/00425] train_loss: 0.012244\n",
      "[574/00475] train_loss: 0.013353\n",
      "[574/00525] train_loss: 0.012719\n",
      "[574/00575] train_loss: 0.012425\n",
      "[574/00625] train_loss: 0.013392\n",
      "[574/00675] train_loss: 0.012499\n",
      "[574/00725] train_loss: 0.013185\n",
      "[574/00775] train_loss: 0.012647\n",
      "[574/00825] train_loss: 0.012973\n",
      "[574/00875] train_loss: 0.013042\n",
      "[574/00925] train_loss: 0.013308\n",
      "[574/00975] train_loss: 0.013385\n",
      "[574/01025] train_loss: 0.012455\n",
      "[574/01075] train_loss: 0.012883\n",
      "[574/01125] train_loss: 0.012536\n",
      "[574/01175] train_loss: 0.012814\n",
      "[574/01225] train_loss: 0.013348\n",
      "[575/00049] train_loss: 0.016217\n",
      "[575/00099] train_loss: 0.014414\n",
      "[575/00149] train_loss: 0.014157\n",
      "[575/00199] train_loss: 0.012458\n",
      "[575/00249] train_loss: 0.013432\n",
      "[575/00299] train_loss: 0.012756\n",
      "[575/00349] train_loss: 0.012949\n",
      "[575/00399] train_loss: 0.012563\n",
      "[575/00449] train_loss: 0.012737\n",
      "[575/00499] train_loss: 0.012790\n",
      "[575/00549] train_loss: 0.012553\n",
      "[575/00599] train_loss: 0.012586\n",
      "[575/00649] train_loss: 0.012525\n",
      "[575/00699] train_loss: 0.013568\n",
      "[575/00749] train_loss: 0.012589\n",
      "[575/00799] train_loss: 0.013035\n",
      "[575/00849] train_loss: 0.012690\n",
      "[575/00899] train_loss: 0.012566\n",
      "[575/00949] train_loss: 0.013676\n",
      "[575/00999] train_loss: 0.013238\n",
      "[575/01049] train_loss: 0.012553\n",
      "[575/01099] train_loss: 0.013236\n",
      "[575/01149] train_loss: 0.013300\n",
      "[575/01199] train_loss: 0.013134\n",
      "[576/00023] train_loss: 0.014373\n",
      "[576/00073] train_loss: 0.015086\n",
      "[576/00123] train_loss: 0.014553\n",
      "[576/00173] train_loss: 0.013375\n",
      "[576/00223] train_loss: 0.013545\n",
      "[576/00273] train_loss: 0.012481\n",
      "[576/00323] train_loss: 0.012662\n",
      "[576/00373] train_loss: 0.013328\n",
      "[576/00423] train_loss: 0.012829\n",
      "[576/00473] train_loss: 0.013200\n",
      "[576/00523] train_loss: 0.013340\n",
      "[576/00573] train_loss: 0.013512\n",
      "[576/00623] train_loss: 0.013049\n",
      "[576/00673] train_loss: 0.013620\n",
      "[576/00723] train_loss: 0.012435\n",
      "[576/00773] train_loss: 0.012447\n",
      "[576/00823] train_loss: 0.011994\n",
      "[576/00873] train_loss: 0.013356\n",
      "[576/00923] train_loss: 0.013856\n",
      "[576/00973] train_loss: 0.013254\n",
      "[576/01023] train_loss: 0.012796\n",
      "[576/01073] train_loss: 0.012538\n",
      "[576/01123] train_loss: 0.012379\n",
      "[576/01173] train_loss: 0.012609\n",
      "[576/01223] train_loss: 0.012791\n",
      "[577/00047] train_loss: 0.015549\n",
      "[577/00097] train_loss: 0.014298\n",
      "[577/00147] train_loss: 0.012947\n",
      "[577/00197] train_loss: 0.013301\n",
      "[577/00247] train_loss: 0.012996\n",
      "[577/00297] train_loss: 0.012909\n",
      "[577/00347] train_loss: 0.013510\n",
      "[577/00397] train_loss: 0.013445\n",
      "[577/00447] train_loss: 0.013136\n",
      "[577/00497] train_loss: 0.012798\n",
      "[577/00547] train_loss: 0.013406\n",
      "[577/00597] train_loss: 0.012139\n",
      "[577/00647] train_loss: 0.012859\n",
      "[577/00697] train_loss: 0.013704\n",
      "[577/00747] train_loss: 0.012701\n",
      "[577/00797] train_loss: 0.012771\n",
      "[577/00847] train_loss: 0.012811\n",
      "[577/00897] train_loss: 0.013149\n",
      "[577/00947] train_loss: 0.012581\n",
      "[577/00997] train_loss: 0.012894\n",
      "[577/01047] train_loss: 0.012857\n",
      "[577/01097] train_loss: 0.012793\n",
      "[577/01147] train_loss: 0.012720\n",
      "[577/01197] train_loss: 0.013098\n",
      "[578/00021] train_loss: 0.014786\n",
      "[578/00071] train_loss: 0.014913\n",
      "[578/00121] train_loss: 0.014576\n",
      "[578/00171] train_loss: 0.013712\n",
      "[578/00221] train_loss: 0.012798\n",
      "[578/00271] train_loss: 0.011638\n",
      "[578/00321] train_loss: 0.012829\n",
      "[578/00371] train_loss: 0.012859\n",
      "[578/00421] train_loss: 0.013626\n",
      "[578/00471] train_loss: 0.012946\n",
      "[578/00521] train_loss: 0.012935\n",
      "[578/00571] train_loss: 0.011687\n",
      "[578/00621] train_loss: 0.012444\n",
      "[578/00671] train_loss: 0.013497\n",
      "[578/00721] train_loss: 0.013285\n",
      "[578/00771] train_loss: 0.012485\n",
      "[578/00821] train_loss: 0.012807\n",
      "[578/00871] train_loss: 0.013050\n",
      "[578/00921] train_loss: 0.012497\n",
      "[578/00971] train_loss: 0.013166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[578/01021] train_loss: 0.013238\n",
      "[578/01071] train_loss: 0.012653\n",
      "[578/01121] train_loss: 0.013119\n",
      "[578/01171] train_loss: 0.013105\n",
      "[578/01221] train_loss: 0.013189\n",
      "[579/00045] train_loss: 0.014895\n",
      "[579/00095] train_loss: 0.014487\n",
      "[579/00145] train_loss: 0.013930\n",
      "[579/00195] train_loss: 0.013503\n",
      "[579/00245] train_loss: 0.012967\n",
      "[579/00295] train_loss: 0.013147\n",
      "[579/00345] train_loss: 0.012913\n",
      "[579/00395] train_loss: 0.013635\n",
      "[579/00445] train_loss: 0.012840\n",
      "[579/00495] train_loss: 0.012780\n",
      "[579/00545] train_loss: 0.013443\n",
      "[579/00595] train_loss: 0.012369\n",
      "[579/00645] train_loss: 0.012884\n",
      "[579/00695] train_loss: 0.013182\n",
      "[579/00745] train_loss: 0.012748\n",
      "[579/00795] train_loss: 0.012315\n",
      "[579/00845] train_loss: 0.012727\n",
      "[579/00895] train_loss: 0.014099\n",
      "[579/00945] train_loss: 0.012761\n",
      "[579/00995] train_loss: 0.012885\n",
      "[579/01045] train_loss: 0.012528\n",
      "[579/01095] train_loss: 0.013477\n",
      "[579/01145] train_loss: 0.013255\n",
      "[579/01195] train_loss: 0.012463\n",
      "[580/00019] train_loss: 0.014388\n",
      "[580/00069] train_loss: 0.015422\n",
      "[580/00119] train_loss: 0.014149\n",
      "[580/00169] train_loss: 0.013216\n",
      "[580/00219] train_loss: 0.013638\n",
      "[580/00269] train_loss: 0.013359\n",
      "[580/00319] train_loss: 0.012914\n",
      "[580/00369] train_loss: 0.012186\n",
      "[580/00419] train_loss: 0.012857\n",
      "[580/00469] train_loss: 0.012885\n",
      "[580/00519] train_loss: 0.012937\n",
      "[580/00569] train_loss: 0.013021\n",
      "[580/00619] train_loss: 0.013584\n",
      "[580/00669] train_loss: 0.013359\n",
      "[580/00719] train_loss: 0.012875\n",
      "[580/00769] train_loss: 0.013186\n",
      "[580/00819] train_loss: 0.013179\n",
      "[580/00869] train_loss: 0.012516\n",
      "[580/00919] train_loss: 0.012769\n",
      "[580/00969] train_loss: 0.013015\n",
      "[580/01019] train_loss: 0.012045\n",
      "[580/01069] train_loss: 0.012633\n",
      "[580/01119] train_loss: 0.012561\n",
      "[580/01169] train_loss: 0.012105\n",
      "[580/01219] train_loss: 0.013184\n",
      "[581/00043] train_loss: 0.015212\n",
      "[581/00093] train_loss: 0.014889\n",
      "[581/00143] train_loss: 0.013761\n",
      "[581/00193] train_loss: 0.013732\n",
      "[581/00243] train_loss: 0.012379\n",
      "[581/00293] train_loss: 0.012673\n",
      "[581/00343] train_loss: 0.013004\n",
      "[581/00393] train_loss: 0.012249\n",
      "[581/00443] train_loss: 0.012862\n",
      "[581/00493] train_loss: 0.012705\n",
      "[581/00543] train_loss: 0.012706\n",
      "[581/00593] train_loss: 0.012568\n",
      "[581/00643] train_loss: 0.012988\n",
      "[581/00693] train_loss: 0.013087\n",
      "[581/00743] train_loss: 0.012885\n",
      "[581/00793] train_loss: 0.012916\n",
      "[581/00843] train_loss: 0.013199\n",
      "[581/00893] train_loss: 0.012569\n",
      "[581/00943] train_loss: 0.013056\n",
      "[581/00993] train_loss: 0.012670\n",
      "[581/01043] train_loss: 0.013428\n",
      "[581/01093] train_loss: 0.012574\n",
      "[581/01143] train_loss: 0.013831\n",
      "[581/01193] train_loss: 0.012412\n",
      "[582/00017] train_loss: 0.014802\n",
      "[582/00067] train_loss: 0.015675\n",
      "[582/00117] train_loss: 0.014167\n",
      "[582/00167] train_loss: 0.013701\n",
      "[582/00217] train_loss: 0.013256\n",
      "[582/00267] train_loss: 0.012942\n",
      "[582/00317] train_loss: 0.013250\n",
      "[582/00367] train_loss: 0.012837\n",
      "[582/00417] train_loss: 0.013247\n",
      "[582/00467] train_loss: 0.012234\n",
      "[582/00517] train_loss: 0.012394\n",
      "[582/00567] train_loss: 0.012992\n",
      "[582/00617] train_loss: 0.012095\n",
      "[582/00667] train_loss: 0.013130\n",
      "[582/00717] train_loss: 0.012496\n",
      "[582/00767] train_loss: 0.012793\n",
      "[582/00817] train_loss: 0.013090\n",
      "[582/00867] train_loss: 0.012910\n",
      "[582/00917] train_loss: 0.013297\n",
      "[582/00967] train_loss: 0.012713\n",
      "[582/01017] train_loss: 0.012576\n",
      "[582/01067] train_loss: 0.013038\n",
      "[582/01117] train_loss: 0.012924\n",
      "[582/01167] train_loss: 0.013464\n",
      "[582/01217] train_loss: 0.012410\n",
      "[583/00041] train_loss: 0.015975\n",
      "[583/00091] train_loss: 0.014916\n",
      "[583/00141] train_loss: 0.013257\n",
      "[583/00191] train_loss: 0.013467\n",
      "[583/00241] train_loss: 0.013174\n",
      "[583/00291] train_loss: 0.013733\n",
      "[583/00341] train_loss: 0.012676\n",
      "[583/00391] train_loss: 0.012598\n",
      "[583/00441] train_loss: 0.013412\n",
      "[583/00491] train_loss: 0.013215\n",
      "[583/00541] train_loss: 0.012579\n",
      "[583/00591] train_loss: 0.012891\n",
      "[583/00641] train_loss: 0.012386\n",
      "[583/00691] train_loss: 0.012583\n",
      "[583/00741] train_loss: 0.012751\n",
      "[583/00791] train_loss: 0.013070\n",
      "[583/00841] train_loss: 0.013048\n",
      "[583/00891] train_loss: 0.012220\n",
      "[583/00941] train_loss: 0.012694\n",
      "[583/00991] train_loss: 0.013121\n",
      "[583/01041] train_loss: 0.013122\n",
      "[583/01091] train_loss: 0.013002\n",
      "[583/01141] train_loss: 0.012503\n",
      "[583/01191] train_loss: 0.012757\n",
      "[584/00015] train_loss: 0.014626\n",
      "[584/00065] train_loss: 0.015056\n",
      "[584/00115] train_loss: 0.013769\n",
      "[584/00165] train_loss: 0.013277\n",
      "[584/00215] train_loss: 0.012887\n",
      "[584/00265] train_loss: 0.012495\n",
      "[584/00315] train_loss: 0.012412\n",
      "[584/00365] train_loss: 0.013825\n",
      "[584/00415] train_loss: 0.013408\n",
      "[584/00465] train_loss: 0.013466\n",
      "[584/00515] train_loss: 0.013176\n",
      "[584/00565] train_loss: 0.013413\n",
      "[584/00615] train_loss: 0.012950\n",
      "[584/00665] train_loss: 0.012725\n",
      "[584/00715] train_loss: 0.012238\n",
      "[584/00765] train_loss: 0.012493\n",
      "[584/00815] train_loss: 0.013357\n",
      "[584/00865] train_loss: 0.013044\n",
      "[584/00915] train_loss: 0.013311\n",
      "[584/00965] train_loss: 0.012420\n",
      "[584/01015] train_loss: 0.012539\n",
      "[584/01065] train_loss: 0.013844\n",
      "[584/01115] train_loss: 0.011674\n",
      "[584/01165] train_loss: 0.013545\n",
      "[584/01215] train_loss: 0.012792\n",
      "[585/00039] train_loss: 0.015755\n",
      "[585/00089] train_loss: 0.014293\n",
      "[585/00139] train_loss: 0.013364\n",
      "[585/00189] train_loss: 0.013831\n",
      "[585/00239] train_loss: 0.013318\n",
      "[585/00289] train_loss: 0.012861\n",
      "[585/00339] train_loss: 0.013398\n",
      "[585/00389] train_loss: 0.012225\n",
      "[585/00439] train_loss: 0.012954\n",
      "[585/00489] train_loss: 0.012928\n",
      "[585/00539] train_loss: 0.013083\n",
      "[585/00589] train_loss: 0.012827\n",
      "[585/00639] train_loss: 0.012894\n",
      "[585/00689] train_loss: 0.012458\n",
      "[585/00739] train_loss: 0.012084\n",
      "[585/00789] train_loss: 0.013419\n",
      "[585/00839] train_loss: 0.011982\n",
      "[585/00889] train_loss: 0.013426\n",
      "[585/00939] train_loss: 0.013153\n",
      "[585/00989] train_loss: 0.013101\n",
      "[585/01039] train_loss: 0.013748\n",
      "[585/01089] train_loss: 0.013651\n",
      "[585/01139] train_loss: 0.012955\n",
      "[585/01189] train_loss: 0.012319\n",
      "[586/00013] train_loss: 0.013643\n",
      "[586/00063] train_loss: 0.014334\n",
      "[586/00113] train_loss: 0.014290\n",
      "[586/00163] train_loss: 0.013640\n",
      "[586/00213] train_loss: 0.013247\n",
      "[586/00263] train_loss: 0.012312\n",
      "[586/00313] train_loss: 0.012519\n",
      "[586/00363] train_loss: 0.013060\n",
      "[586/00413] train_loss: 0.014630\n",
      "[586/00463] train_loss: 0.013136\n",
      "[586/00513] train_loss: 0.013624\n",
      "[586/00563] train_loss: 0.012603\n",
      "[586/00613] train_loss: 0.012931\n",
      "[586/00663] train_loss: 0.012259\n",
      "[586/00713] train_loss: 0.013665\n",
      "[586/00763] train_loss: 0.012971\n",
      "[586/00813] train_loss: 0.012810\n",
      "[586/00863] train_loss: 0.012228\n",
      "[586/00913] train_loss: 0.012411\n",
      "[586/00963] train_loss: 0.012128\n",
      "[586/01013] train_loss: 0.012448\n",
      "[586/01063] train_loss: 0.013033\n",
      "[586/01113] train_loss: 0.013307\n",
      "[586/01163] train_loss: 0.013101\n",
      "[586/01213] train_loss: 0.013697\n",
      "[587/00037] train_loss: 0.015565\n",
      "[587/00087] train_loss: 0.014708\n",
      "[587/00137] train_loss: 0.014849\n",
      "[587/00187] train_loss: 0.012958\n",
      "[587/00237] train_loss: 0.013213\n",
      "[587/00287] train_loss: 0.012963\n",
      "[587/00337] train_loss: 0.012367\n",
      "[587/00387] train_loss: 0.012248\n",
      "[587/00437] train_loss: 0.012860\n",
      "[587/00487] train_loss: 0.013192\n",
      "[587/00537] train_loss: 0.013577\n",
      "[587/00587] train_loss: 0.011997\n",
      "[587/00637] train_loss: 0.012616\n",
      "[587/00687] train_loss: 0.012945\n",
      "[587/00737] train_loss: 0.013160\n",
      "[587/00787] train_loss: 0.012917\n",
      "[587/00837] train_loss: 0.012534\n",
      "[587/00887] train_loss: 0.012963\n",
      "[587/00937] train_loss: 0.012639\n",
      "[587/00987] train_loss: 0.013374\n",
      "[587/01037] train_loss: 0.011496\n",
      "[587/01087] train_loss: 0.013045\n",
      "[587/01137] train_loss: 0.012789\n",
      "[587/01187] train_loss: 0.013579\n",
      "[588/00011] train_loss: 0.014547\n",
      "[588/00061] train_loss: 0.014566\n",
      "[588/00111] train_loss: 0.013791\n",
      "[588/00161] train_loss: 0.014211\n",
      "[588/00211] train_loss: 0.013544\n",
      "[588/00261] train_loss: 0.012393\n",
      "[588/00311] train_loss: 0.013348\n",
      "[588/00361] train_loss: 0.012807\n",
      "[588/00411] train_loss: 0.013250\n",
      "[588/00461] train_loss: 0.013589\n",
      "[588/00511] train_loss: 0.013150\n",
      "[588/00561] train_loss: 0.012623\n",
      "[588/00611] train_loss: 0.012870\n",
      "[588/00661] train_loss: 0.012981\n",
      "[588/00711] train_loss: 0.013052\n",
      "[588/00761] train_loss: 0.013058\n",
      "[588/00811] train_loss: 0.013398\n",
      "[588/00861] train_loss: 0.013266\n",
      "[588/00911] train_loss: 0.013033\n",
      "[588/00961] train_loss: 0.012797\n",
      "[588/01011] train_loss: 0.012610\n",
      "[588/01061] train_loss: 0.012415\n",
      "[588/01111] train_loss: 0.013047\n",
      "[588/01161] train_loss: 0.013002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[588/01211] train_loss: 0.013162\n",
      "[589/00035] train_loss: 0.015284\n",
      "[589/00085] train_loss: 0.015074\n",
      "[589/00135] train_loss: 0.013435\n",
      "[589/00185] train_loss: 0.013021\n",
      "[589/00235] train_loss: 0.013279\n",
      "[589/00285] train_loss: 0.013155\n",
      "[589/00335] train_loss: 0.013201\n",
      "[589/00385] train_loss: 0.012645\n",
      "[589/00435] train_loss: 0.012737\n",
      "[589/00485] train_loss: 0.012126\n",
      "[589/00535] train_loss: 0.012852\n",
      "[589/00585] train_loss: 0.012930\n",
      "[589/00635] train_loss: 0.012456\n",
      "[589/00685] train_loss: 0.012685\n",
      "[589/00735] train_loss: 0.012436\n",
      "[589/00785] train_loss: 0.012820\n",
      "[589/00835] train_loss: 0.013437\n",
      "[589/00885] train_loss: 0.012707\n",
      "[589/00935] train_loss: 0.013768\n",
      "[589/00985] train_loss: 0.012033\n",
      "[589/01035] train_loss: 0.013181\n",
      "[589/01085] train_loss: 0.013386\n",
      "[589/01135] train_loss: 0.012682\n",
      "[589/01185] train_loss: 0.013232\n",
      "[590/00009] train_loss: 0.013636\n",
      "[590/00059] train_loss: 0.015835\n",
      "[590/00109] train_loss: 0.014434\n",
      "[590/00159] train_loss: 0.013485\n",
      "[590/00209] train_loss: 0.013232\n",
      "[590/00259] train_loss: 0.013186\n",
      "[590/00309] train_loss: 0.012539\n",
      "[590/00359] train_loss: 0.013472\n",
      "[590/00409] train_loss: 0.012041\n",
      "[590/00459] train_loss: 0.012907\n",
      "[590/00509] train_loss: 0.012007\n",
      "[590/00559] train_loss: 0.012773\n",
      "[590/00609] train_loss: 0.012755\n",
      "[590/00659] train_loss: 0.012786\n",
      "[590/00709] train_loss: 0.013448\n",
      "[590/00759] train_loss: 0.013169\n",
      "[590/00809] train_loss: 0.013481\n",
      "[590/00859] train_loss: 0.012870\n",
      "[590/00909] train_loss: 0.012910\n",
      "[590/00959] train_loss: 0.012296\n",
      "[590/01009] train_loss: 0.013285\n",
      "[590/01059] train_loss: 0.012605\n",
      "[590/01109] train_loss: 0.012481\n",
      "[590/01159] train_loss: 0.013614\n",
      "[590/01209] train_loss: 0.013099\n",
      "[591/00033] train_loss: 0.015825\n",
      "[591/00083] train_loss: 0.015078\n",
      "[591/00133] train_loss: 0.014026\n",
      "[591/00183] train_loss: 0.012830\n",
      "[591/00233] train_loss: 0.013353\n",
      "[591/00283] train_loss: 0.012687\n",
      "[591/00333] train_loss: 0.013264\n",
      "[591/00383] train_loss: 0.012872\n",
      "[591/00433] train_loss: 0.012349\n",
      "[591/00483] train_loss: 0.013232\n",
      "[591/00533] train_loss: 0.013237\n",
      "[591/00583] train_loss: 0.012441\n",
      "[591/00633] train_loss: 0.012619\n",
      "[591/00683] train_loss: 0.013119\n",
      "[591/00733] train_loss: 0.012552\n",
      "[591/00783] train_loss: 0.013184\n",
      "[591/00833] train_loss: 0.012531\n",
      "[591/00883] train_loss: 0.012052\n",
      "[591/00933] train_loss: 0.012752\n",
      "[591/00983] train_loss: 0.013086\n",
      "[591/01033] train_loss: 0.012393\n",
      "[591/01083] train_loss: 0.013376\n",
      "[591/01133] train_loss: 0.013138\n",
      "[591/01183] train_loss: 0.013843\n",
      "[592/00007] train_loss: 0.012868\n",
      "[592/00057] train_loss: 0.014696\n",
      "[592/00107] train_loss: 0.014014\n",
      "[592/00157] train_loss: 0.013697\n",
      "[592/00207] train_loss: 0.013196\n",
      "[592/00257] train_loss: 0.012657\n",
      "[592/00307] train_loss: 0.013571\n",
      "[592/00357] train_loss: 0.013759\n",
      "[592/00407] train_loss: 0.012462\n",
      "[592/00457] train_loss: 0.013640\n",
      "[592/00507] train_loss: 0.012326\n",
      "[592/00557] train_loss: 0.013071\n",
      "[592/00607] train_loss: 0.013187\n",
      "[592/00657] train_loss: 0.012660\n",
      "[592/00707] train_loss: 0.011959\n",
      "[592/00757] train_loss: 0.012866\n",
      "[592/00807] train_loss: 0.012774\n",
      "[592/00857] train_loss: 0.013630\n",
      "[592/00907] train_loss: 0.012615\n",
      "[592/00957] train_loss: 0.013802\n",
      "[592/01007] train_loss: 0.012648\n",
      "[592/01057] train_loss: 0.013462\n",
      "[592/01107] train_loss: 0.012656\n",
      "[592/01157] train_loss: 0.012633\n",
      "[592/01207] train_loss: 0.013267\n",
      "[593/00031] train_loss: 0.014512\n",
      "[593/00081] train_loss: 0.014997\n",
      "[593/00131] train_loss: 0.013807\n",
      "[593/00181] train_loss: 0.013030\n",
      "[593/00231] train_loss: 0.012846\n",
      "[593/00281] train_loss: 0.012883\n",
      "[593/00331] train_loss: 0.013069\n",
      "[593/00381] train_loss: 0.013052\n",
      "[593/00431] train_loss: 0.013171\n",
      "[593/00481] train_loss: 0.012946\n",
      "[593/00531] train_loss: 0.012614\n",
      "[593/00581] train_loss: 0.013200\n",
      "[593/00631] train_loss: 0.013324\n",
      "[593/00681] train_loss: 0.012946\n",
      "[593/00731] train_loss: 0.013791\n",
      "[593/00781] train_loss: 0.012920\n",
      "[593/00831] train_loss: 0.012330\n",
      "[593/00881] train_loss: 0.013096\n",
      "[593/00931] train_loss: 0.012066\n",
      "[593/00981] train_loss: 0.013538\n",
      "[593/01031] train_loss: 0.013156\n",
      "[593/01081] train_loss: 0.012287\n",
      "[593/01131] train_loss: 0.012880\n",
      "[593/01181] train_loss: 0.012887\n",
      "[594/00005] train_loss: 0.014064\n",
      "[594/00055] train_loss: 0.015192\n",
      "[594/00105] train_loss: 0.013437\n",
      "[594/00155] train_loss: 0.014281\n",
      "[594/00205] train_loss: 0.013226\n",
      "[594/00255] train_loss: 0.012696\n",
      "[594/00305] train_loss: 0.012606\n",
      "[594/00355] train_loss: 0.012560\n",
      "[594/00405] train_loss: 0.012499\n",
      "[594/00455] train_loss: 0.012671\n",
      "[594/00505] train_loss: 0.012610\n",
      "[594/00555] train_loss: 0.012914\n",
      "[594/00605] train_loss: 0.012441\n",
      "[594/00655] train_loss: 0.012970\n",
      "[594/00705] train_loss: 0.013047\n",
      "[594/00755] train_loss: 0.012690\n",
      "[594/00805] train_loss: 0.012712\n",
      "[594/00855] train_loss: 0.012477\n",
      "[594/00905] train_loss: 0.012530\n",
      "[594/00955] train_loss: 0.012650\n",
      "[594/01005] train_loss: 0.013014\n",
      "[594/01055] train_loss: 0.013942\n",
      "[594/01105] train_loss: 0.013094\n",
      "[594/01155] train_loss: 0.013942\n",
      "[594/01205] train_loss: 0.012797\n",
      "[595/00029] train_loss: 0.015267\n",
      "[595/00079] train_loss: 0.013824\n",
      "[595/00129] train_loss: 0.013875\n",
      "[595/00179] train_loss: 0.013416\n",
      "[595/00229] train_loss: 0.012569\n",
      "[595/00279] train_loss: 0.012720\n",
      "[595/00329] train_loss: 0.012934\n",
      "[595/00379] train_loss: 0.013833\n",
      "[595/00429] train_loss: 0.013405\n",
      "[595/00479] train_loss: 0.012285\n",
      "[595/00529] train_loss: 0.012583\n",
      "[595/00579] train_loss: 0.012628\n",
      "[595/00629] train_loss: 0.013181\n",
      "[595/00679] train_loss: 0.012792\n",
      "[595/00729] train_loss: 0.012751\n",
      "[595/00779] train_loss: 0.013211\n",
      "[595/00829] train_loss: 0.013377\n",
      "[595/00879] train_loss: 0.012999\n",
      "[595/00929] train_loss: 0.013133\n",
      "[595/00979] train_loss: 0.012634\n",
      "[595/01029] train_loss: 0.012397\n",
      "[595/01079] train_loss: 0.012521\n",
      "[595/01129] train_loss: 0.013487\n",
      "[595/01179] train_loss: 0.013103\n",
      "[596/00003] train_loss: 0.013505\n",
      "[596/00053] train_loss: 0.015418\n",
      "[596/00103] train_loss: 0.014200\n",
      "[596/00153] train_loss: 0.014485\n",
      "[596/00203] train_loss: 0.013240\n",
      "[596/00253] train_loss: 0.012263\n",
      "[596/00303] train_loss: 0.013198\n",
      "[596/00353] train_loss: 0.012719\n",
      "[596/00403] train_loss: 0.012553\n",
      "[596/00453] train_loss: 0.012513\n",
      "[596/00503] train_loss: 0.012401\n",
      "[596/00553] train_loss: 0.013003\n",
      "[596/00603] train_loss: 0.012147\n",
      "[596/00653] train_loss: 0.012575\n",
      "[596/00703] train_loss: 0.012650\n",
      "[596/00753] train_loss: 0.012480\n",
      "[596/00803] train_loss: 0.012687\n",
      "[596/00853] train_loss: 0.013416\n",
      "[596/00903] train_loss: 0.013372\n",
      "[596/00953] train_loss: 0.012990\n",
      "[596/01003] train_loss: 0.012745\n",
      "[596/01053] train_loss: 0.013157\n",
      "[596/01103] train_loss: 0.013046\n",
      "[596/01153] train_loss: 0.013000\n",
      "[596/01203] train_loss: 0.013291\n",
      "[597/00027] train_loss: 0.014271\n",
      "[597/00077] train_loss: 0.015183\n",
      "[597/00127] train_loss: 0.013713\n",
      "[597/00177] train_loss: 0.013263\n",
      "[597/00227] train_loss: 0.013353\n",
      "[597/00277] train_loss: 0.013793\n",
      "[597/00327] train_loss: 0.012888\n",
      "[597/00377] train_loss: 0.012154\n",
      "[597/00427] train_loss: 0.013509\n",
      "[597/00477] train_loss: 0.012110\n",
      "[597/00527] train_loss: 0.013051\n",
      "[597/00577] train_loss: 0.012656\n",
      "[597/00627] train_loss: 0.013094\n",
      "[597/00677] train_loss: 0.012693\n",
      "[597/00727] train_loss: 0.012512\n",
      "[597/00777] train_loss: 0.012908\n",
      "[597/00827] train_loss: 0.013872\n",
      "[597/00877] train_loss: 0.012590\n",
      "[597/00927] train_loss: 0.012855\n",
      "[597/00977] train_loss: 0.012654\n",
      "[597/01027] train_loss: 0.012244\n",
      "[597/01077] train_loss: 0.013441\n",
      "[597/01127] train_loss: 0.012922\n",
      "[597/01177] train_loss: 0.013183\n",
      "[598/00001] train_loss: 0.013065\n",
      "[598/00051] train_loss: 0.015612\n",
      "[598/00101] train_loss: 0.014619\n",
      "[598/00151] train_loss: 0.014238\n",
      "[598/00201] train_loss: 0.012463\n",
      "[598/00251] train_loss: 0.012751\n",
      "[598/00301] train_loss: 0.012673\n",
      "[598/00351] train_loss: 0.012646\n",
      "[598/00401] train_loss: 0.012871\n",
      "[598/00451] train_loss: 0.013117\n",
      "[598/00501] train_loss: 0.012753\n",
      "[598/00551] train_loss: 0.012943\n",
      "[598/00601] train_loss: 0.012573\n",
      "[598/00651] train_loss: 0.012846\n",
      "[598/00701] train_loss: 0.012656\n",
      "[598/00751] train_loss: 0.012864\n",
      "[598/00801] train_loss: 0.013329\n",
      "[598/00851] train_loss: 0.012826\n",
      "[598/00901] train_loss: 0.012480\n",
      "[598/00951] train_loss: 0.012746\n",
      "[598/01001] train_loss: 0.013329\n",
      "[598/01051] train_loss: 0.012144\n",
      "[598/01101] train_loss: 0.012815\n",
      "[598/01151] train_loss: 0.012619\n",
      "[598/01201] train_loss: 0.013925\n",
      "[599/00025] train_loss: 0.014643\n",
      "[599/00075] train_loss: 0.014957\n",
      "[599/00125] train_loss: 0.013919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[599/00175] train_loss: 0.014448\n",
      "[599/00225] train_loss: 0.013139\n",
      "[599/00275] train_loss: 0.012884\n",
      "[599/00325] train_loss: 0.012654\n",
      "[599/00375] train_loss: 0.013003\n",
      "[599/00425] train_loss: 0.012928\n",
      "[599/00475] train_loss: 0.012703\n",
      "[599/00525] train_loss: 0.012571\n",
      "[599/00575] train_loss: 0.012376\n",
      "[599/00625] train_loss: 0.012009\n",
      "[599/00675] train_loss: 0.013148\n",
      "[599/00725] train_loss: 0.012730\n",
      "[599/00775] train_loss: 0.012935\n",
      "[599/00825] train_loss: 0.013414\n",
      "[599/00875] train_loss: 0.012318\n",
      "[599/00925] train_loss: 0.013264\n",
      "[599/00975] train_loss: 0.013242\n",
      "[599/01025] train_loss: 0.012585\n",
      "[599/01075] train_loss: 0.013047\n",
      "[599/01125] train_loss: 0.013209\n",
      "[599/01175] train_loss: 0.013544\n",
      "[599/01225] train_loss: 0.013629\n",
      "[600/00049] train_loss: 0.015492\n",
      "[600/00099] train_loss: 0.013772\n",
      "[600/00149] train_loss: 0.013856\n",
      "[600/00199] train_loss: 0.013204\n",
      "[600/00249] train_loss: 0.012760\n",
      "[600/00299] train_loss: 0.012264\n",
      "[600/00349] train_loss: 0.012743\n",
      "[600/00399] train_loss: 0.013066\n",
      "[600/00449] train_loss: 0.012586\n",
      "[600/00499] train_loss: 0.012782\n",
      "[600/00549] train_loss: 0.012739\n",
      "[600/00599] train_loss: 0.012873\n",
      "[600/00649] train_loss: 0.013190\n",
      "[600/00699] train_loss: 0.012771\n",
      "[600/00749] train_loss: 0.012735\n",
      "[600/00799] train_loss: 0.013904\n",
      "[600/00849] train_loss: 0.013055\n",
      "[600/00899] train_loss: 0.012446\n",
      "[600/00949] train_loss: 0.013174\n",
      "[600/00999] train_loss: 0.013116\n",
      "[600/01049] train_loss: 0.012569\n",
      "[600/01099] train_loss: 0.013595\n",
      "[600/01149] train_loss: 0.012952\n",
      "[600/01199] train_loss: 0.012747\n",
      "[601/00023] train_loss: 0.014801\n",
      "[601/00073] train_loss: 0.014772\n",
      "[601/00123] train_loss: 0.014473\n",
      "[601/00173] train_loss: 0.012975\n",
      "[601/00223] train_loss: 0.013206\n",
      "[601/00273] train_loss: 0.013514\n",
      "[601/00323] train_loss: 0.013526\n",
      "[601/00373] train_loss: 0.013493\n",
      "[601/00423] train_loss: 0.012643\n",
      "[601/00473] train_loss: 0.012559\n",
      "[601/00523] train_loss: 0.012537\n",
      "[601/00573] train_loss: 0.013064\n",
      "[601/00623] train_loss: 0.012340\n",
      "[601/00673] train_loss: 0.013087\n",
      "[601/00723] train_loss: 0.012356\n",
      "[601/00773] train_loss: 0.012130\n",
      "[601/00823] train_loss: 0.013241\n",
      "[601/00873] train_loss: 0.012387\n",
      "[601/00923] train_loss: 0.012828\n",
      "[601/00973] train_loss: 0.013113\n",
      "[601/01023] train_loss: 0.012963\n",
      "[601/01073] train_loss: 0.012962\n",
      "[601/01123] train_loss: 0.012954\n",
      "[601/01173] train_loss: 0.013388\n",
      "[601/01223] train_loss: 0.012824\n",
      "[602/00047] train_loss: 0.016197\n",
      "[602/00097] train_loss: 0.014198\n",
      "[602/00147] train_loss: 0.013435\n",
      "[602/00197] train_loss: 0.012683\n",
      "[602/00247] train_loss: 0.013157\n",
      "[602/00297] train_loss: 0.012580\n",
      "[602/00347] train_loss: 0.013080\n",
      "[602/00397] train_loss: 0.012728\n",
      "[602/00447] train_loss: 0.013023\n",
      "[602/00497] train_loss: 0.012637\n",
      "[602/00547] train_loss: 0.012214\n",
      "[602/00597] train_loss: 0.012392\n",
      "[602/00647] train_loss: 0.013350\n",
      "[602/00697] train_loss: 0.012978\n",
      "[602/00747] train_loss: 0.012769\n",
      "[602/00797] train_loss: 0.012822\n",
      "[602/00847] train_loss: 0.013087\n",
      "[602/00897] train_loss: 0.012188\n",
      "[602/00947] train_loss: 0.013660\n",
      "[602/00997] train_loss: 0.012895\n",
      "[602/01047] train_loss: 0.013612\n",
      "[602/01097] train_loss: 0.013654\n",
      "[602/01147] train_loss: 0.011791\n",
      "[602/01197] train_loss: 0.012668\n",
      "[603/00021] train_loss: 0.014820\n",
      "[603/00071] train_loss: 0.015450\n",
      "[603/00121] train_loss: 0.013790\n",
      "[603/00171] train_loss: 0.013075\n",
      "[603/00221] train_loss: 0.013896\n",
      "[603/00271] train_loss: 0.012533\n",
      "[603/00321] train_loss: 0.012871\n",
      "[603/00371] train_loss: 0.012464\n",
      "[603/00421] train_loss: 0.012562\n",
      "[603/00471] train_loss: 0.013397\n",
      "[603/00521] train_loss: 0.013366\n",
      "[603/00571] train_loss: 0.011991\n",
      "[603/00621] train_loss: 0.012055\n",
      "[603/00671] train_loss: 0.012595\n",
      "[603/00721] train_loss: 0.012846\n",
      "[603/00771] train_loss: 0.013603\n",
      "[603/00821] train_loss: 0.012967\n",
      "[603/00871] train_loss: 0.012481\n",
      "[603/00921] train_loss: 0.012515\n",
      "[603/00971] train_loss: 0.013052\n",
      "[603/01021] train_loss: 0.013005\n",
      "[603/01071] train_loss: 0.013354\n",
      "[603/01121] train_loss: 0.012635\n",
      "[603/01171] train_loss: 0.012821\n",
      "[603/01221] train_loss: 0.012413\n",
      "[604/00045] train_loss: 0.015166\n",
      "[604/00095] train_loss: 0.014232\n",
      "[604/00145] train_loss: 0.013421\n",
      "[604/00195] train_loss: 0.013350\n",
      "[604/00245] train_loss: 0.013969\n",
      "[604/00295] train_loss: 0.012695\n",
      "[604/00345] train_loss: 0.012855\n",
      "[604/00395] train_loss: 0.013563\n",
      "[604/00445] train_loss: 0.012634\n",
      "[604/00495] train_loss: 0.012009\n",
      "[604/00545] train_loss: 0.013519\n",
      "[604/00595] train_loss: 0.012640\n",
      "[604/00645] train_loss: 0.013225\n",
      "[604/00695] train_loss: 0.013281\n",
      "[604/00745] train_loss: 0.012976\n",
      "[604/00795] train_loss: 0.012726\n",
      "[604/00845] train_loss: 0.012970\n",
      "[604/00895] train_loss: 0.012608\n",
      "[604/00945] train_loss: 0.013379\n",
      "[604/00995] train_loss: 0.012753\n",
      "[604/01045] train_loss: 0.012818\n",
      "[604/01095] train_loss: 0.013357\n",
      "[604/01145] train_loss: 0.012905\n",
      "[604/01195] train_loss: 0.012388\n",
      "[605/00019] train_loss: 0.014775\n",
      "[605/00069] train_loss: 0.014791\n",
      "[605/00119] train_loss: 0.013695\n",
      "[605/00169] train_loss: 0.013478\n",
      "[605/00219] train_loss: 0.013701\n",
      "[605/00269] train_loss: 0.012779\n",
      "[605/00319] train_loss: 0.012310\n",
      "[605/00369] train_loss: 0.013007\n",
      "[605/00419] train_loss: 0.012066\n",
      "[605/00469] train_loss: 0.012704\n",
      "[605/00519] train_loss: 0.012416\n",
      "[605/00569] train_loss: 0.012859\n",
      "[605/00619] train_loss: 0.012984\n",
      "[605/00669] train_loss: 0.012734\n",
      "[605/00719] train_loss: 0.012261\n",
      "[605/00769] train_loss: 0.012814\n",
      "[605/00819] train_loss: 0.012802\n",
      "[605/00869] train_loss: 0.012725\n",
      "[605/00919] train_loss: 0.013002\n",
      "[605/00969] train_loss: 0.012635\n",
      "[605/01019] train_loss: 0.013218\n",
      "[605/01069] train_loss: 0.013094\n",
      "[605/01119] train_loss: 0.012722\n",
      "[605/01169] train_loss: 0.013811\n",
      "[605/01219] train_loss: 0.013124\n",
      "[606/00043] train_loss: 0.016373\n",
      "[606/00093] train_loss: 0.014158\n",
      "[606/00143] train_loss: 0.014265\n",
      "[606/00193] train_loss: 0.013672\n",
      "[606/00243] train_loss: 0.012952\n",
      "[606/00293] train_loss: 0.013178\n",
      "[606/00343] train_loss: 0.013157\n",
      "[606/00393] train_loss: 0.012635\n",
      "[606/00443] train_loss: 0.012665\n",
      "[606/00493] train_loss: 0.012888\n",
      "[606/00543] train_loss: 0.011960\n",
      "[606/00593] train_loss: 0.012898\n",
      "[606/00643] train_loss: 0.013442\n",
      "[606/00693] train_loss: 0.012801\n",
      "[606/00743] train_loss: 0.013005\n",
      "[606/00793] train_loss: 0.013259\n",
      "[606/00843] train_loss: 0.013025\n",
      "[606/00893] train_loss: 0.013045\n",
      "[606/00943] train_loss: 0.012490\n",
      "[606/00993] train_loss: 0.012353\n",
      "[606/01043] train_loss: 0.013040\n",
      "[606/01093] train_loss: 0.012917\n",
      "[606/01143] train_loss: 0.013056\n",
      "[606/01193] train_loss: 0.012312\n",
      "[607/00017] train_loss: 0.014797\n",
      "[607/00067] train_loss: 0.015762\n",
      "[607/00117] train_loss: 0.014028\n",
      "[607/00167] train_loss: 0.013245\n",
      "[607/00217] train_loss: 0.012826\n",
      "[607/00267] train_loss: 0.012470\n",
      "[607/00317] train_loss: 0.013590\n",
      "[607/00367] train_loss: 0.012450\n",
      "[607/00417] train_loss: 0.013157\n",
      "[607/00467] train_loss: 0.012761\n",
      "[607/00517] train_loss: 0.012393\n",
      "[607/00567] train_loss: 0.012924\n",
      "[607/00617] train_loss: 0.012827\n",
      "[607/00667] train_loss: 0.012602\n",
      "[607/00717] train_loss: 0.012443\n",
      "[607/00767] train_loss: 0.012435\n",
      "[607/00817] train_loss: 0.012733\n",
      "[607/00867] train_loss: 0.012696\n",
      "[607/00917] train_loss: 0.013286\n",
      "[607/00967] train_loss: 0.012832\n",
      "[607/01017] train_loss: 0.013247\n",
      "[607/01067] train_loss: 0.012724\n",
      "[607/01117] train_loss: 0.012491\n",
      "[607/01167] train_loss: 0.013115\n",
      "[607/01217] train_loss: 0.012807\n",
      "[608/00041] train_loss: 0.015069\n",
      "[608/00091] train_loss: 0.014114\n",
      "[608/00141] train_loss: 0.013830\n",
      "[608/00191] train_loss: 0.013488\n",
      "[608/00241] train_loss: 0.012227\n",
      "[608/00291] train_loss: 0.013863\n",
      "[608/00341] train_loss: 0.012972\n",
      "[608/00391] train_loss: 0.012704\n",
      "[608/00441] train_loss: 0.013484\n",
      "[608/00491] train_loss: 0.012901\n",
      "[608/00541] train_loss: 0.012371\n",
      "[608/00591] train_loss: 0.012488\n",
      "[608/00641] train_loss: 0.013158\n",
      "[608/00691] train_loss: 0.012515\n",
      "[608/00741] train_loss: 0.012873\n",
      "[608/00791] train_loss: 0.011838\n",
      "[608/00841] train_loss: 0.013202\n",
      "[608/00891] train_loss: 0.012819\n",
      "[608/00941] train_loss: 0.012026\n",
      "[608/00991] train_loss: 0.012886\n",
      "[608/01041] train_loss: 0.012308\n",
      "[608/01091] train_loss: 0.013340\n",
      "[608/01141] train_loss: 0.013126\n",
      "[608/01191] train_loss: 0.013022\n",
      "[609/00015] train_loss: 0.013526\n",
      "[609/00065] train_loss: 0.015126\n",
      "[609/00115] train_loss: 0.014341\n",
      "[609/00165] train_loss: 0.013566\n",
      "[609/00215] train_loss: 0.012749\n",
      "[609/00265] train_loss: 0.013653\n",
      "[609/00315] train_loss: 0.013036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[609/00365] train_loss: 0.012920\n",
      "[609/00415] train_loss: 0.012555\n",
      "[609/00465] train_loss: 0.012969\n",
      "[609/00515] train_loss: 0.012856\n",
      "[609/00565] train_loss: 0.013053\n",
      "[609/00615] train_loss: 0.012425\n",
      "[609/00665] train_loss: 0.012544\n",
      "[609/00715] train_loss: 0.012631\n",
      "[609/00765] train_loss: 0.013166\n",
      "[609/00815] train_loss: 0.012625\n",
      "[609/00865] train_loss: 0.013017\n",
      "[609/00915] train_loss: 0.013425\n",
      "[609/00965] train_loss: 0.012669\n",
      "[609/01015] train_loss: 0.012628\n",
      "[609/01065] train_loss: 0.012539\n",
      "[609/01115] train_loss: 0.012309\n",
      "[609/01165] train_loss: 0.013377\n",
      "[609/01215] train_loss: 0.012500\n",
      "[610/00039] train_loss: 0.016178\n",
      "[610/00089] train_loss: 0.015238\n",
      "[610/00139] train_loss: 0.014083\n",
      "[610/00189] train_loss: 0.013778\n",
      "[610/00239] train_loss: 0.013231\n",
      "[610/00289] train_loss: 0.013192\n",
      "[610/00339] train_loss: 0.012760\n",
      "[610/00389] train_loss: 0.012466\n",
      "[610/00439] train_loss: 0.012519\n",
      "[610/00489] train_loss: 0.013090\n",
      "[610/00539] train_loss: 0.012419\n",
      "[610/00589] train_loss: 0.012766\n",
      "[610/00639] train_loss: 0.012932\n",
      "[610/00689] train_loss: 0.013348\n",
      "[610/00739] train_loss: 0.013465\n",
      "[610/00789] train_loss: 0.012008\n",
      "[610/00839] train_loss: 0.013276\n",
      "[610/00889] train_loss: 0.011851\n",
      "[610/00939] train_loss: 0.013288\n",
      "[610/00989] train_loss: 0.012770\n",
      "[610/01039] train_loss: 0.012632\n",
      "[610/01089] train_loss: 0.013441\n",
      "[610/01139] train_loss: 0.012702\n",
      "[610/01189] train_loss: 0.012795\n",
      "[611/00013] train_loss: 0.013651\n",
      "[611/00063] train_loss: 0.015106\n",
      "[611/00113] train_loss: 0.013882\n",
      "[611/00163] train_loss: 0.013819\n",
      "[611/00213] train_loss: 0.013431\n",
      "[611/00263] train_loss: 0.012776\n",
      "[611/00313] train_loss: 0.013166\n",
      "[611/00363] train_loss: 0.012713\n",
      "[611/00413] train_loss: 0.012965\n",
      "[611/00463] train_loss: 0.012893\n",
      "[611/00513] train_loss: 0.012994\n",
      "[611/00563] train_loss: 0.012190\n",
      "[611/00613] train_loss: 0.013024\n",
      "[611/00663] train_loss: 0.012666\n",
      "[611/00713] train_loss: 0.012578\n",
      "[611/00763] train_loss: 0.012979\n",
      "[611/00813] train_loss: 0.013523\n",
      "[611/00863] train_loss: 0.013211\n",
      "[611/00913] train_loss: 0.012979\n",
      "[611/00963] train_loss: 0.012953\n",
      "[611/01013] train_loss: 0.012513\n",
      "[611/01063] train_loss: 0.012169\n",
      "[611/01113] train_loss: 0.013097\n",
      "[611/01163] train_loss: 0.012330\n",
      "[611/01213] train_loss: 0.013033\n",
      "[612/00037] train_loss: 0.015332\n",
      "[612/00087] train_loss: 0.015024\n",
      "[612/00137] train_loss: 0.014016\n",
      "[612/00187] train_loss: 0.012975\n",
      "[612/00237] train_loss: 0.012672\n",
      "[612/00287] train_loss: 0.013288\n",
      "[612/00337] train_loss: 0.012864\n",
      "[612/00387] train_loss: 0.012731\n",
      "[612/00437] train_loss: 0.012540\n",
      "[612/00487] train_loss: 0.012091\n",
      "[612/00537] train_loss: 0.013030\n",
      "[612/00587] train_loss: 0.012993\n",
      "[612/00637] train_loss: 0.012530\n",
      "[612/00687] train_loss: 0.013053\n",
      "[612/00737] train_loss: 0.012780\n",
      "[612/00787] train_loss: 0.013697\n",
      "[612/00837] train_loss: 0.012827\n",
      "[612/00887] train_loss: 0.012086\n",
      "[612/00937] train_loss: 0.012378\n",
      "[612/00987] train_loss: 0.012734\n",
      "[612/01037] train_loss: 0.013354\n",
      "[612/01087] train_loss: 0.012958\n",
      "[612/01137] train_loss: 0.013415\n",
      "[612/01187] train_loss: 0.013391\n",
      "[613/00011] train_loss: 0.013369\n",
      "[613/00061] train_loss: 0.015076\n",
      "[613/00111] train_loss: 0.013968\n",
      "[613/00161] train_loss: 0.012893\n",
      "[613/00211] train_loss: 0.013646\n",
      "[613/00261] train_loss: 0.013878\n",
      "[613/00311] train_loss: 0.012726\n",
      "[613/00361] train_loss: 0.012900\n",
      "[613/00411] train_loss: 0.013374\n",
      "[613/00461] train_loss: 0.012848\n",
      "[613/00511] train_loss: 0.012487\n",
      "[613/00561] train_loss: 0.012389\n",
      "[613/00611] train_loss: 0.012816\n",
      "[613/00661] train_loss: 0.012910\n",
      "[613/00711] train_loss: 0.012131\n",
      "[613/00761] train_loss: 0.012724\n",
      "[613/00811] train_loss: 0.013146\n",
      "[613/00861] train_loss: 0.013492\n",
      "[613/00911] train_loss: 0.012819\n",
      "[613/00961] train_loss: 0.012067\n",
      "[613/01011] train_loss: 0.013488\n",
      "[613/01061] train_loss: 0.012904\n",
      "[613/01111] train_loss: 0.012706\n",
      "[613/01161] train_loss: 0.013713\n",
      "[613/01211] train_loss: 0.013125\n",
      "[614/00035] train_loss: 0.015080\n",
      "[614/00085] train_loss: 0.014312\n",
      "[614/00135] train_loss: 0.013634\n",
      "[614/00185] train_loss: 0.012752\n",
      "[614/00235] train_loss: 0.013331\n",
      "[614/00285] train_loss: 0.013808\n",
      "[614/00335] train_loss: 0.012881\n",
      "[614/00385] train_loss: 0.012761\n",
      "[614/00435] train_loss: 0.012923\n",
      "[614/00485] train_loss: 0.013140\n",
      "[614/00535] train_loss: 0.013260\n",
      "[614/00585] train_loss: 0.012739\n",
      "[614/00635] train_loss: 0.012958\n",
      "[614/00685] train_loss: 0.012994\n",
      "[614/00735] train_loss: 0.012904\n",
      "[614/00785] train_loss: 0.012761\n",
      "[614/00835] train_loss: 0.011847\n",
      "[614/00885] train_loss: 0.012570\n",
      "[614/00935] train_loss: 0.012798\n",
      "[614/00985] train_loss: 0.012734\n",
      "[614/01035] train_loss: 0.012796\n",
      "[614/01085] train_loss: 0.012855\n",
      "[614/01135] train_loss: 0.013044\n",
      "[614/01185] train_loss: 0.012552\n",
      "[615/00009] train_loss: 0.013039\n",
      "[615/00059] train_loss: 0.014818\n",
      "[615/00109] train_loss: 0.014643\n",
      "[615/00159] train_loss: 0.013218\n",
      "[615/00209] train_loss: 0.012743\n",
      "[615/00259] train_loss: 0.012883\n",
      "[615/00309] train_loss: 0.014167\n",
      "[615/00359] train_loss: 0.013374\n",
      "[615/00409] train_loss: 0.012780\n",
      "[615/00459] train_loss: 0.013460\n",
      "[615/00509] train_loss: 0.013119\n",
      "[615/00559] train_loss: 0.012035\n",
      "[615/00609] train_loss: 0.013909\n",
      "[615/00659] train_loss: 0.013103\n",
      "[615/00709] train_loss: 0.012232\n",
      "[615/00759] train_loss: 0.012564\n",
      "[615/00809] train_loss: 0.012746\n",
      "[615/00859] train_loss: 0.013010\n",
      "[615/00909] train_loss: 0.012063\n",
      "[615/00959] train_loss: 0.013114\n",
      "[615/01009] train_loss: 0.012940\n",
      "[615/01059] train_loss: 0.012612\n",
      "[615/01109] train_loss: 0.012837\n",
      "[615/01159] train_loss: 0.012544\n",
      "[615/01209] train_loss: 0.012834\n",
      "[616/00033] train_loss: 0.014585\n",
      "[616/00083] train_loss: 0.014083\n",
      "[616/00133] train_loss: 0.014492\n",
      "[616/00183] train_loss: 0.012741\n",
      "[616/00233] train_loss: 0.012452\n",
      "[616/00283] train_loss: 0.013296\n",
      "[616/00333] train_loss: 0.012584\n",
      "[616/00383] train_loss: 0.013242\n",
      "[616/00433] train_loss: 0.013073\n",
      "[616/00483] train_loss: 0.012591\n",
      "[616/00533] train_loss: 0.013738\n",
      "[616/00583] train_loss: 0.012868\n",
      "[616/00633] train_loss: 0.013048\n",
      "[616/00683] train_loss: 0.012565\n",
      "[616/00733] train_loss: 0.012833\n",
      "[616/00783] train_loss: 0.012464\n",
      "[616/00833] train_loss: 0.013186\n",
      "[616/00883] train_loss: 0.012824\n",
      "[616/00933] train_loss: 0.011965\n",
      "[616/00983] train_loss: 0.012751\n",
      "[616/01033] train_loss: 0.013293\n",
      "[616/01083] train_loss: 0.012967\n",
      "[616/01133] train_loss: 0.012331\n",
      "[616/01183] train_loss: 0.013677\n",
      "[617/00007] train_loss: 0.013761\n",
      "[617/00057] train_loss: 0.015468\n",
      "[617/00107] train_loss: 0.013745\n",
      "[617/00157] train_loss: 0.013675\n",
      "[617/00207] train_loss: 0.013011\n",
      "[617/00257] train_loss: 0.012403\n",
      "[617/00307] train_loss: 0.012996\n",
      "[617/00357] train_loss: 0.012522\n",
      "[617/00407] train_loss: 0.013232\n",
      "[617/00457] train_loss: 0.013075\n",
      "[617/00507] train_loss: 0.013183\n",
      "[617/00557] train_loss: 0.011997\n",
      "[617/00607] train_loss: 0.012670\n",
      "[617/00657] train_loss: 0.012759\n",
      "[617/00707] train_loss: 0.013793\n",
      "[617/00757] train_loss: 0.012930\n",
      "[617/00807] train_loss: 0.013828\n",
      "[617/00857] train_loss: 0.012867\n",
      "[617/00907] train_loss: 0.012841\n",
      "[617/00957] train_loss: 0.013246\n",
      "[617/01007] train_loss: 0.012628\n",
      "[617/01057] train_loss: 0.012462\n",
      "[617/01107] train_loss: 0.013142\n",
      "[617/01157] train_loss: 0.012917\n",
      "[617/01207] train_loss: 0.013459\n",
      "[618/00031] train_loss: 0.014408\n",
      "[618/00081] train_loss: 0.014896\n",
      "[618/00131] train_loss: 0.014420\n",
      "[618/00181] train_loss: 0.013249\n",
      "[618/00231] train_loss: 0.013130\n",
      "[618/00281] train_loss: 0.013966\n",
      "[618/00331] train_loss: 0.013386\n",
      "[618/00381] train_loss: 0.013442\n",
      "[618/00431] train_loss: 0.013139\n",
      "[618/00481] train_loss: 0.012044\n",
      "[618/00531] train_loss: 0.012452\n",
      "[618/00581] train_loss: 0.012621\n",
      "[618/00631] train_loss: 0.013532\n",
      "[618/00681] train_loss: 0.012869\n",
      "[618/00731] train_loss: 0.013031\n",
      "[618/00781] train_loss: 0.013187\n",
      "[618/00831] train_loss: 0.012178\n",
      "[618/00881] train_loss: 0.012369\n",
      "[618/00931] train_loss: 0.012677\n",
      "[618/00981] train_loss: 0.012773\n",
      "[618/01031] train_loss: 0.012926\n",
      "[618/01081] train_loss: 0.012006\n",
      "[618/01131] train_loss: 0.013254\n",
      "[618/01181] train_loss: 0.012760\n",
      "[619/00005] train_loss: 0.013094\n",
      "[619/00055] train_loss: 0.015395\n",
      "[619/00105] train_loss: 0.013396\n",
      "[619/00155] train_loss: 0.013626\n",
      "[619/00205] train_loss: 0.013552\n",
      "[619/00255] train_loss: 0.012889\n",
      "[619/00305] train_loss: 0.012100\n",
      "[619/00355] train_loss: 0.012486\n",
      "[619/00405] train_loss: 0.012912\n",
      "[619/00455] train_loss: 0.012777\n",
      "[619/00505] train_loss: 0.012565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619/00555] train_loss: 0.012033\n",
      "[619/00605] train_loss: 0.013219\n",
      "[619/00655] train_loss: 0.012965\n",
      "[619/00705] train_loss: 0.013120\n",
      "[619/00755] train_loss: 0.012464\n",
      "[619/00805] train_loss: 0.012464\n",
      "[619/00855] train_loss: 0.012744\n",
      "[619/00905] train_loss: 0.013774\n",
      "[619/00955] train_loss: 0.013641\n",
      "[619/01005] train_loss: 0.012450\n",
      "[619/01055] train_loss: 0.012077\n",
      "[619/01105] train_loss: 0.012446\n",
      "[619/01155] train_loss: 0.013016\n",
      "[619/01205] train_loss: 0.013717\n",
      "[620/00029] train_loss: 0.014437\n",
      "[620/00079] train_loss: 0.015212\n",
      "[620/00129] train_loss: 0.014706\n",
      "[620/00179] train_loss: 0.013029\n",
      "[620/00229] train_loss: 0.013292\n",
      "[620/00279] train_loss: 0.012932\n",
      "[620/00329] train_loss: 0.012664\n",
      "[620/00379] train_loss: 0.012164\n",
      "[620/00429] train_loss: 0.012682\n",
      "[620/00479] train_loss: 0.012205\n",
      "[620/00529] train_loss: 0.012905\n",
      "[620/00579] train_loss: 0.012915\n",
      "[620/00629] train_loss: 0.011888\n",
      "[620/00679] train_loss: 0.012491\n",
      "[620/00729] train_loss: 0.012969\n",
      "[620/00779] train_loss: 0.013186\n",
      "[620/00829] train_loss: 0.012339\n",
      "[620/00879] train_loss: 0.013023\n",
      "[620/00929] train_loss: 0.013488\n",
      "[620/00979] train_loss: 0.013044\n",
      "[620/01029] train_loss: 0.013431\n",
      "[620/01079] train_loss: 0.013123\n",
      "[620/01129] train_loss: 0.013469\n",
      "[620/01179] train_loss: 0.013007\n",
      "[621/00003] train_loss: 0.013747\n",
      "[621/00053] train_loss: 0.015922\n",
      "[621/00103] train_loss: 0.014538\n",
      "[621/00153] train_loss: 0.013874\n",
      "[621/00203] train_loss: 0.013416\n",
      "[621/00253] train_loss: 0.013231\n",
      "[621/00303] train_loss: 0.012242\n",
      "[621/00353] train_loss: 0.012843\n",
      "[621/00403] train_loss: 0.013399\n",
      "[621/00453] train_loss: 0.011807\n",
      "[621/00503] train_loss: 0.013217\n",
      "[621/00553] train_loss: 0.012803\n",
      "[621/00603] train_loss: 0.012725\n",
      "[621/00653] train_loss: 0.013686\n",
      "[621/00703] train_loss: 0.012862\n",
      "[621/00753] train_loss: 0.013608\n",
      "[621/00803] train_loss: 0.012870\n",
      "[621/00853] train_loss: 0.013088\n",
      "[621/00903] train_loss: 0.011949\n",
      "[621/00953] train_loss: 0.012629\n",
      "[621/01003] train_loss: 0.012814\n",
      "[621/01053] train_loss: 0.013066\n",
      "[621/01103] train_loss: 0.012092\n",
      "[621/01153] train_loss: 0.013289\n",
      "[621/01203] train_loss: 0.012962\n",
      "[622/00027] train_loss: 0.013783\n",
      "[622/00077] train_loss: 0.015613\n",
      "[622/00127] train_loss: 0.014492\n",
      "[622/00177] train_loss: 0.013274\n",
      "[622/00227] train_loss: 0.012903\n",
      "[622/00277] train_loss: 0.012960\n",
      "[622/00327] train_loss: 0.012827\n",
      "[622/00377] train_loss: 0.013587\n",
      "[622/00427] train_loss: 0.012771\n",
      "[622/00477] train_loss: 0.011752\n",
      "[622/00527] train_loss: 0.012761\n",
      "[622/00577] train_loss: 0.012282\n",
      "[622/00627] train_loss: 0.012611\n",
      "[622/00677] train_loss: 0.012776\n",
      "[622/00727] train_loss: 0.012641\n",
      "[622/00777] train_loss: 0.013144\n",
      "[622/00827] train_loss: 0.014398\n",
      "[622/00877] train_loss: 0.012323\n",
      "[622/00927] train_loss: 0.013196\n",
      "[622/00977] train_loss: 0.012577\n",
      "[622/01027] train_loss: 0.013094\n",
      "[622/01077] train_loss: 0.012331\n",
      "[622/01127] train_loss: 0.012076\n",
      "[622/01177] train_loss: 0.012614\n",
      "[623/00001] train_loss: 0.013028\n",
      "[623/00051] train_loss: 0.016076\n",
      "[623/00101] train_loss: 0.014779\n",
      "[623/00151] train_loss: 0.013445\n",
      "[623/00201] train_loss: 0.013234\n",
      "[623/00251] train_loss: 0.013108\n",
      "[623/00301] train_loss: 0.013176\n",
      "[623/00351] train_loss: 0.013355\n",
      "[623/00401] train_loss: 0.012567\n",
      "[623/00451] train_loss: 0.012370\n",
      "[623/00501] train_loss: 0.012934\n",
      "[623/00551] train_loss: 0.011825\n",
      "[623/00601] train_loss: 0.012806\n",
      "[623/00651] train_loss: 0.012785\n",
      "[623/00701] train_loss: 0.013528\n",
      "[623/00751] train_loss: 0.012964\n",
      "[623/00801] train_loss: 0.012273\n",
      "[623/00851] train_loss: 0.012877\n",
      "[623/00901] train_loss: 0.011818\n",
      "[623/00951] train_loss: 0.012297\n",
      "[623/01001] train_loss: 0.012894\n",
      "[623/01051] train_loss: 0.013219\n",
      "[623/01101] train_loss: 0.013282\n",
      "[623/01151] train_loss: 0.014016\n",
      "[623/01201] train_loss: 0.012944\n",
      "[624/00025] train_loss: 0.014832\n",
      "[624/00075] train_loss: 0.014144\n",
      "[624/00125] train_loss: 0.013240\n",
      "[624/00175] train_loss: 0.013004\n",
      "[624/00225] train_loss: 0.013014\n",
      "[624/00275] train_loss: 0.012629\n",
      "[624/00325] train_loss: 0.012935\n",
      "[624/00375] train_loss: 0.013595\n",
      "[624/00425] train_loss: 0.012938\n",
      "[624/00475] train_loss: 0.012240\n",
      "[624/00525] train_loss: 0.012617\n",
      "[624/00575] train_loss: 0.012325\n",
      "[624/00625] train_loss: 0.012539\n",
      "[624/00675] train_loss: 0.012914\n",
      "[624/00725] train_loss: 0.012566\n",
      "[624/00775] train_loss: 0.013345\n",
      "[624/00825] train_loss: 0.012571\n",
      "[624/00875] train_loss: 0.013059\n",
      "[624/00925] train_loss: 0.012262\n",
      "[624/00975] train_loss: 0.012605\n",
      "[624/01025] train_loss: 0.012715\n",
      "[624/01075] train_loss: 0.012764\n",
      "[624/01125] train_loss: 0.012471\n",
      "[624/01175] train_loss: 0.013352\n",
      "[624/01225] train_loss: 0.013625\n",
      "[625/00049] train_loss: 0.014878\n",
      "[625/00099] train_loss: 0.014027\n",
      "[625/00149] train_loss: 0.012696\n",
      "[625/00199] train_loss: 0.013205\n",
      "[625/00249] train_loss: 0.012528\n",
      "[625/00299] train_loss: 0.012948\n",
      "[625/00349] train_loss: 0.013412\n",
      "[625/00399] train_loss: 0.012155\n",
      "[625/00449] train_loss: 0.013143\n",
      "[625/00499] train_loss: 0.012985\n",
      "[625/00549] train_loss: 0.012726\n",
      "[625/00599] train_loss: 0.013667\n",
      "[625/00649] train_loss: 0.013264\n",
      "[625/00699] train_loss: 0.012373\n",
      "[625/00749] train_loss: 0.013190\n",
      "[625/00799] train_loss: 0.012603\n",
      "[625/00849] train_loss: 0.012274\n",
      "[625/00899] train_loss: 0.013150\n",
      "[625/00949] train_loss: 0.012519\n",
      "[625/00999] train_loss: 0.012402\n",
      "[625/01049] train_loss: 0.013554\n",
      "[625/01099] train_loss: 0.013566\n",
      "[625/01149] train_loss: 0.013523\n",
      "[625/01199] train_loss: 0.013710\n",
      "[626/00023] train_loss: 0.015034\n",
      "[626/00073] train_loss: 0.014997\n",
      "[626/00123] train_loss: 0.014028\n",
      "[626/00173] train_loss: 0.012584\n",
      "[626/00223] train_loss: 0.012516\n",
      "[626/00273] train_loss: 0.012996\n",
      "[626/00323] train_loss: 0.012825\n",
      "[626/00373] train_loss: 0.013796\n",
      "[626/00423] train_loss: 0.012879\n",
      "[626/00473] train_loss: 0.012778\n",
      "[626/00523] train_loss: 0.012777\n",
      "[626/00573] train_loss: 0.012291\n",
      "[626/00623] train_loss: 0.012166\n",
      "[626/00673] train_loss: 0.012549\n",
      "[626/00723] train_loss: 0.012975\n",
      "[626/00773] train_loss: 0.012911\n",
      "[626/00823] train_loss: 0.013194\n",
      "[626/00873] train_loss: 0.012844\n",
      "[626/00923] train_loss: 0.012884\n",
      "[626/00973] train_loss: 0.012837\n",
      "[626/01023] train_loss: 0.013070\n",
      "[626/01073] train_loss: 0.012577\n",
      "[626/01123] train_loss: 0.012689\n",
      "[626/01173] train_loss: 0.013592\n",
      "[626/01223] train_loss: 0.013306\n",
      "[627/00047] train_loss: 0.015439\n",
      "[627/00097] train_loss: 0.014469\n",
      "[627/00147] train_loss: 0.013864\n",
      "[627/00197] train_loss: 0.013619\n",
      "[627/00247] train_loss: 0.013256\n",
      "[627/00297] train_loss: 0.012071\n",
      "[627/00347] train_loss: 0.012802\n",
      "[627/00397] train_loss: 0.013107\n",
      "[627/00447] train_loss: 0.013101\n",
      "[627/00497] train_loss: 0.012566\n",
      "[627/00547] train_loss: 0.012622\n",
      "[627/00597] train_loss: 0.012794\n",
      "[627/00647] train_loss: 0.012392\n",
      "[627/00697] train_loss: 0.011980\n",
      "[627/00747] train_loss: 0.012925\n",
      "[627/00797] train_loss: 0.012786\n",
      "[627/00847] train_loss: 0.013151\n",
      "[627/00897] train_loss: 0.013091\n",
      "[627/00947] train_loss: 0.012674\n",
      "[627/00997] train_loss: 0.013573\n",
      "[627/01047] train_loss: 0.012803\n",
      "[627/01097] train_loss: 0.013706\n",
      "[627/01147] train_loss: 0.012583\n",
      "[627/01197] train_loss: 0.012061\n",
      "[628/00021] train_loss: 0.013784\n",
      "[628/00071] train_loss: 0.015030\n",
      "[628/00121] train_loss: 0.014313\n",
      "[628/00171] train_loss: 0.013155\n",
      "[628/00221] train_loss: 0.012205\n",
      "[628/00271] train_loss: 0.013631\n",
      "[628/00321] train_loss: 0.012402\n",
      "[628/00371] train_loss: 0.012639\n",
      "[628/00421] train_loss: 0.013866\n",
      "[628/00471] train_loss: 0.012698\n",
      "[628/00521] train_loss: 0.012623\n",
      "[628/00571] train_loss: 0.011965\n",
      "[628/00621] train_loss: 0.012031\n",
      "[628/00671] train_loss: 0.012340\n",
      "[628/00721] train_loss: 0.012151\n",
      "[628/00771] train_loss: 0.013062\n",
      "[628/00821] train_loss: 0.012652\n",
      "[628/00871] train_loss: 0.013595\n",
      "[628/00921] train_loss: 0.012478\n",
      "[628/00971] train_loss: 0.013082\n",
      "[628/01021] train_loss: 0.013060\n",
      "[628/01071] train_loss: 0.012160\n",
      "[628/01121] train_loss: 0.013546\n",
      "[628/01171] train_loss: 0.013207\n",
      "[628/01221] train_loss: 0.013036\n",
      "[629/00045] train_loss: 0.016178\n",
      "[629/00095] train_loss: 0.014640\n",
      "[629/00145] train_loss: 0.013888\n",
      "[629/00195] train_loss: 0.013326\n",
      "[629/00245] train_loss: 0.012975\n",
      "[629/00295] train_loss: 0.012914\n",
      "[629/00345] train_loss: 0.012612\n",
      "[629/00395] train_loss: 0.012424\n",
      "[629/00445] train_loss: 0.012026\n",
      "[629/00495] train_loss: 0.012534\n",
      "[629/00545] train_loss: 0.012794\n",
      "[629/00595] train_loss: 0.012761\n",
      "[629/00645] train_loss: 0.012762\n",
      "[629/00695] train_loss: 0.012623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[629/00745] train_loss: 0.013284\n",
      "[629/00795] train_loss: 0.012441\n",
      "[629/00845] train_loss: 0.012867\n",
      "[629/00895] train_loss: 0.012429\n",
      "[629/00945] train_loss: 0.012892\n",
      "[629/00995] train_loss: 0.013318\n",
      "[629/01045] train_loss: 0.012852\n",
      "[629/01095] train_loss: 0.012263\n",
      "[629/01145] train_loss: 0.013337\n",
      "[629/01195] train_loss: 0.013097\n",
      "[630/00019] train_loss: 0.014530\n",
      "[630/00069] train_loss: 0.015078\n",
      "[630/00119] train_loss: 0.012944\n",
      "[630/00169] train_loss: 0.014330\n",
      "[630/00219] train_loss: 0.013419\n",
      "[630/00269] train_loss: 0.012661\n",
      "[630/00319] train_loss: 0.013402\n",
      "[630/00369] train_loss: 0.012829\n",
      "[630/00419] train_loss: 0.012998\n",
      "[630/00469] train_loss: 0.012681\n",
      "[630/00519] train_loss: 0.012933\n",
      "[630/00569] train_loss: 0.012576\n",
      "[630/00619] train_loss: 0.012659\n",
      "[630/00669] train_loss: 0.012686\n",
      "[630/00719] train_loss: 0.012773\n",
      "[630/00769] train_loss: 0.013363\n",
      "[630/00819] train_loss: 0.012866\n",
      "[630/00869] train_loss: 0.013193\n",
      "[630/00919] train_loss: 0.013432\n",
      "[630/00969] train_loss: 0.012332\n",
      "[630/01019] train_loss: 0.012799\n",
      "[630/01069] train_loss: 0.012790\n",
      "[630/01119] train_loss: 0.012894\n",
      "[630/01169] train_loss: 0.013611\n",
      "[630/01219] train_loss: 0.012587\n",
      "[631/00043] train_loss: 0.014900\n",
      "[631/00093] train_loss: 0.014862\n",
      "[631/00143] train_loss: 0.013453\n",
      "[631/00193] train_loss: 0.013325\n",
      "[631/00243] train_loss: 0.013324\n",
      "[631/00293] train_loss: 0.013298\n",
      "[631/00343] train_loss: 0.013651\n",
      "[631/00393] train_loss: 0.013339\n",
      "[631/00443] train_loss: 0.012509\n",
      "[631/00493] train_loss: 0.011788\n",
      "[631/00543] train_loss: 0.012320\n",
      "[631/00593] train_loss: 0.012225\n",
      "[631/00643] train_loss: 0.012847\n",
      "[631/00693] train_loss: 0.012803\n",
      "[631/00743] train_loss: 0.012463\n",
      "[631/00793] train_loss: 0.012882\n",
      "[631/00843] train_loss: 0.012991\n",
      "[631/00893] train_loss: 0.013163\n",
      "[631/00943] train_loss: 0.012506\n",
      "[631/00993] train_loss: 0.012462\n",
      "[631/01043] train_loss: 0.013002\n",
      "[631/01093] train_loss: 0.013551\n",
      "[631/01143] train_loss: 0.013607\n",
      "[631/01193] train_loss: 0.013097\n",
      "[632/00017] train_loss: 0.014295\n",
      "[632/00067] train_loss: 0.014884\n",
      "[632/00117] train_loss: 0.014165\n",
      "[632/00167] train_loss: 0.012758\n",
      "[632/00217] train_loss: 0.013677\n",
      "[632/00267] train_loss: 0.012752\n",
      "[632/00317] train_loss: 0.012197\n",
      "[632/00367] train_loss: 0.013361\n",
      "[632/00417] train_loss: 0.012575\n",
      "[632/00467] train_loss: 0.012674\n",
      "[632/00517] train_loss: 0.013168\n",
      "[632/00567] train_loss: 0.012294\n",
      "[632/00617] train_loss: 0.012463\n",
      "[632/00667] train_loss: 0.012421\n",
      "[632/00717] train_loss: 0.012270\n",
      "[632/00767] train_loss: 0.013817\n",
      "[632/00817] train_loss: 0.012571\n",
      "[632/00867] train_loss: 0.012667\n",
      "[632/00917] train_loss: 0.013481\n",
      "[632/00967] train_loss: 0.012690\n",
      "[632/01017] train_loss: 0.013632\n",
      "[632/01067] train_loss: 0.012265\n",
      "[632/01117] train_loss: 0.012785\n",
      "[632/01167] train_loss: 0.012688\n",
      "[632/01217] train_loss: 0.012523\n",
      "[633/00041] train_loss: 0.014716\n",
      "[633/00091] train_loss: 0.015385\n",
      "[633/00141] train_loss: 0.013870\n",
      "[633/00191] train_loss: 0.013234\n",
      "[633/00241] train_loss: 0.013065\n",
      "[633/00291] train_loss: 0.012845\n",
      "[633/00341] train_loss: 0.012959\n",
      "[633/00391] train_loss: 0.012287\n",
      "[633/00441] train_loss: 0.013681\n",
      "[633/00491] train_loss: 0.013156\n",
      "[633/00541] train_loss: 0.012993\n",
      "[633/00591] train_loss: 0.013041\n",
      "[633/00641] train_loss: 0.012820\n",
      "[633/00691] train_loss: 0.013078\n",
      "[633/00741] train_loss: 0.012815\n",
      "[633/00791] train_loss: 0.012480\n",
      "[633/00841] train_loss: 0.012688\n",
      "[633/00891] train_loss: 0.012734\n",
      "[633/00941] train_loss: 0.012567\n",
      "[633/00991] train_loss: 0.013522\n",
      "[633/01041] train_loss: 0.013335\n",
      "[633/01091] train_loss: 0.012098\n",
      "[633/01141] train_loss: 0.013395\n",
      "[633/01191] train_loss: 0.012297\n",
      "[634/00015] train_loss: 0.013223\n",
      "[634/00065] train_loss: 0.014665\n",
      "[634/00115] train_loss: 0.014174\n",
      "[634/00165] train_loss: 0.013471\n",
      "[634/00215] train_loss: 0.013162\n",
      "[634/00265] train_loss: 0.013649\n",
      "[634/00315] train_loss: 0.012859\n",
      "[634/00365] train_loss: 0.013555\n",
      "[634/00415] train_loss: 0.012399\n",
      "[634/00465] train_loss: 0.012770\n",
      "[634/00515] train_loss: 0.013060\n",
      "[634/00565] train_loss: 0.012660\n",
      "[634/00615] train_loss: 0.012318\n",
      "[634/00665] train_loss: 0.012435\n",
      "[634/00715] train_loss: 0.013540\n",
      "[634/00765] train_loss: 0.012661\n",
      "[634/00815] train_loss: 0.013083\n",
      "[634/00865] train_loss: 0.012654\n",
      "[634/00915] train_loss: 0.012286\n",
      "[634/00965] train_loss: 0.011869\n",
      "[634/01015] train_loss: 0.012303\n",
      "[634/01065] train_loss: 0.012633\n",
      "[634/01115] train_loss: 0.013231\n",
      "[634/01165] train_loss: 0.013839\n",
      "[634/01215] train_loss: 0.012980\n",
      "[635/00039] train_loss: 0.014078\n",
      "[635/00089] train_loss: 0.014067\n",
      "[635/00139] train_loss: 0.013825\n",
      "[635/00189] train_loss: 0.013184\n",
      "[635/00239] train_loss: 0.013360\n",
      "[635/00289] train_loss: 0.012660\n",
      "[635/00339] train_loss: 0.013006\n",
      "[635/00389] train_loss: 0.012811\n",
      "[635/00439] train_loss: 0.012475\n",
      "[635/00489] train_loss: 0.012848\n",
      "[635/00539] train_loss: 0.013234\n",
      "[635/00589] train_loss: 0.012794\n",
      "[635/00639] train_loss: 0.013324\n",
      "[635/00689] train_loss: 0.012583\n",
      "[635/00739] train_loss: 0.013086\n",
      "[635/00789] train_loss: 0.012417\n",
      "[635/00839] train_loss: 0.013412\n",
      "[635/00889] train_loss: 0.012749\n",
      "[635/00939] train_loss: 0.012392\n",
      "[635/00989] train_loss: 0.012509\n",
      "[635/01039] train_loss: 0.012754\n",
      "[635/01089] train_loss: 0.013150\n",
      "[635/01139] train_loss: 0.012496\n",
      "[635/01189] train_loss: 0.013556\n",
      "[636/00013] train_loss: 0.013949\n",
      "[636/00063] train_loss: 0.015400\n",
      "[636/00113] train_loss: 0.013974\n",
      "[636/00163] train_loss: 0.013427\n",
      "[636/00213] train_loss: 0.013223\n",
      "[636/00263] train_loss: 0.013538\n",
      "[636/00313] train_loss: 0.013107\n",
      "[636/00363] train_loss: 0.012917\n",
      "[636/00413] train_loss: 0.012863\n",
      "[636/00463] train_loss: 0.012590\n",
      "[636/00513] train_loss: 0.012916\n",
      "[636/00563] train_loss: 0.012667\n",
      "[636/00613] train_loss: 0.012585\n",
      "[636/00663] train_loss: 0.012729\n",
      "[636/00713] train_loss: 0.013462\n",
      "[636/00763] train_loss: 0.012627\n",
      "[636/00813] train_loss: 0.013140\n",
      "[636/00863] train_loss: 0.012652\n",
      "[636/00913] train_loss: 0.012853\n",
      "[636/00963] train_loss: 0.012698\n",
      "[636/01013] train_loss: 0.012848\n",
      "[636/01063] train_loss: 0.012565\n",
      "[636/01113] train_loss: 0.013134\n",
      "[636/01163] train_loss: 0.012920\n",
      "[636/01213] train_loss: 0.013369\n",
      "[637/00037] train_loss: 0.014646\n",
      "[637/00087] train_loss: 0.014779\n",
      "[637/00137] train_loss: 0.013318\n",
      "[637/00187] train_loss: 0.012824\n",
      "[637/00237] train_loss: 0.013051\n",
      "[637/00287] train_loss: 0.012761\n",
      "[637/00337] train_loss: 0.012443\n",
      "[637/00387] train_loss: 0.012422\n",
      "[637/00437] train_loss: 0.013727\n",
      "[637/00487] train_loss: 0.012152\n",
      "[637/00537] train_loss: 0.013419\n",
      "[637/00587] train_loss: 0.012792\n",
      "[637/00637] train_loss: 0.013333\n",
      "[637/00687] train_loss: 0.012294\n",
      "[637/00737] train_loss: 0.012931\n",
      "[637/00787] train_loss: 0.012108\n",
      "[637/00837] train_loss: 0.013090\n",
      "[637/00887] train_loss: 0.011998\n",
      "[637/00937] train_loss: 0.013317\n",
      "[637/00987] train_loss: 0.012966\n",
      "[637/01037] train_loss: 0.012476\n",
      "[637/01087] train_loss: 0.013476\n",
      "[637/01137] train_loss: 0.013233\n",
      "[637/01187] train_loss: 0.012358\n",
      "[638/00011] train_loss: 0.013503\n",
      "[638/00061] train_loss: 0.015452\n",
      "[638/00111] train_loss: 0.014506\n",
      "[638/00161] train_loss: 0.013690\n",
      "[638/00211] train_loss: 0.011728\n",
      "[638/00261] train_loss: 0.013406\n",
      "[638/00311] train_loss: 0.012492\n",
      "[638/00361] train_loss: 0.013063\n",
      "[638/00411] train_loss: 0.012811\n",
      "[638/00461] train_loss: 0.013485\n",
      "[638/00511] train_loss: 0.012506\n",
      "[638/00561] train_loss: 0.012164\n",
      "[638/00611] train_loss: 0.011780\n",
      "[638/00661] train_loss: 0.012776\n",
      "[638/00711] train_loss: 0.013568\n",
      "[638/00761] train_loss: 0.013176\n",
      "[638/00811] train_loss: 0.012766\n",
      "[638/00861] train_loss: 0.013275\n",
      "[638/00911] train_loss: 0.011873\n",
      "[638/00961] train_loss: 0.012669\n",
      "[638/01011] train_loss: 0.012944\n",
      "[638/01061] train_loss: 0.013263\n",
      "[638/01111] train_loss: 0.013409\n",
      "[638/01161] train_loss: 0.012642\n",
      "[638/01211] train_loss: 0.013316\n",
      "[639/00035] train_loss: 0.015310\n",
      "[639/00085] train_loss: 0.013891\n",
      "[639/00135] train_loss: 0.013506\n",
      "[639/00185] train_loss: 0.013140\n",
      "[639/00235] train_loss: 0.013259\n",
      "[639/00285] train_loss: 0.012976\n",
      "[639/00335] train_loss: 0.012964\n",
      "[639/00385] train_loss: 0.012361\n",
      "[639/00435] train_loss: 0.013329\n",
      "[639/00485] train_loss: 0.013148\n",
      "[639/00535] train_loss: 0.013230\n",
      "[639/00585] train_loss: 0.012816\n",
      "[639/00635] train_loss: 0.011806\n",
      "[639/00685] train_loss: 0.012629\n",
      "[639/00735] train_loss: 0.012510\n",
      "[639/00785] train_loss: 0.012176\n",
      "[639/00835] train_loss: 0.013084\n",
      "[639/00885] train_loss: 0.013086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[639/00935] train_loss: 0.013223\n",
      "[639/00985] train_loss: 0.012262\n",
      "[639/01035] train_loss: 0.013224\n",
      "[639/01085] train_loss: 0.013288\n",
      "[639/01135] train_loss: 0.012047\n",
      "[639/01185] train_loss: 0.013717\n",
      "[640/00009] train_loss: 0.013974\n",
      "[640/00059] train_loss: 0.015518\n",
      "[640/00109] train_loss: 0.014283\n",
      "[640/00159] train_loss: 0.013506\n",
      "[640/00209] train_loss: 0.013105\n",
      "[640/00259] train_loss: 0.013341\n",
      "[640/00309] train_loss: 0.012468\n",
      "[640/00359] train_loss: 0.013042\n",
      "[640/00409] train_loss: 0.012109\n",
      "[640/00459] train_loss: 0.012963\n",
      "[640/00509] train_loss: 0.012555\n",
      "[640/00559] train_loss: 0.012368\n",
      "[640/00609] train_loss: 0.012431\n",
      "[640/00659] train_loss: 0.012746\n",
      "[640/00709] train_loss: 0.012094\n",
      "[640/00759] train_loss: 0.012297\n",
      "[640/00809] train_loss: 0.012564\n",
      "[640/00859] train_loss: 0.012887\n",
      "[640/00909] train_loss: 0.012946\n",
      "[640/00959] train_loss: 0.013747\n",
      "[640/01009] train_loss: 0.012627\n",
      "[640/01059] train_loss: 0.013576\n",
      "[640/01109] train_loss: 0.012540\n",
      "[640/01159] train_loss: 0.012631\n",
      "[640/01209] train_loss: 0.013093\n",
      "[641/00033] train_loss: 0.015468\n",
      "[641/00083] train_loss: 0.014759\n",
      "[641/00133] train_loss: 0.013480\n",
      "[641/00183] train_loss: 0.012655\n",
      "[641/00233] train_loss: 0.011969\n",
      "[641/00283] train_loss: 0.012864\n",
      "[641/00333] train_loss: 0.012628\n",
      "[641/00383] train_loss: 0.012547\n",
      "[641/00433] train_loss: 0.012254\n",
      "[641/00483] train_loss: 0.012807\n",
      "[641/00533] train_loss: 0.013597\n",
      "[641/00583] train_loss: 0.013226\n",
      "[641/00633] train_loss: 0.013222\n",
      "[641/00683] train_loss: 0.011817\n",
      "[641/00733] train_loss: 0.013310\n",
      "[641/00783] train_loss: 0.013290\n",
      "[641/00833] train_loss: 0.013329\n",
      "[641/00883] train_loss: 0.013197\n",
      "[641/00933] train_loss: 0.012947\n",
      "[641/00983] train_loss: 0.012512\n",
      "[641/01033] train_loss: 0.012496\n",
      "[641/01083] train_loss: 0.012589\n",
      "[641/01133] train_loss: 0.013178\n",
      "[641/01183] train_loss: 0.013537\n",
      "[642/00007] train_loss: 0.012828\n",
      "[642/00057] train_loss: 0.014576\n",
      "[642/00107] train_loss: 0.015075\n",
      "[642/00157] train_loss: 0.013793\n",
      "[642/00207] train_loss: 0.012567\n",
      "[642/00257] train_loss: 0.012785\n",
      "[642/00307] train_loss: 0.013217\n",
      "[642/00357] train_loss: 0.013799\n",
      "[642/00407] train_loss: 0.013086\n",
      "[642/00457] train_loss: 0.012314\n",
      "[642/00507] train_loss: 0.012507\n",
      "[642/00557] train_loss: 0.012957\n",
      "[642/00607] train_loss: 0.012507\n",
      "[642/00657] train_loss: 0.012257\n",
      "[642/00707] train_loss: 0.012590\n",
      "[642/00757] train_loss: 0.012959\n",
      "[642/00807] train_loss: 0.013054\n",
      "[642/00857] train_loss: 0.012555\n",
      "[642/00907] train_loss: 0.012939\n",
      "[642/00957] train_loss: 0.013436\n",
      "[642/01007] train_loss: 0.012450\n",
      "[642/01057] train_loss: 0.013098\n",
      "[642/01107] train_loss: 0.012255\n",
      "[642/01157] train_loss: 0.013394\n",
      "[642/01207] train_loss: 0.012404\n",
      "[643/00031] train_loss: 0.014475\n",
      "[643/00081] train_loss: 0.015756\n",
      "[643/00131] train_loss: 0.013457\n",
      "[643/00181] train_loss: 0.013466\n",
      "[643/00231] train_loss: 0.013201\n",
      "[643/00281] train_loss: 0.012744\n",
      "[643/00331] train_loss: 0.012114\n",
      "[643/00381] train_loss: 0.011987\n",
      "[643/00431] train_loss: 0.013154\n",
      "[643/00481] train_loss: 0.013216\n",
      "[643/00531] train_loss: 0.013367\n",
      "[643/00581] train_loss: 0.013359\n",
      "[643/00631] train_loss: 0.012899\n",
      "[643/00681] train_loss: 0.012753\n",
      "[643/00731] train_loss: 0.012395\n",
      "[643/00781] train_loss: 0.012773\n",
      "[643/00831] train_loss: 0.012055\n",
      "[643/00881] train_loss: 0.012801\n",
      "[643/00931] train_loss: 0.013246\n",
      "[643/00981] train_loss: 0.011684\n",
      "[643/01031] train_loss: 0.013182\n",
      "[643/01081] train_loss: 0.012471\n",
      "[643/01131] train_loss: 0.012753\n",
      "[643/01181] train_loss: 0.012635\n",
      "[644/00005] train_loss: 0.013239\n",
      "[644/00055] train_loss: 0.014751\n",
      "[644/00105] train_loss: 0.014040\n",
      "[644/00155] train_loss: 0.012654\n",
      "[644/00205] train_loss: 0.012515\n",
      "[644/00255] train_loss: 0.012595\n",
      "[644/00305] train_loss: 0.013365\n",
      "[644/00355] train_loss: 0.012458\n",
      "[644/00405] train_loss: 0.012279\n",
      "[644/00455] train_loss: 0.011959\n",
      "[644/00505] train_loss: 0.012569\n",
      "[644/00555] train_loss: 0.013224\n",
      "[644/00605] train_loss: 0.012581\n",
      "[644/00655] train_loss: 0.012722\n",
      "[644/00705] train_loss: 0.012933\n",
      "[644/00755] train_loss: 0.012867\n",
      "[644/00805] train_loss: 0.012551\n",
      "[644/00855] train_loss: 0.012260\n",
      "[644/00905] train_loss: 0.013287\n",
      "[644/00955] train_loss: 0.012402\n",
      "[644/01005] train_loss: 0.013625\n",
      "[644/01055] train_loss: 0.013705\n",
      "[644/01105] train_loss: 0.013789\n",
      "[644/01155] train_loss: 0.012450\n",
      "[644/01205] train_loss: 0.013115\n",
      "[645/00029] train_loss: 0.014856\n",
      "[645/00079] train_loss: 0.014232\n",
      "[645/00129] train_loss: 0.014042\n",
      "[645/00179] train_loss: 0.013128\n",
      "[645/00229] train_loss: 0.013936\n",
      "[645/00279] train_loss: 0.012819\n",
      "[645/00329] train_loss: 0.012912\n",
      "[645/00379] train_loss: 0.012959\n",
      "[645/00429] train_loss: 0.012802\n",
      "[645/00479] train_loss: 0.012345\n",
      "[645/00529] train_loss: 0.012317\n",
      "[645/00579] train_loss: 0.012151\n",
      "[645/00629] train_loss: 0.013379\n",
      "[645/00679] train_loss: 0.013184\n",
      "[645/00729] train_loss: 0.012630\n",
      "[645/00779] train_loss: 0.013536\n",
      "[645/00829] train_loss: 0.012462\n",
      "[645/00879] train_loss: 0.013371\n",
      "[645/00929] train_loss: 0.013184\n",
      "[645/00979] train_loss: 0.012845\n",
      "[645/01029] train_loss: 0.012835\n",
      "[645/01079] train_loss: 0.013011\n",
      "[645/01129] train_loss: 0.013491\n",
      "[645/01179] train_loss: 0.012843\n",
      "[646/00003] train_loss: 0.012751\n",
      "[646/00053] train_loss: 0.015306\n",
      "[646/00103] train_loss: 0.014434\n",
      "[646/00153] train_loss: 0.014384\n",
      "[646/00203] train_loss: 0.013682\n",
      "[646/00253] train_loss: 0.012897\n",
      "[646/00303] train_loss: 0.013116\n",
      "[646/00353] train_loss: 0.013332\n",
      "[646/00403] train_loss: 0.012496\n",
      "[646/00453] train_loss: 0.012760\n",
      "[646/00503] train_loss: 0.012686\n",
      "[646/00553] train_loss: 0.012484\n",
      "[646/00603] train_loss: 0.013009\n",
      "[646/00653] train_loss: 0.012046\n",
      "[646/00703] train_loss: 0.012923\n",
      "[646/00753] train_loss: 0.012627\n",
      "[646/00803] train_loss: 0.013085\n",
      "[646/00853] train_loss: 0.013232\n",
      "[646/00903] train_loss: 0.012379\n",
      "[646/00953] train_loss: 0.012581\n",
      "[646/01003] train_loss: 0.012909\n",
      "[646/01053] train_loss: 0.012225\n",
      "[646/01103] train_loss: 0.012577\n",
      "[646/01153] train_loss: 0.012798\n",
      "[646/01203] train_loss: 0.013754\n",
      "[647/00027] train_loss: 0.014111\n",
      "[647/00077] train_loss: 0.014030\n",
      "[647/00127] train_loss: 0.014054\n",
      "[647/00177] train_loss: 0.013207\n",
      "[647/00227] train_loss: 0.013243\n",
      "[647/00277] train_loss: 0.012964\n",
      "[647/00327] train_loss: 0.012882\n",
      "[647/00377] train_loss: 0.012329\n",
      "[647/00427] train_loss: 0.012951\n",
      "[647/00477] train_loss: 0.012104\n",
      "[647/00527] train_loss: 0.013178\n",
      "[647/00577] train_loss: 0.011982\n",
      "[647/00627] train_loss: 0.012641\n",
      "[647/00677] train_loss: 0.012766\n",
      "[647/00727] train_loss: 0.012903\n",
      "[647/00777] train_loss: 0.012840\n",
      "[647/00827] train_loss: 0.012832\n",
      "[647/00877] train_loss: 0.013125\n",
      "[647/00927] train_loss: 0.013178\n",
      "[647/00977] train_loss: 0.012900\n",
      "[647/01027] train_loss: 0.012317\n",
      "[647/01077] train_loss: 0.012378\n",
      "[647/01127] train_loss: 0.013026\n",
      "[647/01177] train_loss: 0.013002\n",
      "[648/00001] train_loss: 0.013323\n",
      "[648/00051] train_loss: 0.015008\n",
      "[648/00101] train_loss: 0.014482\n",
      "[648/00151] train_loss: 0.013872\n",
      "[648/00201] train_loss: 0.013760\n",
      "[648/00251] train_loss: 0.012368\n",
      "[648/00301] train_loss: 0.013366\n",
      "[648/00351] train_loss: 0.012849\n",
      "[648/00401] train_loss: 0.012755\n",
      "[648/00451] train_loss: 0.012502\n",
      "[648/00501] train_loss: 0.012818\n",
      "[648/00551] train_loss: 0.013098\n",
      "[648/00601] train_loss: 0.011982\n",
      "[648/00651] train_loss: 0.012449\n",
      "[648/00701] train_loss: 0.012259\n",
      "[648/00751] train_loss: 0.013143\n",
      "[648/00801] train_loss: 0.012369\n",
      "[648/00851] train_loss: 0.012959\n",
      "[648/00901] train_loss: 0.013322\n",
      "[648/00951] train_loss: 0.012224\n",
      "[648/01001] train_loss: 0.013099\n",
      "[648/01051] train_loss: 0.012047\n",
      "[648/01101] train_loss: 0.013065\n",
      "[648/01151] train_loss: 0.013118\n",
      "[648/01201] train_loss: 0.012714\n",
      "[649/00025] train_loss: 0.014514\n",
      "[649/00075] train_loss: 0.014475\n",
      "[649/00125] train_loss: 0.014268\n",
      "[649/00175] train_loss: 0.014078\n",
      "[649/00225] train_loss: 0.012931\n",
      "[649/00275] train_loss: 0.011889\n",
      "[649/00325] train_loss: 0.013052\n",
      "[649/00375] train_loss: 0.012543\n",
      "[649/00425] train_loss: 0.012894\n",
      "[649/00475] train_loss: 0.012988\n",
      "[649/00525] train_loss: 0.012694\n",
      "[649/00575] train_loss: 0.011916\n",
      "[649/00625] train_loss: 0.012864\n",
      "[649/00675] train_loss: 0.012987\n",
      "[649/00725] train_loss: 0.013199\n",
      "[649/00775] train_loss: 0.013556\n",
      "[649/00825] train_loss: 0.012155\n",
      "[649/00875] train_loss: 0.012657\n",
      "[649/00925] train_loss: 0.013361\n",
      "[649/00975] train_loss: 0.012986\n",
      "[649/01025] train_loss: 0.011894\n",
      "[649/01075] train_loss: 0.012617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[649/01125] train_loss: 0.012974\n",
      "[649/01175] train_loss: 0.013739\n",
      "[649/01225] train_loss: 0.012510\n",
      "[650/00049] train_loss: 0.016292\n",
      "[650/00099] train_loss: 0.013799\n",
      "[650/00149] train_loss: 0.014263\n",
      "[650/00199] train_loss: 0.014057\n",
      "[650/00249] train_loss: 0.012544\n",
      "[650/00299] train_loss: 0.013167\n",
      "[650/00349] train_loss: 0.012980\n",
      "[650/00399] train_loss: 0.013699\n",
      "[650/00449] train_loss: 0.013659\n",
      "[650/00499] train_loss: 0.012041\n",
      "[650/00549] train_loss: 0.012763\n",
      "[650/00599] train_loss: 0.012598\n",
      "[650/00649] train_loss: 0.012556\n",
      "[650/00699] train_loss: 0.012101\n",
      "[650/00749] train_loss: 0.012255\n",
      "[650/00799] train_loss: 0.012715\n",
      "[650/00849] train_loss: 0.012515\n",
      "[650/00899] train_loss: 0.012606\n",
      "[650/00949] train_loss: 0.012243\n",
      "[650/00999] train_loss: 0.012892\n",
      "[650/01049] train_loss: 0.012291\n",
      "[650/01099] train_loss: 0.013248\n",
      "[650/01149] train_loss: 0.013204\n",
      "[650/01199] train_loss: 0.013199\n",
      "[651/00023] train_loss: 0.013121\n",
      "[651/00073] train_loss: 0.014311\n",
      "[651/00123] train_loss: 0.013616\n",
      "[651/00173] train_loss: 0.014249\n",
      "[651/00223] train_loss: 0.012844\n",
      "[651/00273] train_loss: 0.012066\n",
      "[651/00323] train_loss: 0.013143\n",
      "[651/00373] train_loss: 0.012205\n",
      "[651/00423] train_loss: 0.012917\n",
      "[651/00473] train_loss: 0.013299\n",
      "[651/00523] train_loss: 0.012750\n",
      "[651/00573] train_loss: 0.012443\n",
      "[651/00623] train_loss: 0.013704\n",
      "[651/00673] train_loss: 0.012012\n",
      "[651/00723] train_loss: 0.012549\n",
      "[651/00773] train_loss: 0.012627\n",
      "[651/00823] train_loss: 0.013075\n",
      "[651/00873] train_loss: 0.012600\n",
      "[651/00923] train_loss: 0.013519\n",
      "[651/00973] train_loss: 0.013110\n",
      "[651/01023] train_loss: 0.012892\n",
      "[651/01073] train_loss: 0.012799\n",
      "[651/01123] train_loss: 0.012260\n",
      "[651/01173] train_loss: 0.013492\n",
      "[651/01223] train_loss: 0.012853\n",
      "[652/00047] train_loss: 0.014873\n",
      "[652/00097] train_loss: 0.013940\n",
      "[652/00147] train_loss: 0.012466\n",
      "[652/00197] train_loss: 0.012994\n",
      "[652/00247] train_loss: 0.013360\n",
      "[652/00297] train_loss: 0.013916\n",
      "[652/00347] train_loss: 0.013055\n",
      "[652/00397] train_loss: 0.012433\n",
      "[652/00447] train_loss: 0.012509\n",
      "[652/00497] train_loss: 0.012837\n",
      "[652/00547] train_loss: 0.012051\n",
      "[652/00597] train_loss: 0.013328\n",
      "[652/00647] train_loss: 0.012629\n",
      "[652/00697] train_loss: 0.013159\n",
      "[652/00747] train_loss: 0.013479\n",
      "[652/00797] train_loss: 0.013720\n",
      "[652/00847] train_loss: 0.012149\n",
      "[652/00897] train_loss: 0.012597\n",
      "[652/00947] train_loss: 0.012752\n",
      "[652/00997] train_loss: 0.012783\n",
      "[652/01047] train_loss: 0.013210\n",
      "[652/01097] train_loss: 0.013292\n",
      "[652/01147] train_loss: 0.013396\n",
      "[652/01197] train_loss: 0.012695\n",
      "[653/00021] train_loss: 0.013469\n",
      "[653/00071] train_loss: 0.014454\n",
      "[653/00121] train_loss: 0.014401\n",
      "[653/00171] train_loss: 0.013233\n",
      "[653/00221] train_loss: 0.013478\n",
      "[653/00271] train_loss: 0.013149\n",
      "[653/00321] train_loss: 0.013095\n",
      "[653/00371] train_loss: 0.012862\n",
      "[653/00421] train_loss: 0.012529\n",
      "[653/00471] train_loss: 0.012796\n",
      "[653/00521] train_loss: 0.012158\n",
      "[653/00571] train_loss: 0.012488\n",
      "[653/00621] train_loss: 0.012943\n",
      "[653/00671] train_loss: 0.013166\n",
      "[653/00721] train_loss: 0.013308\n",
      "[653/00771] train_loss: 0.012019\n",
      "[653/00821] train_loss: 0.012676\n",
      "[653/00871] train_loss: 0.011873\n",
      "[653/00921] train_loss: 0.012764\n",
      "[653/00971] train_loss: 0.013043\n",
      "[653/01021] train_loss: 0.013147\n",
      "[653/01071] train_loss: 0.013245\n",
      "[653/01121] train_loss: 0.012210\n",
      "[653/01171] train_loss: 0.013494\n",
      "[653/01221] train_loss: 0.012505\n",
      "[654/00045] train_loss: 0.015570\n",
      "[654/00095] train_loss: 0.014589\n",
      "[654/00145] train_loss: 0.013197\n",
      "[654/00195] train_loss: 0.013553\n",
      "[654/00245] train_loss: 0.012821\n",
      "[654/00295] train_loss: 0.012868\n",
      "[654/00345] train_loss: 0.012816\n",
      "[654/00395] train_loss: 0.012803\n",
      "[654/00445] train_loss: 0.012310\n",
      "[654/00495] train_loss: 0.012881\n",
      "[654/00545] train_loss: 0.012850\n",
      "[654/00595] train_loss: 0.012347\n",
      "[654/00645] train_loss: 0.012067\n",
      "[654/00695] train_loss: 0.012813\n",
      "[654/00745] train_loss: 0.013161\n",
      "[654/00795] train_loss: 0.012880\n",
      "[654/00845] train_loss: 0.012757\n",
      "[654/00895] train_loss: 0.013300\n",
      "[654/00945] train_loss: 0.012544\n",
      "[654/00995] train_loss: 0.013074\n",
      "[654/01045] train_loss: 0.013279\n",
      "[654/01095] train_loss: 0.012993\n",
      "[654/01145] train_loss: 0.012962\n",
      "[654/01195] train_loss: 0.013124\n",
      "[655/00019] train_loss: 0.014514\n",
      "[655/00069] train_loss: 0.015705\n",
      "[655/00119] train_loss: 0.013522\n",
      "[655/00169] train_loss: 0.013355\n",
      "[655/00219] train_loss: 0.012935\n",
      "[655/00269] train_loss: 0.012828\n",
      "[655/00319] train_loss: 0.012774\n",
      "[655/00369] train_loss: 0.012850\n",
      "[655/00419] train_loss: 0.012858\n",
      "[655/00469] train_loss: 0.012970\n",
      "[655/00519] train_loss: 0.012542\n",
      "[655/00569] train_loss: 0.012126\n",
      "[655/00619] train_loss: 0.012367\n",
      "[655/00669] train_loss: 0.012734\n",
      "[655/00719] train_loss: 0.012591\n",
      "[655/00769] train_loss: 0.013234\n",
      "[655/00819] train_loss: 0.012969\n",
      "[655/00869] train_loss: 0.013217\n",
      "[655/00919] train_loss: 0.013306\n",
      "[655/00969] train_loss: 0.013062\n",
      "[655/01019] train_loss: 0.012494\n",
      "[655/01069] train_loss: 0.013011\n",
      "[655/01119] train_loss: 0.012313\n",
      "[655/01169] train_loss: 0.012687\n",
      "[655/01219] train_loss: 0.013113\n",
      "[656/00043] train_loss: 0.015735\n",
      "[656/00093] train_loss: 0.014123\n",
      "[656/00143] train_loss: 0.014574\n",
      "[656/00193] train_loss: 0.013464\n",
      "[656/00243] train_loss: 0.013550\n",
      "[656/00293] train_loss: 0.011979\n",
      "[656/00343] train_loss: 0.012356\n",
      "[656/00393] train_loss: 0.011923\n",
      "[656/00443] train_loss: 0.012670\n",
      "[656/00493] train_loss: 0.013218\n",
      "[656/00543] train_loss: 0.012534\n",
      "[656/00593] train_loss: 0.012802\n",
      "[656/00643] train_loss: 0.012569\n",
      "[656/00693] train_loss: 0.013206\n",
      "[656/00743] train_loss: 0.012725\n",
      "[656/00793] train_loss: 0.013130\n",
      "[656/00843] train_loss: 0.012976\n",
      "[656/00893] train_loss: 0.012771\n",
      "[656/00943] train_loss: 0.012451\n",
      "[656/00993] train_loss: 0.012493\n",
      "[656/01043] train_loss: 0.012524\n",
      "[656/01093] train_loss: 0.013005\n",
      "[656/01143] train_loss: 0.012704\n",
      "[656/01193] train_loss: 0.012654\n",
      "[657/00017] train_loss: 0.013459\n",
      "[657/00067] train_loss: 0.014670\n",
      "[657/00117] train_loss: 0.013849\n",
      "[657/00167] train_loss: 0.013580\n",
      "[657/00217] train_loss: 0.012713\n",
      "[657/00267] train_loss: 0.013323\n",
      "[657/00317] train_loss: 0.013682\n",
      "[657/00367] train_loss: 0.012969\n",
      "[657/00417] train_loss: 0.012338\n",
      "[657/00467] train_loss: 0.013540\n",
      "[657/00517] train_loss: 0.012423\n",
      "[657/00567] train_loss: 0.013075\n",
      "[657/00617] train_loss: 0.012518\n",
      "[657/00667] train_loss: 0.013228\n",
      "[657/00717] train_loss: 0.012352\n",
      "[657/00767] train_loss: 0.012722\n",
      "[657/00817] train_loss: 0.012904\n",
      "[657/00867] train_loss: 0.012329\n",
      "[657/00917] train_loss: 0.012314\n",
      "[657/00967] train_loss: 0.012095\n",
      "[657/01017] train_loss: 0.012678\n",
      "[657/01067] train_loss: 0.013250\n",
      "[657/01117] train_loss: 0.012991\n",
      "[657/01167] train_loss: 0.012630\n",
      "[657/01217] train_loss: 0.012463\n",
      "[658/00041] train_loss: 0.015525\n",
      "[658/00091] train_loss: 0.014472\n",
      "[658/00141] train_loss: 0.013919\n",
      "[658/00191] train_loss: 0.013740\n",
      "[658/00241] train_loss: 0.013006\n",
      "[658/00291] train_loss: 0.013018\n",
      "[658/00341] train_loss: 0.012800\n",
      "[658/00391] train_loss: 0.012174\n",
      "[658/00441] train_loss: 0.013287\n",
      "[658/00491] train_loss: 0.012346\n",
      "[658/00541] train_loss: 0.013305\n",
      "[658/00591] train_loss: 0.012997\n",
      "[658/00641] train_loss: 0.012735\n",
      "[658/00691] train_loss: 0.012413\n",
      "[658/00741] train_loss: 0.012510\n",
      "[658/00791] train_loss: 0.012876\n",
      "[658/00841] train_loss: 0.012908\n",
      "[658/00891] train_loss: 0.012615\n",
      "[658/00941] train_loss: 0.012109\n",
      "[658/00991] train_loss: 0.013046\n",
      "[658/01041] train_loss: 0.012542\n",
      "[658/01091] train_loss: 0.012374\n",
      "[658/01141] train_loss: 0.012987\n",
      "[658/01191] train_loss: 0.012854\n",
      "[659/00015] train_loss: 0.013940\n",
      "[659/00065] train_loss: 0.015268\n",
      "[659/00115] train_loss: 0.013763\n",
      "[659/00165] train_loss: 0.013901\n",
      "[659/00215] train_loss: 0.013740\n",
      "[659/00265] train_loss: 0.013178\n",
      "[659/00315] train_loss: 0.012273\n",
      "[659/00365] train_loss: 0.013032\n",
      "[659/00415] train_loss: 0.013030\n",
      "[659/00465] train_loss: 0.011842\n",
      "[659/00515] train_loss: 0.012228\n",
      "[659/00565] train_loss: 0.012848\n",
      "[659/00615] train_loss: 0.012693\n",
      "[659/00665] train_loss: 0.012875\n",
      "[659/00715] train_loss: 0.012582\n",
      "[659/00765] train_loss: 0.012941\n",
      "[659/00815] train_loss: 0.012806\n",
      "[659/00865] train_loss: 0.012817\n",
      "[659/00915] train_loss: 0.012928\n",
      "[659/00965] train_loss: 0.012676\n",
      "[659/01015] train_loss: 0.013211\n",
      "[659/01065] train_loss: 0.012272\n",
      "[659/01115] train_loss: 0.012598\n",
      "[659/01165] train_loss: 0.012630\n",
      "[659/01215] train_loss: 0.013109\n",
      "[660/00039] train_loss: 0.015586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[660/00089] train_loss: 0.015035\n",
      "[660/00139] train_loss: 0.013702\n",
      "[660/00189] train_loss: 0.012825\n",
      "[660/00239] train_loss: 0.012812\n",
      "[660/00289] train_loss: 0.012759\n",
      "[660/00339] train_loss: 0.013690\n",
      "[660/00389] train_loss: 0.012746\n",
      "[660/00439] train_loss: 0.012166\n",
      "[660/00489] train_loss: 0.012636\n",
      "[660/00539] train_loss: 0.012438\n",
      "[660/00589] train_loss: 0.012924\n",
      "[660/00639] train_loss: 0.012830\n",
      "[660/00689] train_loss: 0.012627\n",
      "[660/00739] train_loss: 0.011813\n",
      "[660/00789] train_loss: 0.012227\n",
      "[660/00839] train_loss: 0.013043\n",
      "[660/00889] train_loss: 0.013072\n",
      "[660/00939] train_loss: 0.012685\n",
      "[660/00989] train_loss: 0.012712\n",
      "[660/01039] train_loss: 0.012211\n",
      "[660/01089] train_loss: 0.012656\n",
      "[660/01139] train_loss: 0.012929\n",
      "[660/01189] train_loss: 0.013190\n",
      "[661/00013] train_loss: 0.013983\n",
      "[661/00063] train_loss: 0.014793\n",
      "[661/00113] train_loss: 0.014127\n",
      "[661/00163] train_loss: 0.013693\n",
      "[661/00213] train_loss: 0.013072\n",
      "[661/00263] train_loss: 0.013287\n",
      "[661/00313] train_loss: 0.012486\n",
      "[661/00363] train_loss: 0.012491\n",
      "[661/00413] train_loss: 0.013097\n",
      "[661/00463] train_loss: 0.012199\n",
      "[661/00513] train_loss: 0.012775\n",
      "[661/00563] train_loss: 0.012636\n",
      "[661/00613] train_loss: 0.013157\n",
      "[661/00663] train_loss: 0.012130\n",
      "[661/00713] train_loss: 0.013053\n",
      "[661/00763] train_loss: 0.013049\n",
      "[661/00813] train_loss: 0.013042\n",
      "[661/00863] train_loss: 0.012978\n",
      "[661/00913] train_loss: 0.012661\n",
      "[661/00963] train_loss: 0.013206\n",
      "[661/01013] train_loss: 0.012575\n",
      "[661/01063] train_loss: 0.012411\n",
      "[661/01113] train_loss: 0.012832\n",
      "[661/01163] train_loss: 0.012756\n",
      "[661/01213] train_loss: 0.012428\n",
      "[662/00037] train_loss: 0.014974\n",
      "[662/00087] train_loss: 0.015111\n",
      "[662/00137] train_loss: 0.014199\n",
      "[662/00187] train_loss: 0.013982\n",
      "[662/00237] train_loss: 0.013144\n",
      "[662/00287] train_loss: 0.013799\n",
      "[662/00337] train_loss: 0.012579\n",
      "[662/00387] train_loss: 0.013097\n",
      "[662/00437] train_loss: 0.012607\n",
      "[662/00487] train_loss: 0.012857\n",
      "[662/00537] train_loss: 0.012504\n",
      "[662/00587] train_loss: 0.013108\n",
      "[662/00637] train_loss: 0.012335\n",
      "[662/00687] train_loss: 0.012909\n",
      "[662/00737] train_loss: 0.013141\n",
      "[662/00787] train_loss: 0.012517\n",
      "[662/00837] train_loss: 0.012238\n",
      "[662/00887] train_loss: 0.012579\n",
      "[662/00937] train_loss: 0.011496\n",
      "[662/00987] train_loss: 0.013144\n",
      "[662/01037] train_loss: 0.011982\n",
      "[662/01087] train_loss: 0.012386\n",
      "[662/01137] train_loss: 0.013277\n",
      "[662/01187] train_loss: 0.012592\n",
      "[663/00011] train_loss: 0.013264\n",
      "[663/00061] train_loss: 0.015219\n",
      "[663/00111] train_loss: 0.014467\n",
      "[663/00161] train_loss: 0.013730\n",
      "[663/00211] train_loss: 0.012845\n",
      "[663/00261] train_loss: 0.012679\n",
      "[663/00311] train_loss: 0.013223\n",
      "[663/00361] train_loss: 0.012673\n",
      "[663/00411] train_loss: 0.012340\n",
      "[663/00461] train_loss: 0.013027\n",
      "[663/00511] train_loss: 0.012387\n",
      "[663/00561] train_loss: 0.012130\n",
      "[663/00611] train_loss: 0.013124\n",
      "[663/00661] train_loss: 0.012080\n",
      "[663/00711] train_loss: 0.012532\n",
      "[663/00761] train_loss: 0.012327\n",
      "[663/00811] train_loss: 0.013792\n",
      "[663/00861] train_loss: 0.012085\n",
      "[663/00911] train_loss: 0.013904\n",
      "[663/00961] train_loss: 0.011813\n",
      "[663/01011] train_loss: 0.013219\n",
      "[663/01061] train_loss: 0.012851\n",
      "[663/01111] train_loss: 0.012911\n",
      "[663/01161] train_loss: 0.013519\n",
      "[663/01211] train_loss: 0.012484\n",
      "[664/00035] train_loss: 0.014837\n",
      "[664/00085] train_loss: 0.014104\n",
      "[664/00135] train_loss: 0.013356\n",
      "[664/00185] train_loss: 0.012668\n",
      "[664/00235] train_loss: 0.012530\n",
      "[664/00285] train_loss: 0.013328\n",
      "[664/00335] train_loss: 0.013290\n",
      "[664/00385] train_loss: 0.012603\n",
      "[664/00435] train_loss: 0.012310\n",
      "[664/00485] train_loss: 0.012126\n",
      "[664/00535] train_loss: 0.012583\n",
      "[664/00585] train_loss: 0.012362\n",
      "[664/00635] train_loss: 0.013683\n",
      "[664/00685] train_loss: 0.012525\n",
      "[664/00735] train_loss: 0.012286\n",
      "[664/00785] train_loss: 0.012367\n",
      "[664/00835] train_loss: 0.013408\n",
      "[664/00885] train_loss: 0.013652\n",
      "[664/00935] train_loss: 0.012964\n",
      "[664/00985] train_loss: 0.012090\n",
      "[664/01035] train_loss: 0.012544\n",
      "[664/01085] train_loss: 0.012857\n",
      "[664/01135] train_loss: 0.013180\n",
      "[664/01185] train_loss: 0.013109\n",
      "[665/00009] train_loss: 0.013884\n",
      "[665/00059] train_loss: 0.015023\n",
      "[665/00109] train_loss: 0.014151\n",
      "[665/00159] train_loss: 0.013060\n",
      "[665/00209] train_loss: 0.013044\n",
      "[665/00259] train_loss: 0.013208\n",
      "[665/00309] train_loss: 0.013400\n",
      "[665/00359] train_loss: 0.012143\n",
      "[665/00409] train_loss: 0.013215\n",
      "[665/00459] train_loss: 0.012265\n",
      "[665/00509] train_loss: 0.012591\n",
      "[665/00559] train_loss: 0.012441\n",
      "[665/00609] train_loss: 0.012962\n",
      "[665/00659] train_loss: 0.013010\n",
      "[665/00709] train_loss: 0.012387\n",
      "[665/00759] train_loss: 0.012048\n",
      "[665/00809] train_loss: 0.013285\n",
      "[665/00859] train_loss: 0.013316\n",
      "[665/00909] train_loss: 0.012439\n",
      "[665/00959] train_loss: 0.013293\n",
      "[665/01009] train_loss: 0.013117\n",
      "[665/01059] train_loss: 0.012902\n",
      "[665/01109] train_loss: 0.012099\n",
      "[665/01159] train_loss: 0.013079\n",
      "[665/01209] train_loss: 0.013382\n",
      "[666/00033] train_loss: 0.015019\n",
      "[666/00083] train_loss: 0.014690\n",
      "[666/00133] train_loss: 0.013182\n",
      "[666/00183] train_loss: 0.012696\n",
      "[666/00233] train_loss: 0.013291\n",
      "[666/00283] train_loss: 0.013155\n",
      "[666/00333] train_loss: 0.013444\n",
      "[666/00383] train_loss: 0.012751\n",
      "[666/00433] train_loss: 0.012877\n",
      "[666/00483] train_loss: 0.013200\n",
      "[666/00533] train_loss: 0.012822\n",
      "[666/00583] train_loss: 0.013046\n",
      "[666/00633] train_loss: 0.012884\n",
      "[666/00683] train_loss: 0.012919\n",
      "[666/00733] train_loss: 0.011962\n",
      "[666/00783] train_loss: 0.012463\n",
      "[666/00833] train_loss: 0.012498\n",
      "[666/00883] train_loss: 0.012554\n",
      "[666/00933] train_loss: 0.012577\n",
      "[666/00983] train_loss: 0.012984\n",
      "[666/01033] train_loss: 0.012393\n",
      "[666/01083] train_loss: 0.013097\n",
      "[666/01133] train_loss: 0.012268\n",
      "[666/01183] train_loss: 0.012664\n",
      "[667/00007] train_loss: 0.012718\n",
      "[667/00057] train_loss: 0.015414\n",
      "[667/00107] train_loss: 0.014829\n",
      "[667/00157] train_loss: 0.013435\n",
      "[667/00207] train_loss: 0.012957\n",
      "[667/00257] train_loss: 0.012992\n",
      "[667/00307] train_loss: 0.012733\n",
      "[667/00357] train_loss: 0.013183\n",
      "[667/00407] train_loss: 0.012725\n",
      "[667/00457] train_loss: 0.012833\n",
      "[667/00507] train_loss: 0.012823\n",
      "[667/00557] train_loss: 0.012089\n",
      "[667/00607] train_loss: 0.012964\n",
      "[667/00657] train_loss: 0.012561\n",
      "[667/00707] train_loss: 0.013035\n",
      "[667/00757] train_loss: 0.012944\n",
      "[667/00807] train_loss: 0.012860\n",
      "[667/00857] train_loss: 0.012540\n",
      "[667/00907] train_loss: 0.013858\n",
      "[667/00957] train_loss: 0.012904\n",
      "[667/01007] train_loss: 0.012521\n",
      "[667/01057] train_loss: 0.012381\n",
      "[667/01107] train_loss: 0.013290\n",
      "[667/01157] train_loss: 0.013223\n",
      "[667/01207] train_loss: 0.012375\n",
      "[668/00031] train_loss: 0.014702\n",
      "[668/00081] train_loss: 0.014661\n",
      "[668/00131] train_loss: 0.013953\n",
      "[668/00181] train_loss: 0.013587\n",
      "[668/00231] train_loss: 0.012857\n",
      "[668/00281] train_loss: 0.013166\n",
      "[668/00331] train_loss: 0.013081\n",
      "[668/00381] train_loss: 0.012871\n",
      "[668/00431] train_loss: 0.012528\n",
      "[668/00481] train_loss: 0.012491\n",
      "[668/00531] train_loss: 0.012990\n",
      "[668/00581] train_loss: 0.012322\n",
      "[668/00631] train_loss: 0.012456\n",
      "[668/00681] train_loss: 0.013388\n",
      "[668/00731] train_loss: 0.012520\n",
      "[668/00781] train_loss: 0.013474\n",
      "[668/00831] train_loss: 0.012184\n",
      "[668/00881] train_loss: 0.012312\n",
      "[668/00931] train_loss: 0.012148\n",
      "[668/00981] train_loss: 0.012389\n",
      "[668/01031] train_loss: 0.012768\n",
      "[668/01081] train_loss: 0.012436\n",
      "[668/01131] train_loss: 0.012713\n",
      "[668/01181] train_loss: 0.012328\n",
      "[669/00005] train_loss: 0.014009\n",
      "[669/00055] train_loss: 0.016062\n",
      "[669/00105] train_loss: 0.013778\n",
      "[669/00155] train_loss: 0.013427\n",
      "[669/00205] train_loss: 0.013314\n",
      "[669/00255] train_loss: 0.012460\n",
      "[669/00305] train_loss: 0.012530\n",
      "[669/00355] train_loss: 0.013352\n",
      "[669/00405] train_loss: 0.013023\n",
      "[669/00455] train_loss: 0.013169\n",
      "[669/00505] train_loss: 0.013346\n",
      "[669/00555] train_loss: 0.012241\n",
      "[669/00605] train_loss: 0.012086\n",
      "[669/00655] train_loss: 0.012388\n",
      "[669/00705] train_loss: 0.012868\n",
      "[669/00755] train_loss: 0.012106\n",
      "[669/00805] train_loss: 0.013449\n",
      "[669/00855] train_loss: 0.012340\n",
      "[669/00905] train_loss: 0.013567\n",
      "[669/00955] train_loss: 0.012835\n",
      "[669/01005] train_loss: 0.012237\n",
      "[669/01055] train_loss: 0.011982\n",
      "[669/01105] train_loss: 0.012749\n",
      "[669/01155] train_loss: 0.013687\n",
      "[669/01205] train_loss: 0.013552\n",
      "[670/00029] train_loss: 0.014576\n",
      "[670/00079] train_loss: 0.014730\n",
      "[670/00129] train_loss: 0.013933\n",
      "[670/00179] train_loss: 0.013847\n",
      "[670/00229] train_loss: 0.012866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[670/00279] train_loss: 0.013218\n",
      "[670/00329] train_loss: 0.012949\n",
      "[670/00379] train_loss: 0.012458\n",
      "[670/00429] train_loss: 0.012533\n",
      "[670/00479] train_loss: 0.013241\n",
      "[670/00529] train_loss: 0.012128\n",
      "[670/00579] train_loss: 0.012808\n",
      "[670/00629] train_loss: 0.012963\n",
      "[670/00679] train_loss: 0.012423\n",
      "[670/00729] train_loss: 0.012441\n",
      "[670/00779] train_loss: 0.012407\n",
      "[670/00829] train_loss: 0.012936\n",
      "[670/00879] train_loss: 0.012701\n",
      "[670/00929] train_loss: 0.013036\n",
      "[670/00979] train_loss: 0.012169\n",
      "[670/01029] train_loss: 0.013035\n",
      "[670/01079] train_loss: 0.013006\n",
      "[670/01129] train_loss: 0.012882\n",
      "[670/01179] train_loss: 0.012789\n",
      "[671/00003] train_loss: 0.013033\n",
      "[671/00053] train_loss: 0.016019\n",
      "[671/00103] train_loss: 0.013507\n",
      "[671/00153] train_loss: 0.012993\n",
      "[671/00203] train_loss: 0.012196\n",
      "[671/00253] train_loss: 0.013367\n",
      "[671/00303] train_loss: 0.012193\n",
      "[671/00353] train_loss: 0.012736\n",
      "[671/00403] train_loss: 0.012594\n",
      "[671/00453] train_loss: 0.012221\n",
      "[671/00503] train_loss: 0.012501\n",
      "[671/00553] train_loss: 0.012894\n",
      "[671/00603] train_loss: 0.013476\n",
      "[671/00653] train_loss: 0.012886\n",
      "[671/00703] train_loss: 0.011671\n",
      "[671/00753] train_loss: 0.012094\n",
      "[671/00803] train_loss: 0.012677\n",
      "[671/00853] train_loss: 0.012801\n",
      "[671/00903] train_loss: 0.013991\n",
      "[671/00953] train_loss: 0.012583\n",
      "[671/01003] train_loss: 0.013589\n",
      "[671/01053] train_loss: 0.012473\n",
      "[671/01103] train_loss: 0.013441\n",
      "[671/01153] train_loss: 0.012762\n",
      "[671/01203] train_loss: 0.012500\n",
      "[672/00027] train_loss: 0.015031\n",
      "[672/00077] train_loss: 0.015189\n",
      "[672/00127] train_loss: 0.013886\n",
      "[672/00177] train_loss: 0.013279\n",
      "[672/00227] train_loss: 0.013999\n",
      "[672/00277] train_loss: 0.012070\n",
      "[672/00327] train_loss: 0.012759\n",
      "[672/00377] train_loss: 0.013406\n",
      "[672/00427] train_loss: 0.012982\n",
      "[672/00477] train_loss: 0.012302\n",
      "[672/00527] train_loss: 0.012514\n",
      "[672/00577] train_loss: 0.012819\n",
      "[672/00627] train_loss: 0.012853\n",
      "[672/00677] train_loss: 0.012651\n",
      "[672/00727] train_loss: 0.012714\n",
      "[672/00777] train_loss: 0.012131\n",
      "[672/00827] train_loss: 0.012394\n",
      "[672/00877] train_loss: 0.012528\n",
      "[672/00927] train_loss: 0.013520\n",
      "[672/00977] train_loss: 0.012598\n",
      "[672/01027] train_loss: 0.012190\n",
      "[672/01077] train_loss: 0.013061\n",
      "[672/01127] train_loss: 0.012354\n",
      "[672/01177] train_loss: 0.013027\n",
      "[673/00001] train_loss: 0.013523\n",
      "[673/00051] train_loss: 0.015377\n",
      "[673/00101] train_loss: 0.014779\n",
      "[673/00151] train_loss: 0.013119\n",
      "[673/00201] train_loss: 0.013630\n",
      "[673/00251] train_loss: 0.013248\n",
      "[673/00301] train_loss: 0.012217\n",
      "[673/00351] train_loss: 0.012167\n",
      "[673/00401] train_loss: 0.012671\n",
      "[673/00451] train_loss: 0.013045\n",
      "[673/00501] train_loss: 0.012596\n",
      "[673/00551] train_loss: 0.012722\n",
      "[673/00601] train_loss: 0.012255\n",
      "[673/00651] train_loss: 0.012673\n",
      "[673/00701] train_loss: 0.013197\n",
      "[673/00751] train_loss: 0.013021\n",
      "[673/00801] train_loss: 0.012295\n",
      "[673/00851] train_loss: 0.012390\n",
      "[673/00901] train_loss: 0.012484\n",
      "[673/00951] train_loss: 0.012142\n",
      "[673/01001] train_loss: 0.012868\n",
      "[673/01051] train_loss: 0.012856\n",
      "[673/01101] train_loss: 0.013407\n",
      "[673/01151] train_loss: 0.012325\n",
      "[673/01201] train_loss: 0.013393\n",
      "[674/00025] train_loss: 0.014742\n",
      "[674/00075] train_loss: 0.014745\n",
      "[674/00125] train_loss: 0.013759\n",
      "[674/00175] train_loss: 0.013402\n",
      "[674/00225] train_loss: 0.012309\n",
      "[674/00275] train_loss: 0.012986\n",
      "[674/00325] train_loss: 0.011955\n",
      "[674/00375] train_loss: 0.012859\n",
      "[674/00425] train_loss: 0.012249\n",
      "[674/00475] train_loss: 0.012727\n",
      "[674/00525] train_loss: 0.013512\n",
      "[674/00575] train_loss: 0.012704\n",
      "[674/00625] train_loss: 0.012621\n",
      "[674/00675] train_loss: 0.012975\n",
      "[674/00725] train_loss: 0.013599\n",
      "[674/00775] train_loss: 0.012757\n",
      "[674/00825] train_loss: 0.012655\n",
      "[674/00875] train_loss: 0.013367\n",
      "[674/00925] train_loss: 0.012775\n",
      "[674/00975] train_loss: 0.012485\n",
      "[674/01025] train_loss: 0.013575\n",
      "[674/01075] train_loss: 0.013205\n",
      "[674/01125] train_loss: 0.012718\n",
      "[674/01175] train_loss: 0.013096\n",
      "[674/01225] train_loss: 0.012486\n",
      "[675/00049] train_loss: 0.015211\n",
      "[675/00099] train_loss: 0.014333\n",
      "[675/00149] train_loss: 0.013598\n",
      "[675/00199] train_loss: 0.013307\n",
      "[675/00249] train_loss: 0.013455\n",
      "[675/00299] train_loss: 0.013061\n",
      "[675/00349] train_loss: 0.012918\n",
      "[675/00399] train_loss: 0.012831\n",
      "[675/00449] train_loss: 0.013342\n",
      "[675/00499] train_loss: 0.012692\n",
      "[675/00549] train_loss: 0.011917\n",
      "[675/00599] train_loss: 0.012385\n",
      "[675/00649] train_loss: 0.013186\n",
      "[675/00699] train_loss: 0.012736\n",
      "[675/00749] train_loss: 0.012503\n",
      "[675/00799] train_loss: 0.012260\n",
      "[675/00849] train_loss: 0.012502\n",
      "[675/00899] train_loss: 0.012755\n",
      "[675/00949] train_loss: 0.012996\n",
      "[675/00999] train_loss: 0.013558\n",
      "[675/01049] train_loss: 0.012551\n",
      "[675/01099] train_loss: 0.012480\n",
      "[675/01149] train_loss: 0.012468\n",
      "[675/01199] train_loss: 0.013816\n",
      "[676/00023] train_loss: 0.013794\n",
      "[676/00073] train_loss: 0.014192\n",
      "[676/00123] train_loss: 0.013825\n",
      "[676/00173] train_loss: 0.014064\n",
      "[676/00223] train_loss: 0.013287\n",
      "[676/00273] train_loss: 0.012736\n",
      "[676/00323] train_loss: 0.012398\n",
      "[676/00373] train_loss: 0.012326\n",
      "[676/00423] train_loss: 0.012293\n",
      "[676/00473] train_loss: 0.013037\n",
      "[676/00523] train_loss: 0.012875\n",
      "[676/00573] train_loss: 0.012168\n",
      "[676/00623] train_loss: 0.012738\n",
      "[676/00673] train_loss: 0.013551\n",
      "[676/00723] train_loss: 0.012146\n",
      "[676/00773] train_loss: 0.012565\n",
      "[676/00823] train_loss: 0.012428\n",
      "[676/00873] train_loss: 0.012320\n",
      "[676/00923] train_loss: 0.012869\n",
      "[676/00973] train_loss: 0.013187\n",
      "[676/01023] train_loss: 0.013238\n",
      "[676/01073] train_loss: 0.013134\n",
      "[676/01123] train_loss: 0.012981\n",
      "[676/01173] train_loss: 0.013477\n",
      "[676/01223] train_loss: 0.012428\n",
      "[677/00047] train_loss: 0.014848\n",
      "[677/00097] train_loss: 0.015185\n",
      "[677/00147] train_loss: 0.013663\n",
      "[677/00197] train_loss: 0.012777\n",
      "[677/00247] train_loss: 0.012884\n",
      "[677/00297] train_loss: 0.013015\n",
      "[677/00347] train_loss: 0.012788\n",
      "[677/00397] train_loss: 0.012978\n",
      "[677/00447] train_loss: 0.012653\n",
      "[677/00497] train_loss: 0.013092\n",
      "[677/00547] train_loss: 0.012860\n",
      "[677/00597] train_loss: 0.012815\n",
      "[677/00647] train_loss: 0.011926\n",
      "[677/00697] train_loss: 0.012311\n",
      "[677/00747] train_loss: 0.012770\n",
      "[677/00797] train_loss: 0.012625\n",
      "[677/00847] train_loss: 0.012420\n",
      "[677/00897] train_loss: 0.013342\n",
      "[677/00947] train_loss: 0.012527\n",
      "[677/00997] train_loss: 0.012676\n",
      "[677/01047] train_loss: 0.012857\n",
      "[677/01097] train_loss: 0.013243\n",
      "[677/01147] train_loss: 0.011808\n",
      "[677/01197] train_loss: 0.013055\n",
      "[678/00021] train_loss: 0.015935\n",
      "[678/00071] train_loss: 0.014539\n",
      "[678/00121] train_loss: 0.013981\n",
      "[678/00171] train_loss: 0.013518\n",
      "[678/00221] train_loss: 0.012719\n",
      "[678/00271] train_loss: 0.012470\n",
      "[678/00321] train_loss: 0.013124\n",
      "[678/00371] train_loss: 0.013460\n",
      "[678/00421] train_loss: 0.012491\n",
      "[678/00471] train_loss: 0.013036\n",
      "[678/00521] train_loss: 0.013276\n",
      "[678/00571] train_loss: 0.013230\n",
      "[678/00621] train_loss: 0.012231\n",
      "[678/00671] train_loss: 0.012238\n",
      "[678/00721] train_loss: 0.013343\n",
      "[678/00771] train_loss: 0.012458\n",
      "[678/00821] train_loss: 0.012879\n",
      "[678/00871] train_loss: 0.012451\n",
      "[678/00921] train_loss: 0.012766\n",
      "[678/00971] train_loss: 0.011880\n",
      "[678/01021] train_loss: 0.012611\n",
      "[678/01071] train_loss: 0.012413\n",
      "[678/01121] train_loss: 0.012580\n",
      "[678/01171] train_loss: 0.013206\n",
      "[678/01221] train_loss: 0.013062\n",
      "[679/00045] train_loss: 0.014796\n",
      "[679/00095] train_loss: 0.014619\n",
      "[679/00145] train_loss: 0.014618\n",
      "[679/00195] train_loss: 0.013304\n",
      "[679/00245] train_loss: 0.012860\n",
      "[679/00295] train_loss: 0.012520\n",
      "[679/00345] train_loss: 0.012865\n",
      "[679/00395] train_loss: 0.012591\n",
      "[679/00445] train_loss: 0.012182\n",
      "[679/00495] train_loss: 0.012510\n",
      "[679/00545] train_loss: 0.013460\n",
      "[679/00595] train_loss: 0.012816\n",
      "[679/00645] train_loss: 0.012384\n",
      "[679/00695] train_loss: 0.012655\n",
      "[679/00745] train_loss: 0.012766\n",
      "[679/00795] train_loss: 0.012791\n",
      "[679/00845] train_loss: 0.012246\n",
      "[679/00895] train_loss: 0.013246\n",
      "[679/00945] train_loss: 0.013772\n",
      "[679/00995] train_loss: 0.012721\n",
      "[679/01045] train_loss: 0.012848\n",
      "[679/01095] train_loss: 0.013162\n",
      "[679/01145] train_loss: 0.012550\n",
      "[679/01195] train_loss: 0.013796\n",
      "[680/00019] train_loss: 0.013269\n",
      "[680/00069] train_loss: 0.015028\n",
      "[680/00119] train_loss: 0.014212\n",
      "[680/00169] train_loss: 0.013563\n",
      "[680/00219] train_loss: 0.012967\n",
      "[680/00269] train_loss: 0.013171\n",
      "[680/00319] train_loss: 0.012808\n",
      "[680/00369] train_loss: 0.012587\n",
      "[680/00419] train_loss: 0.012042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[680/00469] train_loss: 0.012306\n",
      "[680/00519] train_loss: 0.012796\n",
      "[680/00569] train_loss: 0.012525\n",
      "[680/00619] train_loss: 0.012999\n",
      "[680/00669] train_loss: 0.012496\n",
      "[680/00719] train_loss: 0.012778\n",
      "[680/00769] train_loss: 0.013032\n",
      "[680/00819] train_loss: 0.012635\n",
      "[680/00869] train_loss: 0.013350\n",
      "[680/00919] train_loss: 0.012729\n",
      "[680/00969] train_loss: 0.012601\n",
      "[680/01019] train_loss: 0.012697\n",
      "[680/01069] train_loss: 0.013309\n",
      "[680/01119] train_loss: 0.013397\n",
      "[680/01169] train_loss: 0.012972\n",
      "[680/01219] train_loss: 0.012595\n",
      "[681/00043] train_loss: 0.015112\n",
      "[681/00093] train_loss: 0.014575\n",
      "[681/00143] train_loss: 0.013273\n",
      "[681/00193] train_loss: 0.013404\n",
      "[681/00243] train_loss: 0.012673\n",
      "[681/00293] train_loss: 0.012756\n",
      "[681/00343] train_loss: 0.012986\n",
      "[681/00393] train_loss: 0.012727\n",
      "[681/00443] train_loss: 0.012617\n",
      "[681/00493] train_loss: 0.011779\n",
      "[681/00543] train_loss: 0.012757\n",
      "[681/00593] train_loss: 0.012849\n",
      "[681/00643] train_loss: 0.012599\n",
      "[681/00693] train_loss: 0.012916\n",
      "[681/00743] train_loss: 0.012443\n",
      "[681/00793] train_loss: 0.012677\n",
      "[681/00843] train_loss: 0.012505\n",
      "[681/00893] train_loss: 0.012099\n",
      "[681/00943] train_loss: 0.012801\n",
      "[681/00993] train_loss: 0.012328\n",
      "[681/01043] train_loss: 0.012800\n",
      "[681/01093] train_loss: 0.013100\n",
      "[681/01143] train_loss: 0.012434\n",
      "[681/01193] train_loss: 0.013456\n",
      "[682/00017] train_loss: 0.013542\n",
      "[682/00067] train_loss: 0.015886\n",
      "[682/00117] train_loss: 0.013389\n",
      "[682/00167] train_loss: 0.013217\n",
      "[682/00217] train_loss: 0.012505\n",
      "[682/00267] train_loss: 0.013303\n",
      "[682/00317] train_loss: 0.013135\n",
      "[682/00367] train_loss: 0.012815\n",
      "[682/00417] train_loss: 0.012006\n",
      "[682/00467] train_loss: 0.012394\n",
      "[682/00517] train_loss: 0.012672\n",
      "[682/00567] train_loss: 0.012639\n",
      "[682/00617] train_loss: 0.012702\n",
      "[682/00667] train_loss: 0.012197\n",
      "[682/00717] train_loss: 0.012087\n",
      "[682/00767] train_loss: 0.013123\n",
      "[682/00817] train_loss: 0.012747\n",
      "[682/00867] train_loss: 0.013300\n",
      "[682/00917] train_loss: 0.012663\n",
      "[682/00967] train_loss: 0.013153\n",
      "[682/01017] train_loss: 0.012503\n",
      "[682/01067] train_loss: 0.013623\n",
      "[682/01117] train_loss: 0.013259\n",
      "[682/01167] train_loss: 0.012727\n",
      "[682/01217] train_loss: 0.013902\n",
      "[683/00041] train_loss: 0.015066\n",
      "[683/00091] train_loss: 0.014048\n",
      "[683/00141] train_loss: 0.013933\n",
      "[683/00191] train_loss: 0.013298\n",
      "[683/00241] train_loss: 0.012804\n",
      "[683/00291] train_loss: 0.013046\n",
      "[683/00341] train_loss: 0.012974\n",
      "[683/00391] train_loss: 0.013619\n",
      "[683/00441] train_loss: 0.012553\n",
      "[683/00491] train_loss: 0.012281\n",
      "[683/00541] train_loss: 0.012777\n",
      "[683/00591] train_loss: 0.012920\n",
      "[683/00641] train_loss: 0.012735\n",
      "[683/00691] train_loss: 0.012961\n",
      "[683/00741] train_loss: 0.012425\n",
      "[683/00791] train_loss: 0.012344\n",
      "[683/00841] train_loss: 0.013085\n",
      "[683/00891] train_loss: 0.013116\n",
      "[683/00941] train_loss: 0.012456\n",
      "[683/00991] train_loss: 0.012433\n",
      "[683/01041] train_loss: 0.013391\n",
      "[683/01091] train_loss: 0.013213\n",
      "[683/01141] train_loss: 0.012419\n",
      "[683/01191] train_loss: 0.013541\n",
      "[684/00015] train_loss: 0.014284\n",
      "[684/00065] train_loss: 0.015352\n",
      "[684/00115] train_loss: 0.014481\n",
      "[684/00165] train_loss: 0.013162\n",
      "[684/00215] train_loss: 0.012739\n",
      "[684/00265] train_loss: 0.013328\n",
      "[684/00315] train_loss: 0.013301\n",
      "[684/00365] train_loss: 0.012315\n",
      "[684/00415] train_loss: 0.011940\n",
      "[684/00465] train_loss: 0.012599\n",
      "[684/00515] train_loss: 0.012751\n",
      "[684/00565] train_loss: 0.012705\n",
      "[684/00615] train_loss: 0.013160\n",
      "[684/00665] train_loss: 0.013378\n",
      "[684/00715] train_loss: 0.012176\n",
      "[684/00765] train_loss: 0.012753\n",
      "[684/00815] train_loss: 0.012165\n",
      "[684/00865] train_loss: 0.012051\n",
      "[684/00915] train_loss: 0.012562\n",
      "[684/00965] train_loss: 0.012265\n",
      "[684/01015] train_loss: 0.012941\n",
      "[684/01065] train_loss: 0.012107\n",
      "[684/01115] train_loss: 0.013299\n",
      "[684/01165] train_loss: 0.012515\n",
      "[684/01215] train_loss: 0.012748\n",
      "[685/00039] train_loss: 0.015731\n",
      "[685/00089] train_loss: 0.013578\n",
      "[685/00139] train_loss: 0.013846\n",
      "[685/00189] train_loss: 0.013573\n",
      "[685/00239] train_loss: 0.013459\n",
      "[685/00289] train_loss: 0.013002\n",
      "[685/00339] train_loss: 0.012736\n",
      "[685/00389] train_loss: 0.012533\n",
      "[685/00439] train_loss: 0.013302\n",
      "[685/00489] train_loss: 0.012977\n",
      "[685/00539] train_loss: 0.011920\n",
      "[685/00589] train_loss: 0.012599\n",
      "[685/00639] train_loss: 0.012669\n",
      "[685/00689] train_loss: 0.012157\n",
      "[685/00739] train_loss: 0.012497\n",
      "[685/00789] train_loss: 0.012766\n",
      "[685/00839] train_loss: 0.013472\n",
      "[685/00889] train_loss: 0.012500\n",
      "[685/00939] train_loss: 0.012401\n",
      "[685/00989] train_loss: 0.012725\n",
      "[685/01039] train_loss: 0.012450\n",
      "[685/01089] train_loss: 0.012604\n",
      "[685/01139] train_loss: 0.012467\n",
      "[685/01189] train_loss: 0.013254\n",
      "[686/00013] train_loss: 0.013775\n",
      "[686/00063] train_loss: 0.015715\n",
      "[686/00113] train_loss: 0.013718\n",
      "[686/00163] train_loss: 0.012546\n",
      "[686/00213] train_loss: 0.012490\n",
      "[686/00263] train_loss: 0.012805\n",
      "[686/00313] train_loss: 0.012497\n",
      "[686/00363] train_loss: 0.013494\n",
      "[686/00413] train_loss: 0.012447\n",
      "[686/00463] train_loss: 0.012277\n",
      "[686/00513] train_loss: 0.012722\n",
      "[686/00563] train_loss: 0.012657\n",
      "[686/00613] train_loss: 0.013819\n",
      "[686/00663] train_loss: 0.012974\n",
      "[686/00713] train_loss: 0.012859\n",
      "[686/00763] train_loss: 0.012626\n",
      "[686/00813] train_loss: 0.013089\n",
      "[686/00863] train_loss: 0.011947\n",
      "[686/00913] train_loss: 0.012587\n",
      "[686/00963] train_loss: 0.012824\n",
      "[686/01013] train_loss: 0.012468\n",
      "[686/01063] train_loss: 0.012414\n",
      "[686/01113] train_loss: 0.013111\n",
      "[686/01163] train_loss: 0.013649\n",
      "[686/01213] train_loss: 0.012720\n",
      "[687/00037] train_loss: 0.015098\n",
      "[687/00087] train_loss: 0.014018\n",
      "[687/00137] train_loss: 0.013828\n",
      "[687/00187] train_loss: 0.013665\n",
      "[687/00237] train_loss: 0.012953\n",
      "[687/00287] train_loss: 0.013121\n",
      "[687/00337] train_loss: 0.012964\n",
      "[687/00387] train_loss: 0.012533\n",
      "[687/00437] train_loss: 0.012840\n",
      "[687/00487] train_loss: 0.012889\n",
      "[687/00537] train_loss: 0.012541\n",
      "[687/00587] train_loss: 0.012107\n",
      "[687/00637] train_loss: 0.013110\n",
      "[687/00687] train_loss: 0.013279\n",
      "[687/00737] train_loss: 0.012951\n",
      "[687/00787] train_loss: 0.012241\n",
      "[687/00837] train_loss: 0.013171\n",
      "[687/00887] train_loss: 0.013053\n",
      "[687/00937] train_loss: 0.012704\n",
      "[687/00987] train_loss: 0.012835\n",
      "[687/01037] train_loss: 0.012452\n",
      "[687/01087] train_loss: 0.012850\n",
      "[687/01137] train_loss: 0.012641\n",
      "[687/01187] train_loss: 0.012756\n",
      "[688/00011] train_loss: 0.013498\n",
      "[688/00061] train_loss: 0.015710\n",
      "[688/00111] train_loss: 0.013912\n",
      "[688/00161] train_loss: 0.013519\n",
      "[688/00211] train_loss: 0.013242\n",
      "[688/00261] train_loss: 0.012847\n",
      "[688/00311] train_loss: 0.012771\n",
      "[688/00361] train_loss: 0.013232\n",
      "[688/00411] train_loss: 0.012384\n",
      "[688/00461] train_loss: 0.012702\n",
      "[688/00511] train_loss: 0.012772\n",
      "[688/00561] train_loss: 0.012766\n",
      "[688/00611] train_loss: 0.012020\n",
      "[688/00661] train_loss: 0.012341\n",
      "[688/00711] train_loss: 0.012292\n",
      "[688/00761] train_loss: 0.013345\n",
      "[688/00811] train_loss: 0.012953\n",
      "[688/00861] train_loss: 0.012713\n",
      "[688/00911] train_loss: 0.011906\n",
      "[688/00961] train_loss: 0.012812\n",
      "[688/01011] train_loss: 0.012504\n",
      "[688/01061] train_loss: 0.013310\n",
      "[688/01111] train_loss: 0.012567\n",
      "[688/01161] train_loss: 0.012851\n",
      "[688/01211] train_loss: 0.013932\n",
      "[689/00035] train_loss: 0.013510\n",
      "[689/00085] train_loss: 0.014737\n",
      "[689/00135] train_loss: 0.013982\n",
      "[689/00185] train_loss: 0.013592\n",
      "[689/00235] train_loss: 0.012543\n",
      "[689/00285] train_loss: 0.013063\n",
      "[689/00335] train_loss: 0.013220\n",
      "[689/00385] train_loss: 0.012559\n",
      "[689/00435] train_loss: 0.012626\n",
      "[689/00485] train_loss: 0.012395\n",
      "[689/00535] train_loss: 0.012750\n",
      "[689/00585] train_loss: 0.013845\n",
      "[689/00635] train_loss: 0.012892\n",
      "[689/00685] train_loss: 0.012438\n",
      "[689/00735] train_loss: 0.012414\n",
      "[689/00785] train_loss: 0.012916\n",
      "[689/00835] train_loss: 0.012699\n",
      "[689/00885] train_loss: 0.013084\n",
      "[689/00935] train_loss: 0.012413\n",
      "[689/00985] train_loss: 0.012075\n",
      "[689/01035] train_loss: 0.012999\n",
      "[689/01085] train_loss: 0.012624\n",
      "[689/01135] train_loss: 0.013359\n",
      "[689/01185] train_loss: 0.012750\n",
      "[690/00009] train_loss: 0.013199\n",
      "[690/00059] train_loss: 0.015492\n",
      "[690/00109] train_loss: 0.013708\n",
      "[690/00159] train_loss: 0.013315\n",
      "[690/00209] train_loss: 0.012729\n",
      "[690/00259] train_loss: 0.013465\n",
      "[690/00309] train_loss: 0.012705\n",
      "[690/00359] train_loss: 0.012446\n",
      "[690/00409] train_loss: 0.012036\n",
      "[690/00459] train_loss: 0.013090\n",
      "[690/00509] train_loss: 0.012163\n",
      "[690/00559] train_loss: 0.012364\n",
      "[690/00609] train_loss: 0.012067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[690/00659] train_loss: 0.012824\n",
      "[690/00709] train_loss: 0.012761\n",
      "[690/00759] train_loss: 0.012600\n",
      "[690/00809] train_loss: 0.012855\n",
      "[690/00859] train_loss: 0.013030\n",
      "[690/00909] train_loss: 0.012631\n",
      "[690/00959] train_loss: 0.012988\n",
      "[690/01009] train_loss: 0.013419\n",
      "[690/01059] train_loss: 0.013009\n",
      "[690/01109] train_loss: 0.012675\n",
      "[690/01159] train_loss: 0.012965\n",
      "[690/01209] train_loss: 0.012303\n",
      "[691/00033] train_loss: 0.015457\n",
      "[691/00083] train_loss: 0.014619\n",
      "[691/00133] train_loss: 0.013976\n",
      "[691/00183] train_loss: 0.013567\n",
      "[691/00233] train_loss: 0.013568\n",
      "[691/00283] train_loss: 0.012778\n",
      "[691/00333] train_loss: 0.011770\n",
      "[691/00383] train_loss: 0.012441\n",
      "[691/00433] train_loss: 0.013178\n",
      "[691/00483] train_loss: 0.012668\n",
      "[691/00533] train_loss: 0.012753\n",
      "[691/00583] train_loss: 0.011628\n",
      "[691/00633] train_loss: 0.012611\n",
      "[691/00683] train_loss: 0.012619\n",
      "[691/00733] train_loss: 0.012714\n",
      "[691/00783] train_loss: 0.011952\n",
      "[691/00833] train_loss: 0.012827\n",
      "[691/00883] train_loss: 0.012477\n",
      "[691/00933] train_loss: 0.012472\n",
      "[691/00983] train_loss: 0.012861\n",
      "[691/01033] train_loss: 0.013910\n",
      "[691/01083] train_loss: 0.012912\n",
      "[691/01133] train_loss: 0.012505\n",
      "[691/01183] train_loss: 0.012647\n",
      "[692/00007] train_loss: 0.013078\n",
      "[692/00057] train_loss: 0.015948\n",
      "[692/00107] train_loss: 0.014177\n",
      "[692/00157] train_loss: 0.013286\n",
      "[692/00207] train_loss: 0.013419\n",
      "[692/00257] train_loss: 0.013697\n",
      "[692/00307] train_loss: 0.012801\n",
      "[692/00357] train_loss: 0.013077\n",
      "[692/00407] train_loss: 0.012501\n",
      "[692/00457] train_loss: 0.012127\n",
      "[692/00507] train_loss: 0.012749\n",
      "[692/00557] train_loss: 0.012367\n",
      "[692/00607] train_loss: 0.012570\n",
      "[692/00657] train_loss: 0.013217\n",
      "[692/00707] train_loss: 0.013028\n",
      "[692/00757] train_loss: 0.012582\n",
      "[692/00807] train_loss: 0.012732\n",
      "[692/00857] train_loss: 0.012755\n",
      "[692/00907] train_loss: 0.013068\n",
      "[692/00957] train_loss: 0.012721\n",
      "[692/01007] train_loss: 0.012594\n",
      "[692/01057] train_loss: 0.012881\n",
      "[692/01107] train_loss: 0.013065\n",
      "[692/01157] train_loss: 0.012166\n",
      "[692/01207] train_loss: 0.013037\n",
      "[693/00031] train_loss: 0.014356\n",
      "[693/00081] train_loss: 0.015013\n",
      "[693/00131] train_loss: 0.013808\n",
      "[693/00181] train_loss: 0.012713\n",
      "[693/00231] train_loss: 0.013141\n",
      "[693/00281] train_loss: 0.013053\n",
      "[693/00331] train_loss: 0.013606\n",
      "[693/00381] train_loss: 0.012487\n",
      "[693/00431] train_loss: 0.012598\n",
      "[693/00481] train_loss: 0.011699\n",
      "[693/00531] train_loss: 0.012587\n",
      "[693/00581] train_loss: 0.013390\n",
      "[693/00631] train_loss: 0.013066\n",
      "[693/00681] train_loss: 0.011886\n",
      "[693/00731] train_loss: 0.012135\n",
      "[693/00781] train_loss: 0.012479\n",
      "[693/00831] train_loss: 0.012720\n",
      "[693/00881] train_loss: 0.012443\n",
      "[693/00931] train_loss: 0.012581\n",
      "[693/00981] train_loss: 0.012673\n",
      "[693/01031] train_loss: 0.012573\n",
      "[693/01081] train_loss: 0.012479\n",
      "[693/01131] train_loss: 0.012899\n",
      "[693/01181] train_loss: 0.013358\n",
      "[694/00005] train_loss: 0.013219\n",
      "[694/00055] train_loss: 0.015507\n",
      "[694/00105] train_loss: 0.014300\n",
      "[694/00155] train_loss: 0.013904\n",
      "[694/00205] train_loss: 0.012947\n",
      "[694/00255] train_loss: 0.012777\n",
      "[694/00305] train_loss: 0.013255\n",
      "[694/00355] train_loss: 0.012907\n",
      "[694/00405] train_loss: 0.012809\n",
      "[694/00455] train_loss: 0.013636\n",
      "[694/00505] train_loss: 0.012423\n",
      "[694/00555] train_loss: 0.012273\n",
      "[694/00605] train_loss: 0.013329\n",
      "[694/00655] train_loss: 0.012366\n",
      "[694/00705] train_loss: 0.012317\n",
      "[694/00755] train_loss: 0.012576\n",
      "[694/00805] train_loss: 0.012758\n",
      "[694/00855] train_loss: 0.012677\n",
      "[694/00905] train_loss: 0.012926\n",
      "[694/00955] train_loss: 0.012562\n",
      "[694/01005] train_loss: 0.012596\n",
      "[694/01055] train_loss: 0.013355\n",
      "[694/01105] train_loss: 0.012899\n",
      "[694/01155] train_loss: 0.012438\n",
      "[694/01205] train_loss: 0.012339\n",
      "[695/00029] train_loss: 0.014380\n",
      "[695/00079] train_loss: 0.015066\n",
      "[695/00129] train_loss: 0.013680\n",
      "[695/00179] train_loss: 0.013209\n",
      "[695/00229] train_loss: 0.012702\n",
      "[695/00279] train_loss: 0.012272\n",
      "[695/00329] train_loss: 0.012846\n",
      "[695/00379] train_loss: 0.013016\n",
      "[695/00429] train_loss: 0.012507\n",
      "[695/00479] train_loss: 0.012102\n",
      "[695/00529] train_loss: 0.012824\n",
      "[695/00579] train_loss: 0.012888\n",
      "[695/00629] train_loss: 0.013250\n",
      "[695/00679] train_loss: 0.012871\n",
      "[695/00729] train_loss: 0.013111\n",
      "[695/00779] train_loss: 0.013222\n",
      "[695/00829] train_loss: 0.012535\n",
      "[695/00879] train_loss: 0.012179\n",
      "[695/00929] train_loss: 0.013151\n",
      "[695/00979] train_loss: 0.012491\n",
      "[695/01029] train_loss: 0.012862\n",
      "[695/01079] train_loss: 0.012537\n",
      "[695/01129] train_loss: 0.012411\n",
      "[695/01179] train_loss: 0.013316\n",
      "[696/00003] train_loss: 0.013654\n",
      "[696/00053] train_loss: 0.015069\n",
      "[696/00103] train_loss: 0.014244\n",
      "[696/00153] train_loss: 0.012992\n",
      "[696/00203] train_loss: 0.012726\n",
      "[696/00253] train_loss: 0.012678\n",
      "[696/00303] train_loss: 0.012808\n",
      "[696/00353] train_loss: 0.012831\n",
      "[696/00403] train_loss: 0.013263\n",
      "[696/00453] train_loss: 0.012769\n",
      "[696/00503] train_loss: 0.014241\n",
      "[696/00553] train_loss: 0.012531\n",
      "[696/00603] train_loss: 0.012497\n",
      "[696/00653] train_loss: 0.012602\n",
      "[696/00703] train_loss: 0.013053\n",
      "[696/00753] train_loss: 0.012592\n",
      "[696/00803] train_loss: 0.012456\n",
      "[696/00853] train_loss: 0.012216\n",
      "[696/00903] train_loss: 0.012436\n",
      "[696/00953] train_loss: 0.012330\n",
      "[696/01003] train_loss: 0.012923\n",
      "[696/01053] train_loss: 0.012221\n",
      "[696/01103] train_loss: 0.012719\n",
      "[696/01153] train_loss: 0.013362\n",
      "[696/01203] train_loss: 0.013249\n",
      "[697/00027] train_loss: 0.014352\n",
      "[697/00077] train_loss: 0.015181\n",
      "[697/00127] train_loss: 0.013479\n",
      "[697/00177] train_loss: 0.013933\n",
      "[697/00227] train_loss: 0.012271\n",
      "[697/00277] train_loss: 0.012704\n",
      "[697/00327] train_loss: 0.013023\n",
      "[697/00377] train_loss: 0.012207\n",
      "[697/00427] train_loss: 0.013427\n",
      "[697/00477] train_loss: 0.012397\n",
      "[697/00527] train_loss: 0.013103\n",
      "[697/00577] train_loss: 0.012254\n",
      "[697/00627] train_loss: 0.012824\n",
      "[697/00677] train_loss: 0.012855\n",
      "[697/00727] train_loss: 0.012466\n",
      "[697/00777] train_loss: 0.012045\n",
      "[697/00827] train_loss: 0.012631\n",
      "[697/00877] train_loss: 0.012860\n",
      "[697/00927] train_loss: 0.013397\n",
      "[697/00977] train_loss: 0.012109\n",
      "[697/01027] train_loss: 0.012868\n",
      "[697/01077] train_loss: 0.013232\n",
      "[697/01127] train_loss: 0.013172\n",
      "[697/01177] train_loss: 0.013048\n",
      "[698/00001] train_loss: 0.012167\n",
      "[698/00051] train_loss: 0.015737\n",
      "[698/00101] train_loss: 0.014551\n",
      "[698/00151] train_loss: 0.013545\n",
      "[698/00201] train_loss: 0.013826\n",
      "[698/00251] train_loss: 0.012234\n",
      "[698/00301] train_loss: 0.012689\n",
      "[698/00351] train_loss: 0.013177\n",
      "[698/00401] train_loss: 0.012587\n",
      "[698/00451] train_loss: 0.012924\n",
      "[698/00501] train_loss: 0.012087\n",
      "[698/00551] train_loss: 0.013371\n",
      "[698/00601] train_loss: 0.013386\n",
      "[698/00651] train_loss: 0.012613\n",
      "[698/00701] train_loss: 0.012687\n",
      "[698/00751] train_loss: 0.012722\n",
      "[698/00801] train_loss: 0.012571\n",
      "[698/00851] train_loss: 0.012681\n",
      "[698/00901] train_loss: 0.012248\n",
      "[698/00951] train_loss: 0.012084\n",
      "[698/01001] train_loss: 0.011645\n",
      "[698/01051] train_loss: 0.012557\n",
      "[698/01101] train_loss: 0.012078\n",
      "[698/01151] train_loss: 0.013632\n",
      "[698/01201] train_loss: 0.012839\n",
      "[699/00025] train_loss: 0.014220\n",
      "[699/00075] train_loss: 0.015177\n",
      "[699/00125] train_loss: 0.014091\n",
      "[699/00175] train_loss: 0.013482\n",
      "[699/00225] train_loss: 0.012577\n",
      "[699/00275] train_loss: 0.012740\n",
      "[699/00325] train_loss: 0.013103\n",
      "[699/00375] train_loss: 0.013211\n",
      "[699/00425] train_loss: 0.012399\n",
      "[699/00475] train_loss: 0.012217\n",
      "[699/00525] train_loss: 0.012305\n",
      "[699/00575] train_loss: 0.012773\n",
      "[699/00625] train_loss: 0.012775\n",
      "[699/00675] train_loss: 0.012425\n",
      "[699/00725] train_loss: 0.012114\n",
      "[699/00775] train_loss: 0.013486\n",
      "[699/00825] train_loss: 0.012435\n",
      "[699/00875] train_loss: 0.013178\n",
      "[699/00925] train_loss: 0.011982\n",
      "[699/00975] train_loss: 0.012881\n",
      "[699/01025] train_loss: 0.012835\n",
      "[699/01075] train_loss: 0.012470\n",
      "[699/01125] train_loss: 0.012401\n",
      "[699/01175] train_loss: 0.012895\n",
      "[699/01225] train_loss: 0.013411\n",
      "[700/00049] train_loss: 0.015285\n",
      "[700/00099] train_loss: 0.014417\n",
      "[700/00149] train_loss: 0.012825\n",
      "[700/00199] train_loss: 0.012696\n",
      "[700/00249] train_loss: 0.012583\n",
      "[700/00299] train_loss: 0.012469\n",
      "[700/00349] train_loss: 0.012078\n",
      "[700/00399] train_loss: 0.012749\n",
      "[700/00449] train_loss: 0.012449\n",
      "[700/00499] train_loss: 0.012698\n",
      "[700/00549] train_loss: 0.012680\n",
      "[700/00599] train_loss: 0.012162\n",
      "[700/00649] train_loss: 0.012468\n",
      "[700/00699] train_loss: 0.012297\n",
      "[700/00749] train_loss: 0.012383\n",
      "[700/00799] train_loss: 0.013524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700/00849] train_loss: 0.013112\n",
      "[700/00899] train_loss: 0.013778\n",
      "[700/00949] train_loss: 0.012084\n",
      "[700/00999] train_loss: 0.012225\n",
      "[700/01049] train_loss: 0.012372\n",
      "[700/01099] train_loss: 0.013149\n",
      "[700/01149] train_loss: 0.013102\n",
      "[700/01199] train_loss: 0.013304\n",
      "[701/00023] train_loss: 0.015847\n",
      "[701/00073] train_loss: 0.014963\n",
      "[701/00123] train_loss: 0.014167\n",
      "[701/00173] train_loss: 0.013482\n",
      "[701/00223] train_loss: 0.012729\n",
      "[701/00273] train_loss: 0.013079\n",
      "[701/00323] train_loss: 0.012771\n",
      "[701/00373] train_loss: 0.013339\n",
      "[701/00423] train_loss: 0.012233\n",
      "[701/00473] train_loss: 0.013141\n",
      "[701/00523] train_loss: 0.012072\n",
      "[701/00573] train_loss: 0.012015\n",
      "[701/00623] train_loss: 0.012624\n",
      "[701/00673] train_loss: 0.012361\n",
      "[701/00723] train_loss: 0.013124\n",
      "[701/00773] train_loss: 0.012877\n",
      "[701/00823] train_loss: 0.012578\n",
      "[701/00873] train_loss: 0.012802\n",
      "[701/00923] train_loss: 0.011821\n",
      "[701/00973] train_loss: 0.013115\n",
      "[701/01023] train_loss: 0.012319\n",
      "[701/01073] train_loss: 0.013135\n",
      "[701/01123] train_loss: 0.012705\n",
      "[701/01173] train_loss: 0.014094\n",
      "[701/01223] train_loss: 0.012415\n",
      "[702/00047] train_loss: 0.015295\n",
      "[702/00097] train_loss: 0.015183\n",
      "[702/00147] train_loss: 0.013247\n",
      "[702/00197] train_loss: 0.012314\n",
      "[702/00247] train_loss: 0.013095\n",
      "[702/00297] train_loss: 0.013177\n",
      "[702/00347] train_loss: 0.012469\n",
      "[702/00397] train_loss: 0.012267\n",
      "[702/00447] train_loss: 0.012662\n",
      "[702/00497] train_loss: 0.012726\n",
      "[702/00547] train_loss: 0.012799\n",
      "[702/00597] train_loss: 0.012496\n",
      "[702/00647] train_loss: 0.011791\n",
      "[702/00697] train_loss: 0.012430\n",
      "[702/00747] train_loss: 0.011953\n",
      "[702/00797] train_loss: 0.012995\n",
      "[702/00847] train_loss: 0.011973\n",
      "[702/00897] train_loss: 0.012480\n",
      "[702/00947] train_loss: 0.012235\n",
      "[702/00997] train_loss: 0.012747\n",
      "[702/01047] train_loss: 0.013444\n",
      "[702/01097] train_loss: 0.013845\n",
      "[702/01147] train_loss: 0.013334\n",
      "[702/01197] train_loss: 0.013298\n",
      "[703/00021] train_loss: 0.014076\n",
      "[703/00071] train_loss: 0.014042\n",
      "[703/00121] train_loss: 0.013661\n",
      "[703/00171] train_loss: 0.013218\n",
      "[703/00221] train_loss: 0.014049\n",
      "[703/00271] train_loss: 0.012985\n",
      "[703/00321] train_loss: 0.012178\n",
      "[703/00371] train_loss: 0.012530\n",
      "[703/00421] train_loss: 0.012669\n",
      "[703/00471] train_loss: 0.012922\n",
      "[703/00521] train_loss: 0.013148\n",
      "[703/00571] train_loss: 0.012314\n",
      "[703/00621] train_loss: 0.012269\n",
      "[703/00671] train_loss: 0.012728\n",
      "[703/00721] train_loss: 0.012665\n",
      "[703/00771] train_loss: 0.012650\n",
      "[703/00821] train_loss: 0.012300\n",
      "[703/00871] train_loss: 0.012226\n",
      "[703/00921] train_loss: 0.013320\n",
      "[703/00971] train_loss: 0.012537\n",
      "[703/01021] train_loss: 0.013151\n",
      "[703/01071] train_loss: 0.012120\n",
      "[703/01121] train_loss: 0.012496\n",
      "[703/01171] train_loss: 0.013402\n",
      "[703/01221] train_loss: 0.012903\n",
      "[704/00045] train_loss: 0.015536\n",
      "[704/00095] train_loss: 0.014655\n",
      "[704/00145] train_loss: 0.013517\n",
      "[704/00195] train_loss: 0.012692\n",
      "[704/00245] train_loss: 0.013643\n",
      "[704/00295] train_loss: 0.012276\n",
      "[704/00345] train_loss: 0.012514\n",
      "[704/00395] train_loss: 0.012523\n",
      "[704/00445] train_loss: 0.012427\n",
      "[704/00495] train_loss: 0.012769\n",
      "[704/00545] train_loss: 0.012952\n",
      "[704/00595] train_loss: 0.012071\n",
      "[704/00645] train_loss: 0.012929\n",
      "[704/00695] train_loss: 0.012806\n",
      "[704/00745] train_loss: 0.013091\n",
      "[704/00795] train_loss: 0.012348\n",
      "[704/00845] train_loss: 0.012241\n",
      "[704/00895] train_loss: 0.012776\n",
      "[704/00945] train_loss: 0.012450\n",
      "[704/00995] train_loss: 0.011990\n",
      "[704/01045] train_loss: 0.013303\n",
      "[704/01095] train_loss: 0.013188\n",
      "[704/01145] train_loss: 0.013291\n",
      "[704/01195] train_loss: 0.013080\n",
      "[705/00019] train_loss: 0.014524\n",
      "[705/00069] train_loss: 0.015385\n",
      "[705/00119] train_loss: 0.013770\n",
      "[705/00169] train_loss: 0.013275\n",
      "[705/00219] train_loss: 0.012639\n",
      "[705/00269] train_loss: 0.012795\n",
      "[705/00319] train_loss: 0.012440\n",
      "[705/00369] train_loss: 0.012731\n",
      "[705/00419] train_loss: 0.013439\n",
      "[705/00469] train_loss: 0.012529\n",
      "[705/00519] train_loss: 0.012870\n",
      "[705/00569] train_loss: 0.013046\n",
      "[705/00619] train_loss: 0.012563\n",
      "[705/00669] train_loss: 0.012634\n",
      "[705/00719] train_loss: 0.012641\n",
      "[705/00769] train_loss: 0.012940\n",
      "[705/00819] train_loss: 0.012321\n",
      "[705/00869] train_loss: 0.012348\n",
      "[705/00919] train_loss: 0.013118\n",
      "[705/00969] train_loss: 0.012840\n",
      "[705/01019] train_loss: 0.012740\n",
      "[705/01069] train_loss: 0.013473\n",
      "[705/01119] train_loss: 0.012759\n",
      "[705/01169] train_loss: 0.012321\n",
      "[705/01219] train_loss: 0.012901\n",
      "[706/00043] train_loss: 0.015155\n",
      "[706/00093] train_loss: 0.014586\n",
      "[706/00143] train_loss: 0.013699\n",
      "[706/00193] train_loss: 0.013332\n",
      "[706/00243] train_loss: 0.012874\n",
      "[706/00293] train_loss: 0.013133\n",
      "[706/00343] train_loss: 0.012518\n",
      "[706/00393] train_loss: 0.013295\n",
      "[706/00443] train_loss: 0.012628\n",
      "[706/00493] train_loss: 0.012295\n",
      "[706/00543] train_loss: 0.013109\n",
      "[706/00593] train_loss: 0.012589\n",
      "[706/00643] train_loss: 0.012793\n",
      "[706/00693] train_loss: 0.012392\n",
      "[706/00743] train_loss: 0.012792\n",
      "[706/00793] train_loss: 0.012514\n",
      "[706/00843] train_loss: 0.012418\n",
      "[706/00893] train_loss: 0.012795\n",
      "[706/00943] train_loss: 0.012783\n",
      "[706/00993] train_loss: 0.012481\n",
      "[706/01043] train_loss: 0.013203\n",
      "[706/01093] train_loss: 0.013028\n",
      "[706/01143] train_loss: 0.012848\n",
      "[706/01193] train_loss: 0.012672\n",
      "[707/00017] train_loss: 0.014224\n",
      "[707/00067] train_loss: 0.014904\n",
      "[707/00117] train_loss: 0.014174\n",
      "[707/00167] train_loss: 0.013883\n",
      "[707/00217] train_loss: 0.012964\n",
      "[707/00267] train_loss: 0.012728\n",
      "[707/00317] train_loss: 0.012031\n",
      "[707/00367] train_loss: 0.012849\n",
      "[707/00417] train_loss: 0.012767\n",
      "[707/00467] train_loss: 0.013230\n",
      "[707/00517] train_loss: 0.012065\n",
      "[707/00567] train_loss: 0.011710\n",
      "[707/00617] train_loss: 0.012091\n",
      "[707/00667] train_loss: 0.012404\n",
      "[707/00717] train_loss: 0.013292\n",
      "[707/00767] train_loss: 0.012098\n",
      "[707/00817] train_loss: 0.011880\n",
      "[707/00867] train_loss: 0.013760\n",
      "[707/00917] train_loss: 0.013230\n",
      "[707/00967] train_loss: 0.012947\n",
      "[707/01017] train_loss: 0.011710\n",
      "[707/01067] train_loss: 0.012402\n",
      "[707/01117] train_loss: 0.012507\n",
      "[707/01167] train_loss: 0.012403\n",
      "[707/01217] train_loss: 0.012770\n",
      "[708/00041] train_loss: 0.016015\n",
      "[708/00091] train_loss: 0.014032\n",
      "[708/00141] train_loss: 0.013185\n",
      "[708/00191] train_loss: 0.013186\n",
      "[708/00241] train_loss: 0.012854\n",
      "[708/00291] train_loss: 0.012311\n",
      "[708/00341] train_loss: 0.012886\n",
      "[708/00391] train_loss: 0.012975\n",
      "[708/00441] train_loss: 0.011849\n",
      "[708/00491] train_loss: 0.014120\n",
      "[708/00541] train_loss: 0.012237\n",
      "[708/00591] train_loss: 0.013166\n",
      "[708/00641] train_loss: 0.012799\n",
      "[708/00691] train_loss: 0.012836\n",
      "[708/00741] train_loss: 0.012602\n",
      "[708/00791] train_loss: 0.012829\n",
      "[708/00841] train_loss: 0.013018\n",
      "[708/00891] train_loss: 0.012440\n",
      "[708/00941] train_loss: 0.012789\n",
      "[708/00991] train_loss: 0.012394\n",
      "[708/01041] train_loss: 0.012609\n",
      "[708/01091] train_loss: 0.012721\n",
      "[708/01141] train_loss: 0.012271\n",
      "[708/01191] train_loss: 0.013440\n",
      "[709/00015] train_loss: 0.013529\n",
      "[709/00065] train_loss: 0.014983\n",
      "[709/00115] train_loss: 0.014322\n",
      "[709/00165] train_loss: 0.013470\n",
      "[709/00215] train_loss: 0.012965\n",
      "[709/00265] train_loss: 0.012771\n",
      "[709/00315] train_loss: 0.012551\n",
      "[709/00365] train_loss: 0.012004\n",
      "[709/00415] train_loss: 0.012551\n",
      "[709/00465] train_loss: 0.013424\n",
      "[709/00515] train_loss: 0.012424\n",
      "[709/00565] train_loss: 0.012514\n",
      "[709/00615] train_loss: 0.011860\n",
      "[709/00665] train_loss: 0.012673\n",
      "[709/00715] train_loss: 0.012133\n",
      "[709/00765] train_loss: 0.012819\n",
      "[709/00815] train_loss: 0.013823\n",
      "[709/00865] train_loss: 0.012979\n",
      "[709/00915] train_loss: 0.013016\n",
      "[709/00965] train_loss: 0.012479\n",
      "[709/01015] train_loss: 0.012017\n",
      "[709/01065] train_loss: 0.012929\n",
      "[709/01115] train_loss: 0.012508\n",
      "[709/01165] train_loss: 0.013121\n",
      "[709/01215] train_loss: 0.012480\n",
      "[710/00039] train_loss: 0.014172\n",
      "[710/00089] train_loss: 0.014031\n",
      "[710/00139] train_loss: 0.013613\n",
      "[710/00189] train_loss: 0.013730\n",
      "[710/00239] train_loss: 0.012854\n",
      "[710/00289] train_loss: 0.012315\n",
      "[710/00339] train_loss: 0.013395\n",
      "[710/00389] train_loss: 0.012917\n",
      "[710/00439] train_loss: 0.012697\n",
      "[710/00489] train_loss: 0.012362\n",
      "[710/00539] train_loss: 0.012375\n",
      "[710/00589] train_loss: 0.012935\n",
      "[710/00639] train_loss: 0.013048\n",
      "[710/00689] train_loss: 0.012874\n",
      "[710/00739] train_loss: 0.012447\n",
      "[710/00789] train_loss: 0.012497\n",
      "[710/00839] train_loss: 0.013104\n",
      "[710/00889] train_loss: 0.012493\n",
      "[710/00939] train_loss: 0.012634\n",
      "[710/00989] train_loss: 0.013014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[710/01039] train_loss: 0.013107\n",
      "[710/01089] train_loss: 0.012831\n",
      "[710/01139] train_loss: 0.012911\n",
      "[710/01189] train_loss: 0.012374\n",
      "[711/00013] train_loss: 0.014059\n",
      "[711/00063] train_loss: 0.014741\n",
      "[711/00113] train_loss: 0.013764\n",
      "[711/00163] train_loss: 0.012732\n",
      "[711/00213] train_loss: 0.012511\n",
      "[711/00263] train_loss: 0.013756\n",
      "[711/00313] train_loss: 0.013075\n",
      "[711/00363] train_loss: 0.012584\n",
      "[711/00413] train_loss: 0.012644\n",
      "[711/00463] train_loss: 0.012542\n",
      "[711/00513] train_loss: 0.012487\n",
      "[711/00563] train_loss: 0.013495\n",
      "[711/00613] train_loss: 0.012903\n",
      "[711/00663] train_loss: 0.011831\n",
      "[711/00713] train_loss: 0.012259\n",
      "[711/00763] train_loss: 0.013031\n",
      "[711/00813] train_loss: 0.013449\n",
      "[711/00863] train_loss: 0.012592\n",
      "[711/00913] train_loss: 0.012199\n",
      "[711/00963] train_loss: 0.013173\n",
      "[711/01013] train_loss: 0.013196\n",
      "[711/01063] train_loss: 0.013323\n",
      "[711/01113] train_loss: 0.012448\n",
      "[711/01163] train_loss: 0.012703\n",
      "[711/01213] train_loss: 0.013018\n",
      "[712/00037] train_loss: 0.015137\n",
      "[712/00087] train_loss: 0.014169\n",
      "[712/00137] train_loss: 0.013634\n",
      "[712/00187] train_loss: 0.013592\n",
      "[712/00237] train_loss: 0.013374\n",
      "[712/00287] train_loss: 0.012710\n",
      "[712/00337] train_loss: 0.012644\n",
      "[712/00387] train_loss: 0.012881\n",
      "[712/00437] train_loss: 0.012765\n",
      "[712/00487] train_loss: 0.012423\n",
      "[712/00537] train_loss: 0.012612\n",
      "[712/00587] train_loss: 0.011957\n",
      "[712/00637] train_loss: 0.012979\n",
      "[712/00687] train_loss: 0.012988\n",
      "[712/00737] train_loss: 0.012198\n",
      "[712/00787] train_loss: 0.013649\n",
      "[712/00837] train_loss: 0.012952\n",
      "[712/00887] train_loss: 0.012258\n",
      "[712/00937] train_loss: 0.012897\n",
      "[712/00987] train_loss: 0.012314\n",
      "[712/01037] train_loss: 0.012846\n",
      "[712/01087] train_loss: 0.012680\n",
      "[712/01137] train_loss: 0.012895\n",
      "[712/01187] train_loss: 0.011572\n",
      "[713/00011] train_loss: 0.013850\n",
      "[713/00061] train_loss: 0.015233\n",
      "[713/00111] train_loss: 0.014037\n",
      "[713/00161] train_loss: 0.013219\n",
      "[713/00211] train_loss: 0.013368\n",
      "[713/00261] train_loss: 0.012772\n",
      "[713/00311] train_loss: 0.012169\n",
      "[713/00361] train_loss: 0.012413\n",
      "[713/00411] train_loss: 0.012791\n",
      "[713/00461] train_loss: 0.013015\n",
      "[713/00511] train_loss: 0.012495\n",
      "[713/00561] train_loss: 0.012956\n",
      "[713/00611] train_loss: 0.013616\n",
      "[713/00661] train_loss: 0.012720\n",
      "[713/00711] train_loss: 0.013165\n",
      "[713/00761] train_loss: 0.012081\n",
      "[713/00811] train_loss: 0.012417\n",
      "[713/00861] train_loss: 0.012913\n",
      "[713/00911] train_loss: 0.012310\n",
      "[713/00961] train_loss: 0.012514\n",
      "[713/01011] train_loss: 0.013485\n",
      "[713/01061] train_loss: 0.012787\n",
      "[713/01111] train_loss: 0.012822\n",
      "[713/01161] train_loss: 0.012368\n",
      "[713/01211] train_loss: 0.012421\n",
      "[714/00035] train_loss: 0.014842\n",
      "[714/00085] train_loss: 0.014441\n",
      "[714/00135] train_loss: 0.013682\n",
      "[714/00185] train_loss: 0.012991\n",
      "[714/00235] train_loss: 0.012578\n",
      "[714/00285] train_loss: 0.012393\n",
      "[714/00335] train_loss: 0.012795\n",
      "[714/00385] train_loss: 0.012690\n",
      "[714/00435] train_loss: 0.011899\n",
      "[714/00485] train_loss: 0.012619\n",
      "[714/00535] train_loss: 0.013543\n",
      "[714/00585] train_loss: 0.012879\n",
      "[714/00635] train_loss: 0.011853\n",
      "[714/00685] train_loss: 0.012913\n",
      "[714/00735] train_loss: 0.012208\n",
      "[714/00785] train_loss: 0.012479\n",
      "[714/00835] train_loss: 0.012509\n",
      "[714/00885] train_loss: 0.012224\n",
      "[714/00935] train_loss: 0.012770\n",
      "[714/00985] train_loss: 0.012760\n",
      "[714/01035] train_loss: 0.012727\n",
      "[714/01085] train_loss: 0.012996\n",
      "[714/01135] train_loss: 0.012873\n",
      "[714/01185] train_loss: 0.013589\n",
      "[715/00009] train_loss: 0.013768\n",
      "[715/00059] train_loss: 0.015940\n",
      "[715/00109] train_loss: 0.013130\n",
      "[715/00159] train_loss: 0.013685\n",
      "[715/00209] train_loss: 0.013584\n",
      "[715/00259] train_loss: 0.012758\n",
      "[715/00309] train_loss: 0.013352\n",
      "[715/00359] train_loss: 0.012783\n",
      "[715/00409] train_loss: 0.012213\n",
      "[715/00459] train_loss: 0.012872\n",
      "[715/00509] train_loss: 0.011893\n",
      "[715/00559] train_loss: 0.013035\n",
      "[715/00609] train_loss: 0.012616\n",
      "[715/00659] train_loss: 0.012666\n",
      "[715/00709] train_loss: 0.012378\n",
      "[715/00759] train_loss: 0.011748\n",
      "[715/00809] train_loss: 0.012901\n",
      "[715/00859] train_loss: 0.012131\n",
      "[715/00909] train_loss: 0.012799\n",
      "[715/00959] train_loss: 0.013014\n",
      "[715/01009] train_loss: 0.012747\n",
      "[715/01059] train_loss: 0.012873\n",
      "[715/01109] train_loss: 0.013156\n",
      "[715/01159] train_loss: 0.012646\n",
      "[715/01209] train_loss: 0.012906\n",
      "[716/00033] train_loss: 0.014492\n",
      "[716/00083] train_loss: 0.014820\n",
      "[716/00133] train_loss: 0.013310\n",
      "[716/00183] train_loss: 0.013084\n",
      "[716/00233] train_loss: 0.012930\n",
      "[716/00283] train_loss: 0.012414\n",
      "[716/00333] train_loss: 0.012877\n",
      "[716/00383] train_loss: 0.012444\n",
      "[716/00433] train_loss: 0.012201\n",
      "[716/00483] train_loss: 0.012155\n",
      "[716/00533] train_loss: 0.012523\n",
      "[716/00583] train_loss: 0.012958\n",
      "[716/00633] train_loss: 0.011886\n",
      "[716/00683] train_loss: 0.013173\n",
      "[716/00733] train_loss: 0.012781\n",
      "[716/00783] train_loss: 0.012671\n",
      "[716/00833] train_loss: 0.012373\n",
      "[716/00883] train_loss: 0.013263\n",
      "[716/00933] train_loss: 0.012371\n",
      "[716/00983] train_loss: 0.012839\n",
      "[716/01033] train_loss: 0.012869\n",
      "[716/01083] train_loss: 0.012740\n",
      "[716/01133] train_loss: 0.013131\n",
      "[716/01183] train_loss: 0.013746\n",
      "[717/00007] train_loss: 0.013661\n",
      "[717/00057] train_loss: 0.015789\n",
      "[717/00107] train_loss: 0.014027\n",
      "[717/00157] train_loss: 0.013686\n",
      "[717/00207] train_loss: 0.012375\n",
      "[717/00257] train_loss: 0.012746\n",
      "[717/00307] train_loss: 0.012104\n",
      "[717/00357] train_loss: 0.012858\n",
      "[717/00407] train_loss: 0.012998\n",
      "[717/00457] train_loss: 0.012290\n",
      "[717/00507] train_loss: 0.012735\n",
      "[717/00557] train_loss: 0.012680\n",
      "[717/00607] train_loss: 0.012945\n",
      "[717/00657] train_loss: 0.012889\n",
      "[717/00707] train_loss: 0.012413\n",
      "[717/00757] train_loss: 0.012979\n",
      "[717/00807] train_loss: 0.012244\n",
      "[717/00857] train_loss: 0.012246\n",
      "[717/00907] train_loss: 0.012754\n",
      "[717/00957] train_loss: 0.013018\n",
      "[717/01007] train_loss: 0.011998\n",
      "[717/01057] train_loss: 0.013191\n",
      "[717/01107] train_loss: 0.012409\n",
      "[717/01157] train_loss: 0.013172\n",
      "[717/01207] train_loss: 0.013706\n",
      "[718/00031] train_loss: 0.014005\n",
      "[718/00081] train_loss: 0.015073\n",
      "[718/00131] train_loss: 0.014349\n",
      "[718/00181] train_loss: 0.013627\n",
      "[718/00231] train_loss: 0.012826\n",
      "[718/00281] train_loss: 0.013011\n",
      "[718/00331] train_loss: 0.012974\n",
      "[718/00381] train_loss: 0.013024\n",
      "[718/00431] train_loss: 0.012610\n",
      "[718/00481] train_loss: 0.012593\n",
      "[718/00531] train_loss: 0.013055\n",
      "[718/00581] train_loss: 0.011791\n",
      "[718/00631] train_loss: 0.012307\n",
      "[718/00681] train_loss: 0.012822\n",
      "[718/00731] train_loss: 0.012737\n",
      "[718/00781] train_loss: 0.011723\n",
      "[718/00831] train_loss: 0.012983\n",
      "[718/00881] train_loss: 0.012823\n",
      "[718/00931] train_loss: 0.012224\n",
      "[718/00981] train_loss: 0.012197\n",
      "[718/01031] train_loss: 0.012458\n",
      "[718/01081] train_loss: 0.012354\n",
      "[718/01131] train_loss: 0.011833\n",
      "[718/01181] train_loss: 0.013025\n",
      "[719/00005] train_loss: 0.012994\n",
      "[719/00055] train_loss: 0.015692\n",
      "[719/00105] train_loss: 0.015006\n",
      "[719/00155] train_loss: 0.013134\n",
      "[719/00205] train_loss: 0.013544\n",
      "[719/00255] train_loss: 0.012382\n",
      "[719/00305] train_loss: 0.012078\n",
      "[719/00355] train_loss: 0.012759\n",
      "[719/00405] train_loss: 0.012633\n",
      "[719/00455] train_loss: 0.013133\n",
      "[719/00505] train_loss: 0.012587\n",
      "[719/00555] train_loss: 0.013067\n",
      "[719/00605] train_loss: 0.013084\n",
      "[719/00655] train_loss: 0.012411\n",
      "[719/00705] train_loss: 0.013206\n",
      "[719/00755] train_loss: 0.012188\n",
      "[719/00805] train_loss: 0.012403\n",
      "[719/00855] train_loss: 0.012225\n",
      "[719/00905] train_loss: 0.012209\n",
      "[719/00955] train_loss: 0.013445\n",
      "[719/01005] train_loss: 0.012350\n",
      "[719/01055] train_loss: 0.012748\n",
      "[719/01105] train_loss: 0.012072\n",
      "[719/01155] train_loss: 0.012491\n",
      "[719/01205] train_loss: 0.012904\n",
      "[720/00029] train_loss: 0.013919\n",
      "[720/00079] train_loss: 0.014044\n",
      "[720/00129] train_loss: 0.013799\n",
      "[720/00179] train_loss: 0.013045\n",
      "[720/00229] train_loss: 0.013587\n",
      "[720/00279] train_loss: 0.013129\n",
      "[720/00329] train_loss: 0.013142\n",
      "[720/00379] train_loss: 0.013034\n",
      "[720/00429] train_loss: 0.012465\n",
      "[720/00479] train_loss: 0.013117\n",
      "[720/00529] train_loss: 0.012507\n",
      "[720/00579] train_loss: 0.012256\n",
      "[720/00629] train_loss: 0.013223\n",
      "[720/00679] train_loss: 0.012402\n",
      "[720/00729] train_loss: 0.012093\n",
      "[720/00779] train_loss: 0.012613\n",
      "[720/00829] train_loss: 0.012019\n",
      "[720/00879] train_loss: 0.012576\n",
      "[720/00929] train_loss: 0.012487\n",
      "[720/00979] train_loss: 0.013364\n",
      "[720/01029] train_loss: 0.012510\n",
      "[720/01079] train_loss: 0.013233\n",
      "[720/01129] train_loss: 0.013136\n",
      "[720/01179] train_loss: 0.013824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[721/00003] train_loss: 0.014003\n",
      "[721/00053] train_loss: 0.015512\n",
      "[721/00103] train_loss: 0.013700\n",
      "[721/00153] train_loss: 0.013825\n",
      "[721/00203] train_loss: 0.013849\n",
      "[721/00253] train_loss: 0.012400\n",
      "[721/00303] train_loss: 0.012564\n",
      "[721/00353] train_loss: 0.012465\n",
      "[721/00403] train_loss: 0.011989\n",
      "[721/00453] train_loss: 0.012154\n",
      "[721/00503] train_loss: 0.012044\n",
      "[721/00553] train_loss: 0.013426\n",
      "[721/00603] train_loss: 0.012353\n",
      "[721/00653] train_loss: 0.012552\n",
      "[721/00703] train_loss: 0.013251\n",
      "[721/00753] train_loss: 0.012767\n",
      "[721/00803] train_loss: 0.012707\n",
      "[721/00853] train_loss: 0.013671\n",
      "[721/00903] train_loss: 0.012751\n",
      "[721/00953] train_loss: 0.012716\n",
      "[721/01003] train_loss: 0.013248\n",
      "[721/01053] train_loss: 0.012566\n",
      "[721/01103] train_loss: 0.012839\n",
      "[721/01153] train_loss: 0.011820\n",
      "[721/01203] train_loss: 0.013426\n",
      "[722/00027] train_loss: 0.013968\n",
      "[722/00077] train_loss: 0.014835\n",
      "[722/00127] train_loss: 0.013311\n",
      "[722/00177] train_loss: 0.014050\n",
      "[722/00227] train_loss: 0.013080\n",
      "[722/00277] train_loss: 0.012651\n",
      "[722/00327] train_loss: 0.012405\n",
      "[722/00377] train_loss: 0.013431\n",
      "[722/00427] train_loss: 0.012732\n",
      "[722/00477] train_loss: 0.012307\n",
      "[722/00527] train_loss: 0.013116\n",
      "[722/00577] train_loss: 0.012374\n",
      "[722/00627] train_loss: 0.011808\n",
      "[722/00677] train_loss: 0.012154\n",
      "[722/00727] train_loss: 0.012222\n",
      "[722/00777] train_loss: 0.012117\n",
      "[722/00827] train_loss: 0.012966\n",
      "[722/00877] train_loss: 0.013187\n",
      "[722/00927] train_loss: 0.012956\n",
      "[722/00977] train_loss: 0.012782\n",
      "[722/01027] train_loss: 0.011940\n",
      "[722/01077] train_loss: 0.013020\n",
      "[722/01127] train_loss: 0.012662\n",
      "[722/01177] train_loss: 0.012824\n",
      "[723/00001] train_loss: 0.012457\n",
      "[723/00051] train_loss: 0.016645\n",
      "[723/00101] train_loss: 0.015037\n",
      "[723/00151] train_loss: 0.013437\n",
      "[723/00201] train_loss: 0.013139\n",
      "[723/00251] train_loss: 0.013382\n",
      "[723/00301] train_loss: 0.012820\n",
      "[723/00351] train_loss: 0.012161\n",
      "[723/00401] train_loss: 0.012790\n",
      "[723/00451] train_loss: 0.011784\n",
      "[723/00501] train_loss: 0.011914\n",
      "[723/00551] train_loss: 0.012393\n",
      "[723/00601] train_loss: 0.012239\n",
      "[723/00651] train_loss: 0.012931\n",
      "[723/00701] train_loss: 0.012755\n",
      "[723/00751] train_loss: 0.013151\n",
      "[723/00801] train_loss: 0.012552\n",
      "[723/00851] train_loss: 0.012091\n",
      "[723/00901] train_loss: 0.011671\n",
      "[723/00951] train_loss: 0.012490\n",
      "[723/01001] train_loss: 0.012926\n",
      "[723/01051] train_loss: 0.012833\n",
      "[723/01101] train_loss: 0.012280\n",
      "[723/01151] train_loss: 0.013128\n",
      "[723/01201] train_loss: 0.012704\n",
      "[724/00025] train_loss: 0.014119\n",
      "[724/00075] train_loss: 0.014559\n",
      "[724/00125] train_loss: 0.013100\n",
      "[724/00175] train_loss: 0.013635\n",
      "[724/00225] train_loss: 0.012787\n",
      "[724/00275] train_loss: 0.012370\n",
      "[724/00325] train_loss: 0.012050\n",
      "[724/00375] train_loss: 0.013004\n",
      "[724/00425] train_loss: 0.012789\n",
      "[724/00475] train_loss: 0.013393\n",
      "[724/00525] train_loss: 0.011663\n",
      "[724/00575] train_loss: 0.013068\n",
      "[724/00625] train_loss: 0.011896\n",
      "[724/00675] train_loss: 0.013048\n",
      "[724/00725] train_loss: 0.012940\n",
      "[724/00775] train_loss: 0.013008\n",
      "[724/00825] train_loss: 0.012792\n",
      "[724/00875] train_loss: 0.012745\n",
      "[724/00925] train_loss: 0.013083\n",
      "[724/00975] train_loss: 0.011945\n",
      "[724/01025] train_loss: 0.012862\n",
      "[724/01075] train_loss: 0.013337\n",
      "[724/01125] train_loss: 0.013076\n",
      "[724/01175] train_loss: 0.012202\n",
      "[724/01225] train_loss: 0.012753\n",
      "[725/00049] train_loss: 0.015547\n",
      "[725/00099] train_loss: 0.015230\n",
      "[725/00149] train_loss: 0.013835\n",
      "[725/00199] train_loss: 0.012660\n",
      "[725/00249] train_loss: 0.013268\n",
      "[725/00299] train_loss: 0.012231\n",
      "[725/00349] train_loss: 0.012816\n",
      "[725/00399] train_loss: 0.012498\n",
      "[725/00449] train_loss: 0.012479\n",
      "[725/00499] train_loss: 0.012469\n",
      "[725/00549] train_loss: 0.012684\n",
      "[725/00599] train_loss: 0.012559\n",
      "[725/00649] train_loss: 0.012585\n",
      "[725/00699] train_loss: 0.012720\n",
      "[725/00749] train_loss: 0.012786\n",
      "[725/00799] train_loss: 0.013005\n",
      "[725/00849] train_loss: 0.011925\n",
      "[725/00899] train_loss: 0.012728\n",
      "[725/00949] train_loss: 0.012925\n",
      "[725/00999] train_loss: 0.012417\n",
      "[725/01049] train_loss: 0.013092\n",
      "[725/01099] train_loss: 0.013173\n",
      "[725/01149] train_loss: 0.012616\n",
      "[725/01199] train_loss: 0.011955\n",
      "[726/00023] train_loss: 0.014012\n",
      "[726/00073] train_loss: 0.014069\n",
      "[726/00123] train_loss: 0.013665\n",
      "[726/00173] train_loss: 0.013165\n",
      "[726/00223] train_loss: 0.012362\n",
      "[726/00273] train_loss: 0.012531\n",
      "[726/00323] train_loss: 0.012734\n",
      "[726/00373] train_loss: 0.012637\n",
      "[726/00423] train_loss: 0.012061\n",
      "[726/00473] train_loss: 0.013100\n",
      "[726/00523] train_loss: 0.012649\n",
      "[726/00573] train_loss: 0.011826\n",
      "[726/00623] train_loss: 0.012805\n",
      "[726/00673] train_loss: 0.012051\n",
      "[726/00723] train_loss: 0.012947\n",
      "[726/00773] train_loss: 0.012460\n",
      "[726/00823] train_loss: 0.012637\n",
      "[726/00873] train_loss: 0.013076\n",
      "[726/00923] train_loss: 0.012879\n",
      "[726/00973] train_loss: 0.012815\n",
      "[726/01023] train_loss: 0.013008\n",
      "[726/01073] train_loss: 0.012291\n",
      "[726/01123] train_loss: 0.013156\n",
      "[726/01173] train_loss: 0.012702\n",
      "[726/01223] train_loss: 0.013033\n",
      "[727/00047] train_loss: 0.015117\n",
      "[727/00097] train_loss: 0.014117\n",
      "[727/00147] train_loss: 0.013105\n",
      "[727/00197] train_loss: 0.012851\n",
      "[727/00247] train_loss: 0.012319\n",
      "[727/00297] train_loss: 0.012466\n",
      "[727/00347] train_loss: 0.013086\n",
      "[727/00397] train_loss: 0.013469\n",
      "[727/00447] train_loss: 0.012133\n",
      "[727/00497] train_loss: 0.012822\n",
      "[727/00547] train_loss: 0.012266\n",
      "[727/00597] train_loss: 0.012643\n",
      "[727/00647] train_loss: 0.012343\n",
      "[727/00697] train_loss: 0.012509\n",
      "[727/00747] train_loss: 0.012788\n",
      "[727/00797] train_loss: 0.011858\n",
      "[727/00847] train_loss: 0.013727\n",
      "[727/00897] train_loss: 0.012899\n",
      "[727/00947] train_loss: 0.012693\n",
      "[727/00997] train_loss: 0.012904\n",
      "[727/01047] train_loss: 0.013162\n",
      "[727/01097] train_loss: 0.012851\n",
      "[727/01147] train_loss: 0.012998\n",
      "[727/01197] train_loss: 0.012860\n",
      "[728/00021] train_loss: 0.013504\n",
      "[728/00071] train_loss: 0.015408\n",
      "[728/00121] train_loss: 0.013675\n",
      "[728/00171] train_loss: 0.013654\n",
      "[728/00221] train_loss: 0.012881\n",
      "[728/00271] train_loss: 0.012642\n",
      "[728/00321] train_loss: 0.012376\n",
      "[728/00371] train_loss: 0.012739\n",
      "[728/00421] train_loss: 0.012244\n",
      "[728/00471] train_loss: 0.012295\n",
      "[728/00521] train_loss: 0.012980\n",
      "[728/00571] train_loss: 0.013219\n",
      "[728/00621] train_loss: 0.012213\n",
      "[728/00671] train_loss: 0.012418\n",
      "[728/00721] train_loss: 0.013267\n",
      "[728/00771] train_loss: 0.012598\n",
      "[728/00821] train_loss: 0.012734\n",
      "[728/00871] train_loss: 0.012110\n",
      "[728/00921] train_loss: 0.013604\n",
      "[728/00971] train_loss: 0.012882\n",
      "[728/01021] train_loss: 0.012331\n",
      "[728/01071] train_loss: 0.013137\n",
      "[728/01121] train_loss: 0.012825\n",
      "[728/01171] train_loss: 0.012432\n",
      "[728/01221] train_loss: 0.012065\n",
      "[729/00045] train_loss: 0.016249\n",
      "[729/00095] train_loss: 0.014322\n",
      "[729/00145] train_loss: 0.013244\n",
      "[729/00195] train_loss: 0.013112\n",
      "[729/00245] train_loss: 0.012623\n",
      "[729/00295] train_loss: 0.011903\n",
      "[729/00345] train_loss: 0.013037\n",
      "[729/00395] train_loss: 0.012345\n",
      "[729/00445] train_loss: 0.012197\n",
      "[729/00495] train_loss: 0.012904\n",
      "[729/00545] train_loss: 0.013352\n",
      "[729/00595] train_loss: 0.012779\n",
      "[729/00645] train_loss: 0.012791\n",
      "[729/00695] train_loss: 0.012824\n",
      "[729/00745] train_loss: 0.011824\n",
      "[729/00795] train_loss: 0.012710\n",
      "[729/00845] train_loss: 0.012078\n",
      "[729/00895] train_loss: 0.013137\n",
      "[729/00945] train_loss: 0.012836\n",
      "[729/00995] train_loss: 0.012649\n",
      "[729/01045] train_loss: 0.012521\n",
      "[729/01095] train_loss: 0.013219\n",
      "[729/01145] train_loss: 0.012615\n",
      "[729/01195] train_loss: 0.012292\n",
      "[730/00019] train_loss: 0.013432\n",
      "[730/00069] train_loss: 0.015137\n",
      "[730/00119] train_loss: 0.015125\n",
      "[730/00169] train_loss: 0.013521\n",
      "[730/00219] train_loss: 0.013023\n",
      "[730/00269] train_loss: 0.012901\n",
      "[730/00319] train_loss: 0.013261\n",
      "[730/00369] train_loss: 0.012417\n",
      "[730/00419] train_loss: 0.011637\n",
      "[730/00469] train_loss: 0.012573\n",
      "[730/00519] train_loss: 0.012490\n",
      "[730/00569] train_loss: 0.013040\n",
      "[730/00619] train_loss: 0.011786\n",
      "[730/00669] train_loss: 0.012853\n",
      "[730/00719] train_loss: 0.012255\n",
      "[730/00769] train_loss: 0.012430\n",
      "[730/00819] train_loss: 0.012680\n",
      "[730/00869] train_loss: 0.012570\n",
      "[730/00919] train_loss: 0.013157\n",
      "[730/00969] train_loss: 0.012841\n",
      "[730/01019] train_loss: 0.011946\n",
      "[730/01069] train_loss: 0.012279\n",
      "[730/01119] train_loss: 0.012672\n",
      "[730/01169] train_loss: 0.012689\n",
      "[730/01219] train_loss: 0.013415\n",
      "[731/00043] train_loss: 0.014900\n",
      "[731/00093] train_loss: 0.014832\n",
      "[731/00143] train_loss: 0.013796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[731/00193] train_loss: 0.014162\n",
      "[731/00243] train_loss: 0.013226\n",
      "[731/00293] train_loss: 0.012727\n",
      "[731/00343] train_loss: 0.012054\n",
      "[731/00393] train_loss: 0.013137\n",
      "[731/00443] train_loss: 0.012706\n",
      "[731/00493] train_loss: 0.011986\n",
      "[731/00543] train_loss: 0.013448\n",
      "[731/00593] train_loss: 0.012828\n",
      "[731/00643] train_loss: 0.012631\n",
      "[731/00693] train_loss: 0.011572\n",
      "[731/00743] train_loss: 0.012666\n",
      "[731/00793] train_loss: 0.012348\n",
      "[731/00843] train_loss: 0.012704\n",
      "[731/00893] train_loss: 0.012573\n",
      "[731/00943] train_loss: 0.012600\n",
      "[731/00993] train_loss: 0.011777\n",
      "[731/01043] train_loss: 0.013835\n",
      "[731/01093] train_loss: 0.012342\n",
      "[731/01143] train_loss: 0.012750\n",
      "[731/01193] train_loss: 0.012494\n",
      "[732/00017] train_loss: 0.013581\n",
      "[732/00067] train_loss: 0.015568\n",
      "[732/00117] train_loss: 0.013930\n",
      "[732/00167] train_loss: 0.012830\n",
      "[732/00217] train_loss: 0.012708\n",
      "[732/00267] train_loss: 0.013241\n",
      "[732/00317] train_loss: 0.012467\n",
      "[732/00367] train_loss: 0.012870\n",
      "[732/00417] train_loss: 0.012235\n",
      "[732/00467] train_loss: 0.012490\n",
      "[732/00517] train_loss: 0.012258\n",
      "[732/00567] train_loss: 0.013022\n",
      "[732/00617] train_loss: 0.013016\n",
      "[732/00667] train_loss: 0.012534\n",
      "[732/00717] train_loss: 0.012134\n",
      "[732/00767] train_loss: 0.012369\n",
      "[732/00817] train_loss: 0.013295\n",
      "[732/00867] train_loss: 0.012994\n",
      "[732/00917] train_loss: 0.012219\n",
      "[732/00967] train_loss: 0.012358\n",
      "[732/01017] train_loss: 0.012987\n",
      "[732/01067] train_loss: 0.013766\n",
      "[732/01117] train_loss: 0.012926\n",
      "[732/01167] train_loss: 0.013196\n",
      "[732/01217] train_loss: 0.012647\n",
      "[733/00041] train_loss: 0.014493\n",
      "[733/00091] train_loss: 0.014319\n",
      "[733/00141] train_loss: 0.013157\n",
      "[733/00191] train_loss: 0.013837\n",
      "[733/00241] train_loss: 0.012767\n",
      "[733/00291] train_loss: 0.013289\n",
      "[733/00341] train_loss: 0.013045\n",
      "[733/00391] train_loss: 0.013111\n",
      "[733/00441] train_loss: 0.012425\n",
      "[733/00491] train_loss: 0.012381\n",
      "[733/00541] train_loss: 0.012021\n",
      "[733/00591] train_loss: 0.012226\n",
      "[733/00641] train_loss: 0.012758\n",
      "[733/00691] train_loss: 0.012453\n",
      "[733/00741] train_loss: 0.012819\n",
      "[733/00791] train_loss: 0.012740\n",
      "[733/00841] train_loss: 0.012404\n",
      "[733/00891] train_loss: 0.012243\n",
      "[733/00941] train_loss: 0.012991\n",
      "[733/00991] train_loss: 0.012541\n",
      "[733/01041] train_loss: 0.012976\n",
      "[733/01091] train_loss: 0.012040\n",
      "[733/01141] train_loss: 0.013359\n",
      "[733/01191] train_loss: 0.012803\n",
      "[734/00015] train_loss: 0.014583\n",
      "[734/00065] train_loss: 0.014545\n",
      "[734/00115] train_loss: 0.013916\n",
      "[734/00165] train_loss: 0.012630\n",
      "[734/00215] train_loss: 0.013049\n",
      "[734/00265] train_loss: 0.012532\n",
      "[734/00315] train_loss: 0.012744\n",
      "[734/00365] train_loss: 0.012501\n",
      "[734/00415] train_loss: 0.013083\n",
      "[734/00465] train_loss: 0.012287\n",
      "[734/00515] train_loss: 0.012258\n",
      "[734/00565] train_loss: 0.012639\n",
      "[734/00615] train_loss: 0.012734\n",
      "[734/00665] train_loss: 0.013580\n",
      "[734/00715] train_loss: 0.012332\n",
      "[734/00765] train_loss: 0.013819\n",
      "[734/00815] train_loss: 0.013045\n",
      "[734/00865] train_loss: 0.013150\n",
      "[734/00915] train_loss: 0.012821\n",
      "[734/00965] train_loss: 0.012863\n",
      "[734/01015] train_loss: 0.012796\n",
      "[734/01065] train_loss: 0.012831\n",
      "[734/01115] train_loss: 0.012029\n",
      "[734/01165] train_loss: 0.013134\n",
      "[734/01215] train_loss: 0.012930\n",
      "[735/00039] train_loss: 0.015276\n",
      "[735/00089] train_loss: 0.014453\n",
      "[735/00139] train_loss: 0.012956\n",
      "[735/00189] train_loss: 0.012654\n",
      "[735/00239] train_loss: 0.013396\n",
      "[735/00289] train_loss: 0.012764\n",
      "[735/00339] train_loss: 0.012704\n",
      "[735/00389] train_loss: 0.012228\n",
      "[735/00439] train_loss: 0.012124\n",
      "[735/00489] train_loss: 0.012521\n",
      "[735/00539] train_loss: 0.012493\n",
      "[735/00589] train_loss: 0.012853\n",
      "[735/00639] train_loss: 0.013043\n",
      "[735/00689] train_loss: 0.012201\n",
      "[735/00739] train_loss: 0.012711\n",
      "[735/00789] train_loss: 0.012592\n",
      "[735/00839] train_loss: 0.012458\n",
      "[735/00889] train_loss: 0.014083\n",
      "[735/00939] train_loss: 0.013109\n",
      "[735/00989] train_loss: 0.011687\n",
      "[735/01039] train_loss: 0.012650\n",
      "[735/01089] train_loss: 0.012644\n",
      "[735/01139] train_loss: 0.013044\n",
      "[735/01189] train_loss: 0.012786\n",
      "[736/00013] train_loss: 0.014334\n",
      "[736/00063] train_loss: 0.014804\n",
      "[736/00113] train_loss: 0.014545\n",
      "[736/00163] train_loss: 0.012953\n",
      "[736/00213] train_loss: 0.013279\n",
      "[736/00263] train_loss: 0.013033\n",
      "[736/00313] train_loss: 0.012772\n",
      "[736/00363] train_loss: 0.012821\n",
      "[736/00413] train_loss: 0.012312\n",
      "[736/00463] train_loss: 0.012562\n",
      "[736/00513] train_loss: 0.012662\n",
      "[736/00563] train_loss: 0.012788\n",
      "[736/00613] train_loss: 0.012459\n",
      "[736/00663] train_loss: 0.012209\n",
      "[736/00713] train_loss: 0.012347\n",
      "[736/00763] train_loss: 0.012705\n",
      "[736/00813] train_loss: 0.012847\n",
      "[736/00863] train_loss: 0.012285\n",
      "[736/00913] train_loss: 0.012854\n",
      "[736/00963] train_loss: 0.012595\n",
      "[736/01013] train_loss: 0.012710\n",
      "[736/01063] train_loss: 0.012713\n",
      "[736/01113] train_loss: 0.012459\n",
      "[736/01163] train_loss: 0.013010\n",
      "[736/01213] train_loss: 0.012022\n",
      "[737/00037] train_loss: 0.014339\n",
      "[737/00087] train_loss: 0.014836\n",
      "[737/00137] train_loss: 0.013626\n",
      "[737/00187] train_loss: 0.013337\n",
      "[737/00237] train_loss: 0.013266\n",
      "[737/00287] train_loss: 0.012978\n",
      "[737/00337] train_loss: 0.012477\n",
      "[737/00387] train_loss: 0.012724\n",
      "[737/00437] train_loss: 0.012681\n",
      "[737/00487] train_loss: 0.011623\n",
      "[737/00537] train_loss: 0.012832\n",
      "[737/00587] train_loss: 0.012273\n",
      "[737/00637] train_loss: 0.013326\n",
      "[737/00687] train_loss: 0.012678\n",
      "[737/00737] train_loss: 0.012250\n",
      "[737/00787] train_loss: 0.012619\n",
      "[737/00837] train_loss: 0.012235\n",
      "[737/00887] train_loss: 0.013261\n",
      "[737/00937] train_loss: 0.012971\n",
      "[737/00987] train_loss: 0.012687\n",
      "[737/01037] train_loss: 0.012234\n",
      "[737/01087] train_loss: 0.012562\n",
      "[737/01137] train_loss: 0.012082\n",
      "[737/01187] train_loss: 0.012823\n",
      "[738/00011] train_loss: 0.013101\n",
      "[738/00061] train_loss: 0.015558\n",
      "[738/00111] train_loss: 0.014527\n",
      "[738/00161] train_loss: 0.013278\n",
      "[738/00211] train_loss: 0.013425\n",
      "[738/00261] train_loss: 0.013478\n",
      "[738/00311] train_loss: 0.012345\n",
      "[738/00361] train_loss: 0.013106\n",
      "[738/00411] train_loss: 0.012629\n",
      "[738/00461] train_loss: 0.012544\n",
      "[738/00511] train_loss: 0.012869\n",
      "[738/00561] train_loss: 0.012224\n",
      "[738/00611] train_loss: 0.011704\n",
      "[738/00661] train_loss: 0.012362\n",
      "[738/00711] train_loss: 0.012473\n",
      "[738/00761] train_loss: 0.011820\n",
      "[738/00811] train_loss: 0.013193\n",
      "[738/00861] train_loss: 0.012505\n",
      "[738/00911] train_loss: 0.012539\n",
      "[738/00961] train_loss: 0.013517\n",
      "[738/01011] train_loss: 0.012147\n",
      "[738/01061] train_loss: 0.012835\n",
      "[738/01111] train_loss: 0.013213\n",
      "[738/01161] train_loss: 0.012429\n",
      "[738/01211] train_loss: 0.013144\n",
      "[739/00035] train_loss: 0.014208\n",
      "[739/00085] train_loss: 0.014681\n",
      "[739/00135] train_loss: 0.013225\n",
      "[739/00185] train_loss: 0.013192\n",
      "[739/00235] train_loss: 0.012914\n",
      "[739/00285] train_loss: 0.013294\n",
      "[739/00335] train_loss: 0.012215\n",
      "[739/00385] train_loss: 0.013013\n",
      "[739/00435] train_loss: 0.013368\n",
      "[739/00485] train_loss: 0.012389\n",
      "[739/00535] train_loss: 0.012514\n",
      "[739/00585] train_loss: 0.012882\n",
      "[739/00635] train_loss: 0.012717\n",
      "[739/00685] train_loss: 0.013013\n",
      "[739/00735] train_loss: 0.012071\n",
      "[739/00785] train_loss: 0.012662\n",
      "[739/00835] train_loss: 0.012261\n",
      "[739/00885] train_loss: 0.013341\n",
      "[739/00935] train_loss: 0.012320\n",
      "[739/00985] train_loss: 0.013059\n",
      "[739/01035] train_loss: 0.012237\n",
      "[739/01085] train_loss: 0.011815\n",
      "[739/01135] train_loss: 0.012194\n",
      "[739/01185] train_loss: 0.012808\n",
      "[740/00009] train_loss: 0.012793\n",
      "[740/00059] train_loss: 0.014940\n",
      "[740/00109] train_loss: 0.013679\n",
      "[740/00159] train_loss: 0.012807\n",
      "[740/00209] train_loss: 0.012719\n",
      "[740/00259] train_loss: 0.013710\n",
      "[740/00309] train_loss: 0.012041\n",
      "[740/00359] train_loss: 0.012779\n",
      "[740/00409] train_loss: 0.013553\n",
      "[740/00459] train_loss: 0.012546\n",
      "[740/00509] train_loss: 0.012934\n",
      "[740/00559] train_loss: 0.012756\n",
      "[740/00609] train_loss: 0.012765\n",
      "[740/00659] train_loss: 0.012368\n",
      "[740/00709] train_loss: 0.012315\n",
      "[740/00759] train_loss: 0.013032\n",
      "[740/00809] train_loss: 0.012669\n",
      "[740/00859] train_loss: 0.012729\n",
      "[740/00909] train_loss: 0.013207\n",
      "[740/00959] train_loss: 0.012451\n",
      "[740/01009] train_loss: 0.012704\n",
      "[740/01059] train_loss: 0.012151\n",
      "[740/01109] train_loss: 0.013132\n",
      "[740/01159] train_loss: 0.012876\n",
      "[740/01209] train_loss: 0.012505\n",
      "[741/00033] train_loss: 0.015391\n",
      "[741/00083] train_loss: 0.014450\n",
      "[741/00133] train_loss: 0.013979\n",
      "[741/00183] train_loss: 0.013935\n",
      "[741/00233] train_loss: 0.013091\n",
      "[741/00283] train_loss: 0.012814\n",
      "[741/00333] train_loss: 0.012870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[741/00383] train_loss: 0.012935\n",
      "[741/00433] train_loss: 0.012178\n",
      "[741/00483] train_loss: 0.012944\n",
      "[741/00533] train_loss: 0.013812\n",
      "[741/00583] train_loss: 0.011889\n",
      "[741/00633] train_loss: 0.012840\n",
      "[741/00683] train_loss: 0.012136\n",
      "[741/00733] train_loss: 0.011967\n",
      "[741/00783] train_loss: 0.012330\n",
      "[741/00833] train_loss: 0.012353\n",
      "[741/00883] train_loss: 0.011486\n",
      "[741/00933] train_loss: 0.013014\n",
      "[741/00983] train_loss: 0.012970\n",
      "[741/01033] train_loss: 0.012604\n",
      "[741/01083] train_loss: 0.012325\n",
      "[741/01133] train_loss: 0.012414\n",
      "[741/01183] train_loss: 0.012473\n",
      "[742/00007] train_loss: 0.012873\n",
      "[742/00057] train_loss: 0.015234\n",
      "[742/00107] train_loss: 0.014870\n",
      "[742/00157] train_loss: 0.013894\n",
      "[742/00207] train_loss: 0.013538\n",
      "[742/00257] train_loss: 0.013344\n",
      "[742/00307] train_loss: 0.012396\n",
      "[742/00357] train_loss: 0.012225\n",
      "[742/00407] train_loss: 0.011988\n",
      "[742/00457] train_loss: 0.012843\n",
      "[742/00507] train_loss: 0.012731\n",
      "[742/00557] train_loss: 0.012425\n",
      "[742/00607] train_loss: 0.012645\n",
      "[742/00657] train_loss: 0.012197\n",
      "[742/00707] train_loss: 0.011978\n",
      "[742/00757] train_loss: 0.012257\n",
      "[742/00807] train_loss: 0.013263\n",
      "[742/00857] train_loss: 0.012146\n",
      "[742/00907] train_loss: 0.012111\n",
      "[742/00957] train_loss: 0.013064\n",
      "[742/01007] train_loss: 0.012693\n",
      "[742/01057] train_loss: 0.012927\n",
      "[742/01107] train_loss: 0.012445\n",
      "[742/01157] train_loss: 0.012193\n",
      "[742/01207] train_loss: 0.012520\n",
      "[743/00031] train_loss: 0.014639\n",
      "[743/00081] train_loss: 0.014555\n",
      "[743/00131] train_loss: 0.014412\n",
      "[743/00181] train_loss: 0.013773\n",
      "[743/00231] train_loss: 0.012437\n",
      "[743/00281] train_loss: 0.012888\n",
      "[743/00331] train_loss: 0.013065\n",
      "[743/00381] train_loss: 0.012437\n",
      "[743/00431] train_loss: 0.012072\n",
      "[743/00481] train_loss: 0.012597\n",
      "[743/00531] train_loss: 0.012726\n",
      "[743/00581] train_loss: 0.013167\n",
      "[743/00631] train_loss: 0.012818\n",
      "[743/00681] train_loss: 0.012269\n",
      "[743/00731] train_loss: 0.012731\n",
      "[743/00781] train_loss: 0.012599\n",
      "[743/00831] train_loss: 0.012041\n",
      "[743/00881] train_loss: 0.012750\n",
      "[743/00931] train_loss: 0.013117\n",
      "[743/00981] train_loss: 0.012665\n",
      "[743/01031] train_loss: 0.012648\n",
      "[743/01081] train_loss: 0.012815\n",
      "[743/01131] train_loss: 0.012139\n",
      "[743/01181] train_loss: 0.013360\n",
      "[744/00005] train_loss: 0.013423\n",
      "[744/00055] train_loss: 0.015260\n",
      "[744/00105] train_loss: 0.014500\n",
      "[744/00155] train_loss: 0.012662\n",
      "[744/00205] train_loss: 0.012935\n",
      "[744/00255] train_loss: 0.012689\n",
      "[744/00305] train_loss: 0.012369\n",
      "[744/00355] train_loss: 0.012335\n",
      "[744/00405] train_loss: 0.011914\n",
      "[744/00455] train_loss: 0.012509\n",
      "[744/00505] train_loss: 0.012806\n",
      "[744/00555] train_loss: 0.013070\n",
      "[744/00605] train_loss: 0.013527\n",
      "[744/00655] train_loss: 0.012180\n",
      "[744/00705] train_loss: 0.012615\n",
      "[744/00755] train_loss: 0.012990\n",
      "[744/00805] train_loss: 0.013639\n",
      "[744/00855] train_loss: 0.012462\n",
      "[744/00905] train_loss: 0.012403\n",
      "[744/00955] train_loss: 0.012822\n",
      "[744/01005] train_loss: 0.012443\n",
      "[744/01055] train_loss: 0.012739\n",
      "[744/01105] train_loss: 0.012749\n",
      "[744/01155] train_loss: 0.012969\n",
      "[744/01205] train_loss: 0.013555\n",
      "[745/00029] train_loss: 0.015072\n",
      "[745/00079] train_loss: 0.014176\n",
      "[745/00129] train_loss: 0.013195\n",
      "[745/00179] train_loss: 0.014053\n",
      "[745/00229] train_loss: 0.012334\n",
      "[745/00279] train_loss: 0.012711\n",
      "[745/00329] train_loss: 0.012464\n",
      "[745/00379] train_loss: 0.012529\n",
      "[745/00429] train_loss: 0.012954\n",
      "[745/00479] train_loss: 0.012523\n",
      "[745/00529] train_loss: 0.012028\n",
      "[745/00579] train_loss: 0.012391\n",
      "[745/00629] train_loss: 0.012703\n",
      "[745/00679] train_loss: 0.012637\n",
      "[745/00729] train_loss: 0.012598\n",
      "[745/00779] train_loss: 0.012462\n",
      "[745/00829] train_loss: 0.012965\n",
      "[745/00879] train_loss: 0.012774\n",
      "[745/00929] train_loss: 0.012674\n",
      "[745/00979] train_loss: 0.013048\n",
      "[745/01029] train_loss: 0.012678\n",
      "[745/01079] train_loss: 0.013094\n",
      "[745/01129] train_loss: 0.012478\n",
      "[745/01179] train_loss: 0.013069\n",
      "[746/00003] train_loss: 0.013123\n",
      "[746/00053] train_loss: 0.015777\n",
      "[746/00103] train_loss: 0.014228\n",
      "[746/00153] train_loss: 0.013348\n",
      "[746/00203] train_loss: 0.013151\n",
      "[746/00253] train_loss: 0.012434\n",
      "[746/00303] train_loss: 0.013176\n",
      "[746/00353] train_loss: 0.012881\n",
      "[746/00403] train_loss: 0.012159\n",
      "[746/00453] train_loss: 0.011566\n",
      "[746/00503] train_loss: 0.012539\n",
      "[746/00553] train_loss: 0.012807\n",
      "[746/00603] train_loss: 0.013043\n",
      "[746/00653] train_loss: 0.012977\n",
      "[746/00703] train_loss: 0.011965\n",
      "[746/00753] train_loss: 0.013395\n",
      "[746/00803] train_loss: 0.012015\n",
      "[746/00853] train_loss: 0.012430\n",
      "[746/00903] train_loss: 0.012716\n",
      "[746/00953] train_loss: 0.012961\n",
      "[746/01003] train_loss: 0.013060\n",
      "[746/01053] train_loss: 0.012574\n",
      "[746/01103] train_loss: 0.012084\n",
      "[746/01153] train_loss: 0.012206\n",
      "[746/01203] train_loss: 0.012111\n",
      "[747/00027] train_loss: 0.013930\n",
      "[747/00077] train_loss: 0.014808\n",
      "[747/00127] train_loss: 0.013718\n",
      "[747/00177] train_loss: 0.012723\n",
      "[747/00227] train_loss: 0.012651\n",
      "[747/00277] train_loss: 0.012295\n",
      "[747/00327] train_loss: 0.013093\n",
      "[747/00377] train_loss: 0.013101\n",
      "[747/00427] train_loss: 0.012775\n",
      "[747/00477] train_loss: 0.012811\n",
      "[747/00527] train_loss: 0.013152\n",
      "[747/00577] train_loss: 0.012364\n",
      "[747/00627] train_loss: 0.013099\n",
      "[747/00677] train_loss: 0.011976\n",
      "[747/00727] train_loss: 0.012998\n",
      "[747/00777] train_loss: 0.012907\n",
      "[747/00827] train_loss: 0.013207\n",
      "[747/00877] train_loss: 0.012334\n",
      "[747/00927] train_loss: 0.013055\n",
      "[747/00977] train_loss: 0.012981\n",
      "[747/01027] train_loss: 0.012260\n",
      "[747/01077] train_loss: 0.013126\n",
      "[747/01127] train_loss: 0.012110\n",
      "[747/01177] train_loss: 0.012928\n",
      "[748/00001] train_loss: 0.012217\n",
      "[748/00051] train_loss: 0.015113\n",
      "[748/00101] train_loss: 0.014293\n",
      "[748/00151] train_loss: 0.013714\n",
      "[748/00201] train_loss: 0.012817\n",
      "[748/00251] train_loss: 0.012628\n",
      "[748/00301] train_loss: 0.012828\n",
      "[748/00351] train_loss: 0.012990\n",
      "[748/00401] train_loss: 0.013262\n",
      "[748/00451] train_loss: 0.012760\n",
      "[748/00501] train_loss: 0.013098\n",
      "[748/00551] train_loss: 0.013596\n",
      "[748/00601] train_loss: 0.012394\n",
      "[748/00651] train_loss: 0.011881\n",
      "[748/00701] train_loss: 0.012814\n",
      "[748/00751] train_loss: 0.011803\n",
      "[748/00801] train_loss: 0.012847\n",
      "[748/00851] train_loss: 0.012550\n",
      "[748/00901] train_loss: 0.012526\n",
      "[748/00951] train_loss: 0.012829\n",
      "[748/01001] train_loss: 0.012523\n",
      "[748/01051] train_loss: 0.012357\n",
      "[748/01101] train_loss: 0.012562\n",
      "[748/01151] train_loss: 0.012936\n",
      "[748/01201] train_loss: 0.012690\n",
      "[749/00025] train_loss: 0.014651\n",
      "[749/00075] train_loss: 0.014056\n",
      "[749/00125] train_loss: 0.013603\n",
      "[749/00175] train_loss: 0.013118\n",
      "[749/00225] train_loss: 0.012548\n",
      "[749/00275] train_loss: 0.012684\n",
      "[749/00325] train_loss: 0.012067\n",
      "[749/00375] train_loss: 0.012957\n",
      "[749/00425] train_loss: 0.013221\n",
      "[749/00475] train_loss: 0.012680\n",
      "[749/00525] train_loss: 0.012793\n",
      "[749/00575] train_loss: 0.012237\n",
      "[749/00625] train_loss: 0.012185\n",
      "[749/00675] train_loss: 0.012516\n",
      "[749/00725] train_loss: 0.012167\n",
      "[749/00775] train_loss: 0.012970\n",
      "[749/00825] train_loss: 0.013339\n",
      "[749/00875] train_loss: 0.012603\n",
      "[749/00925] train_loss: 0.012733\n",
      "[749/00975] train_loss: 0.012500\n",
      "[749/01025] train_loss: 0.013966\n",
      "[749/01075] train_loss: 0.012756\n",
      "[749/01125] train_loss: 0.012276\n",
      "[749/01175] train_loss: 0.012833\n",
      "[749/01225] train_loss: 0.013045\n",
      "[750/00049] train_loss: 0.016031\n",
      "[750/00099] train_loss: 0.013813\n",
      "[750/00149] train_loss: 0.013480\n",
      "[750/00199] train_loss: 0.013589\n",
      "[750/00249] train_loss: 0.011823\n",
      "[750/00299] train_loss: 0.013050\n",
      "[750/00349] train_loss: 0.012506\n",
      "[750/00399] train_loss: 0.012794\n",
      "[750/00449] train_loss: 0.011621\n",
      "[750/00499] train_loss: 0.012231\n",
      "[750/00549] train_loss: 0.012529\n",
      "[750/00599] train_loss: 0.012273\n",
      "[750/00649] train_loss: 0.012627\n",
      "[750/00699] train_loss: 0.012387\n",
      "[750/00749] train_loss: 0.012960\n",
      "[750/00799] train_loss: 0.012618\n",
      "[750/00849] train_loss: 0.012980\n",
      "[750/00899] train_loss: 0.012546\n",
      "[750/00949] train_loss: 0.012459\n",
      "[750/00999] train_loss: 0.012104\n",
      "[750/01049] train_loss: 0.014072\n",
      "[750/01099] train_loss: 0.013051\n",
      "[750/01149] train_loss: 0.013233\n",
      "[750/01199] train_loss: 0.012848\n",
      "[751/00023] train_loss: 0.014407\n",
      "[751/00073] train_loss: 0.015327\n",
      "[751/00123] train_loss: 0.013872\n",
      "[751/00173] train_loss: 0.013671\n",
      "[751/00223] train_loss: 0.013644\n",
      "[751/00273] train_loss: 0.012542\n",
      "[751/00323] train_loss: 0.011990\n",
      "[751/00373] train_loss: 0.013263\n",
      "[751/00423] train_loss: 0.012811\n",
      "[751/00473] train_loss: 0.012529\n",
      "[751/00523] train_loss: 0.012726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[751/00573] train_loss: 0.012342\n",
      "[751/00623] train_loss: 0.013123\n",
      "[751/00673] train_loss: 0.012465\n",
      "[751/00723] train_loss: 0.012196\n",
      "[751/00773] train_loss: 0.011843\n",
      "[751/00823] train_loss: 0.012354\n",
      "[751/00873] train_loss: 0.011948\n",
      "[751/00923] train_loss: 0.012925\n",
      "[751/00973] train_loss: 0.013391\n",
      "[751/01023] train_loss: 0.012798\n",
      "[751/01073] train_loss: 0.012835\n",
      "[751/01123] train_loss: 0.013342\n",
      "[751/01173] train_loss: 0.012563\n",
      "[751/01223] train_loss: 0.012487\n",
      "[752/00047] train_loss: 0.015381\n",
      "[752/00097] train_loss: 0.013799\n",
      "[752/00147] train_loss: 0.013186\n",
      "[752/00197] train_loss: 0.012372\n",
      "[752/00247] train_loss: 0.013096\n",
      "[752/00297] train_loss: 0.012688\n",
      "[752/00347] train_loss: 0.012380\n",
      "[752/00397] train_loss: 0.011887\n",
      "[752/00447] train_loss: 0.012862\n",
      "[752/00497] train_loss: 0.012686\n",
      "[752/00547] train_loss: 0.012915\n",
      "[752/00597] train_loss: 0.012698\n",
      "[752/00647] train_loss: 0.012533\n",
      "[752/00697] train_loss: 0.012621\n",
      "[752/00747] train_loss: 0.012756\n",
      "[752/00797] train_loss: 0.012514\n",
      "[752/00847] train_loss: 0.012861\n",
      "[752/00897] train_loss: 0.013228\n",
      "[752/00947] train_loss: 0.011833\n",
      "[752/00997] train_loss: 0.012832\n",
      "[752/01047] train_loss: 0.012217\n",
      "[752/01097] train_loss: 0.013079\n",
      "[752/01147] train_loss: 0.013371\n",
      "[752/01197] train_loss: 0.012723\n",
      "[753/00021] train_loss: 0.014181\n",
      "[753/00071] train_loss: 0.014604\n",
      "[753/00121] train_loss: 0.013671\n",
      "[753/00171] train_loss: 0.012829\n",
      "[753/00221] train_loss: 0.013500\n",
      "[753/00271] train_loss: 0.012904\n",
      "[753/00321] train_loss: 0.012461\n",
      "[753/00371] train_loss: 0.012722\n",
      "[753/00421] train_loss: 0.014266\n",
      "[753/00471] train_loss: 0.012291\n",
      "[753/00521] train_loss: 0.012982\n",
      "[753/00571] train_loss: 0.012717\n",
      "[753/00621] train_loss: 0.012682\n",
      "[753/00671] train_loss: 0.012899\n",
      "[753/00721] train_loss: 0.012438\n",
      "[753/00771] train_loss: 0.012695\n",
      "[753/00821] train_loss: 0.013215\n",
      "[753/00871] train_loss: 0.012530\n",
      "[753/00921] train_loss: 0.012784\n",
      "[753/00971] train_loss: 0.012537\n",
      "[753/01021] train_loss: 0.011832\n",
      "[753/01071] train_loss: 0.012775\n",
      "[753/01121] train_loss: 0.013112\n",
      "[753/01171] train_loss: 0.013057\n",
      "[753/01221] train_loss: 0.013637\n",
      "[754/00045] train_loss: 0.014938\n",
      "[754/00095] train_loss: 0.014003\n",
      "[754/00145] train_loss: 0.013561\n",
      "[754/00195] train_loss: 0.012960\n",
      "[754/00245] train_loss: 0.013041\n",
      "[754/00295] train_loss: 0.012539\n",
      "[754/00345] train_loss: 0.013205\n",
      "[754/00395] train_loss: 0.012342\n",
      "[754/00445] train_loss: 0.012532\n",
      "[754/00495] train_loss: 0.012719\n",
      "[754/00545] train_loss: 0.012851\n",
      "[754/00595] train_loss: 0.012115\n",
      "[754/00645] train_loss: 0.012631\n",
      "[754/00695] train_loss: 0.012272\n",
      "[754/00745] train_loss: 0.012314\n",
      "[754/00795] train_loss: 0.012435\n",
      "[754/00845] train_loss: 0.013113\n",
      "[754/00895] train_loss: 0.012787\n",
      "[754/00945] train_loss: 0.012940\n",
      "[754/00995] train_loss: 0.011990\n",
      "[754/01045] train_loss: 0.012400\n",
      "[754/01095] train_loss: 0.012054\n",
      "[754/01145] train_loss: 0.013142\n",
      "[754/01195] train_loss: 0.013176\n",
      "[755/00019] train_loss: 0.014620\n",
      "[755/00069] train_loss: 0.014407\n",
      "[755/00119] train_loss: 0.014077\n",
      "[755/00169] train_loss: 0.012760\n",
      "[755/00219] train_loss: 0.012779\n",
      "[755/00269] train_loss: 0.012802\n",
      "[755/00319] train_loss: 0.013112\n",
      "[755/00369] train_loss: 0.012110\n",
      "[755/00419] train_loss: 0.012553\n",
      "[755/00469] train_loss: 0.013268\n",
      "[755/00519] train_loss: 0.012124\n",
      "[755/00569] train_loss: 0.013055\n",
      "[755/00619] train_loss: 0.011981\n",
      "[755/00669] train_loss: 0.011974\n",
      "[755/00719] train_loss: 0.012774\n",
      "[755/00769] train_loss: 0.012790\n",
      "[755/00819] train_loss: 0.012195\n",
      "[755/00869] train_loss: 0.012294\n",
      "[755/00919] train_loss: 0.012550\n",
      "[755/00969] train_loss: 0.012423\n",
      "[755/01019] train_loss: 0.012560\n",
      "[755/01069] train_loss: 0.012662\n",
      "[755/01119] train_loss: 0.013015\n",
      "[755/01169] train_loss: 0.013518\n",
      "[755/01219] train_loss: 0.012855\n",
      "[756/00043] train_loss: 0.015412\n",
      "[756/00093] train_loss: 0.014049\n",
      "[756/00143] train_loss: 0.013525\n",
      "[756/00193] train_loss: 0.012476\n",
      "[756/00243] train_loss: 0.012528\n",
      "[756/00293] train_loss: 0.012509\n",
      "[756/00343] train_loss: 0.012696\n",
      "[756/00393] train_loss: 0.012186\n",
      "[756/00443] train_loss: 0.013024\n",
      "[756/00493] train_loss: 0.012097\n",
      "[756/00543] train_loss: 0.012978\n",
      "[756/00593] train_loss: 0.013455\n",
      "[756/00643] train_loss: 0.012117\n",
      "[756/00693] train_loss: 0.013376\n",
      "[756/00743] train_loss: 0.013039\n",
      "[756/00793] train_loss: 0.012766\n",
      "[756/00843] train_loss: 0.012521\n",
      "[756/00893] train_loss: 0.013370\n",
      "[756/00943] train_loss: 0.012070\n",
      "[756/00993] train_loss: 0.012623\n",
      "[756/01043] train_loss: 0.012370\n",
      "[756/01093] train_loss: 0.013062\n",
      "[756/01143] train_loss: 0.012420\n",
      "[756/01193] train_loss: 0.012736\n",
      "[757/00017] train_loss: 0.014184\n",
      "[757/00067] train_loss: 0.015103\n",
      "[757/00117] train_loss: 0.014856\n",
      "[757/00167] train_loss: 0.013781\n",
      "[757/00217] train_loss: 0.012656\n",
      "[757/00267] train_loss: 0.013339\n",
      "[757/00317] train_loss: 0.012775\n",
      "[757/00367] train_loss: 0.012970\n",
      "[757/00417] train_loss: 0.012832\n",
      "[757/00467] train_loss: 0.013157\n",
      "[757/00517] train_loss: 0.012597\n",
      "[757/00567] train_loss: 0.012422\n",
      "[757/00617] train_loss: 0.012415\n",
      "[757/00667] train_loss: 0.012742\n",
      "[757/00717] train_loss: 0.012119\n",
      "[757/00767] train_loss: 0.012694\n",
      "[757/00817] train_loss: 0.012247\n",
      "[757/00867] train_loss: 0.012259\n",
      "[757/00917] train_loss: 0.012936\n",
      "[757/00967] train_loss: 0.013223\n",
      "[757/01017] train_loss: 0.012113\n",
      "[757/01067] train_loss: 0.012641\n",
      "[757/01117] train_loss: 0.012020\n",
      "[757/01167] train_loss: 0.012298\n",
      "[757/01217] train_loss: 0.012679\n",
      "[758/00041] train_loss: 0.015430\n",
      "[758/00091] train_loss: 0.014294\n",
      "[758/00141] train_loss: 0.013838\n",
      "[758/00191] train_loss: 0.012774\n",
      "[758/00241] train_loss: 0.012614\n",
      "[758/00291] train_loss: 0.013261\n",
      "[758/00341] train_loss: 0.012161\n",
      "[758/00391] train_loss: 0.012188\n",
      "[758/00441] train_loss: 0.012845\n",
      "[758/00491] train_loss: 0.013196\n",
      "[758/00541] train_loss: 0.012455\n",
      "[758/00591] train_loss: 0.012824\n",
      "[758/00641] train_loss: 0.012544\n",
      "[758/00691] train_loss: 0.012603\n",
      "[758/00741] train_loss: 0.011964\n",
      "[758/00791] train_loss: 0.012102\n",
      "[758/00841] train_loss: 0.012529\n",
      "[758/00891] train_loss: 0.012957\n",
      "[758/00941] train_loss: 0.012794\n",
      "[758/00991] train_loss: 0.012730\n",
      "[758/01041] train_loss: 0.013197\n",
      "[758/01091] train_loss: 0.012744\n",
      "[758/01141] train_loss: 0.012049\n",
      "[758/01191] train_loss: 0.013318\n",
      "[759/00015] train_loss: 0.014647\n",
      "[759/00065] train_loss: 0.014617\n",
      "[759/00115] train_loss: 0.013790\n",
      "[759/00165] train_loss: 0.013316\n",
      "[759/00215] train_loss: 0.013268\n",
      "[759/00265] train_loss: 0.013320\n",
      "[759/00315] train_loss: 0.012412\n",
      "[759/00365] train_loss: 0.013044\n",
      "[759/00415] train_loss: 0.012761\n",
      "[759/00465] train_loss: 0.012367\n",
      "[759/00515] train_loss: 0.012484\n",
      "[759/00565] train_loss: 0.012523\n",
      "[759/00615] train_loss: 0.012302\n",
      "[759/00665] train_loss: 0.012553\n",
      "[759/00715] train_loss: 0.013048\n",
      "[759/00765] train_loss: 0.012706\n",
      "[759/00815] train_loss: 0.012364\n",
      "[759/00865] train_loss: 0.012642\n",
      "[759/00915] train_loss: 0.012792\n",
      "[759/00965] train_loss: 0.012344\n",
      "[759/01015] train_loss: 0.012539\n",
      "[759/01065] train_loss: 0.012727\n",
      "[759/01115] train_loss: 0.012877\n",
      "[759/01165] train_loss: 0.012876\n",
      "[759/01215] train_loss: 0.012651\n",
      "[760/00039] train_loss: 0.016220\n",
      "[760/00089] train_loss: 0.014969\n",
      "[760/00139] train_loss: 0.012944\n",
      "[760/00189] train_loss: 0.012520\n",
      "[760/00239] train_loss: 0.013572\n",
      "[760/00289] train_loss: 0.013263\n",
      "[760/00339] train_loss: 0.011820\n",
      "[760/00389] train_loss: 0.013387\n",
      "[760/00439] train_loss: 0.012668\n",
      "[760/00489] train_loss: 0.012331\n",
      "[760/00539] train_loss: 0.011956\n",
      "[760/00589] train_loss: 0.012123\n",
      "[760/00639] train_loss: 0.012118\n",
      "[760/00689] train_loss: 0.013218\n",
      "[760/00739] train_loss: 0.012100\n",
      "[760/00789] train_loss: 0.012150\n",
      "[760/00839] train_loss: 0.011740\n",
      "[760/00889] train_loss: 0.013154\n",
      "[760/00939] train_loss: 0.013229\n",
      "[760/00989] train_loss: 0.011769\n",
      "[760/01039] train_loss: 0.012087\n",
      "[760/01089] train_loss: 0.013147\n",
      "[760/01139] train_loss: 0.012116\n",
      "[760/01189] train_loss: 0.013542\n",
      "[761/00013] train_loss: 0.014113\n",
      "[761/00063] train_loss: 0.015988\n",
      "[761/00113] train_loss: 0.013376\n",
      "[761/00163] train_loss: 0.013184\n",
      "[761/00213] train_loss: 0.012785\n",
      "[761/00263] train_loss: 0.012003\n",
      "[761/00313] train_loss: 0.012133\n",
      "[761/00363] train_loss: 0.012622\n",
      "[761/00413] train_loss: 0.012884\n",
      "[761/00463] train_loss: 0.013126\n",
      "[761/00513] train_loss: 0.012424\n",
      "[761/00563] train_loss: 0.012336\n",
      "[761/00613] train_loss: 0.013048\n",
      "[761/00663] train_loss: 0.012884\n",
      "[761/00713] train_loss: 0.011882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[761/00763] train_loss: 0.012394\n",
      "[761/00813] train_loss: 0.012864\n",
      "[761/00863] train_loss: 0.012328\n",
      "[761/00913] train_loss: 0.012591\n",
      "[761/00963] train_loss: 0.013422\n",
      "[761/01013] train_loss: 0.012291\n",
      "[761/01063] train_loss: 0.012530\n",
      "[761/01113] train_loss: 0.012258\n",
      "[761/01163] train_loss: 0.013118\n",
      "[761/01213] train_loss: 0.012595\n",
      "[762/00037] train_loss: 0.014633\n",
      "[762/00087] train_loss: 0.014291\n",
      "[762/00137] train_loss: 0.014265\n",
      "[762/00187] train_loss: 0.013230\n",
      "[762/00237] train_loss: 0.012898\n",
      "[762/00287] train_loss: 0.012830\n",
      "[762/00337] train_loss: 0.013253\n",
      "[762/00387] train_loss: 0.012344\n",
      "[762/00437] train_loss: 0.012611\n",
      "[762/00487] train_loss: 0.012196\n",
      "[762/00537] train_loss: 0.012284\n",
      "[762/00587] train_loss: 0.012690\n",
      "[762/00637] train_loss: 0.012639\n",
      "[762/00687] train_loss: 0.012752\n",
      "[762/00737] train_loss: 0.013006\n",
      "[762/00787] train_loss: 0.012658\n",
      "[762/00837] train_loss: 0.012492\n",
      "[762/00887] train_loss: 0.012805\n",
      "[762/00937] train_loss: 0.012391\n",
      "[762/00987] train_loss: 0.012761\n",
      "[762/01037] train_loss: 0.011928\n",
      "[762/01087] train_loss: 0.012865\n",
      "[762/01137] train_loss: 0.011920\n",
      "[762/01187] train_loss: 0.012324\n",
      "[763/00011] train_loss: 0.013442\n",
      "[763/00061] train_loss: 0.015043\n",
      "[763/00111] train_loss: 0.014182\n",
      "[763/00161] train_loss: 0.013231\n",
      "[763/00211] train_loss: 0.012589\n",
      "[763/00261] train_loss: 0.012741\n",
      "[763/00311] train_loss: 0.012744\n",
      "[763/00361] train_loss: 0.012222\n",
      "[763/00411] train_loss: 0.012751\n",
      "[763/00461] train_loss: 0.012359\n",
      "[763/00511] train_loss: 0.012957\n",
      "[763/00561] train_loss: 0.012912\n",
      "[763/00611] train_loss: 0.013714\n",
      "[763/00661] train_loss: 0.012983\n",
      "[763/00711] train_loss: 0.013120\n",
      "[763/00761] train_loss: 0.012665\n",
      "[763/00811] train_loss: 0.012960\n",
      "[763/00861] train_loss: 0.012631\n",
      "[763/00911] train_loss: 0.012851\n",
      "[763/00961] train_loss: 0.012648\n",
      "[763/01011] train_loss: 0.012694\n",
      "[763/01061] train_loss: 0.012677\n",
      "[763/01111] train_loss: 0.012321\n",
      "[763/01161] train_loss: 0.012952\n",
      "[763/01211] train_loss: 0.012330\n",
      "[764/00035] train_loss: 0.014785\n",
      "[764/00085] train_loss: 0.014472\n",
      "[764/00135] train_loss: 0.014426\n",
      "[764/00185] train_loss: 0.012528\n",
      "[764/00235] train_loss: 0.012509\n",
      "[764/00285] train_loss: 0.012897\n",
      "[764/00335] train_loss: 0.013158\n",
      "[764/00385] train_loss: 0.012275\n",
      "[764/00435] train_loss: 0.012368\n",
      "[764/00485] train_loss: 0.012477\n",
      "[764/00535] train_loss: 0.011866\n",
      "[764/00585] train_loss: 0.012809\n",
      "[764/00635] train_loss: 0.012224\n",
      "[764/00685] train_loss: 0.013356\n",
      "[764/00735] train_loss: 0.012737\n",
      "[764/00785] train_loss: 0.012262\n",
      "[764/00835] train_loss: 0.013316\n",
      "[764/00885] train_loss: 0.012369\n",
      "[764/00935] train_loss: 0.012240\n",
      "[764/00985] train_loss: 0.012200\n",
      "[764/01035] train_loss: 0.012966\n",
      "[764/01085] train_loss: 0.012329\n",
      "[764/01135] train_loss: 0.012780\n",
      "[764/01185] train_loss: 0.013389\n",
      "[765/00009] train_loss: 0.013532\n",
      "[765/00059] train_loss: 0.014833\n",
      "[765/00109] train_loss: 0.013806\n",
      "[765/00159] train_loss: 0.013092\n",
      "[765/00209] train_loss: 0.012215\n",
      "[765/00259] train_loss: 0.012721\n",
      "[765/00309] train_loss: 0.012440\n",
      "[765/00359] train_loss: 0.012410\n",
      "[765/00409] train_loss: 0.013154\n",
      "[765/00459] train_loss: 0.012726\n",
      "[765/00509] train_loss: 0.012563\n",
      "[765/00559] train_loss: 0.012716\n",
      "[765/00609] train_loss: 0.011268\n",
      "[765/00659] train_loss: 0.012241\n",
      "[765/00709] train_loss: 0.013126\n",
      "[765/00759] train_loss: 0.012284\n",
      "[765/00809] train_loss: 0.013396\n",
      "[765/00859] train_loss: 0.012382\n",
      "[765/00909] train_loss: 0.012522\n",
      "[765/00959] train_loss: 0.012662\n",
      "[765/01009] train_loss: 0.013307\n",
      "[765/01059] train_loss: 0.012529\n",
      "[765/01109] train_loss: 0.012722\n",
      "[765/01159] train_loss: 0.012954\n",
      "[765/01209] train_loss: 0.012847\n",
      "[766/00033] train_loss: 0.015031\n",
      "[766/00083] train_loss: 0.014122\n",
      "[766/00133] train_loss: 0.012747\n",
      "[766/00183] train_loss: 0.013323\n",
      "[766/00233] train_loss: 0.012534\n",
      "[766/00283] train_loss: 0.012958\n",
      "[766/00333] train_loss: 0.011158\n",
      "[766/00383] train_loss: 0.012901\n",
      "[766/00433] train_loss: 0.011848\n",
      "[766/00483] train_loss: 0.013060\n",
      "[766/00533] train_loss: 0.012842\n",
      "[766/00583] train_loss: 0.012996\n",
      "[766/00633] train_loss: 0.012151\n",
      "[766/00683] train_loss: 0.012169\n",
      "[766/00733] train_loss: 0.013289\n",
      "[766/00783] train_loss: 0.012058\n",
      "[766/00833] train_loss: 0.012134\n",
      "[766/00883] train_loss: 0.012868\n",
      "[766/00933] train_loss: 0.012557\n",
      "[766/00983] train_loss: 0.012224\n",
      "[766/01033] train_loss: 0.012148\n",
      "[766/01083] train_loss: 0.013163\n",
      "[766/01133] train_loss: 0.013432\n",
      "[766/01183] train_loss: 0.013090\n",
      "[767/00007] train_loss: 0.013267\n",
      "[767/00057] train_loss: 0.016052\n",
      "[767/00107] train_loss: 0.014565\n",
      "[767/00157] train_loss: 0.013027\n",
      "[767/00207] train_loss: 0.013232\n",
      "[767/00257] train_loss: 0.012307\n",
      "[767/00307] train_loss: 0.013234\n",
      "[767/00357] train_loss: 0.012462\n",
      "[767/00407] train_loss: 0.012166\n",
      "[767/00457] train_loss: 0.013632\n",
      "[767/00507] train_loss: 0.011978\n",
      "[767/00557] train_loss: 0.012634\n",
      "[767/00607] train_loss: 0.012964\n",
      "[767/00657] train_loss: 0.012662\n",
      "[767/00707] train_loss: 0.012526\n",
      "[767/00757] train_loss: 0.012564\n",
      "[767/00807] train_loss: 0.012240\n",
      "[767/00857] train_loss: 0.012723\n",
      "[767/00907] train_loss: 0.012837\n",
      "[767/00957] train_loss: 0.011673\n",
      "[767/01007] train_loss: 0.012942\n",
      "[767/01057] train_loss: 0.012366\n",
      "[767/01107] train_loss: 0.012375\n",
      "[767/01157] train_loss: 0.012202\n",
      "[767/01207] train_loss: 0.012933\n",
      "[768/00031] train_loss: 0.014693\n",
      "[768/00081] train_loss: 0.014755\n",
      "[768/00131] train_loss: 0.013585\n",
      "[768/00181] train_loss: 0.012807\n",
      "[768/00231] train_loss: 0.012587\n",
      "[768/00281] train_loss: 0.013467\n",
      "[768/00331] train_loss: 0.012525\n",
      "[768/00381] train_loss: 0.013036\n",
      "[768/00431] train_loss: 0.012612\n",
      "[768/00481] train_loss: 0.013066\n",
      "[768/00531] train_loss: 0.012766\n",
      "[768/00581] train_loss: 0.011550\n",
      "[768/00631] train_loss: 0.012615\n",
      "[768/00681] train_loss: 0.012765\n",
      "[768/00731] train_loss: 0.012455\n",
      "[768/00781] train_loss: 0.012989\n",
      "[768/00831] train_loss: 0.011889\n",
      "[768/00881] train_loss: 0.012576\n",
      "[768/00931] train_loss: 0.012478\n",
      "[768/00981] train_loss: 0.013971\n",
      "[768/01031] train_loss: 0.012956\n",
      "[768/01081] train_loss: 0.013308\n",
      "[768/01131] train_loss: 0.012317\n",
      "[768/01181] train_loss: 0.012581\n",
      "[769/00005] train_loss: 0.013046\n",
      "[769/00055] train_loss: 0.014642\n",
      "[769/00105] train_loss: 0.013743\n",
      "[769/00155] train_loss: 0.013035\n",
      "[769/00205] train_loss: 0.013238\n",
      "[769/00255] train_loss: 0.012068\n",
      "[769/00305] train_loss: 0.012933\n",
      "[769/00355] train_loss: 0.012938\n",
      "[769/00405] train_loss: 0.013401\n",
      "[769/00455] train_loss: 0.012467\n",
      "[769/00505] train_loss: 0.012847\n",
      "[769/00555] train_loss: 0.012147\n",
      "[769/00605] train_loss: 0.012837\n",
      "[769/00655] train_loss: 0.011962\n",
      "[769/00705] train_loss: 0.012823\n",
      "[769/00755] train_loss: 0.011993\n",
      "[769/00805] train_loss: 0.012007\n",
      "[769/00855] train_loss: 0.012582\n",
      "[769/00905] train_loss: 0.012619\n",
      "[769/00955] train_loss: 0.011779\n",
      "[769/01005] train_loss: 0.013783\n",
      "[769/01055] train_loss: 0.012447\n",
      "[769/01105] train_loss: 0.013257\n",
      "[769/01155] train_loss: 0.012925\n",
      "[769/01205] train_loss: 0.012927\n",
      "[770/00029] train_loss: 0.014474\n",
      "[770/00079] train_loss: 0.014389\n",
      "[770/00129] train_loss: 0.013445\n",
      "[770/00179] train_loss: 0.013111\n",
      "[770/00229] train_loss: 0.012753\n",
      "[770/00279] train_loss: 0.013254\n",
      "[770/00329] train_loss: 0.013036\n",
      "[770/00379] train_loss: 0.011824\n",
      "[770/00429] train_loss: 0.012376\n",
      "[770/00479] train_loss: 0.012452\n",
      "[770/00529] train_loss: 0.012276\n",
      "[770/00579] train_loss: 0.012846\n",
      "[770/00629] train_loss: 0.012862\n",
      "[770/00679] train_loss: 0.012600\n",
      "[770/00729] train_loss: 0.012592\n",
      "[770/00779] train_loss: 0.012925\n",
      "[770/00829] train_loss: 0.013000\n",
      "[770/00879] train_loss: 0.012430\n",
      "[770/00929] train_loss: 0.013327\n",
      "[770/00979] train_loss: 0.011905\n",
      "[770/01029] train_loss: 0.012809\n",
      "[770/01079] train_loss: 0.013114\n",
      "[770/01129] train_loss: 0.013102\n",
      "[770/01179] train_loss: 0.012541\n",
      "[771/00003] train_loss: 0.012486\n",
      "[771/00053] train_loss: 0.014741\n",
      "[771/00103] train_loss: 0.013755\n",
      "[771/00153] train_loss: 0.013007\n",
      "[771/00203] train_loss: 0.013536\n",
      "[771/00253] train_loss: 0.012972\n",
      "[771/00303] train_loss: 0.012777\n",
      "[771/00353] train_loss: 0.012766\n",
      "[771/00403] train_loss: 0.012344\n",
      "[771/00453] train_loss: 0.013501\n",
      "[771/00503] train_loss: 0.012010\n",
      "[771/00553] train_loss: 0.012651\n",
      "[771/00603] train_loss: 0.012989\n",
      "[771/00653] train_loss: 0.012068\n",
      "[771/00703] train_loss: 0.011876\n",
      "[771/00753] train_loss: 0.013022\n",
      "[771/00803] train_loss: 0.012724\n",
      "[771/00853] train_loss: 0.012623\n",
      "[771/00903] train_loss: 0.013141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[771/00953] train_loss: 0.012908\n",
      "[771/01003] train_loss: 0.012543\n",
      "[771/01053] train_loss: 0.011960\n",
      "[771/01103] train_loss: 0.012173\n",
      "[771/01153] train_loss: 0.012644\n",
      "[771/01203] train_loss: 0.013101\n",
      "[772/00027] train_loss: 0.015092\n",
      "[772/00077] train_loss: 0.014090\n",
      "[772/00127] train_loss: 0.014043\n",
      "[772/00177] train_loss: 0.013946\n",
      "[772/00227] train_loss: 0.013051\n",
      "[772/00277] train_loss: 0.012245\n",
      "[772/00327] train_loss: 0.012638\n",
      "[772/00377] train_loss: 0.012590\n",
      "[772/00427] train_loss: 0.012453\n",
      "[772/00477] train_loss: 0.012544\n",
      "[772/00527] train_loss: 0.012991\n",
      "[772/00577] train_loss: 0.012483\n",
      "[772/00627] train_loss: 0.012316\n",
      "[772/00677] train_loss: 0.012120\n",
      "[772/00727] train_loss: 0.011820\n",
      "[772/00777] train_loss: 0.012301\n",
      "[772/00827] train_loss: 0.012551\n",
      "[772/00877] train_loss: 0.012565\n",
      "[772/00927] train_loss: 0.012648\n",
      "[772/00977] train_loss: 0.012402\n",
      "[772/01027] train_loss: 0.011689\n",
      "[772/01077] train_loss: 0.012550\n",
      "[772/01127] train_loss: 0.013224\n",
      "[772/01177] train_loss: 0.013139\n",
      "[773/00001] train_loss: 0.013268\n",
      "[773/00051] train_loss: 0.014525\n",
      "[773/00101] train_loss: 0.014551\n",
      "[773/00151] train_loss: 0.013660\n",
      "[773/00201] train_loss: 0.012925\n",
      "[773/00251] train_loss: 0.013502\n",
      "[773/00301] train_loss: 0.011725\n",
      "[773/00351] train_loss: 0.012447\n",
      "[773/00401] train_loss: 0.012794\n",
      "[773/00451] train_loss: 0.013319\n",
      "[773/00501] train_loss: 0.012394\n",
      "[773/00551] train_loss: 0.012391\n",
      "[773/00601] train_loss: 0.013076\n",
      "[773/00651] train_loss: 0.011702\n",
      "[773/00701] train_loss: 0.012164\n",
      "[773/00751] train_loss: 0.012416\n",
      "[773/00801] train_loss: 0.011532\n",
      "[773/00851] train_loss: 0.012714\n",
      "[773/00901] train_loss: 0.012678\n",
      "[773/00951] train_loss: 0.012225\n",
      "[773/01001] train_loss: 0.013295\n",
      "[773/01051] train_loss: 0.013266\n",
      "[773/01101] train_loss: 0.013556\n",
      "[773/01151] train_loss: 0.012697\n",
      "[773/01201] train_loss: 0.012696\n",
      "[774/00025] train_loss: 0.014295\n",
      "[774/00075] train_loss: 0.014426\n",
      "[774/00125] train_loss: 0.014534\n",
      "[774/00175] train_loss: 0.013014\n",
      "[774/00225] train_loss: 0.012910\n",
      "[774/00275] train_loss: 0.012553\n",
      "[774/00325] train_loss: 0.012517\n",
      "[774/00375] train_loss: 0.012583\n",
      "[774/00425] train_loss: 0.012387\n",
      "[774/00475] train_loss: 0.013482\n",
      "[774/00525] train_loss: 0.012563\n",
      "[774/00575] train_loss: 0.012693\n",
      "[774/00625] train_loss: 0.012230\n",
      "[774/00675] train_loss: 0.012960\n",
      "[774/00725] train_loss: 0.012312\n",
      "[774/00775] train_loss: 0.013056\n",
      "[774/00825] train_loss: 0.012663\n",
      "[774/00875] train_loss: 0.012266\n",
      "[774/00925] train_loss: 0.012418\n",
      "[774/00975] train_loss: 0.013008\n",
      "[774/01025] train_loss: 0.012511\n",
      "[774/01075] train_loss: 0.011836\n",
      "[774/01125] train_loss: 0.012485\n",
      "[774/01175] train_loss: 0.012739\n",
      "[774/01225] train_loss: 0.012823\n",
      "[775/00049] train_loss: 0.015400\n",
      "[775/00099] train_loss: 0.013531\n",
      "[775/00149] train_loss: 0.013631\n",
      "[775/00199] train_loss: 0.012918\n",
      "[775/00249] train_loss: 0.013006\n",
      "[775/00299] train_loss: 0.013532\n",
      "[775/00349] train_loss: 0.011907\n",
      "[775/00399] train_loss: 0.012743\n",
      "[775/00449] train_loss: 0.012185\n",
      "[775/00499] train_loss: 0.012538\n",
      "[775/00549] train_loss: 0.012138\n",
      "[775/00599] train_loss: 0.012546\n",
      "[775/00649] train_loss: 0.011810\n",
      "[775/00699] train_loss: 0.012786\n",
      "[775/00749] train_loss: 0.012810\n",
      "[775/00799] train_loss: 0.012905\n",
      "[775/00849] train_loss: 0.012334\n",
      "[775/00899] train_loss: 0.013438\n",
      "[775/00949] train_loss: 0.011807\n",
      "[775/00999] train_loss: 0.012746\n",
      "[775/01049] train_loss: 0.012374\n",
      "[775/01099] train_loss: 0.012476\n",
      "[775/01149] train_loss: 0.012393\n",
      "[775/01199] train_loss: 0.012825\n",
      "[776/00023] train_loss: 0.014563\n",
      "[776/00073] train_loss: 0.014722\n",
      "[776/00123] train_loss: 0.013378\n",
      "[776/00173] train_loss: 0.012823\n",
      "[776/00223] train_loss: 0.012309\n",
      "[776/00273] train_loss: 0.012504\n",
      "[776/00323] train_loss: 0.011522\n",
      "[776/00373] train_loss: 0.013110\n",
      "[776/00423] train_loss: 0.012817\n",
      "[776/00473] train_loss: 0.012400\n",
      "[776/00523] train_loss: 0.013191\n",
      "[776/00573] train_loss: 0.012687\n",
      "[776/00623] train_loss: 0.012098\n",
      "[776/00673] train_loss: 0.012311\n",
      "[776/00723] train_loss: 0.013120\n",
      "[776/00773] train_loss: 0.012620\n",
      "[776/00823] train_loss: 0.013133\n",
      "[776/00873] train_loss: 0.012586\n",
      "[776/00923] train_loss: 0.012320\n",
      "[776/00973] train_loss: 0.013050\n",
      "[776/01023] train_loss: 0.012372\n",
      "[776/01073] train_loss: 0.012651\n",
      "[776/01123] train_loss: 0.012585\n",
      "[776/01173] train_loss: 0.013828\n",
      "[776/01223] train_loss: 0.012461\n",
      "[777/00047] train_loss: 0.016226\n",
      "[777/00097] train_loss: 0.014126\n",
      "[777/00147] train_loss: 0.012983\n",
      "[777/00197] train_loss: 0.013426\n",
      "[777/00247] train_loss: 0.012846\n",
      "[777/00297] train_loss: 0.013259\n",
      "[777/00347] train_loss: 0.012961\n",
      "[777/00397] train_loss: 0.012728\n",
      "[777/00447] train_loss: 0.012191\n",
      "[777/00497] train_loss: 0.011573\n",
      "[777/00547] train_loss: 0.012422\n",
      "[777/00597] train_loss: 0.011959\n",
      "[777/00647] train_loss: 0.012119\n",
      "[777/00697] train_loss: 0.012077\n",
      "[777/00747] train_loss: 0.013038\n",
      "[777/00797] train_loss: 0.012399\n",
      "[777/00847] train_loss: 0.012156\n",
      "[777/00897] train_loss: 0.012852\n",
      "[777/00947] train_loss: 0.013532\n",
      "[777/00997] train_loss: 0.012479\n",
      "[777/01047] train_loss: 0.012724\n",
      "[777/01097] train_loss: 0.012747\n",
      "[777/01147] train_loss: 0.013396\n",
      "[777/01197] train_loss: 0.012821\n",
      "[778/00021] train_loss: 0.013703\n",
      "[778/00071] train_loss: 0.015578\n",
      "[778/00121] train_loss: 0.014194\n",
      "[778/00171] train_loss: 0.013608\n",
      "[778/00221] train_loss: 0.012864\n",
      "[778/00271] train_loss: 0.013004\n",
      "[778/00321] train_loss: 0.012711\n",
      "[778/00371] train_loss: 0.011945\n",
      "[778/00421] train_loss: 0.012247\n",
      "[778/00471] train_loss: 0.012167\n",
      "[778/00521] train_loss: 0.012376\n",
      "[778/00571] train_loss: 0.012203\n",
      "[778/00621] train_loss: 0.012599\n",
      "[778/00671] train_loss: 0.011805\n",
      "[778/00721] train_loss: 0.012275\n",
      "[778/00771] train_loss: 0.013221\n",
      "[778/00821] train_loss: 0.012675\n",
      "[778/00871] train_loss: 0.012247\n",
      "[778/00921] train_loss: 0.012630\n",
      "[778/00971] train_loss: 0.012418\n",
      "[778/01021] train_loss: 0.012270\n",
      "[778/01071] train_loss: 0.012937\n",
      "[778/01121] train_loss: 0.013238\n",
      "[778/01171] train_loss: 0.012891\n",
      "[778/01221] train_loss: 0.012407\n",
      "[779/00045] train_loss: 0.014891\n",
      "[779/00095] train_loss: 0.014433\n",
      "[779/00145] train_loss: 0.013471\n",
      "[779/00195] train_loss: 0.013671\n",
      "[779/00245] train_loss: 0.012849\n",
      "[779/00295] train_loss: 0.012755\n",
      "[779/00345] train_loss: 0.012976\n",
      "[779/00395] train_loss: 0.013473\n",
      "[779/00445] train_loss: 0.012509\n",
      "[779/00495] train_loss: 0.013471\n",
      "[779/00545] train_loss: 0.012588\n",
      "[779/00595] train_loss: 0.012432\n",
      "[779/00645] train_loss: 0.012285\n",
      "[779/00695] train_loss: 0.013068\n",
      "[779/00745] train_loss: 0.012787\n",
      "[779/00795] train_loss: 0.012235\n",
      "[779/00845] train_loss: 0.012063\n",
      "[779/00895] train_loss: 0.012434\n",
      "[779/00945] train_loss: 0.012931\n",
      "[779/00995] train_loss: 0.012829\n",
      "[779/01045] train_loss: 0.012983\n",
      "[779/01095] train_loss: 0.012392\n",
      "[779/01145] train_loss: 0.012809\n",
      "[779/01195] train_loss: 0.012579\n",
      "[780/00019] train_loss: 0.013988\n",
      "[780/00069] train_loss: 0.015448\n",
      "[780/00119] train_loss: 0.014434\n",
      "[780/00169] train_loss: 0.013493\n",
      "[780/00219] train_loss: 0.011635\n",
      "[780/00269] train_loss: 0.012978\n",
      "[780/00319] train_loss: 0.012771\n",
      "[780/00369] train_loss: 0.012022\n",
      "[780/00419] train_loss: 0.012638\n",
      "[780/00469] train_loss: 0.012225\n",
      "[780/00519] train_loss: 0.012833\n",
      "[780/00569] train_loss: 0.013003\n",
      "[780/00619] train_loss: 0.011901\n",
      "[780/00669] train_loss: 0.011954\n",
      "[780/00719] train_loss: 0.013224\n",
      "[780/00769] train_loss: 0.011939\n",
      "[780/00819] train_loss: 0.012921\n",
      "[780/00869] train_loss: 0.012233\n",
      "[780/00919] train_loss: 0.011859\n",
      "[780/00969] train_loss: 0.012895\n",
      "[780/01019] train_loss: 0.012788\n",
      "[780/01069] train_loss: 0.012403\n",
      "[780/01119] train_loss: 0.012781\n",
      "[780/01169] train_loss: 0.013168\n",
      "[780/01219] train_loss: 0.013530\n",
      "[781/00043] train_loss: 0.014413\n",
      "[781/00093] train_loss: 0.014513\n",
      "[781/00143] train_loss: 0.014785\n",
      "[781/00193] train_loss: 0.012583\n",
      "[781/00243] train_loss: 0.013137\n",
      "[781/00293] train_loss: 0.011791\n",
      "[781/00343] train_loss: 0.012758\n",
      "[781/00393] train_loss: 0.013025\n",
      "[781/00443] train_loss: 0.012335\n",
      "[781/00493] train_loss: 0.012242\n",
      "[781/00543] train_loss: 0.012999\n",
      "[781/00593] train_loss: 0.011978\n",
      "[781/00643] train_loss: 0.012403\n",
      "[781/00693] train_loss: 0.011987\n",
      "[781/00743] train_loss: 0.012084\n",
      "[781/00793] train_loss: 0.013139\n",
      "[781/00843] train_loss: 0.012733\n",
      "[781/00893] train_loss: 0.012466\n",
      "[781/00943] train_loss: 0.013453\n",
      "[781/00993] train_loss: 0.013313\n",
      "[781/01043] train_loss: 0.011852\n",
      "[781/01093] train_loss: 0.013139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[781/01143] train_loss: 0.012888\n",
      "[781/01193] train_loss: 0.012881\n",
      "[782/00017] train_loss: 0.013795\n",
      "[782/00067] train_loss: 0.014829\n",
      "[782/00117] train_loss: 0.013624\n",
      "[782/00167] train_loss: 0.012328\n",
      "[782/00217] train_loss: 0.012271\n",
      "[782/00267] train_loss: 0.012918\n",
      "[782/00317] train_loss: 0.013130\n",
      "[782/00367] train_loss: 0.012411\n",
      "[782/00417] train_loss: 0.012749\n",
      "[782/00467] train_loss: 0.012743\n",
      "[782/00517] train_loss: 0.013623\n",
      "[782/00567] train_loss: 0.012867\n",
      "[782/00617] train_loss: 0.012015\n",
      "[782/00667] train_loss: 0.012891\n",
      "[782/00717] train_loss: 0.012400\n",
      "[782/00767] train_loss: 0.011992\n",
      "[782/00817] train_loss: 0.012606\n",
      "[782/00867] train_loss: 0.012663\n",
      "[782/00917] train_loss: 0.013063\n",
      "[782/00967] train_loss: 0.012798\n",
      "[782/01017] train_loss: 0.013062\n",
      "[782/01067] train_loss: 0.012592\n",
      "[782/01117] train_loss: 0.012414\n",
      "[782/01167] train_loss: 0.013441\n",
      "[782/01217] train_loss: 0.012948\n",
      "[783/00041] train_loss: 0.015855\n",
      "[783/00091] train_loss: 0.014494\n",
      "[783/00141] train_loss: 0.013639\n",
      "[783/00191] train_loss: 0.012829\n",
      "[783/00241] train_loss: 0.012021\n",
      "[783/00291] train_loss: 0.013347\n",
      "[783/00341] train_loss: 0.012692\n",
      "[783/00391] train_loss: 0.012657\n",
      "[783/00441] train_loss: 0.012770\n",
      "[783/00491] train_loss: 0.012319\n",
      "[783/00541] train_loss: 0.012626\n",
      "[783/00591] train_loss: 0.012343\n",
      "[783/00641] train_loss: 0.012572\n",
      "[783/00691] train_loss: 0.012363\n",
      "[783/00741] train_loss: 0.012056\n",
      "[783/00791] train_loss: 0.012721\n",
      "[783/00841] train_loss: 0.012225\n",
      "[783/00891] train_loss: 0.012472\n",
      "[783/00941] train_loss: 0.012952\n",
      "[783/00991] train_loss: 0.012367\n",
      "[783/01041] train_loss: 0.013177\n",
      "[783/01091] train_loss: 0.012814\n",
      "[783/01141] train_loss: 0.013014\n",
      "[783/01191] train_loss: 0.012539\n",
      "[784/00015] train_loss: 0.013263\n",
      "[784/00065] train_loss: 0.014570\n",
      "[784/00115] train_loss: 0.014269\n",
      "[784/00165] train_loss: 0.013415\n",
      "[784/00215] train_loss: 0.012858\n",
      "[784/00265] train_loss: 0.013033\n",
      "[784/00315] train_loss: 0.012985\n",
      "[784/00365] train_loss: 0.013260\n",
      "[784/00415] train_loss: 0.012307\n",
      "[784/00465] train_loss: 0.013331\n",
      "[784/00515] train_loss: 0.011744\n",
      "[784/00565] train_loss: 0.012635\n",
      "[784/00615] train_loss: 0.012321\n",
      "[784/00665] train_loss: 0.011898\n",
      "[784/00715] train_loss: 0.012895\n",
      "[784/00765] train_loss: 0.012242\n",
      "[784/00815] train_loss: 0.012068\n",
      "[784/00865] train_loss: 0.012456\n",
      "[784/00915] train_loss: 0.012376\n",
      "[784/00965] train_loss: 0.012826\n",
      "[784/01015] train_loss: 0.012125\n",
      "[784/01065] train_loss: 0.012440\n",
      "[784/01115] train_loss: 0.012393\n",
      "[784/01165] train_loss: 0.013198\n",
      "[784/01215] train_loss: 0.012972\n",
      "[785/00039] train_loss: 0.014073\n",
      "[785/00089] train_loss: 0.014640\n",
      "[785/00139] train_loss: 0.013847\n",
      "[785/00189] train_loss: 0.012820\n",
      "[785/00239] train_loss: 0.012972\n",
      "[785/00289] train_loss: 0.013431\n",
      "[785/00339] train_loss: 0.012819\n",
      "[785/00389] train_loss: 0.012462\n",
      "[785/00439] train_loss: 0.012889\n",
      "[785/00489] train_loss: 0.012778\n",
      "[785/00539] train_loss: 0.012886\n",
      "[785/00589] train_loss: 0.013325\n",
      "[785/00639] train_loss: 0.012656\n",
      "[785/00689] train_loss: 0.012004\n",
      "[785/00739] train_loss: 0.013657\n",
      "[785/00789] train_loss: 0.012879\n",
      "[785/00839] train_loss: 0.012696\n",
      "[785/00889] train_loss: 0.012377\n",
      "[785/00939] train_loss: 0.012276\n",
      "[785/00989] train_loss: 0.012517\n",
      "[785/01039] train_loss: 0.012391\n",
      "[785/01089] train_loss: 0.012466\n",
      "[785/01139] train_loss: 0.013113\n",
      "[785/01189] train_loss: 0.011802\n",
      "[786/00013] train_loss: 0.013510\n",
      "[786/00063] train_loss: 0.014811\n",
      "[786/00113] train_loss: 0.013772\n",
      "[786/00163] train_loss: 0.013820\n",
      "[786/00213] train_loss: 0.013728\n",
      "[786/00263] train_loss: 0.012461\n",
      "[786/00313] train_loss: 0.012893\n",
      "[786/00363] train_loss: 0.012844\n",
      "[786/00413] train_loss: 0.012749\n",
      "[786/00463] train_loss: 0.012868\n",
      "[786/00513] train_loss: 0.012029\n",
      "[786/00563] train_loss: 0.012921\n",
      "[786/00613] train_loss: 0.011442\n",
      "[786/00663] train_loss: 0.011605\n",
      "[786/00713] train_loss: 0.012310\n",
      "[786/00763] train_loss: 0.012302\n",
      "[786/00813] train_loss: 0.012874\n",
      "[786/00863] train_loss: 0.013404\n",
      "[786/00913] train_loss: 0.012378\n",
      "[786/00963] train_loss: 0.012092\n",
      "[786/01013] train_loss: 0.011904\n",
      "[786/01063] train_loss: 0.013034\n",
      "[786/01113] train_loss: 0.012961\n",
      "[786/01163] train_loss: 0.013178\n",
      "[786/01213] train_loss: 0.013010\n",
      "[787/00037] train_loss: 0.015666\n",
      "[787/00087] train_loss: 0.014056\n",
      "[787/00137] train_loss: 0.013006\n",
      "[787/00187] train_loss: 0.012445\n",
      "[787/00237] train_loss: 0.012546\n",
      "[787/00287] train_loss: 0.012900\n",
      "[787/00337] train_loss: 0.012639\n",
      "[787/00387] train_loss: 0.012298\n",
      "[787/00437] train_loss: 0.012657\n",
      "[787/00487] train_loss: 0.012150\n",
      "[787/00537] train_loss: 0.012316\n",
      "[787/00587] train_loss: 0.013047\n",
      "[787/00637] train_loss: 0.012203\n",
      "[787/00687] train_loss: 0.012274\n",
      "[787/00737] train_loss: 0.012471\n",
      "[787/00787] train_loss: 0.012622\n",
      "[787/00837] train_loss: 0.012117\n",
      "[787/00887] train_loss: 0.012639\n",
      "[787/00937] train_loss: 0.013080\n",
      "[787/00987] train_loss: 0.012773\n",
      "[787/01037] train_loss: 0.013087\n",
      "[787/01087] train_loss: 0.012778\n",
      "[787/01137] train_loss: 0.012593\n",
      "[787/01187] train_loss: 0.013335\n",
      "[788/00011] train_loss: 0.012697\n",
      "[788/00061] train_loss: 0.014268\n",
      "[788/00111] train_loss: 0.013524\n",
      "[788/00161] train_loss: 0.013649\n",
      "[788/00211] train_loss: 0.013381\n",
      "[788/00261] train_loss: 0.012865\n",
      "[788/00311] train_loss: 0.012167\n",
      "[788/00361] train_loss: 0.013397\n",
      "[788/00411] train_loss: 0.012216\n",
      "[788/00461] train_loss: 0.012492\n",
      "[788/00511] train_loss: 0.011978\n",
      "[788/00561] train_loss: 0.011761\n",
      "[788/00611] train_loss: 0.012512\n",
      "[788/00661] train_loss: 0.012617\n",
      "[788/00711] train_loss: 0.012091\n",
      "[788/00761] train_loss: 0.013432\n",
      "[788/00811] train_loss: 0.012293\n",
      "[788/00861] train_loss: 0.013040\n",
      "[788/00911] train_loss: 0.013133\n",
      "[788/00961] train_loss: 0.012622\n",
      "[788/01011] train_loss: 0.013066\n",
      "[788/01061] train_loss: 0.012435\n",
      "[788/01111] train_loss: 0.013239\n",
      "[788/01161] train_loss: 0.013240\n",
      "[788/01211] train_loss: 0.012383\n",
      "[789/00035] train_loss: 0.015157\n",
      "[789/00085] train_loss: 0.014129\n",
      "[789/00135] train_loss: 0.013392\n",
      "[789/00185] train_loss: 0.012967\n",
      "[789/00235] train_loss: 0.013022\n",
      "[789/00285] train_loss: 0.013052\n",
      "[789/00335] train_loss: 0.012601\n",
      "[789/00385] train_loss: 0.012825\n",
      "[789/00435] train_loss: 0.012532\n",
      "[789/00485] train_loss: 0.012962\n",
      "[789/00535] train_loss: 0.012804\n",
      "[789/00585] train_loss: 0.012568\n",
      "[789/00635] train_loss: 0.012597\n",
      "[789/00685] train_loss: 0.011771\n",
      "[789/00735] train_loss: 0.012958\n",
      "[789/00785] train_loss: 0.012497\n",
      "[789/00835] train_loss: 0.012734\n",
      "[789/00885] train_loss: 0.012331\n",
      "[789/00935] train_loss: 0.012623\n",
      "[789/00985] train_loss: 0.012540\n",
      "[789/01035] train_loss: 0.012807\n",
      "[789/01085] train_loss: 0.012759\n",
      "[789/01135] train_loss: 0.012468\n",
      "[789/01185] train_loss: 0.013124\n",
      "[790/00009] train_loss: 0.013986\n",
      "[790/00059] train_loss: 0.015410\n",
      "[790/00109] train_loss: 0.013672\n",
      "[790/00159] train_loss: 0.012648\n",
      "[790/00209] train_loss: 0.012917\n",
      "[790/00259] train_loss: 0.012454\n",
      "[790/00309] train_loss: 0.011970\n",
      "[790/00359] train_loss: 0.012519\n",
      "[790/00409] train_loss: 0.012596\n",
      "[790/00459] train_loss: 0.012687\n",
      "[790/00509] train_loss: 0.012375\n",
      "[790/00559] train_loss: 0.012334\n",
      "[790/00609] train_loss: 0.012830\n",
      "[790/00659] train_loss: 0.012421\n",
      "[790/00709] train_loss: 0.012875\n",
      "[790/00759] train_loss: 0.013105\n",
      "[790/00809] train_loss: 0.012733\n",
      "[790/00859] train_loss: 0.012242\n",
      "[790/00909] train_loss: 0.012302\n",
      "[790/00959] train_loss: 0.012471\n",
      "[790/01009] train_loss: 0.013269\n",
      "[790/01059] train_loss: 0.013177\n",
      "[790/01109] train_loss: 0.012596\n",
      "[790/01159] train_loss: 0.013225\n",
      "[790/01209] train_loss: 0.012911\n",
      "[791/00033] train_loss: 0.014806\n",
      "[791/00083] train_loss: 0.014038\n",
      "[791/00133] train_loss: 0.014035\n",
      "[791/00183] train_loss: 0.012864\n",
      "[791/00233] train_loss: 0.012912\n",
      "[791/00283] train_loss: 0.012965\n",
      "[791/00333] train_loss: 0.012438\n",
      "[791/00383] train_loss: 0.012496\n",
      "[791/00433] train_loss: 0.012864\n",
      "[791/00483] train_loss: 0.011996\n",
      "[791/00533] train_loss: 0.012132\n",
      "[791/00583] train_loss: 0.012472\n",
      "[791/00633] train_loss: 0.013190\n",
      "[791/00683] train_loss: 0.012571\n",
      "[791/00733] train_loss: 0.013521\n",
      "[791/00783] train_loss: 0.012442\n",
      "[791/00833] train_loss: 0.012986\n",
      "[791/00883] train_loss: 0.012312\n",
      "[791/00933] train_loss: 0.012076\n",
      "[791/00983] train_loss: 0.013086\n",
      "[791/01033] train_loss: 0.012356\n",
      "[791/01083] train_loss: 0.012161\n",
      "[791/01133] train_loss: 0.012719\n",
      "[791/01183] train_loss: 0.012915\n",
      "[792/00007] train_loss: 0.013401\n",
      "[792/00057] train_loss: 0.015508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[792/00107] train_loss: 0.013569\n",
      "[792/00157] train_loss: 0.012579\n",
      "[792/00207] train_loss: 0.012986\n",
      "[792/00257] train_loss: 0.012696\n",
      "[792/00307] train_loss: 0.012736\n",
      "[792/00357] train_loss: 0.012227\n",
      "[792/00407] train_loss: 0.012761\n",
      "[792/00457] train_loss: 0.012837\n",
      "[792/00507] train_loss: 0.012999\n",
      "[792/00557] train_loss: 0.012544\n",
      "[792/00607] train_loss: 0.012222\n",
      "[792/00657] train_loss: 0.012893\n",
      "[792/00707] train_loss: 0.012059\n",
      "[792/00757] train_loss: 0.012240\n",
      "[792/00807] train_loss: 0.012754\n",
      "[792/00857] train_loss: 0.012734\n",
      "[792/00907] train_loss: 0.012591\n",
      "[792/00957] train_loss: 0.012538\n",
      "[792/01007] train_loss: 0.012862\n",
      "[792/01057] train_loss: 0.012453\n",
      "[792/01107] train_loss: 0.012227\n",
      "[792/01157] train_loss: 0.012102\n",
      "[792/01207] train_loss: 0.013018\n",
      "[793/00031] train_loss: 0.016378\n",
      "[793/00081] train_loss: 0.014354\n",
      "[793/00131] train_loss: 0.013643\n",
      "[793/00181] train_loss: 0.013543\n",
      "[793/00231] train_loss: 0.012265\n",
      "[793/00281] train_loss: 0.013384\n",
      "[793/00331] train_loss: 0.012084\n",
      "[793/00381] train_loss: 0.013097\n",
      "[793/00431] train_loss: 0.012695\n",
      "[793/00481] train_loss: 0.012547\n",
      "[793/00531] train_loss: 0.012217\n",
      "[793/00581] train_loss: 0.012197\n",
      "[793/00631] train_loss: 0.012454\n",
      "[793/00681] train_loss: 0.012436\n",
      "[793/00731] train_loss: 0.012930\n",
      "[793/00781] train_loss: 0.011915\n",
      "[793/00831] train_loss: 0.013086\n",
      "[793/00881] train_loss: 0.012110\n",
      "[793/00931] train_loss: 0.012693\n",
      "[793/00981] train_loss: 0.013586\n",
      "[793/01031] train_loss: 0.012223\n",
      "[793/01081] train_loss: 0.012864\n",
      "[793/01131] train_loss: 0.012257\n",
      "[793/01181] train_loss: 0.012437\n",
      "[794/00005] train_loss: 0.012988\n",
      "[794/00055] train_loss: 0.014753\n",
      "[794/00105] train_loss: 0.013637\n",
      "[794/00155] train_loss: 0.013751\n",
      "[794/00205] train_loss: 0.012996\n",
      "[794/00255] train_loss: 0.013404\n",
      "[794/00305] train_loss: 0.012964\n",
      "[794/00355] train_loss: 0.013009\n",
      "[794/00405] train_loss: 0.012654\n",
      "[794/00455] train_loss: 0.012061\n",
      "[794/00505] train_loss: 0.012679\n",
      "[794/00555] train_loss: 0.012866\n",
      "[794/00605] train_loss: 0.012307\n",
      "[794/00655] train_loss: 0.011681\n",
      "[794/00705] train_loss: 0.012102\n",
      "[794/00755] train_loss: 0.013074\n",
      "[794/00805] train_loss: 0.012985\n",
      "[794/00855] train_loss: 0.012842\n",
      "[794/00905] train_loss: 0.011188\n",
      "[794/00955] train_loss: 0.012651\n",
      "[794/01005] train_loss: 0.012813\n",
      "[794/01055] train_loss: 0.012531\n",
      "[794/01105] train_loss: 0.013722\n",
      "[794/01155] train_loss: 0.012776\n",
      "[794/01205] train_loss: 0.013215\n",
      "[795/00029] train_loss: 0.014415\n",
      "[795/00079] train_loss: 0.015196\n",
      "[795/00129] train_loss: 0.012845\n",
      "[795/00179] train_loss: 0.013304\n",
      "[795/00229] train_loss: 0.013362\n",
      "[795/00279] train_loss: 0.012554\n",
      "[795/00329] train_loss: 0.012219\n",
      "[795/00379] train_loss: 0.012573\n",
      "[795/00429] train_loss: 0.012997\n",
      "[795/00479] train_loss: 0.012050\n",
      "[795/00529] train_loss: 0.012745\n",
      "[795/00579] train_loss: 0.012627\n",
      "[795/00629] train_loss: 0.012814\n",
      "[795/00679] train_loss: 0.012184\n",
      "[795/00729] train_loss: 0.012264\n",
      "[795/00779] train_loss: 0.012793\n",
      "[795/00829] train_loss: 0.012223\n",
      "[795/00879] train_loss: 0.012056\n",
      "[795/00929] train_loss: 0.012084\n",
      "[795/00979] train_loss: 0.012498\n",
      "[795/01029] train_loss: 0.012595\n",
      "[795/01079] train_loss: 0.013259\n",
      "[795/01129] train_loss: 0.012375\n",
      "[795/01179] train_loss: 0.011769\n",
      "[796/00003] train_loss: 0.013066\n",
      "[796/00053] train_loss: 0.015858\n",
      "[796/00103] train_loss: 0.014734\n",
      "[796/00153] train_loss: 0.012528\n",
      "[796/00203] train_loss: 0.013011\n",
      "[796/00253] train_loss: 0.012409\n",
      "[796/00303] train_loss: 0.012651\n",
      "[796/00353] train_loss: 0.013429\n",
      "[796/00403] train_loss: 0.013205\n",
      "[796/00453] train_loss: 0.013440\n",
      "[796/00503] train_loss: 0.012801\n",
      "[796/00553] train_loss: 0.012205\n",
      "[796/00603] train_loss: 0.012268\n",
      "[796/00653] train_loss: 0.012598\n",
      "[796/00703] train_loss: 0.012902\n",
      "[796/00753] train_loss: 0.012967\n",
      "[796/00803] train_loss: 0.012967\n",
      "[796/00853] train_loss: 0.012423\n",
      "[796/00903] train_loss: 0.012097\n",
      "[796/00953] train_loss: 0.012348\n",
      "[796/01003] train_loss: 0.012830\n",
      "[796/01053] train_loss: 0.013513\n",
      "[796/01103] train_loss: 0.012588\n",
      "[796/01153] train_loss: 0.012757\n",
      "[796/01203] train_loss: 0.011632\n",
      "[797/00027] train_loss: 0.013696\n",
      "[797/00077] train_loss: 0.014823\n",
      "[797/00127] train_loss: 0.013402\n",
      "[797/00177] train_loss: 0.013294\n",
      "[797/00227] train_loss: 0.013028\n",
      "[797/00277] train_loss: 0.011981\n",
      "[797/00327] train_loss: 0.012726\n",
      "[797/00377] train_loss: 0.012500\n",
      "[797/00427] train_loss: 0.012425\n",
      "[797/00477] train_loss: 0.013133\n",
      "[797/00527] train_loss: 0.013292\n",
      "[797/00577] train_loss: 0.012230\n",
      "[797/00627] train_loss: 0.013490\n",
      "[797/00677] train_loss: 0.012839\n",
      "[797/00727] train_loss: 0.012535\n",
      "[797/00777] train_loss: 0.012389\n",
      "[797/00827] train_loss: 0.012612\n",
      "[797/00877] train_loss: 0.012949\n",
      "[797/00927] train_loss: 0.012628\n",
      "[797/00977] train_loss: 0.012693\n",
      "[797/01027] train_loss: 0.012524\n",
      "[797/01077] train_loss: 0.012384\n",
      "[797/01127] train_loss: 0.012938\n",
      "[797/01177] train_loss: 0.012524\n",
      "[798/00001] train_loss: 0.012199\n",
      "[798/00051] train_loss: 0.015819\n",
      "[798/00101] train_loss: 0.014080\n",
      "[798/00151] train_loss: 0.012937\n",
      "[798/00201] train_loss: 0.012272\n",
      "[798/00251] train_loss: 0.012186\n",
      "[798/00301] train_loss: 0.013073\n",
      "[798/00351] train_loss: 0.012704\n",
      "[798/00401] train_loss: 0.012507\n",
      "[798/00451] train_loss: 0.013139\n",
      "[798/00501] train_loss: 0.011980\n",
      "[798/00551] train_loss: 0.012210\n",
      "[798/00601] train_loss: 0.012056\n",
      "[798/00651] train_loss: 0.013281\n",
      "[798/00701] train_loss: 0.012203\n",
      "[798/00751] train_loss: 0.012274\n",
      "[798/00801] train_loss: 0.012552\n",
      "[798/00851] train_loss: 0.012780\n",
      "[798/00901] train_loss: 0.013600\n",
      "[798/00951] train_loss: 0.012563\n",
      "[798/01001] train_loss: 0.012899\n",
      "[798/01051] train_loss: 0.012441\n",
      "[798/01101] train_loss: 0.012386\n",
      "[798/01151] train_loss: 0.012464\n",
      "[798/01201] train_loss: 0.013542\n",
      "[799/00025] train_loss: 0.014153\n",
      "[799/00075] train_loss: 0.014161\n",
      "[799/00125] train_loss: 0.013921\n",
      "[799/00175] train_loss: 0.013045\n",
      "[799/00225] train_loss: 0.014004\n",
      "[799/00275] train_loss: 0.012622\n",
      "[799/00325] train_loss: 0.012501\n",
      "[799/00375] train_loss: 0.013025\n",
      "[799/00425] train_loss: 0.012715\n",
      "[799/00475] train_loss: 0.012597\n",
      "[799/00525] train_loss: 0.012312\n",
      "[799/00575] train_loss: 0.012492\n",
      "[799/00625] train_loss: 0.012319\n",
      "[799/00675] train_loss: 0.011775\n",
      "[799/00725] train_loss: 0.011874\n",
      "[799/00775] train_loss: 0.012163\n",
      "[799/00825] train_loss: 0.012247\n",
      "[799/00875] train_loss: 0.012865\n",
      "[799/00925] train_loss: 0.012554\n",
      "[799/00975] train_loss: 0.012738\n",
      "[799/01025] train_loss: 0.012269\n",
      "[799/01075] train_loss: 0.012572\n",
      "[799/01125] train_loss: 0.013274\n",
      "[799/01175] train_loss: 0.012858\n",
      "[799/01225] train_loss: 0.012772\n",
      "[800/00049] train_loss: 0.015952\n",
      "[800/00099] train_loss: 0.014182\n",
      "[800/00149] train_loss: 0.013486\n",
      "[800/00199] train_loss: 0.012507\n",
      "[800/00249] train_loss: 0.013163\n",
      "[800/00299] train_loss: 0.013150\n",
      "[800/00349] train_loss: 0.013056\n",
      "[800/00399] train_loss: 0.012834\n",
      "[800/00449] train_loss: 0.012623\n",
      "[800/00499] train_loss: 0.012245\n",
      "[800/00549] train_loss: 0.011804\n",
      "[800/00599] train_loss: 0.012546\n",
      "[800/00649] train_loss: 0.012067\n",
      "[800/00699] train_loss: 0.012653\n",
      "[800/00749] train_loss: 0.012950\n",
      "[800/00799] train_loss: 0.012632\n",
      "[800/00849] train_loss: 0.011762\n",
      "[800/00899] train_loss: 0.012704\n",
      "[800/00949] train_loss: 0.011870\n",
      "[800/00999] train_loss: 0.012922\n",
      "[800/01049] train_loss: 0.012529\n",
      "[800/01099] train_loss: 0.012055\n",
      "[800/01149] train_loss: 0.012921\n",
      "[800/01199] train_loss: 0.013117\n",
      "[801/00023] train_loss: 0.014651\n",
      "[801/00073] train_loss: 0.015152\n",
      "[801/00123] train_loss: 0.013769\n",
      "[801/00173] train_loss: 0.012662\n",
      "[801/00223] train_loss: 0.012115\n",
      "[801/00273] train_loss: 0.012796\n",
      "[801/00323] train_loss: 0.012407\n",
      "[801/00373] train_loss: 0.012726\n",
      "[801/00423] train_loss: 0.013032\n",
      "[801/00473] train_loss: 0.012527\n",
      "[801/00523] train_loss: 0.012328\n",
      "[801/00573] train_loss: 0.012771\n",
      "[801/00623] train_loss: 0.012742\n",
      "[801/00673] train_loss: 0.012432\n",
      "[801/00723] train_loss: 0.012831\n",
      "[801/00773] train_loss: 0.012295\n",
      "[801/00823] train_loss: 0.012726\n",
      "[801/00873] train_loss: 0.012890\n",
      "[801/00923] train_loss: 0.012337\n",
      "[801/00973] train_loss: 0.013532\n",
      "[801/01023] train_loss: 0.012027\n",
      "[801/01073] train_loss: 0.012786\n",
      "[801/01123] train_loss: 0.014097\n",
      "[801/01173] train_loss: 0.012804\n",
      "[801/01223] train_loss: 0.012578\n",
      "[802/00047] train_loss: 0.015285\n",
      "[802/00097] train_loss: 0.013635\n",
      "[802/00147] train_loss: 0.013032\n",
      "[802/00197] train_loss: 0.012964\n",
      "[802/00247] train_loss: 0.013011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[802/00297] train_loss: 0.012342\n",
      "[802/00347] train_loss: 0.013584\n",
      "[802/00397] train_loss: 0.012758\n",
      "[802/00447] train_loss: 0.012988\n",
      "[802/00497] train_loss: 0.012950\n",
      "[802/00547] train_loss: 0.012078\n",
      "[802/00597] train_loss: 0.011964\n",
      "[802/00647] train_loss: 0.012134\n",
      "[802/00697] train_loss: 0.012372\n",
      "[802/00747] train_loss: 0.012920\n",
      "[802/00797] train_loss: 0.013161\n",
      "[802/00847] train_loss: 0.012068\n",
      "[802/00897] train_loss: 0.012598\n",
      "[802/00947] train_loss: 0.012658\n",
      "[802/00997] train_loss: 0.012614\n",
      "[802/01047] train_loss: 0.012724\n",
      "[802/01097] train_loss: 0.014271\n",
      "[802/01147] train_loss: 0.012609\n",
      "[802/01197] train_loss: 0.011843\n",
      "[803/00021] train_loss: 0.014612\n",
      "[803/00071] train_loss: 0.015004\n",
      "[803/00121] train_loss: 0.013515\n",
      "[803/00171] train_loss: 0.012504\n",
      "[803/00221] train_loss: 0.012912\n",
      "[803/00271] train_loss: 0.013107\n",
      "[803/00321] train_loss: 0.011903\n",
      "[803/00371] train_loss: 0.012225\n",
      "[803/00421] train_loss: 0.012912\n",
      "[803/00471] train_loss: 0.012835\n",
      "[803/00521] train_loss: 0.012506\n",
      "[803/00571] train_loss: 0.012530\n",
      "[803/00621] train_loss: 0.012760\n",
      "[803/00671] train_loss: 0.012443\n",
      "[803/00721] train_loss: 0.012748\n",
      "[803/00771] train_loss: 0.013288\n",
      "[803/00821] train_loss: 0.012831\n",
      "[803/00871] train_loss: 0.012937\n",
      "[803/00921] train_loss: 0.012403\n",
      "[803/00971] train_loss: 0.012763\n",
      "[803/01021] train_loss: 0.012070\n",
      "[803/01071] train_loss: 0.012388\n",
      "[803/01121] train_loss: 0.012323\n",
      "[803/01171] train_loss: 0.012699\n",
      "[803/01221] train_loss: 0.013087\n",
      "[804/00045] train_loss: 0.015241\n",
      "[804/00095] train_loss: 0.013685\n",
      "[804/00145] train_loss: 0.013618\n",
      "[804/00195] train_loss: 0.013333\n",
      "[804/00245] train_loss: 0.013064\n",
      "[804/00295] train_loss: 0.012167\n",
      "[804/00345] train_loss: 0.012310\n",
      "[804/00395] train_loss: 0.012669\n",
      "[804/00445] train_loss: 0.012164\n",
      "[804/00495] train_loss: 0.012376\n",
      "[804/00545] train_loss: 0.012447\n",
      "[804/00595] train_loss: 0.012483\n",
      "[804/00645] train_loss: 0.012222\n",
      "[804/00695] train_loss: 0.012528\n",
      "[804/00745] train_loss: 0.012638\n",
      "[804/00795] train_loss: 0.013153\n",
      "[804/00845] train_loss: 0.012296\n",
      "[804/00895] train_loss: 0.013072\n",
      "[804/00945] train_loss: 0.012985\n",
      "[804/00995] train_loss: 0.012043\n",
      "[804/01045] train_loss: 0.012278\n",
      "[804/01095] train_loss: 0.013021\n",
      "[804/01145] train_loss: 0.012647\n",
      "[804/01195] train_loss: 0.012862\n",
      "[805/00019] train_loss: 0.014302\n",
      "[805/00069] train_loss: 0.014977\n",
      "[805/00119] train_loss: 0.013687\n",
      "[805/00169] train_loss: 0.013430\n",
      "[805/00219] train_loss: 0.011592\n",
      "[805/00269] train_loss: 0.014010\n",
      "[805/00319] train_loss: 0.012554\n",
      "[805/00369] train_loss: 0.012523\n",
      "[805/00419] train_loss: 0.012024\n",
      "[805/00469] train_loss: 0.013228\n",
      "[805/00519] train_loss: 0.011906\n",
      "[805/00569] train_loss: 0.012290\n",
      "[805/00619] train_loss: 0.013008\n",
      "[805/00669] train_loss: 0.011902\n",
      "[805/00719] train_loss: 0.012831\n",
      "[805/00769] train_loss: 0.012344\n",
      "[805/00819] train_loss: 0.012407\n",
      "[805/00869] train_loss: 0.012461\n",
      "[805/00919] train_loss: 0.013099\n",
      "[805/00969] train_loss: 0.012686\n",
      "[805/01019] train_loss: 0.012765\n",
      "[805/01069] train_loss: 0.012899\n",
      "[805/01119] train_loss: 0.012637\n",
      "[805/01169] train_loss: 0.013033\n",
      "[805/01219] train_loss: 0.013024\n",
      "[806/00043] train_loss: 0.014189\n",
      "[806/00093] train_loss: 0.013823\n",
      "[806/00143] train_loss: 0.013794\n",
      "[806/00193] train_loss: 0.012756\n",
      "[806/00243] train_loss: 0.012465\n",
      "[806/00293] train_loss: 0.013626\n",
      "[806/00343] train_loss: 0.012458\n",
      "[806/00393] train_loss: 0.012788\n",
      "[806/00443] train_loss: 0.012540\n",
      "[806/00493] train_loss: 0.012516\n",
      "[806/00543] train_loss: 0.011688\n",
      "[806/00593] train_loss: 0.012323\n",
      "[806/00643] train_loss: 0.012356\n",
      "[806/00693] train_loss: 0.012829\n",
      "[806/00743] train_loss: 0.012319\n",
      "[806/00793] train_loss: 0.012554\n",
      "[806/00843] train_loss: 0.012759\n",
      "[806/00893] train_loss: 0.012673\n",
      "[806/00943] train_loss: 0.013275\n",
      "[806/00993] train_loss: 0.012416\n",
      "[806/01043] train_loss: 0.012454\n",
      "[806/01093] train_loss: 0.012746\n",
      "[806/01143] train_loss: 0.013169\n",
      "[806/01193] train_loss: 0.012560\n",
      "[807/00017] train_loss: 0.014064\n",
      "[807/00067] train_loss: 0.014744\n",
      "[807/00117] train_loss: 0.013789\n",
      "[807/00167] train_loss: 0.012321\n",
      "[807/00217] train_loss: 0.013557\n",
      "[807/00267] train_loss: 0.012888\n",
      "[807/00317] train_loss: 0.012603\n",
      "[807/00367] train_loss: 0.012237\n",
      "[807/00417] train_loss: 0.012740\n",
      "[807/00467] train_loss: 0.013048\n",
      "[807/00517] train_loss: 0.012751\n",
      "[807/00567] train_loss: 0.011608\n",
      "[807/00617] train_loss: 0.013125\n",
      "[807/00667] train_loss: 0.012208\n",
      "[807/00717] train_loss: 0.013088\n",
      "[807/00767] train_loss: 0.012913\n",
      "[807/00817] train_loss: 0.012605\n",
      "[807/00867] train_loss: 0.012172\n",
      "[807/00917] train_loss: 0.013146\n",
      "[807/00967] train_loss: 0.012442\n",
      "[807/01017] train_loss: 0.013245\n",
      "[807/01067] train_loss: 0.012164\n",
      "[807/01117] train_loss: 0.012812\n",
      "[807/01167] train_loss: 0.012125\n",
      "[807/01217] train_loss: 0.013170\n",
      "[808/00041] train_loss: 0.015096\n",
      "[808/00091] train_loss: 0.014144\n",
      "[808/00141] train_loss: 0.013634\n",
      "[808/00191] train_loss: 0.013019\n",
      "[808/00241] train_loss: 0.012668\n",
      "[808/00291] train_loss: 0.012768\n",
      "[808/00341] train_loss: 0.012094\n",
      "[808/00391] train_loss: 0.012369\n",
      "[808/00441] train_loss: 0.011457\n",
      "[808/00491] train_loss: 0.012993\n",
      "[808/00541] train_loss: 0.012134\n",
      "[808/00591] train_loss: 0.013301\n",
      "[808/00641] train_loss: 0.012641\n",
      "[808/00691] train_loss: 0.012685\n",
      "[808/00741] train_loss: 0.013015\n",
      "[808/00791] train_loss: 0.012513\n",
      "[808/00841] train_loss: 0.013992\n",
      "[808/00891] train_loss: 0.011840\n",
      "[808/00941] train_loss: 0.012265\n",
      "[808/00991] train_loss: 0.012090\n",
      "[808/01041] train_loss: 0.012402\n",
      "[808/01091] train_loss: 0.012795\n",
      "[808/01141] train_loss: 0.013403\n",
      "[808/01191] train_loss: 0.012507\n",
      "[809/00015] train_loss: 0.014049\n",
      "[809/00065] train_loss: 0.014949\n",
      "[809/00115] train_loss: 0.013833\n",
      "[809/00165] train_loss: 0.013244\n",
      "[809/00215] train_loss: 0.013009\n",
      "[809/00265] train_loss: 0.012333\n",
      "[809/00315] train_loss: 0.012426\n",
      "[809/00365] train_loss: 0.012871\n",
      "[809/00415] train_loss: 0.012207\n",
      "[809/00465] train_loss: 0.012022\n",
      "[809/00515] train_loss: 0.012117\n",
      "[809/00565] train_loss: 0.013479\n",
      "[809/00615] train_loss: 0.012235\n",
      "[809/00665] train_loss: 0.011827\n",
      "[809/00715] train_loss: 0.011972\n",
      "[809/00765] train_loss: 0.012417\n",
      "[809/00815] train_loss: 0.012858\n",
      "[809/00865] train_loss: 0.013378\n",
      "[809/00915] train_loss: 0.012593\n",
      "[809/00965] train_loss: 0.012844\n",
      "[809/01015] train_loss: 0.012150\n",
      "[809/01065] train_loss: 0.012710\n",
      "[809/01115] train_loss: 0.012580\n",
      "[809/01165] train_loss: 0.013533\n",
      "[809/01215] train_loss: 0.012798\n",
      "[810/00039] train_loss: 0.015311\n",
      "[810/00089] train_loss: 0.013931\n",
      "[810/00139] train_loss: 0.013727\n",
      "[810/00189] train_loss: 0.012756\n",
      "[810/00239] train_loss: 0.013186\n",
      "[810/00289] train_loss: 0.013104\n",
      "[810/00339] train_loss: 0.012435\n",
      "[810/00389] train_loss: 0.012636\n",
      "[810/00439] train_loss: 0.012465\n",
      "[810/00489] train_loss: 0.012309\n",
      "[810/00539] train_loss: 0.012628\n",
      "[810/00589] train_loss: 0.012133\n",
      "[810/00639] train_loss: 0.013632\n",
      "[810/00689] train_loss: 0.012348\n",
      "[810/00739] train_loss: 0.011386\n",
      "[810/00789] train_loss: 0.013138\n",
      "[810/00839] train_loss: 0.013252\n",
      "[810/00889] train_loss: 0.012996\n",
      "[810/00939] train_loss: 0.013019\n",
      "[810/00989] train_loss: 0.012134\n",
      "[810/01039] train_loss: 0.011964\n",
      "[810/01089] train_loss: 0.012685\n",
      "[810/01139] train_loss: 0.012714\n",
      "[810/01189] train_loss: 0.012379\n",
      "[811/00013] train_loss: 0.013742\n",
      "[811/00063] train_loss: 0.014894\n",
      "[811/00113] train_loss: 0.013863\n",
      "[811/00163] train_loss: 0.013108\n",
      "[811/00213] train_loss: 0.013245\n",
      "[811/00263] train_loss: 0.012817\n",
      "[811/00313] train_loss: 0.012011\n",
      "[811/00363] train_loss: 0.012709\n",
      "[811/00413] train_loss: 0.012871\n",
      "[811/00463] train_loss: 0.012794\n",
      "[811/00513] train_loss: 0.012100\n",
      "[811/00563] train_loss: 0.012713\n",
      "[811/00613] train_loss: 0.013044\n",
      "[811/00663] train_loss: 0.011353\n",
      "[811/00713] train_loss: 0.012949\n",
      "[811/00763] train_loss: 0.012667\n",
      "[811/00813] train_loss: 0.012212\n",
      "[811/00863] train_loss: 0.013124\n",
      "[811/00913] train_loss: 0.012905\n",
      "[811/00963] train_loss: 0.012445\n",
      "[811/01013] train_loss: 0.012399\n",
      "[811/01063] train_loss: 0.012219\n",
      "[811/01113] train_loss: 0.012805\n",
      "[811/01163] train_loss: 0.012734\n",
      "[811/01213] train_loss: 0.012058\n",
      "[812/00037] train_loss: 0.014994\n",
      "[812/00087] train_loss: 0.015318\n",
      "[812/00137] train_loss: 0.013343\n",
      "[812/00187] train_loss: 0.013187\n",
      "[812/00237] train_loss: 0.013885\n",
      "[812/00287] train_loss: 0.012835\n",
      "[812/00337] train_loss: 0.012672\n",
      "[812/00387] train_loss: 0.013042\n",
      "[812/00437] train_loss: 0.012293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[812/00487] train_loss: 0.012526\n",
      "[812/00537] train_loss: 0.012504\n",
      "[812/00587] train_loss: 0.013323\n",
      "[812/00637] train_loss: 0.011871\n",
      "[812/00687] train_loss: 0.012753\n",
      "[812/00737] train_loss: 0.012582\n",
      "[812/00787] train_loss: 0.012156\n",
      "[812/00837] train_loss: 0.012348\n",
      "[812/00887] train_loss: 0.012546\n",
      "[812/00937] train_loss: 0.012340\n",
      "[812/00987] train_loss: 0.012670\n",
      "[812/01037] train_loss: 0.012488\n",
      "[812/01087] train_loss: 0.012460\n",
      "[812/01137] train_loss: 0.012560\n",
      "[812/01187] train_loss: 0.013363\n",
      "[813/00011] train_loss: 0.013092\n",
      "[813/00061] train_loss: 0.015856\n",
      "[813/00111] train_loss: 0.013851\n",
      "[813/00161] train_loss: 0.012940\n",
      "[813/00211] train_loss: 0.012393\n",
      "[813/00261] train_loss: 0.012285\n",
      "[813/00311] train_loss: 0.013436\n",
      "[813/00361] train_loss: 0.012023\n",
      "[813/00411] train_loss: 0.012689\n",
      "[813/00461] train_loss: 0.013299\n",
      "[813/00511] train_loss: 0.012499\n",
      "[813/00561] train_loss: 0.012831\n",
      "[813/00611] train_loss: 0.012308\n",
      "[813/00661] train_loss: 0.012141\n",
      "[813/00711] train_loss: 0.012698\n",
      "[813/00761] train_loss: 0.012618\n",
      "[813/00811] train_loss: 0.012518\n",
      "[813/00861] train_loss: 0.012355\n",
      "[813/00911] train_loss: 0.013098\n",
      "[813/00961] train_loss: 0.012756\n",
      "[813/01011] train_loss: 0.012792\n",
      "[813/01061] train_loss: 0.012405\n",
      "[813/01111] train_loss: 0.012502\n",
      "[813/01161] train_loss: 0.012212\n",
      "[813/01211] train_loss: 0.013239\n",
      "[814/00035] train_loss: 0.015147\n",
      "[814/00085] train_loss: 0.013743\n",
      "[814/00135] train_loss: 0.014293\n",
      "[814/00185] train_loss: 0.014036\n",
      "[814/00235] train_loss: 0.012943\n",
      "[814/00285] train_loss: 0.011949\n",
      "[814/00335] train_loss: 0.013400\n",
      "[814/00385] train_loss: 0.012298\n",
      "[814/00435] train_loss: 0.012734\n",
      "[814/00485] train_loss: 0.011821\n",
      "[814/00535] train_loss: 0.013302\n",
      "[814/00585] train_loss: 0.012473\n",
      "[814/00635] train_loss: 0.012603\n",
      "[814/00685] train_loss: 0.011791\n",
      "[814/00735] train_loss: 0.012698\n",
      "[814/00785] train_loss: 0.011702\n",
      "[814/00835] train_loss: 0.013281\n",
      "[814/00885] train_loss: 0.013284\n",
      "[814/00935] train_loss: 0.012594\n",
      "[814/00985] train_loss: 0.012101\n",
      "[814/01035] train_loss: 0.013492\n",
      "[814/01085] train_loss: 0.012316\n",
      "[814/01135] train_loss: 0.012069\n",
      "[814/01185] train_loss: 0.011785\n",
      "[815/00009] train_loss: 0.013034\n",
      "[815/00059] train_loss: 0.014972\n",
      "[815/00109] train_loss: 0.014426\n",
      "[815/00159] train_loss: 0.013082\n",
      "[815/00209] train_loss: 0.012466\n",
      "[815/00259] train_loss: 0.012327\n",
      "[815/00309] train_loss: 0.013087\n",
      "[815/00359] train_loss: 0.012617\n",
      "[815/00409] train_loss: 0.013420\n",
      "[815/00459] train_loss: 0.012031\n",
      "[815/00509] train_loss: 0.013497\n",
      "[815/00559] train_loss: 0.012648\n",
      "[815/00609] train_loss: 0.011852\n",
      "[815/00659] train_loss: 0.013008\n",
      "[815/00709] train_loss: 0.012717\n",
      "[815/00759] train_loss: 0.012364\n",
      "[815/00809] train_loss: 0.012454\n",
      "[815/00859] train_loss: 0.012638\n",
      "[815/00909] train_loss: 0.012089\n",
      "[815/00959] train_loss: 0.012825\n",
      "[815/01009] train_loss: 0.012415\n",
      "[815/01059] train_loss: 0.012082\n",
      "[815/01109] train_loss: 0.013097\n",
      "[815/01159] train_loss: 0.012954\n",
      "[815/01209] train_loss: 0.012820\n",
      "[816/00033] train_loss: 0.014685\n",
      "[816/00083] train_loss: 0.014430\n",
      "[816/00133] train_loss: 0.014345\n",
      "[816/00183] train_loss: 0.013208\n",
      "[816/00233] train_loss: 0.013530\n",
      "[816/00283] train_loss: 0.012633\n",
      "[816/00333] train_loss: 0.013015\n",
      "[816/00383] train_loss: 0.012969\n",
      "[816/00433] train_loss: 0.012651\n",
      "[816/00483] train_loss: 0.012154\n",
      "[816/00533] train_loss: 0.012418\n",
      "[816/00583] train_loss: 0.012683\n",
      "[816/00633] train_loss: 0.011997\n",
      "[816/00683] train_loss: 0.012254\n",
      "[816/00733] train_loss: 0.012322\n",
      "[816/00783] train_loss: 0.012669\n",
      "[816/00833] train_loss: 0.012629\n",
      "[816/00883] train_loss: 0.011729\n",
      "[816/00933] train_loss: 0.012612\n",
      "[816/00983] train_loss: 0.011830\n",
      "[816/01033] train_loss: 0.012752\n",
      "[816/01083] train_loss: 0.012995\n",
      "[816/01133] train_loss: 0.013062\n",
      "[816/01183] train_loss: 0.013221\n",
      "[817/00007] train_loss: 0.013089\n",
      "[817/00057] train_loss: 0.015107\n",
      "[817/00107] train_loss: 0.014298\n",
      "[817/00157] train_loss: 0.013519\n",
      "[817/00207] train_loss: 0.013234\n",
      "[817/00257] train_loss: 0.012719\n",
      "[817/00307] train_loss: 0.012478\n",
      "[817/00357] train_loss: 0.013354\n",
      "[817/00407] train_loss: 0.012718\n",
      "[817/00457] train_loss: 0.012305\n",
      "[817/00507] train_loss: 0.013296\n",
      "[817/00557] train_loss: 0.011937\n",
      "[817/00607] train_loss: 0.012233\n",
      "[817/00657] train_loss: 0.011994\n",
      "[817/00707] train_loss: 0.012003\n",
      "[817/00757] train_loss: 0.012098\n",
      "[817/00807] train_loss: 0.012044\n",
      "[817/00857] train_loss: 0.012107\n",
      "[817/00907] train_loss: 0.012362\n",
      "[817/00957] train_loss: 0.013007\n",
      "[817/01007] train_loss: 0.013317\n",
      "[817/01057] train_loss: 0.011914\n",
      "[817/01107] train_loss: 0.013886\n",
      "[817/01157] train_loss: 0.012308\n",
      "[817/01207] train_loss: 0.012510\n",
      "[818/00031] train_loss: 0.014540\n",
      "[818/00081] train_loss: 0.015224\n",
      "[818/00131] train_loss: 0.013992\n",
      "[818/00181] train_loss: 0.012674\n",
      "[818/00231] train_loss: 0.012761\n",
      "[818/00281] train_loss: 0.012797\n",
      "[818/00331] train_loss: 0.012070\n",
      "[818/00381] train_loss: 0.012539\n",
      "[818/00431] train_loss: 0.012558\n",
      "[818/00481] train_loss: 0.012514\n",
      "[818/00531] train_loss: 0.013106\n",
      "[818/00581] train_loss: 0.012859\n",
      "[818/00631] train_loss: 0.012372\n",
      "[818/00681] train_loss: 0.012494\n",
      "[818/00731] train_loss: 0.012467\n",
      "[818/00781] train_loss: 0.012775\n",
      "[818/00831] train_loss: 0.012563\n",
      "[818/00881] train_loss: 0.012018\n",
      "[818/00931] train_loss: 0.012510\n",
      "[818/00981] train_loss: 0.012483\n",
      "[818/01031] train_loss: 0.012168\n",
      "[818/01081] train_loss: 0.012798\n",
      "[818/01131] train_loss: 0.012842\n",
      "[818/01181] train_loss: 0.012441\n",
      "[819/00005] train_loss: 0.012723\n",
      "[819/00055] train_loss: 0.015833\n",
      "[819/00105] train_loss: 0.014889\n",
      "[819/00155] train_loss: 0.013098\n",
      "[819/00205] train_loss: 0.012993\n",
      "[819/00255] train_loss: 0.012523\n",
      "[819/00305] train_loss: 0.012078\n",
      "[819/00355] train_loss: 0.012242\n",
      "[819/00405] train_loss: 0.013336\n",
      "[819/00455] train_loss: 0.012318\n",
      "[819/00505] train_loss: 0.012147\n",
      "[819/00555] train_loss: 0.012474\n",
      "[819/00605] train_loss: 0.012662\n",
      "[819/00655] train_loss: 0.012999\n",
      "[819/00705] train_loss: 0.012197\n",
      "[819/00755] train_loss: 0.012874\n",
      "[819/00805] train_loss: 0.012509\n",
      "[819/00855] train_loss: 0.012241\n",
      "[819/00905] train_loss: 0.012874\n",
      "[819/00955] train_loss: 0.012769\n",
      "[819/01005] train_loss: 0.011987\n",
      "[819/01055] train_loss: 0.012978\n",
      "[819/01105] train_loss: 0.013297\n",
      "[819/01155] train_loss: 0.012279\n",
      "[819/01205] train_loss: 0.012420\n",
      "[820/00029] train_loss: 0.014840\n",
      "[820/00079] train_loss: 0.014959\n",
      "[820/00129] train_loss: 0.013781\n",
      "[820/00179] train_loss: 0.012998\n",
      "[820/00229] train_loss: 0.012508\n",
      "[820/00279] train_loss: 0.012585\n",
      "[820/00329] train_loss: 0.012689\n",
      "[820/00379] train_loss: 0.012109\n",
      "[820/00429] train_loss: 0.012635\n",
      "[820/00479] train_loss: 0.012746\n",
      "[820/00529] train_loss: 0.012491\n",
      "[820/00579] train_loss: 0.011669\n",
      "[820/00629] train_loss: 0.012648\n",
      "[820/00679] train_loss: 0.011753\n",
      "[820/00729] train_loss: 0.012271\n",
      "[820/00779] train_loss: 0.013355\n",
      "[820/00829] train_loss: 0.013077\n",
      "[820/00879] train_loss: 0.012207\n",
      "[820/00929] train_loss: 0.013149\n",
      "[820/00979] train_loss: 0.012463\n",
      "[820/01029] train_loss: 0.012414\n",
      "[820/01079] train_loss: 0.012606\n",
      "[820/01129] train_loss: 0.012919\n",
      "[820/01179] train_loss: 0.012976\n",
      "[821/00003] train_loss: 0.013421\n",
      "[821/00053] train_loss: 0.014936\n",
      "[821/00103] train_loss: 0.013819\n",
      "[821/00153] train_loss: 0.013761\n",
      "[821/00203] train_loss: 0.013292\n",
      "[821/00253] train_loss: 0.013387\n",
      "[821/00303] train_loss: 0.013076\n",
      "[821/00353] train_loss: 0.013303\n",
      "[821/00403] train_loss: 0.012151\n",
      "[821/00453] train_loss: 0.012386\n",
      "[821/00503] train_loss: 0.012952\n",
      "[821/00553] train_loss: 0.012853\n",
      "[821/00603] train_loss: 0.013243\n",
      "[821/00653] train_loss: 0.011814\n",
      "[821/00703] train_loss: 0.012516\n",
      "[821/00753] train_loss: 0.012908\n",
      "[821/00803] train_loss: 0.012749\n",
      "[821/00853] train_loss: 0.012404\n",
      "[821/00903] train_loss: 0.012260\n",
      "[821/00953] train_loss: 0.012566\n",
      "[821/01003] train_loss: 0.012047\n",
      "[821/01053] train_loss: 0.012967\n",
      "[821/01103] train_loss: 0.012924\n",
      "[821/01153] train_loss: 0.011985\n",
      "[821/01203] train_loss: 0.013172\n",
      "[822/00027] train_loss: 0.014465\n",
      "[822/00077] train_loss: 0.014931\n",
      "[822/00127] train_loss: 0.013741\n",
      "[822/00177] train_loss: 0.014445\n",
      "[822/00227] train_loss: 0.012642\n",
      "[822/00277] train_loss: 0.012492\n",
      "[822/00327] train_loss: 0.012026\n",
      "[822/00377] train_loss: 0.012475\n",
      "[822/00427] train_loss: 0.012947\n",
      "[822/00477] train_loss: 0.012972\n",
      "[822/00527] train_loss: 0.012977\n",
      "[822/00577] train_loss: 0.012466\n",
      "[822/00627] train_loss: 0.013538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822/00677] train_loss: 0.012026\n",
      "[822/00727] train_loss: 0.012338\n",
      "[822/00777] train_loss: 0.012253\n",
      "[822/00827] train_loss: 0.013466\n",
      "[822/00877] train_loss: 0.012482\n",
      "[822/00927] train_loss: 0.012947\n",
      "[822/00977] train_loss: 0.012304\n",
      "[822/01027] train_loss: 0.012652\n",
      "[822/01077] train_loss: 0.012571\n",
      "[822/01127] train_loss: 0.012717\n",
      "[822/01177] train_loss: 0.012459\n",
      "[823/00001] train_loss: 0.013031\n",
      "[823/00051] train_loss: 0.014812\n",
      "[823/00101] train_loss: 0.013948\n",
      "[823/00151] train_loss: 0.013388\n",
      "[823/00201] train_loss: 0.013322\n",
      "[823/00251] train_loss: 0.013154\n",
      "[823/00301] train_loss: 0.012747\n",
      "[823/00351] train_loss: 0.012932\n",
      "[823/00401] train_loss: 0.012680\n",
      "[823/00451] train_loss: 0.012199\n",
      "[823/00501] train_loss: 0.012355\n",
      "[823/00551] train_loss: 0.012548\n",
      "[823/00601] train_loss: 0.012637\n",
      "[823/00651] train_loss: 0.011957\n",
      "[823/00701] train_loss: 0.013274\n",
      "[823/00751] train_loss: 0.013292\n",
      "[823/00801] train_loss: 0.012260\n",
      "[823/00851] train_loss: 0.011611\n",
      "[823/00901] train_loss: 0.012838\n",
      "[823/00951] train_loss: 0.012168\n",
      "[823/01001] train_loss: 0.012438\n",
      "[823/01051] train_loss: 0.012269\n",
      "[823/01101] train_loss: 0.012912\n",
      "[823/01151] train_loss: 0.012947\n",
      "[823/01201] train_loss: 0.012425\n",
      "[824/00025] train_loss: 0.013944\n",
      "[824/00075] train_loss: 0.014591\n",
      "[824/00125] train_loss: 0.013508\n",
      "[824/00175] train_loss: 0.013845\n",
      "[824/00225] train_loss: 0.013008\n",
      "[824/00275] train_loss: 0.013362\n",
      "[824/00325] train_loss: 0.012724\n",
      "[824/00375] train_loss: 0.012355\n",
      "[824/00425] train_loss: 0.013172\n",
      "[824/00475] train_loss: 0.012668\n",
      "[824/00525] train_loss: 0.012383\n",
      "[824/00575] train_loss: 0.013400\n",
      "[824/00625] train_loss: 0.012857\n",
      "[824/00675] train_loss: 0.012295\n",
      "[824/00725] train_loss: 0.011873\n",
      "[824/00775] train_loss: 0.011985\n",
      "[824/00825] train_loss: 0.012679\n",
      "[824/00875] train_loss: 0.012618\n",
      "[824/00925] train_loss: 0.012719\n",
      "[824/00975] train_loss: 0.012196\n",
      "[824/01025] train_loss: 0.012471\n",
      "[824/01075] train_loss: 0.011971\n",
      "[824/01125] train_loss: 0.012335\n",
      "[824/01175] train_loss: 0.013100\n",
      "[824/01225] train_loss: 0.013307\n",
      "[825/00049] train_loss: 0.015245\n",
      "[825/00099] train_loss: 0.014211\n",
      "[825/00149] train_loss: 0.013986\n",
      "[825/00199] train_loss: 0.013475\n",
      "[825/00249] train_loss: 0.013004\n",
      "[825/00299] train_loss: 0.012997\n",
      "[825/00349] train_loss: 0.012512\n",
      "[825/00399] train_loss: 0.012607\n",
      "[825/00449] train_loss: 0.012321\n",
      "[825/00499] train_loss: 0.012507\n",
      "[825/00549] train_loss: 0.012422\n",
      "[825/00599] train_loss: 0.012477\n",
      "[825/00649] train_loss: 0.012557\n",
      "[825/00699] train_loss: 0.012606\n",
      "[825/00749] train_loss: 0.012007\n",
      "[825/00799] train_loss: 0.012425\n",
      "[825/00849] train_loss: 0.012824\n",
      "[825/00899] train_loss: 0.013054\n",
      "[825/00949] train_loss: 0.012215\n",
      "[825/00999] train_loss: 0.013033\n",
      "[825/01049] train_loss: 0.012659\n",
      "[825/01099] train_loss: 0.012889\n",
      "[825/01149] train_loss: 0.012968\n",
      "[825/01199] train_loss: 0.011837\n",
      "[826/00023] train_loss: 0.013496\n",
      "[826/00073] train_loss: 0.014717\n",
      "[826/00123] train_loss: 0.013647\n",
      "[826/00173] train_loss: 0.012965\n",
      "[826/00223] train_loss: 0.012291\n",
      "[826/00273] train_loss: 0.011747\n",
      "[826/00323] train_loss: 0.012937\n",
      "[826/00373] train_loss: 0.012517\n",
      "[826/00423] train_loss: 0.012572\n",
      "[826/00473] train_loss: 0.012736\n",
      "[826/00523] train_loss: 0.012890\n",
      "[826/00573] train_loss: 0.011956\n",
      "[826/00623] train_loss: 0.012681\n",
      "[826/00673] train_loss: 0.012098\n",
      "[826/00723] train_loss: 0.012401\n",
      "[826/00773] train_loss: 0.013363\n",
      "[826/00823] train_loss: 0.012360\n",
      "[826/00873] train_loss: 0.011873\n",
      "[826/00923] train_loss: 0.012459\n",
      "[826/00973] train_loss: 0.012347\n",
      "[826/01023] train_loss: 0.013258\n",
      "[826/01073] train_loss: 0.013023\n",
      "[826/01123] train_loss: 0.012930\n",
      "[826/01173] train_loss: 0.012911\n",
      "[826/01223] train_loss: 0.012926\n",
      "[827/00047] train_loss: 0.014965\n",
      "[827/00097] train_loss: 0.014636\n",
      "[827/00147] train_loss: 0.013225\n",
      "[827/00197] train_loss: 0.013143\n",
      "[827/00247] train_loss: 0.012646\n",
      "[827/00297] train_loss: 0.013005\n",
      "[827/00347] train_loss: 0.012426\n",
      "[827/00397] train_loss: 0.012793\n",
      "[827/00447] train_loss: 0.012250\n",
      "[827/00497] train_loss: 0.013058\n",
      "[827/00547] train_loss: 0.012783\n",
      "[827/00597] train_loss: 0.012197\n",
      "[827/00647] train_loss: 0.012204\n",
      "[827/00697] train_loss: 0.012459\n",
      "[827/00747] train_loss: 0.013034\n",
      "[827/00797] train_loss: 0.012720\n",
      "[827/00847] train_loss: 0.012694\n",
      "[827/00897] train_loss: 0.012156\n",
      "[827/00947] train_loss: 0.012760\n",
      "[827/00997] train_loss: 0.012675\n",
      "[827/01047] train_loss: 0.013049\n",
      "[827/01097] train_loss: 0.013224\n",
      "[827/01147] train_loss: 0.012477\n",
      "[827/01197] train_loss: 0.012141\n",
      "[828/00021] train_loss: 0.013725\n",
      "[828/00071] train_loss: 0.014688\n",
      "[828/00121] train_loss: 0.013571\n",
      "[828/00171] train_loss: 0.013775\n",
      "[828/00221] train_loss: 0.012835\n",
      "[828/00271] train_loss: 0.012302\n",
      "[828/00321] train_loss: 0.012948\n",
      "[828/00371] train_loss: 0.012202\n",
      "[828/00421] train_loss: 0.012332\n",
      "[828/00471] train_loss: 0.012427\n",
      "[828/00521] train_loss: 0.014094\n",
      "[828/00571] train_loss: 0.012163\n",
      "[828/00621] train_loss: 0.012149\n",
      "[828/00671] train_loss: 0.012673\n",
      "[828/00721] train_loss: 0.012559\n",
      "[828/00771] train_loss: 0.012154\n",
      "[828/00821] train_loss: 0.011989\n",
      "[828/00871] train_loss: 0.011996\n",
      "[828/00921] train_loss: 0.012973\n",
      "[828/00971] train_loss: 0.013264\n",
      "[828/01021] train_loss: 0.012105\n",
      "[828/01071] train_loss: 0.012228\n",
      "[828/01121] train_loss: 0.012228\n",
      "[828/01171] train_loss: 0.012915\n",
      "[828/01221] train_loss: 0.012641\n",
      "[829/00045] train_loss: 0.014869\n",
      "[829/00095] train_loss: 0.014677\n",
      "[829/00145] train_loss: 0.013680\n",
      "[829/00195] train_loss: 0.012248\n",
      "[829/00245] train_loss: 0.012377\n",
      "[829/00295] train_loss: 0.013107\n",
      "[829/00345] train_loss: 0.013371\n",
      "[829/00395] train_loss: 0.012386\n",
      "[829/00445] train_loss: 0.012859\n",
      "[829/00495] train_loss: 0.012103\n",
      "[829/00545] train_loss: 0.012071\n",
      "[829/00595] train_loss: 0.013056\n",
      "[829/00645] train_loss: 0.012440\n",
      "[829/00695] train_loss: 0.012722\n",
      "[829/00745] train_loss: 0.012054\n",
      "[829/00795] train_loss: 0.013167\n",
      "[829/00845] train_loss: 0.012503\n",
      "[829/00895] train_loss: 0.013171\n",
      "[829/00945] train_loss: 0.011939\n",
      "[829/00995] train_loss: 0.013070\n",
      "[829/01045] train_loss: 0.013314\n",
      "[829/01095] train_loss: 0.013491\n",
      "[829/01145] train_loss: 0.012822\n",
      "[829/01195] train_loss: 0.012206\n",
      "[830/00019] train_loss: 0.013218\n",
      "[830/00069] train_loss: 0.015534\n",
      "[830/00119] train_loss: 0.013051\n",
      "[830/00169] train_loss: 0.013583\n",
      "[830/00219] train_loss: 0.013521\n",
      "[830/00269] train_loss: 0.012683\n",
      "[830/00319] train_loss: 0.013009\n",
      "[830/00369] train_loss: 0.012375\n",
      "[830/00419] train_loss: 0.012919\n",
      "[830/00469] train_loss: 0.012120\n",
      "[830/00519] train_loss: 0.011826\n",
      "[830/00569] train_loss: 0.013258\n",
      "[830/00619] train_loss: 0.011969\n",
      "[830/00669] train_loss: 0.011184\n",
      "[830/00719] train_loss: 0.012672\n",
      "[830/00769] train_loss: 0.013015\n",
      "[830/00819] train_loss: 0.012992\n",
      "[830/00869] train_loss: 0.012496\n",
      "[830/00919] train_loss: 0.011952\n",
      "[830/00969] train_loss: 0.012483\n",
      "[830/01019] train_loss: 0.013436\n",
      "[830/01069] train_loss: 0.012160\n",
      "[830/01119] train_loss: 0.012898\n",
      "[830/01169] train_loss: 0.012564\n",
      "[830/01219] train_loss: 0.012761\n",
      "[831/00043] train_loss: 0.015111\n",
      "[831/00093] train_loss: 0.014533\n",
      "[831/00143] train_loss: 0.013906\n",
      "[831/00193] train_loss: 0.013208\n",
      "[831/00243] train_loss: 0.012460\n",
      "[831/00293] train_loss: 0.012469\n",
      "[831/00343] train_loss: 0.012155\n",
      "[831/00393] train_loss: 0.012109\n",
      "[831/00443] train_loss: 0.012197\n",
      "[831/00493] train_loss: 0.012367\n",
      "[831/00543] train_loss: 0.012031\n",
      "[831/00593] train_loss: 0.012691\n",
      "[831/00643] train_loss: 0.011435\n",
      "[831/00693] train_loss: 0.013004\n",
      "[831/00743] train_loss: 0.012446\n",
      "[831/00793] train_loss: 0.011965\n",
      "[831/00843] train_loss: 0.012392\n",
      "[831/00893] train_loss: 0.012844\n",
      "[831/00943] train_loss: 0.012487\n",
      "[831/00993] train_loss: 0.012433\n",
      "[831/01043] train_loss: 0.013426\n",
      "[831/01093] train_loss: 0.012852\n",
      "[831/01143] train_loss: 0.012453\n",
      "[831/01193] train_loss: 0.012669\n",
      "[832/00017] train_loss: 0.013829\n",
      "[832/00067] train_loss: 0.014830\n",
      "[832/00117] train_loss: 0.014442\n",
      "[832/00167] train_loss: 0.013167\n",
      "[832/00217] train_loss: 0.013565\n",
      "[832/00267] train_loss: 0.012917\n",
      "[832/00317] train_loss: 0.012904\n",
      "[832/00367] train_loss: 0.012978\n",
      "[832/00417] train_loss: 0.012895\n",
      "[832/00467] train_loss: 0.012869\n",
      "[832/00517] train_loss: 0.012807\n",
      "[832/00567] train_loss: 0.012265\n",
      "[832/00617] train_loss: 0.012450\n",
      "[832/00667] train_loss: 0.012094\n",
      "[832/00717] train_loss: 0.011780\n",
      "[832/00767] train_loss: 0.012705\n",
      "[832/00817] train_loss: 0.012449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[832/00867] train_loss: 0.012436\n",
      "[832/00917] train_loss: 0.012670\n",
      "[832/00967] train_loss: 0.012279\n",
      "[832/01017] train_loss: 0.012695\n",
      "[832/01067] train_loss: 0.011854\n",
      "[832/01117] train_loss: 0.012942\n",
      "[832/01167] train_loss: 0.012084\n",
      "[832/01217] train_loss: 0.012919\n",
      "[833/00041] train_loss: 0.015800\n",
      "[833/00091] train_loss: 0.014299\n",
      "[833/00141] train_loss: 0.013061\n",
      "[833/00191] train_loss: 0.013336\n",
      "[833/00241] train_loss: 0.012941\n",
      "[833/00291] train_loss: 0.012613\n",
      "[833/00341] train_loss: 0.012825\n",
      "[833/00391] train_loss: 0.012488\n",
      "[833/00441] train_loss: 0.012256\n",
      "[833/00491] train_loss: 0.013002\n",
      "[833/00541] train_loss: 0.012884\n",
      "[833/00591] train_loss: 0.012739\n",
      "[833/00641] train_loss: 0.012438\n",
      "[833/00691] train_loss: 0.012094\n",
      "[833/00741] train_loss: 0.012243\n",
      "[833/00791] train_loss: 0.012294\n",
      "[833/00841] train_loss: 0.012508\n",
      "[833/00891] train_loss: 0.012437\n",
      "[833/00941] train_loss: 0.013038\n",
      "[833/00991] train_loss: 0.012437\n",
      "[833/01041] train_loss: 0.012286\n",
      "[833/01091] train_loss: 0.012432\n",
      "[833/01141] train_loss: 0.012707\n",
      "[833/01191] train_loss: 0.012540\n",
      "[834/00015] train_loss: 0.013273\n",
      "[834/00065] train_loss: 0.014731\n",
      "[834/00115] train_loss: 0.013432\n",
      "[834/00165] train_loss: 0.012646\n",
      "[834/00215] train_loss: 0.012979\n",
      "[834/00265] train_loss: 0.013168\n",
      "[834/00315] train_loss: 0.012515\n",
      "[834/00365] train_loss: 0.012875\n",
      "[834/00415] train_loss: 0.012206\n",
      "[834/00465] train_loss: 0.012701\n",
      "[834/00515] train_loss: 0.012220\n",
      "[834/00565] train_loss: 0.012257\n",
      "[834/00615] train_loss: 0.013383\n",
      "[834/00665] train_loss: 0.012881\n",
      "[834/00715] train_loss: 0.012433\n",
      "[834/00765] train_loss: 0.012458\n",
      "[834/00815] train_loss: 0.011836\n",
      "[834/00865] train_loss: 0.012388\n",
      "[834/00915] train_loss: 0.013288\n",
      "[834/00965] train_loss: 0.013037\n",
      "[834/01015] train_loss: 0.012534\n",
      "[834/01065] train_loss: 0.013643\n",
      "[834/01115] train_loss: 0.012389\n",
      "[834/01165] train_loss: 0.012464\n",
      "[834/01215] train_loss: 0.012262\n",
      "[835/00039] train_loss: 0.014946\n",
      "[835/00089] train_loss: 0.014634\n",
      "[835/00139] train_loss: 0.013695\n",
      "[835/00189] train_loss: 0.013357\n",
      "[835/00239] train_loss: 0.012851\n",
      "[835/00289] train_loss: 0.012591\n",
      "[835/00339] train_loss: 0.011897\n",
      "[835/00389] train_loss: 0.012117\n",
      "[835/00439] train_loss: 0.011790\n",
      "[835/00489] train_loss: 0.012889\n",
      "[835/00539] train_loss: 0.012645\n",
      "[835/00589] train_loss: 0.012180\n",
      "[835/00639] train_loss: 0.013150\n",
      "[835/00689] train_loss: 0.012732\n",
      "[835/00739] train_loss: 0.012748\n",
      "[835/00789] train_loss: 0.012054\n",
      "[835/00839] train_loss: 0.012914\n",
      "[835/00889] train_loss: 0.013078\n",
      "[835/00939] train_loss: 0.012204\n",
      "[835/00989] train_loss: 0.012464\n",
      "[835/01039] train_loss: 0.012433\n",
      "[835/01089] train_loss: 0.012282\n",
      "[835/01139] train_loss: 0.012487\n",
      "[835/01189] train_loss: 0.012798\n",
      "[836/00013] train_loss: 0.012849\n",
      "[836/00063] train_loss: 0.015008\n",
      "[836/00113] train_loss: 0.014066\n",
      "[836/00163] train_loss: 0.013279\n",
      "[836/00213] train_loss: 0.012646\n",
      "[836/00263] train_loss: 0.012523\n",
      "[836/00313] train_loss: 0.013782\n",
      "[836/00363] train_loss: 0.012494\n",
      "[836/00413] train_loss: 0.012348\n",
      "[836/00463] train_loss: 0.011888\n",
      "[836/00513] train_loss: 0.013462\n",
      "[836/00563] train_loss: 0.012382\n",
      "[836/00613] train_loss: 0.012530\n",
      "[836/00663] train_loss: 0.012197\n",
      "[836/00713] train_loss: 0.011682\n",
      "[836/00763] train_loss: 0.011666\n",
      "[836/00813] train_loss: 0.013413\n",
      "[836/00863] train_loss: 0.012946\n",
      "[836/00913] train_loss: 0.012086\n",
      "[836/00963] train_loss: 0.012098\n",
      "[836/01013] train_loss: 0.012575\n",
      "[836/01063] train_loss: 0.012746\n",
      "[836/01113] train_loss: 0.012111\n",
      "[836/01163] train_loss: 0.013097\n",
      "[836/01213] train_loss: 0.012743\n",
      "[837/00037] train_loss: 0.014647\n",
      "[837/00087] train_loss: 0.014501\n",
      "[837/00137] train_loss: 0.012902\n",
      "[837/00187] train_loss: 0.012928\n",
      "[837/00237] train_loss: 0.013515\n",
      "[837/00287] train_loss: 0.012641\n",
      "[837/00337] train_loss: 0.012234\n",
      "[837/00387] train_loss: 0.012047\n",
      "[837/00437] train_loss: 0.012033\n",
      "[837/00487] train_loss: 0.012489\n",
      "[837/00537] train_loss: 0.012983\n",
      "[837/00587] train_loss: 0.012908\n",
      "[837/00637] train_loss: 0.013267\n",
      "[837/00687] train_loss: 0.012801\n",
      "[837/00737] train_loss: 0.012405\n",
      "[837/00787] train_loss: 0.012510\n",
      "[837/00837] train_loss: 0.012495\n",
      "[837/00887] train_loss: 0.012308\n",
      "[837/00937] train_loss: 0.012016\n",
      "[837/00987] train_loss: 0.013873\n",
      "[837/01037] train_loss: 0.012264\n",
      "[837/01087] train_loss: 0.012237\n",
      "[837/01137] train_loss: 0.012717\n",
      "[837/01187] train_loss: 0.012288\n",
      "[838/00011] train_loss: 0.013429\n",
      "[838/00061] train_loss: 0.014879\n",
      "[838/00111] train_loss: 0.014371\n",
      "[838/00161] train_loss: 0.013421\n",
      "[838/00211] train_loss: 0.012388\n",
      "[838/00261] train_loss: 0.012805\n",
      "[838/00311] train_loss: 0.012073\n",
      "[838/00361] train_loss: 0.012825\n",
      "[838/00411] train_loss: 0.012239\n",
      "[838/00461] train_loss: 0.012433\n",
      "[838/00511] train_loss: 0.012907\n",
      "[838/00561] train_loss: 0.012068\n",
      "[838/00611] train_loss: 0.012531\n",
      "[838/00661] train_loss: 0.012508\n",
      "[838/00711] train_loss: 0.012763\n",
      "[838/00761] train_loss: 0.012223\n",
      "[838/00811] train_loss: 0.012425\n",
      "[838/00861] train_loss: 0.012971\n",
      "[838/00911] train_loss: 0.012333\n",
      "[838/00961] train_loss: 0.012679\n",
      "[838/01011] train_loss: 0.012081\n",
      "[838/01061] train_loss: 0.013140\n",
      "[838/01111] train_loss: 0.012772\n",
      "[838/01161] train_loss: 0.012266\n",
      "[838/01211] train_loss: 0.013387\n",
      "[839/00035] train_loss: 0.015037\n",
      "[839/00085] train_loss: 0.014352\n",
      "[839/00135] train_loss: 0.013045\n",
      "[839/00185] train_loss: 0.013151\n",
      "[839/00235] train_loss: 0.013065\n",
      "[839/00285] train_loss: 0.012035\n",
      "[839/00335] train_loss: 0.013263\n",
      "[839/00385] train_loss: 0.012260\n",
      "[839/00435] train_loss: 0.012880\n",
      "[839/00485] train_loss: 0.012901\n",
      "[839/00535] train_loss: 0.012221\n",
      "[839/00585] train_loss: 0.011832\n",
      "[839/00635] train_loss: 0.012491\n",
      "[839/00685] train_loss: 0.013070\n",
      "[839/00735] train_loss: 0.012330\n",
      "[839/00785] train_loss: 0.012286\n",
      "[839/00835] train_loss: 0.011782\n",
      "[839/00885] train_loss: 0.012534\n",
      "[839/00935] train_loss: 0.012506\n",
      "[839/00985] train_loss: 0.012483\n",
      "[839/01035] train_loss: 0.013037\n",
      "[839/01085] train_loss: 0.013121\n",
      "[839/01135] train_loss: 0.012411\n",
      "[839/01185] train_loss: 0.013511\n",
      "[840/00009] train_loss: 0.014273\n",
      "[840/00059] train_loss: 0.015950\n",
      "[840/00109] train_loss: 0.013115\n",
      "[840/00159] train_loss: 0.012940\n",
      "[840/00209] train_loss: 0.012962\n",
      "[840/00259] train_loss: 0.012890\n",
      "[840/00309] train_loss: 0.012816\n",
      "[840/00359] train_loss: 0.013055\n",
      "[840/00409] train_loss: 0.012765\n",
      "[840/00459] train_loss: 0.012521\n",
      "[840/00509] train_loss: 0.012846\n",
      "[840/00559] train_loss: 0.012381\n",
      "[840/00609] train_loss: 0.013141\n",
      "[840/00659] train_loss: 0.012331\n",
      "[840/00709] train_loss: 0.011966\n",
      "[840/00759] train_loss: 0.012159\n",
      "[840/00809] train_loss: 0.013020\n",
      "[840/00859] train_loss: 0.012340\n",
      "[840/00909] train_loss: 0.013117\n",
      "[840/00959] train_loss: 0.012773\n",
      "[840/01009] train_loss: 0.012615\n",
      "[840/01059] train_loss: 0.011632\n",
      "[840/01109] train_loss: 0.012383\n",
      "[840/01159] train_loss: 0.012679\n",
      "[840/01209] train_loss: 0.012401\n",
      "[841/00033] train_loss: 0.014215\n",
      "[841/00083] train_loss: 0.014790\n",
      "[841/00133] train_loss: 0.013468\n",
      "[841/00183] train_loss: 0.012577\n",
      "[841/00233] train_loss: 0.012195\n",
      "[841/00283] train_loss: 0.012539\n",
      "[841/00333] train_loss: 0.012678\n",
      "[841/00383] train_loss: 0.012262\n",
      "[841/00433] train_loss: 0.012747\n",
      "[841/00483] train_loss: 0.012371\n",
      "[841/00533] train_loss: 0.012500\n",
      "[841/00583] train_loss: 0.012754\n",
      "[841/00633] train_loss: 0.012152\n",
      "[841/00683] train_loss: 0.011695\n",
      "[841/00733] train_loss: 0.012237\n",
      "[841/00783] train_loss: 0.012737\n",
      "[841/00833] train_loss: 0.012958\n",
      "[841/00883] train_loss: 0.012868\n",
      "[841/00933] train_loss: 0.012007\n",
      "[841/00983] train_loss: 0.012934\n",
      "[841/01033] train_loss: 0.012885\n",
      "[841/01083] train_loss: 0.012029\n",
      "[841/01133] train_loss: 0.012679\n",
      "[841/01183] train_loss: 0.013266\n",
      "[842/00007] train_loss: 0.013966\n",
      "[842/00057] train_loss: 0.014925\n",
      "[842/00107] train_loss: 0.014031\n",
      "[842/00157] train_loss: 0.013330\n",
      "[842/00207] train_loss: 0.012545\n",
      "[842/00257] train_loss: 0.012504\n",
      "[842/00307] train_loss: 0.012054\n",
      "[842/00357] train_loss: 0.012674\n",
      "[842/00407] train_loss: 0.013249\n",
      "[842/00457] train_loss: 0.013461\n",
      "[842/00507] train_loss: 0.012478\n",
      "[842/00557] train_loss: 0.011907\n",
      "[842/00607] train_loss: 0.011772\n",
      "[842/00657] train_loss: 0.012842\n",
      "[842/00707] train_loss: 0.012008\n",
      "[842/00757] train_loss: 0.011934\n",
      "[842/00807] train_loss: 0.012754\n",
      "[842/00857] train_loss: 0.012587\n",
      "[842/00907] train_loss: 0.013402\n",
      "[842/00957] train_loss: 0.012490\n",
      "[842/01007] train_loss: 0.012797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[842/01057] train_loss: 0.012147\n",
      "[842/01107] train_loss: 0.012400\n",
      "[842/01157] train_loss: 0.012658\n",
      "[842/01207] train_loss: 0.013018\n",
      "[843/00031] train_loss: 0.015571\n",
      "[843/00081] train_loss: 0.014142\n",
      "[843/00131] train_loss: 0.014261\n",
      "[843/00181] train_loss: 0.013005\n",
      "[843/00231] train_loss: 0.012995\n",
      "[843/00281] train_loss: 0.012934\n",
      "[843/00331] train_loss: 0.011930\n",
      "[843/00381] train_loss: 0.012997\n",
      "[843/00431] train_loss: 0.012047\n",
      "[843/00481] train_loss: 0.012432\n",
      "[843/00531] train_loss: 0.012974\n",
      "[843/00581] train_loss: 0.012130\n",
      "[843/00631] train_loss: 0.012227\n",
      "[843/00681] train_loss: 0.012645\n",
      "[843/00731] train_loss: 0.012839\n",
      "[843/00781] train_loss: 0.012216\n",
      "[843/00831] train_loss: 0.012023\n",
      "[843/00881] train_loss: 0.012236\n",
      "[843/00931] train_loss: 0.012452\n",
      "[843/00981] train_loss: 0.012901\n",
      "[843/01031] train_loss: 0.013414\n",
      "[843/01081] train_loss: 0.013210\n",
      "[843/01131] train_loss: 0.012914\n",
      "[843/01181] train_loss: 0.012511\n",
      "[844/00005] train_loss: 0.013385\n",
      "[844/00055] train_loss: 0.015087\n",
      "[844/00105] train_loss: 0.014445\n",
      "[844/00155] train_loss: 0.013411\n",
      "[844/00205] train_loss: 0.012978\n",
      "[844/00255] train_loss: 0.012068\n",
      "[844/00305] train_loss: 0.012311\n",
      "[844/00355] train_loss: 0.012197\n",
      "[844/00405] train_loss: 0.012904\n",
      "[844/00455] train_loss: 0.013045\n",
      "[844/00505] train_loss: 0.011975\n",
      "[844/00555] train_loss: 0.012307\n",
      "[844/00605] train_loss: 0.012503\n",
      "[844/00655] train_loss: 0.012287\n",
      "[844/00705] train_loss: 0.012749\n",
      "[844/00755] train_loss: 0.012263\n",
      "[844/00805] train_loss: 0.012755\n",
      "[844/00855] train_loss: 0.011743\n",
      "[844/00905] train_loss: 0.012447\n",
      "[844/00955] train_loss: 0.012629\n",
      "[844/01005] train_loss: 0.012505\n",
      "[844/01055] train_loss: 0.013649\n",
      "[844/01105] train_loss: 0.012637\n",
      "[844/01155] train_loss: 0.012570\n",
      "[844/01205] train_loss: 0.011926\n",
      "[845/00029] train_loss: 0.013882\n",
      "[845/00079] train_loss: 0.015190\n",
      "[845/00129] train_loss: 0.013782\n",
      "[845/00179] train_loss: 0.013045\n",
      "[845/00229] train_loss: 0.013173\n",
      "[845/00279] train_loss: 0.012025\n",
      "[845/00329] train_loss: 0.012509\n",
      "[845/00379] train_loss: 0.012493\n",
      "[845/00429] train_loss: 0.012788\n",
      "[845/00479] train_loss: 0.012020\n",
      "[845/00529] train_loss: 0.012812\n",
      "[845/00579] train_loss: 0.012377\n",
      "[845/00629] train_loss: 0.012399\n",
      "[845/00679] train_loss: 0.012652\n",
      "[845/00729] train_loss: 0.013707\n",
      "[845/00779] train_loss: 0.012734\n",
      "[845/00829] train_loss: 0.012199\n",
      "[845/00879] train_loss: 0.012053\n",
      "[845/00929] train_loss: 0.012364\n",
      "[845/00979] train_loss: 0.012482\n",
      "[845/01029] train_loss: 0.012417\n",
      "[845/01079] train_loss: 0.011769\n",
      "[845/01129] train_loss: 0.013028\n",
      "[845/01179] train_loss: 0.013975\n",
      "[846/00003] train_loss: 0.013036\n",
      "[846/00053] train_loss: 0.015495\n",
      "[846/00103] train_loss: 0.014167\n",
      "[846/00153] train_loss: 0.013907\n",
      "[846/00203] train_loss: 0.012601\n",
      "[846/00253] train_loss: 0.012584\n",
      "[846/00303] train_loss: 0.013579\n",
      "[846/00353] train_loss: 0.011882\n",
      "[846/00403] train_loss: 0.012400\n",
      "[846/00453] train_loss: 0.012740\n",
      "[846/00503] train_loss: 0.012054\n",
      "[846/00553] train_loss: 0.012805\n",
      "[846/00603] train_loss: 0.012106\n",
      "[846/00653] train_loss: 0.012288\n",
      "[846/00703] train_loss: 0.013263\n",
      "[846/00753] train_loss: 0.012287\n",
      "[846/00803] train_loss: 0.011668\n",
      "[846/00853] train_loss: 0.012970\n",
      "[846/00903] train_loss: 0.011760\n",
      "[846/00953] train_loss: 0.013295\n",
      "[846/01003] train_loss: 0.012578\n",
      "[846/01053] train_loss: 0.012217\n",
      "[846/01103] train_loss: 0.012805\n",
      "[846/01153] train_loss: 0.012700\n",
      "[846/01203] train_loss: 0.012650\n",
      "[847/00027] train_loss: 0.013710\n",
      "[847/00077] train_loss: 0.014117\n",
      "[847/00127] train_loss: 0.013410\n",
      "[847/00177] train_loss: 0.012984\n",
      "[847/00227] train_loss: 0.012940\n",
      "[847/00277] train_loss: 0.012786\n",
      "[847/00327] train_loss: 0.012579\n",
      "[847/00377] train_loss: 0.012680\n",
      "[847/00427] train_loss: 0.012913\n",
      "[847/00477] train_loss: 0.012480\n",
      "[847/00527] train_loss: 0.012514\n",
      "[847/00577] train_loss: 0.012478\n",
      "[847/00627] train_loss: 0.011520\n",
      "[847/00677] train_loss: 0.012324\n",
      "[847/00727] train_loss: 0.013149\n",
      "[847/00777] train_loss: 0.012354\n",
      "[847/00827] train_loss: 0.013402\n",
      "[847/00877] train_loss: 0.012343\n",
      "[847/00927] train_loss: 0.013123\n",
      "[847/00977] train_loss: 0.012274\n",
      "[847/01027] train_loss: 0.012220\n",
      "[847/01077] train_loss: 0.012840\n",
      "[847/01127] train_loss: 0.012946\n",
      "[847/01177] train_loss: 0.012679\n",
      "[848/00001] train_loss: 0.013988\n",
      "[848/00051] train_loss: 0.016051\n",
      "[848/00101] train_loss: 0.013309\n",
      "[848/00151] train_loss: 0.013332\n",
      "[848/00201] train_loss: 0.012607\n",
      "[848/00251] train_loss: 0.013728\n",
      "[848/00301] train_loss: 0.013062\n",
      "[848/00351] train_loss: 0.012924\n",
      "[848/00401] train_loss: 0.012143\n",
      "[848/00451] train_loss: 0.011894\n",
      "[848/00501] train_loss: 0.012353\n",
      "[848/00551] train_loss: 0.011949\n",
      "[848/00601] train_loss: 0.012445\n",
      "[848/00651] train_loss: 0.011946\n",
      "[848/00701] train_loss: 0.012127\n",
      "[848/00751] train_loss: 0.012949\n",
      "[848/00801] train_loss: 0.012425\n",
      "[848/00851] train_loss: 0.013406\n",
      "[848/00901] train_loss: 0.012408\n",
      "[848/00951] train_loss: 0.012452\n",
      "[848/01001] train_loss: 0.011848\n",
      "[848/01051] train_loss: 0.012855\n",
      "[848/01101] train_loss: 0.013092\n",
      "[848/01151] train_loss: 0.012584\n",
      "[848/01201] train_loss: 0.011793\n",
      "[849/00025] train_loss: 0.015196\n",
      "[849/00075] train_loss: 0.014994\n",
      "[849/00125] train_loss: 0.013951\n",
      "[849/00175] train_loss: 0.013184\n",
      "[849/00225] train_loss: 0.012959\n",
      "[849/00275] train_loss: 0.013465\n",
      "[849/00325] train_loss: 0.012162\n",
      "[849/00375] train_loss: 0.012411\n",
      "[849/00425] train_loss: 0.013123\n",
      "[849/00475] train_loss: 0.012007\n",
      "[849/00525] train_loss: 0.012062\n",
      "[849/00575] train_loss: 0.013558\n",
      "[849/00625] train_loss: 0.011758\n",
      "[849/00675] train_loss: 0.013211\n",
      "[849/00725] train_loss: 0.011768\n",
      "[849/00775] train_loss: 0.012357\n",
      "[849/00825] train_loss: 0.013084\n",
      "[849/00875] train_loss: 0.012117\n",
      "[849/00925] train_loss: 0.012760\n",
      "[849/00975] train_loss: 0.012351\n",
      "[849/01025] train_loss: 0.011953\n",
      "[849/01075] train_loss: 0.012315\n",
      "[849/01125] train_loss: 0.012888\n",
      "[849/01175] train_loss: 0.011793\n",
      "[849/01225] train_loss: 0.012455\n",
      "[850/00049] train_loss: 0.015868\n",
      "[850/00099] train_loss: 0.014370\n",
      "[850/00149] train_loss: 0.013337\n",
      "[850/00199] train_loss: 0.013254\n",
      "[850/00249] train_loss: 0.012848\n",
      "[850/00299] train_loss: 0.012424\n",
      "[850/00349] train_loss: 0.012399\n",
      "[850/00399] train_loss: 0.012811\n",
      "[850/00449] train_loss: 0.012263\n",
      "[850/00499] train_loss: 0.012497\n",
      "[850/00549] train_loss: 0.012260\n",
      "[850/00599] train_loss: 0.012647\n",
      "[850/00649] train_loss: 0.013049\n",
      "[850/00699] train_loss: 0.012957\n",
      "[850/00749] train_loss: 0.012991\n",
      "[850/00799] train_loss: 0.012287\n",
      "[850/00849] train_loss: 0.012142\n",
      "[850/00899] train_loss: 0.012273\n",
      "[850/00949] train_loss: 0.013378\n",
      "[850/00999] train_loss: 0.011950\n",
      "[850/01049] train_loss: 0.012115\n",
      "[850/01099] train_loss: 0.012549\n",
      "[850/01149] train_loss: 0.013095\n",
      "[850/01199] train_loss: 0.012891\n",
      "[851/00023] train_loss: 0.014025\n",
      "[851/00073] train_loss: 0.014865\n",
      "[851/00123] train_loss: 0.013701\n",
      "[851/00173] train_loss: 0.014274\n",
      "[851/00223] train_loss: 0.012733\n",
      "[851/00273] train_loss: 0.012355\n",
      "[851/00323] train_loss: 0.012851\n",
      "[851/00373] train_loss: 0.012695\n",
      "[851/00423] train_loss: 0.012617\n",
      "[851/00473] train_loss: 0.012721\n",
      "[851/00523] train_loss: 0.013114\n",
      "[851/00573] train_loss: 0.012746\n",
      "[851/00623] train_loss: 0.012469\n",
      "[851/00673] train_loss: 0.012782\n",
      "[851/00723] train_loss: 0.012725\n",
      "[851/00773] train_loss: 0.012337\n",
      "[851/00823] train_loss: 0.011884\n",
      "[851/00873] train_loss: 0.012061\n",
      "[851/00923] train_loss: 0.012671\n",
      "[851/00973] train_loss: 0.014000\n",
      "[851/01023] train_loss: 0.011951\n",
      "[851/01073] train_loss: 0.012241\n",
      "[851/01123] train_loss: 0.011882\n",
      "[851/01173] train_loss: 0.013191\n",
      "[851/01223] train_loss: 0.012371\n",
      "[852/00047] train_loss: 0.014706\n",
      "[852/00097] train_loss: 0.013528\n",
      "[852/00147] train_loss: 0.013551\n",
      "[852/00197] train_loss: 0.013026\n",
      "[852/00247] train_loss: 0.012899\n",
      "[852/00297] train_loss: 0.013539\n",
      "[852/00347] train_loss: 0.012490\n",
      "[852/00397] train_loss: 0.012198\n",
      "[852/00447] train_loss: 0.012804\n",
      "[852/00497] train_loss: 0.012438\n",
      "[852/00547] train_loss: 0.012253\n",
      "[852/00597] train_loss: 0.012472\n",
      "[852/00647] train_loss: 0.011913\n",
      "[852/00697] train_loss: 0.012676\n",
      "[852/00747] train_loss: 0.012135\n",
      "[852/00797] train_loss: 0.013074\n",
      "[852/00847] train_loss: 0.013223\n",
      "[852/00897] train_loss: 0.013128\n",
      "[852/00947] train_loss: 0.012549\n",
      "[852/00997] train_loss: 0.012096\n",
      "[852/01047] train_loss: 0.012087\n",
      "[852/01097] train_loss: 0.012056\n",
      "[852/01147] train_loss: 0.012415\n",
      "[852/01197] train_loss: 0.012915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[853/00021] train_loss: 0.014308\n",
      "[853/00071] train_loss: 0.014529\n",
      "[853/00121] train_loss: 0.012984\n",
      "[853/00171] train_loss: 0.012633\n",
      "[853/00221] train_loss: 0.012834\n",
      "[853/00271] train_loss: 0.013137\n",
      "[853/00321] train_loss: 0.012141\n",
      "[853/00371] train_loss: 0.013870\n",
      "[853/00421] train_loss: 0.012231\n",
      "[853/00471] train_loss: 0.012744\n",
      "[853/00521] train_loss: 0.012677\n",
      "[853/00571] train_loss: 0.012430\n",
      "[853/00621] train_loss: 0.012566\n",
      "[853/00671] train_loss: 0.011629\n",
      "[853/00721] train_loss: 0.012888\n",
      "[853/00771] train_loss: 0.012438\n",
      "[853/00821] train_loss: 0.012478\n",
      "[853/00871] train_loss: 0.012692\n",
      "[853/00921] train_loss: 0.012142\n",
      "[853/00971] train_loss: 0.012317\n",
      "[853/01021] train_loss: 0.012772\n",
      "[853/01071] train_loss: 0.013030\n",
      "[853/01121] train_loss: 0.012293\n",
      "[853/01171] train_loss: 0.012558\n",
      "[853/01221] train_loss: 0.012875\n",
      "[854/00045] train_loss: 0.016304\n",
      "[854/00095] train_loss: 0.013396\n",
      "[854/00145] train_loss: 0.012811\n",
      "[854/00195] train_loss: 0.013935\n",
      "[854/00245] train_loss: 0.012020\n",
      "[854/00295] train_loss: 0.012111\n",
      "[854/00345] train_loss: 0.012531\n",
      "[854/00395] train_loss: 0.012978\n",
      "[854/00445] train_loss: 0.012868\n",
      "[854/00495] train_loss: 0.012427\n",
      "[854/00545] train_loss: 0.013362\n",
      "[854/00595] train_loss: 0.012008\n",
      "[854/00645] train_loss: 0.012865\n",
      "[854/00695] train_loss: 0.012348\n",
      "[854/00745] train_loss: 0.012598\n",
      "[854/00795] train_loss: 0.012738\n",
      "[854/00845] train_loss: 0.011702\n",
      "[854/00895] train_loss: 0.012839\n",
      "[854/00945] train_loss: 0.013059\n",
      "[854/00995] train_loss: 0.011637\n",
      "[854/01045] train_loss: 0.012648\n",
      "[854/01095] train_loss: 0.012191\n",
      "[854/01145] train_loss: 0.012262\n",
      "[854/01195] train_loss: 0.012819\n",
      "[855/00019] train_loss: 0.014258\n",
      "[855/00069] train_loss: 0.015296\n",
      "[855/00119] train_loss: 0.013180\n",
      "[855/00169] train_loss: 0.012817\n",
      "[855/00219] train_loss: 0.012889\n",
      "[855/00269] train_loss: 0.013210\n",
      "[855/00319] train_loss: 0.013392\n",
      "[855/00369] train_loss: 0.012566\n",
      "[855/00419] train_loss: 0.012611\n",
      "[855/00469] train_loss: 0.012741\n",
      "[855/00519] train_loss: 0.012295\n",
      "[855/00569] train_loss: 0.012104\n",
      "[855/00619] train_loss: 0.012160\n",
      "[855/00669] train_loss: 0.012370\n",
      "[855/00719] train_loss: 0.012277\n",
      "[855/00769] train_loss: 0.012048\n",
      "[855/00819] train_loss: 0.012721\n",
      "[855/00869] train_loss: 0.012370\n",
      "[855/00919] train_loss: 0.011606\n",
      "[855/00969] train_loss: 0.012358\n",
      "[855/01019] train_loss: 0.012538\n",
      "[855/01069] train_loss: 0.013194\n",
      "[855/01119] train_loss: 0.012986\n",
      "[855/01169] train_loss: 0.012259\n",
      "[855/01219] train_loss: 0.012683\n",
      "[856/00043] train_loss: 0.014872\n",
      "[856/00093] train_loss: 0.014139\n",
      "[856/00143] train_loss: 0.013300\n",
      "[856/00193] train_loss: 0.013449\n",
      "[856/00243] train_loss: 0.012614\n",
      "[856/00293] train_loss: 0.012854\n",
      "[856/00343] train_loss: 0.012361\n",
      "[856/00393] train_loss: 0.012023\n",
      "[856/00443] train_loss: 0.012112\n",
      "[856/00493] train_loss: 0.012678\n",
      "[856/00543] train_loss: 0.012262\n",
      "[856/00593] train_loss: 0.012411\n",
      "[856/00643] train_loss: 0.012360\n",
      "[856/00693] train_loss: 0.012917\n",
      "[856/00743] train_loss: 0.012460\n",
      "[856/00793] train_loss: 0.012302\n",
      "[856/00843] train_loss: 0.012275\n",
      "[856/00893] train_loss: 0.012067\n",
      "[856/00943] train_loss: 0.013415\n",
      "[856/00993] train_loss: 0.012866\n",
      "[856/01043] train_loss: 0.012652\n",
      "[856/01093] train_loss: 0.012782\n",
      "[856/01143] train_loss: 0.012093\n",
      "[856/01193] train_loss: 0.012575\n",
      "[857/00017] train_loss: 0.013763\n",
      "[857/00067] train_loss: 0.015259\n",
      "[857/00117] train_loss: 0.013946\n",
      "[857/00167] train_loss: 0.012856\n",
      "[857/00217] train_loss: 0.012306\n",
      "[857/00267] train_loss: 0.013384\n",
      "[857/00317] train_loss: 0.012636\n",
      "[857/00367] train_loss: 0.012391\n",
      "[857/00417] train_loss: 0.012069\n",
      "[857/00467] train_loss: 0.012129\n",
      "[857/00517] train_loss: 0.012429\n",
      "[857/00567] train_loss: 0.013080\n",
      "[857/00617] train_loss: 0.011866\n",
      "[857/00667] train_loss: 0.012614\n",
      "[857/00717] train_loss: 0.012905\n",
      "[857/00767] train_loss: 0.012044\n",
      "[857/00817] train_loss: 0.012185\n",
      "[857/00867] train_loss: 0.012162\n",
      "[857/00917] train_loss: 0.012767\n",
      "[857/00967] train_loss: 0.012555\n",
      "[857/01017] train_loss: 0.013357\n",
      "[857/01067] train_loss: 0.012943\n",
      "[857/01117] train_loss: 0.012648\n",
      "[857/01167] train_loss: 0.013593\n",
      "[857/01217] train_loss: 0.012876\n",
      "[858/00041] train_loss: 0.015304\n",
      "[858/00091] train_loss: 0.013972\n",
      "[858/00141] train_loss: 0.013129\n",
      "[858/00191] train_loss: 0.013241\n",
      "[858/00241] train_loss: 0.012428\n",
      "[858/00291] train_loss: 0.011665\n",
      "[858/00341] train_loss: 0.012241\n",
      "[858/00391] train_loss: 0.011732\n",
      "[858/00441] train_loss: 0.012553\n",
      "[858/00491] train_loss: 0.012656\n",
      "[858/00541] train_loss: 0.012518\n",
      "[858/00591] train_loss: 0.012389\n",
      "[858/00641] train_loss: 0.013320\n",
      "[858/00691] train_loss: 0.011893\n",
      "[858/00741] train_loss: 0.013333\n",
      "[858/00791] train_loss: 0.012734\n",
      "[858/00841] train_loss: 0.012710\n",
      "[858/00891] train_loss: 0.013097\n",
      "[858/00941] train_loss: 0.012018\n",
      "[858/00991] train_loss: 0.011920\n",
      "[858/01041] train_loss: 0.012356\n",
      "[858/01091] train_loss: 0.011929\n",
      "[858/01141] train_loss: 0.013614\n",
      "[858/01191] train_loss: 0.012334\n",
      "[859/00015] train_loss: 0.013815\n",
      "[859/00065] train_loss: 0.014541\n",
      "[859/00115] train_loss: 0.013231\n",
      "[859/00165] train_loss: 0.013195\n",
      "[859/00215] train_loss: 0.012663\n",
      "[859/00265] train_loss: 0.012525\n",
      "[859/00315] train_loss: 0.012970\n",
      "[859/00365] train_loss: 0.012253\n",
      "[859/00415] train_loss: 0.012384\n",
      "[859/00465] train_loss: 0.012612\n",
      "[859/00515] train_loss: 0.013443\n",
      "[859/00565] train_loss: 0.012381\n",
      "[859/00615] train_loss: 0.012271\n",
      "[859/00665] train_loss: 0.012227\n",
      "[859/00715] train_loss: 0.012145\n",
      "[859/00765] train_loss: 0.013080\n",
      "[859/00815] train_loss: 0.012975\n",
      "[859/00865] train_loss: 0.012865\n",
      "[859/00915] train_loss: 0.012039\n",
      "[859/00965] train_loss: 0.012757\n",
      "[859/01015] train_loss: 0.012004\n",
      "[859/01065] train_loss: 0.012750\n",
      "[859/01115] train_loss: 0.012254\n",
      "[859/01165] train_loss: 0.012165\n",
      "[859/01215] train_loss: 0.013606\n",
      "[860/00039] train_loss: 0.015641\n",
      "[860/00089] train_loss: 0.013868\n",
      "[860/00139] train_loss: 0.013923\n",
      "[860/00189] train_loss: 0.013619\n",
      "[860/00239] train_loss: 0.012558\n",
      "[860/00289] train_loss: 0.012039\n",
      "[860/00339] train_loss: 0.013247\n",
      "[860/00389] train_loss: 0.011964\n",
      "[860/00439] train_loss: 0.012469\n",
      "[860/00489] train_loss: 0.012959\n",
      "[860/00539] train_loss: 0.012265\n",
      "[860/00589] train_loss: 0.012648\n",
      "[860/00639] train_loss: 0.012697\n",
      "[860/00689] train_loss: 0.012793\n",
      "[860/00739] train_loss: 0.012490\n",
      "[860/00789] train_loss: 0.012675\n",
      "[860/00839] train_loss: 0.012526\n",
      "[860/00889] train_loss: 0.012711\n",
      "[860/00939] train_loss: 0.013019\n",
      "[860/00989] train_loss: 0.012183\n",
      "[860/01039] train_loss: 0.011658\n",
      "[860/01089] train_loss: 0.012020\n",
      "[860/01139] train_loss: 0.012487\n",
      "[860/01189] train_loss: 0.011923\n",
      "[861/00013] train_loss: 0.014291\n",
      "[861/00063] train_loss: 0.014467\n",
      "[861/00113] train_loss: 0.013693\n",
      "[861/00163] train_loss: 0.013305\n",
      "[861/00213] train_loss: 0.012866\n",
      "[861/00263] train_loss: 0.013081\n",
      "[861/00313] train_loss: 0.013465\n",
      "[861/00363] train_loss: 0.012165\n",
      "[861/00413] train_loss: 0.013187\n",
      "[861/00463] train_loss: 0.012174\n",
      "[861/00513] train_loss: 0.011805\n",
      "[861/00563] train_loss: 0.012252\n",
      "[861/00613] train_loss: 0.012747\n",
      "[861/00663] train_loss: 0.012648\n",
      "[861/00713] train_loss: 0.012218\n",
      "[861/00763] train_loss: 0.011802\n",
      "[861/00813] train_loss: 0.011751\n",
      "[861/00863] train_loss: 0.012332\n",
      "[861/00913] train_loss: 0.013518\n",
      "[861/00963] train_loss: 0.012271\n",
      "[861/01013] train_loss: 0.013249\n",
      "[861/01063] train_loss: 0.012997\n",
      "[861/01113] train_loss: 0.012415\n",
      "[861/01163] train_loss: 0.012914\n",
      "[861/01213] train_loss: 0.012620\n",
      "[862/00037] train_loss: 0.014822\n",
      "[862/00087] train_loss: 0.014391\n",
      "[862/00137] train_loss: 0.013758\n",
      "[862/00187] train_loss: 0.013367\n",
      "[862/00237] train_loss: 0.012772\n",
      "[862/00287] train_loss: 0.012470\n",
      "[862/00337] train_loss: 0.011761\n",
      "[862/00387] train_loss: 0.012749\n",
      "[862/00437] train_loss: 0.011761\n",
      "[862/00487] train_loss: 0.012553\n",
      "[862/00537] train_loss: 0.012482\n",
      "[862/00587] train_loss: 0.012899\n",
      "[862/00637] train_loss: 0.013264\n",
      "[862/00687] train_loss: 0.012363\n",
      "[862/00737] train_loss: 0.012327\n",
      "[862/00787] train_loss: 0.012311\n",
      "[862/00837] train_loss: 0.013101\n",
      "[862/00887] train_loss: 0.012348\n",
      "[862/00937] train_loss: 0.012660\n",
      "[862/00987] train_loss: 0.012550\n",
      "[862/01037] train_loss: 0.013501\n",
      "[862/01087] train_loss: 0.012341\n",
      "[862/01137] train_loss: 0.012267\n",
      "[862/01187] train_loss: 0.013375\n",
      "[863/00011] train_loss: 0.012487\n",
      "[863/00061] train_loss: 0.015697\n",
      "[863/00111] train_loss: 0.013754\n",
      "[863/00161] train_loss: 0.013822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[863/00211] train_loss: 0.012889\n",
      "[863/00261] train_loss: 0.012804\n",
      "[863/00311] train_loss: 0.012642\n",
      "[863/00361] train_loss: 0.011968\n",
      "[863/00411] train_loss: 0.012765\n",
      "[863/00461] train_loss: 0.012360\n",
      "[863/00511] train_loss: 0.013212\n",
      "[863/00561] train_loss: 0.013097\n",
      "[863/00611] train_loss: 0.013033\n",
      "[863/00661] train_loss: 0.012127\n",
      "[863/00711] train_loss: 0.012635\n",
      "[863/00761] train_loss: 0.012374\n",
      "[863/00811] train_loss: 0.011407\n",
      "[863/00861] train_loss: 0.012101\n",
      "[863/00911] train_loss: 0.011624\n",
      "[863/00961] train_loss: 0.012404\n",
      "[863/01011] train_loss: 0.012690\n",
      "[863/01061] train_loss: 0.012384\n",
      "[863/01111] train_loss: 0.012789\n",
      "[863/01161] train_loss: 0.012873\n",
      "[863/01211] train_loss: 0.012781\n",
      "[864/00035] train_loss: 0.014526\n",
      "[864/00085] train_loss: 0.013764\n",
      "[864/00135] train_loss: 0.012937\n",
      "[864/00185] train_loss: 0.013360\n",
      "[864/00235] train_loss: 0.012437\n",
      "[864/00285] train_loss: 0.012398\n",
      "[864/00335] train_loss: 0.012499\n",
      "[864/00385] train_loss: 0.013218\n",
      "[864/00435] train_loss: 0.012269\n",
      "[864/00485] train_loss: 0.012445\n",
      "[864/00535] train_loss: 0.012999\n",
      "[864/00585] train_loss: 0.013181\n",
      "[864/00635] train_loss: 0.011891\n",
      "[864/00685] train_loss: 0.012427\n",
      "[864/00735] train_loss: 0.012195\n",
      "[864/00785] train_loss: 0.012304\n",
      "[864/00835] train_loss: 0.011868\n",
      "[864/00885] train_loss: 0.012506\n",
      "[864/00935] train_loss: 0.012758\n",
      "[864/00985] train_loss: 0.013188\n",
      "[864/01035] train_loss: 0.012971\n",
      "[864/01085] train_loss: 0.013116\n",
      "[864/01135] train_loss: 0.012876\n",
      "[864/01185] train_loss: 0.012695\n",
      "[865/00009] train_loss: 0.013516\n",
      "[865/00059] train_loss: 0.015827\n",
      "[865/00109] train_loss: 0.013318\n",
      "[865/00159] train_loss: 0.014018\n",
      "[865/00209] train_loss: 0.013323\n",
      "[865/00259] train_loss: 0.012761\n",
      "[865/00309] train_loss: 0.013413\n",
      "[865/00359] train_loss: 0.012738\n",
      "[865/00409] train_loss: 0.012134\n",
      "[865/00459] train_loss: 0.011565\n",
      "[865/00509] train_loss: 0.012515\n",
      "[865/00559] train_loss: 0.012599\n",
      "[865/00609] train_loss: 0.012296\n",
      "[865/00659] train_loss: 0.012475\n",
      "[865/00709] train_loss: 0.012168\n",
      "[865/00759] train_loss: 0.012982\n",
      "[865/00809] train_loss: 0.011861\n",
      "[865/00859] train_loss: 0.011747\n",
      "[865/00909] train_loss: 0.011908\n",
      "[865/00959] train_loss: 0.012599\n",
      "[865/01009] train_loss: 0.012198\n",
      "[865/01059] train_loss: 0.012881\n",
      "[865/01109] train_loss: 0.012925\n",
      "[865/01159] train_loss: 0.012533\n",
      "[865/01209] train_loss: 0.013508\n",
      "[866/00033] train_loss: 0.014511\n",
      "[866/00083] train_loss: 0.015556\n",
      "[866/00133] train_loss: 0.013914\n",
      "[866/00183] train_loss: 0.013019\n",
      "[866/00233] train_loss: 0.013487\n",
      "[866/00283] train_loss: 0.013180\n",
      "[866/00333] train_loss: 0.012318\n",
      "[866/00383] train_loss: 0.012264\n",
      "[866/00433] train_loss: 0.012505\n",
      "[866/00483] train_loss: 0.011736\n",
      "[866/00533] train_loss: 0.011935\n",
      "[866/00583] train_loss: 0.012756\n",
      "[866/00633] train_loss: 0.012139\n",
      "[866/00683] train_loss: 0.012319\n",
      "[866/00733] train_loss: 0.012331\n",
      "[866/00783] train_loss: 0.012371\n",
      "[866/00833] train_loss: 0.012440\n",
      "[866/00883] train_loss: 0.012572\n",
      "[866/00933] train_loss: 0.012972\n",
      "[866/00983] train_loss: 0.012360\n",
      "[866/01033] train_loss: 0.012276\n",
      "[866/01083] train_loss: 0.013558\n",
      "[866/01133] train_loss: 0.011763\n",
      "[866/01183] train_loss: 0.012687\n",
      "[867/00007] train_loss: 0.013114\n",
      "[867/00057] train_loss: 0.015085\n",
      "[867/00107] train_loss: 0.013702\n",
      "[867/00157] train_loss: 0.013946\n",
      "[867/00207] train_loss: 0.012891\n",
      "[867/00257] train_loss: 0.013496\n",
      "[867/00307] train_loss: 0.012255\n",
      "[867/00357] train_loss: 0.012183\n",
      "[867/00407] train_loss: 0.013184\n",
      "[867/00457] train_loss: 0.012487\n",
      "[867/00507] train_loss: 0.012198\n",
      "[867/00557] train_loss: 0.012842\n",
      "[867/00607] train_loss: 0.012342\n",
      "[867/00657] train_loss: 0.012716\n",
      "[867/00707] train_loss: 0.012383\n",
      "[867/00757] train_loss: 0.012397\n",
      "[867/00807] train_loss: 0.012409\n",
      "[867/00857] train_loss: 0.012909\n",
      "[867/00907] train_loss: 0.011900\n",
      "[867/00957] train_loss: 0.013322\n",
      "[867/01007] train_loss: 0.012282\n",
      "[867/01057] train_loss: 0.013525\n",
      "[867/01107] train_loss: 0.012348\n",
      "[867/01157] train_loss: 0.012381\n",
      "[867/01207] train_loss: 0.013175\n",
      "[868/00031] train_loss: 0.014640\n",
      "[868/00081] train_loss: 0.015874\n",
      "[868/00131] train_loss: 0.013835\n",
      "[868/00181] train_loss: 0.013540\n",
      "[868/00231] train_loss: 0.012516\n",
      "[868/00281] train_loss: 0.013047\n",
      "[868/00331] train_loss: 0.012988\n",
      "[868/00381] train_loss: 0.012554\n",
      "[868/00431] train_loss: 0.012031\n",
      "[868/00481] train_loss: 0.013301\n",
      "[868/00531] train_loss: 0.012516\n",
      "[868/00581] train_loss: 0.012308\n",
      "[868/00631] train_loss: 0.012854\n",
      "[868/00681] train_loss: 0.012140\n",
      "[868/00731] train_loss: 0.012256\n",
      "[868/00781] train_loss: 0.012045\n",
      "[868/00831] train_loss: 0.012804\n",
      "[868/00881] train_loss: 0.012234\n",
      "[868/00931] train_loss: 0.012089\n",
      "[868/00981] train_loss: 0.011536\n",
      "[868/01031] train_loss: 0.012669\n",
      "[868/01081] train_loss: 0.012164\n",
      "[868/01131] train_loss: 0.012798\n",
      "[868/01181] train_loss: 0.012905\n",
      "[869/00005] train_loss: 0.013057\n",
      "[869/00055] train_loss: 0.015756\n",
      "[869/00105] train_loss: 0.013518\n",
      "[869/00155] train_loss: 0.013240\n",
      "[869/00205] train_loss: 0.013044\n",
      "[869/00255] train_loss: 0.012690\n",
      "[869/00305] train_loss: 0.012133\n",
      "[869/00355] train_loss: 0.012462\n",
      "[869/00405] train_loss: 0.012574\n",
      "[869/00455] train_loss: 0.012987\n",
      "[869/00505] train_loss: 0.013074\n",
      "[869/00555] train_loss: 0.012425\n",
      "[869/00605] train_loss: 0.012804\n",
      "[869/00655] train_loss: 0.012590\n",
      "[869/00705] train_loss: 0.012091\n",
      "[869/00755] train_loss: 0.012199\n",
      "[869/00805] train_loss: 0.012722\n",
      "[869/00855] train_loss: 0.012060\n",
      "[869/00905] train_loss: 0.012058\n",
      "[869/00955] train_loss: 0.012028\n",
      "[869/01005] train_loss: 0.013574\n",
      "[869/01055] train_loss: 0.012182\n",
      "[869/01105] train_loss: 0.013090\n",
      "[869/01155] train_loss: 0.012148\n",
      "[869/01205] train_loss: 0.012675\n",
      "[870/00029] train_loss: 0.015020\n",
      "[870/00079] train_loss: 0.014399\n",
      "[870/00129] train_loss: 0.013860\n",
      "[870/00179] train_loss: 0.013182\n",
      "[870/00229] train_loss: 0.012806\n",
      "[870/00279] train_loss: 0.012654\n",
      "[870/00329] train_loss: 0.012843\n",
      "[870/00379] train_loss: 0.013040\n",
      "[870/00429] train_loss: 0.012445\n",
      "[870/00479] train_loss: 0.012348\n",
      "[870/00529] train_loss: 0.013132\n",
      "[870/00579] train_loss: 0.011852\n",
      "[870/00629] train_loss: 0.012460\n",
      "[870/00679] train_loss: 0.012483\n",
      "[870/00729] train_loss: 0.013127\n",
      "[870/00779] train_loss: 0.011770\n",
      "[870/00829] train_loss: 0.011861\n",
      "[870/00879] train_loss: 0.012950\n",
      "[870/00929] train_loss: 0.012499\n",
      "[870/00979] train_loss: 0.012615\n",
      "[870/01029] train_loss: 0.012016\n",
      "[870/01079] train_loss: 0.012822\n",
      "[870/01129] train_loss: 0.011674\n",
      "[870/01179] train_loss: 0.012809\n",
      "[871/00003] train_loss: 0.012167\n",
      "[871/00053] train_loss: 0.016268\n",
      "[871/00103] train_loss: 0.015569\n",
      "[871/00153] train_loss: 0.013625\n",
      "[871/00203] train_loss: 0.012617\n",
      "[871/00253] train_loss: 0.012649\n",
      "[871/00303] train_loss: 0.011912\n",
      "[871/00353] train_loss: 0.012525\n",
      "[871/00403] train_loss: 0.012832\n",
      "[871/00453] train_loss: 0.012367\n",
      "[871/00503] train_loss: 0.012388\n",
      "[871/00553] train_loss: 0.012584\n",
      "[871/00603] train_loss: 0.011818\n",
      "[871/00653] train_loss: 0.012368\n",
      "[871/00703] train_loss: 0.012661\n",
      "[871/00753] train_loss: 0.013446\n",
      "[871/00803] train_loss: 0.012043\n",
      "[871/00853] train_loss: 0.013007\n",
      "[871/00903] train_loss: 0.011840\n",
      "[871/00953] train_loss: 0.011787\n",
      "[871/01003] train_loss: 0.012394\n",
      "[871/01053] train_loss: 0.012203\n",
      "[871/01103] train_loss: 0.012947\n",
      "[871/01153] train_loss: 0.013245\n",
      "[871/01203] train_loss: 0.012437\n",
      "[872/00027] train_loss: 0.013661\n",
      "[872/00077] train_loss: 0.013665\n",
      "[872/00127] train_loss: 0.013608\n",
      "[872/00177] train_loss: 0.013206\n",
      "[872/00227] train_loss: 0.012377\n",
      "[872/00277] train_loss: 0.012785\n",
      "[872/00327] train_loss: 0.012941\n",
      "[872/00377] train_loss: 0.011845\n",
      "[872/00427] train_loss: 0.012289\n",
      "[872/00477] train_loss: 0.012030\n",
      "[872/00527] train_loss: 0.012360\n",
      "[872/00577] train_loss: 0.013145\n",
      "[872/00627] train_loss: 0.012222\n",
      "[872/00677] train_loss: 0.012454\n",
      "[872/00727] train_loss: 0.012047\n",
      "[872/00777] train_loss: 0.012525\n",
      "[872/00827] train_loss: 0.012405\n",
      "[872/00877] train_loss: 0.013233\n",
      "[872/00927] train_loss: 0.012919\n",
      "[872/00977] train_loss: 0.012224\n",
      "[872/01027] train_loss: 0.012572\n",
      "[872/01077] train_loss: 0.012842\n",
      "[872/01127] train_loss: 0.012286\n",
      "[872/01177] train_loss: 0.013541\n",
      "[873/00001] train_loss: 0.012527\n",
      "[873/00051] train_loss: 0.014602\n",
      "[873/00101] train_loss: 0.013898\n",
      "[873/00151] train_loss: 0.013321\n",
      "[873/00201] train_loss: 0.013252\n",
      "[873/00251] train_loss: 0.012787\n",
      "[873/00301] train_loss: 0.012298\n",
      "[873/00351] train_loss: 0.013027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[873/00401] train_loss: 0.013044\n",
      "[873/00451] train_loss: 0.012908\n",
      "[873/00501] train_loss: 0.012404\n",
      "[873/00551] train_loss: 0.013399\n",
      "[873/00601] train_loss: 0.012350\n",
      "[873/00651] train_loss: 0.012120\n",
      "[873/00701] train_loss: 0.013316\n",
      "[873/00751] train_loss: 0.013076\n",
      "[873/00801] train_loss: 0.011769\n",
      "[873/00851] train_loss: 0.012372\n",
      "[873/00901] train_loss: 0.012424\n",
      "[873/00951] train_loss: 0.012603\n",
      "[873/01001] train_loss: 0.012473\n",
      "[873/01051] train_loss: 0.012506\n",
      "[873/01101] train_loss: 0.012399\n",
      "[873/01151] train_loss: 0.012852\n",
      "[873/01201] train_loss: 0.011830\n",
      "[874/00025] train_loss: 0.014619\n",
      "[874/00075] train_loss: 0.014625\n",
      "[874/00125] train_loss: 0.012860\n",
      "[874/00175] train_loss: 0.014046\n",
      "[874/00225] train_loss: 0.012914\n",
      "[874/00275] train_loss: 0.012658\n",
      "[874/00325] train_loss: 0.012679\n",
      "[874/00375] train_loss: 0.012542\n",
      "[874/00425] train_loss: 0.011927\n",
      "[874/00475] train_loss: 0.012745\n",
      "[874/00525] train_loss: 0.012375\n",
      "[874/00575] train_loss: 0.013072\n",
      "[874/00625] train_loss: 0.012627\n",
      "[874/00675] train_loss: 0.011642\n",
      "[874/00725] train_loss: 0.012681\n",
      "[874/00775] train_loss: 0.013403\n",
      "[874/00825] train_loss: 0.012297\n",
      "[874/00875] train_loss: 0.012806\n",
      "[874/00925] train_loss: 0.012485\n",
      "[874/00975] train_loss: 0.011613\n",
      "[874/01025] train_loss: 0.012309\n",
      "[874/01075] train_loss: 0.012418\n",
      "[874/01125] train_loss: 0.012210\n",
      "[874/01175] train_loss: 0.012359\n",
      "[874/01225] train_loss: 0.012688\n",
      "[875/00049] train_loss: 0.015113\n",
      "[875/00099] train_loss: 0.014165\n",
      "[875/00149] train_loss: 0.013469\n",
      "[875/00199] train_loss: 0.012061\n",
      "[875/00249] train_loss: 0.013164\n",
      "[875/00299] train_loss: 0.012529\n",
      "[875/00349] train_loss: 0.012985\n",
      "[875/00399] train_loss: 0.013262\n",
      "[875/00449] train_loss: 0.012220\n",
      "[875/00499] train_loss: 0.012196\n",
      "[875/00549] train_loss: 0.012431\n",
      "[875/00599] train_loss: 0.012770\n",
      "[875/00649] train_loss: 0.012847\n",
      "[875/00699] train_loss: 0.012798\n",
      "[875/00749] train_loss: 0.011875\n",
      "[875/00799] train_loss: 0.011993\n",
      "[875/00849] train_loss: 0.012106\n",
      "[875/00899] train_loss: 0.012449\n",
      "[875/00949] train_loss: 0.012672\n",
      "[875/00999] train_loss: 0.012832\n",
      "[875/01049] train_loss: 0.012894\n",
      "[875/01099] train_loss: 0.012892\n",
      "[875/01149] train_loss: 0.012227\n",
      "[875/01199] train_loss: 0.013165\n",
      "[876/00023] train_loss: 0.014122\n",
      "[876/00073] train_loss: 0.015053\n",
      "[876/00123] train_loss: 0.013943\n",
      "[876/00173] train_loss: 0.012952\n",
      "[876/00223] train_loss: 0.012953\n",
      "[876/00273] train_loss: 0.013251\n",
      "[876/00323] train_loss: 0.011637\n",
      "[876/00373] train_loss: 0.011791\n",
      "[876/00423] train_loss: 0.012832\n",
      "[876/00473] train_loss: 0.012297\n",
      "[876/00523] train_loss: 0.012334\n",
      "[876/00573] train_loss: 0.011609\n",
      "[876/00623] train_loss: 0.011747\n",
      "[876/00673] train_loss: 0.012585\n",
      "[876/00723] train_loss: 0.012651\n",
      "[876/00773] train_loss: 0.011938\n",
      "[876/00823] train_loss: 0.012719\n",
      "[876/00873] train_loss: 0.012708\n",
      "[876/00923] train_loss: 0.012694\n",
      "[876/00973] train_loss: 0.012410\n",
      "[876/01023] train_loss: 0.012604\n",
      "[876/01073] train_loss: 0.012609\n",
      "[876/01123] train_loss: 0.012327\n",
      "[876/01173] train_loss: 0.012957\n",
      "[876/01223] train_loss: 0.013020\n",
      "[877/00047] train_loss: 0.015114\n",
      "[877/00097] train_loss: 0.014065\n",
      "[877/00147] train_loss: 0.012884\n",
      "[877/00197] train_loss: 0.013328\n",
      "[877/00247] train_loss: 0.012235\n",
      "[877/00297] train_loss: 0.012613\n",
      "[877/00347] train_loss: 0.012752\n",
      "[877/00397] train_loss: 0.012469\n",
      "[877/00447] train_loss: 0.012903\n",
      "[877/00497] train_loss: 0.012546\n",
      "[877/00547] train_loss: 0.012370\n",
      "[877/00597] train_loss: 0.011885\n",
      "[877/00647] train_loss: 0.012859\n",
      "[877/00697] train_loss: 0.012323\n",
      "[877/00747] train_loss: 0.012922\n",
      "[877/00797] train_loss: 0.012515\n",
      "[877/00847] train_loss: 0.013070\n",
      "[877/00897] train_loss: 0.012331\n",
      "[877/00947] train_loss: 0.012553\n",
      "[877/00997] train_loss: 0.012111\n",
      "[877/01047] train_loss: 0.012900\n",
      "[877/01097] train_loss: 0.012503\n",
      "[877/01147] train_loss: 0.012941\n",
      "[877/01197] train_loss: 0.012160\n",
      "[878/00021] train_loss: 0.014752\n",
      "[878/00071] train_loss: 0.015307\n",
      "[878/00121] train_loss: 0.013833\n",
      "[878/00171] train_loss: 0.013083\n",
      "[878/00221] train_loss: 0.013161\n",
      "[878/00271] train_loss: 0.012542\n",
      "[878/00321] train_loss: 0.012449\n",
      "[878/00371] train_loss: 0.012849\n",
      "[878/00421] train_loss: 0.012856\n",
      "[878/00471] train_loss: 0.012304\n",
      "[878/00521] train_loss: 0.012124\n",
      "[878/00571] train_loss: 0.012151\n",
      "[878/00621] train_loss: 0.012742\n",
      "[878/00671] train_loss: 0.011608\n",
      "[878/00721] train_loss: 0.012815\n",
      "[878/00771] train_loss: 0.013253\n",
      "[878/00821] train_loss: 0.012023\n",
      "[878/00871] train_loss: 0.012661\n",
      "[878/00921] train_loss: 0.012132\n",
      "[878/00971] train_loss: 0.012296\n",
      "[878/01021] train_loss: 0.011937\n",
      "[878/01071] train_loss: 0.012843\n",
      "[878/01121] train_loss: 0.012594\n",
      "[878/01171] train_loss: 0.013902\n",
      "[878/01221] train_loss: 0.013212\n",
      "[879/00045] train_loss: 0.015528\n",
      "[879/00095] train_loss: 0.014329\n",
      "[879/00145] train_loss: 0.012903\n",
      "[879/00195] train_loss: 0.012470\n",
      "[879/00245] train_loss: 0.012642\n",
      "[879/00295] train_loss: 0.012737\n",
      "[879/00345] train_loss: 0.014022\n",
      "[879/00395] train_loss: 0.012278\n",
      "[879/00445] train_loss: 0.012877\n",
      "[879/00495] train_loss: 0.012452\n",
      "[879/00545] train_loss: 0.012855\n",
      "[879/00595] train_loss: 0.012546\n",
      "[879/00645] train_loss: 0.012261\n",
      "[879/00695] train_loss: 0.012472\n",
      "[879/00745] train_loss: 0.013092\n",
      "[879/00795] train_loss: 0.012089\n",
      "[879/00845] train_loss: 0.013044\n",
      "[879/00895] train_loss: 0.012089\n",
      "[879/00945] train_loss: 0.012560\n",
      "[879/00995] train_loss: 0.012046\n",
      "[879/01045] train_loss: 0.012169\n",
      "[879/01095] train_loss: 0.012012\n",
      "[879/01145] train_loss: 0.012248\n",
      "[879/01195] train_loss: 0.012175\n",
      "[880/00019] train_loss: 0.014507\n",
      "[880/00069] train_loss: 0.013940\n",
      "[880/00119] train_loss: 0.013994\n",
      "[880/00169] train_loss: 0.013331\n",
      "[880/00219] train_loss: 0.013618\n",
      "[880/00269] train_loss: 0.011823\n",
      "[880/00319] train_loss: 0.012449\n",
      "[880/00369] train_loss: 0.013768\n",
      "[880/00419] train_loss: 0.012558\n",
      "[880/00469] train_loss: 0.012986\n",
      "[880/00519] train_loss: 0.012333\n",
      "[880/00569] train_loss: 0.013095\n",
      "[880/00619] train_loss: 0.012004\n",
      "[880/00669] train_loss: 0.012235\n",
      "[880/00719] train_loss: 0.012265\n",
      "[880/00769] train_loss: 0.011609\n",
      "[880/00819] train_loss: 0.012201\n",
      "[880/00869] train_loss: 0.012508\n",
      "[880/00919] train_loss: 0.012328\n",
      "[880/00969] train_loss: 0.012227\n",
      "[880/01019] train_loss: 0.012587\n",
      "[880/01069] train_loss: 0.012258\n",
      "[880/01119] train_loss: 0.012086\n",
      "[880/01169] train_loss: 0.012193\n",
      "[880/01219] train_loss: 0.012436\n",
      "[881/00043] train_loss: 0.015279\n",
      "[881/00093] train_loss: 0.013882\n",
      "[881/00143] train_loss: 0.013380\n",
      "[881/00193] train_loss: 0.013289\n",
      "[881/00243] train_loss: 0.013181\n",
      "[881/00293] train_loss: 0.011855\n",
      "[881/00343] train_loss: 0.012410\n",
      "[881/00393] train_loss: 0.011599\n",
      "[881/00443] train_loss: 0.013012\n",
      "[881/00493] train_loss: 0.012077\n",
      "[881/00543] train_loss: 0.012832\n",
      "[881/00593] train_loss: 0.013030\n",
      "[881/00643] train_loss: 0.012842\n",
      "[881/00693] train_loss: 0.012208\n",
      "[881/00743] train_loss: 0.011996\n",
      "[881/00793] train_loss: 0.011821\n",
      "[881/00843] train_loss: 0.013289\n",
      "[881/00893] train_loss: 0.011652\n",
      "[881/00943] train_loss: 0.012091\n",
      "[881/00993] train_loss: 0.012637\n",
      "[881/01043] train_loss: 0.013425\n",
      "[881/01093] train_loss: 0.012336\n",
      "[881/01143] train_loss: 0.012887\n",
      "[881/01193] train_loss: 0.012876\n",
      "[882/00017] train_loss: 0.013730\n",
      "[882/00067] train_loss: 0.014317\n",
      "[882/00117] train_loss: 0.013178\n",
      "[882/00167] train_loss: 0.013479\n",
      "[882/00217] train_loss: 0.013010\n",
      "[882/00267] train_loss: 0.012256\n",
      "[882/00317] train_loss: 0.012484\n",
      "[882/00367] train_loss: 0.012616\n",
      "[882/00417] train_loss: 0.012226\n",
      "[882/00467] train_loss: 0.012644\n",
      "[882/00517] train_loss: 0.012859\n",
      "[882/00567] train_loss: 0.012623\n",
      "[882/00617] train_loss: 0.013338\n",
      "[882/00667] train_loss: 0.013115\n",
      "[882/00717] train_loss: 0.012087\n",
      "[882/00767] train_loss: 0.013197\n",
      "[882/00817] train_loss: 0.013365\n",
      "[882/00867] train_loss: 0.011556\n",
      "[882/00917] train_loss: 0.011760\n",
      "[882/00967] train_loss: 0.012311\n",
      "[882/01017] train_loss: 0.012682\n",
      "[882/01067] train_loss: 0.012183\n",
      "[882/01117] train_loss: 0.012054\n",
      "[882/01167] train_loss: 0.013131\n",
      "[882/01217] train_loss: 0.012986\n",
      "[883/00041] train_loss: 0.015242\n",
      "[883/00091] train_loss: 0.014586\n",
      "[883/00141] train_loss: 0.013262\n",
      "[883/00191] train_loss: 0.012179\n",
      "[883/00241] train_loss: 0.012603\n",
      "[883/00291] train_loss: 0.012622\n",
      "[883/00341] train_loss: 0.012127\n",
      "[883/00391] train_loss: 0.012373\n",
      "[883/00441] train_loss: 0.012853\n",
      "[883/00491] train_loss: 0.012874\n",
      "[883/00541] train_loss: 0.012354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[883/00591] train_loss: 0.012692\n",
      "[883/00641] train_loss: 0.012000\n",
      "[883/00691] train_loss: 0.012724\n",
      "[883/00741] train_loss: 0.012370\n",
      "[883/00791] train_loss: 0.012127\n",
      "[883/00841] train_loss: 0.012473\n",
      "[883/00891] train_loss: 0.012077\n",
      "[883/00941] train_loss: 0.012775\n",
      "[883/00991] train_loss: 0.012497\n",
      "[883/01041] train_loss: 0.013503\n",
      "[883/01091] train_loss: 0.012326\n",
      "[883/01141] train_loss: 0.012625\n",
      "[883/01191] train_loss: 0.012618\n",
      "[884/00015] train_loss: 0.014106\n",
      "[884/00065] train_loss: 0.014465\n",
      "[884/00115] train_loss: 0.013737\n",
      "[884/00165] train_loss: 0.013120\n",
      "[884/00215] train_loss: 0.012901\n",
      "[884/00265] train_loss: 0.013265\n",
      "[884/00315] train_loss: 0.012529\n",
      "[884/00365] train_loss: 0.013107\n",
      "[884/00415] train_loss: 0.012212\n",
      "[884/00465] train_loss: 0.012312\n",
      "[884/00515] train_loss: 0.012853\n",
      "[884/00565] train_loss: 0.012396\n",
      "[884/00615] train_loss: 0.012293\n",
      "[884/00665] train_loss: 0.012364\n",
      "[884/00715] train_loss: 0.012613\n",
      "[884/00765] train_loss: 0.011824\n",
      "[884/00815] train_loss: 0.012235\n",
      "[884/00865] train_loss: 0.013447\n",
      "[884/00915] train_loss: 0.012174\n",
      "[884/00965] train_loss: 0.011857\n",
      "[884/01015] train_loss: 0.012923\n",
      "[884/01065] train_loss: 0.012188\n",
      "[884/01115] train_loss: 0.012002\n",
      "[884/01165] train_loss: 0.012792\n",
      "[884/01215] train_loss: 0.012785\n",
      "[885/00039] train_loss: 0.015963\n",
      "[885/00089] train_loss: 0.014476\n",
      "[885/00139] train_loss: 0.013200\n",
      "[885/00189] train_loss: 0.013301\n",
      "[885/00239] train_loss: 0.013142\n",
      "[885/00289] train_loss: 0.012426\n",
      "[885/00339] train_loss: 0.012427\n",
      "[885/00389] train_loss: 0.012847\n",
      "[885/00439] train_loss: 0.011905\n",
      "[885/00489] train_loss: 0.012565\n",
      "[885/00539] train_loss: 0.012144\n",
      "[885/00589] train_loss: 0.012476\n",
      "[885/00639] train_loss: 0.013108\n",
      "[885/00689] train_loss: 0.012866\n",
      "[885/00739] train_loss: 0.012168\n",
      "[885/00789] train_loss: 0.012151\n",
      "[885/00839] train_loss: 0.011727\n",
      "[885/00889] train_loss: 0.012169\n",
      "[885/00939] train_loss: 0.011897\n",
      "[885/00989] train_loss: 0.012583\n",
      "[885/01039] train_loss: 0.012912\n",
      "[885/01089] train_loss: 0.012987\n",
      "[885/01139] train_loss: 0.012501\n",
      "[885/01189] train_loss: 0.012246\n",
      "[886/00013] train_loss: 0.012985\n",
      "[886/00063] train_loss: 0.014301\n",
      "[886/00113] train_loss: 0.013864\n",
      "[886/00163] train_loss: 0.013244\n",
      "[886/00213] train_loss: 0.012332\n",
      "[886/00263] train_loss: 0.012671\n",
      "[886/00313] train_loss: 0.012436\n",
      "[886/00363] train_loss: 0.012319\n",
      "[886/00413] train_loss: 0.013267\n",
      "[886/00463] train_loss: 0.012694\n",
      "[886/00513] train_loss: 0.012615\n",
      "[886/00563] train_loss: 0.012301\n",
      "[886/00613] train_loss: 0.011991\n",
      "[886/00663] train_loss: 0.012056\n",
      "[886/00713] train_loss: 0.012104\n",
      "[886/00763] train_loss: 0.012099\n",
      "[886/00813] train_loss: 0.012266\n",
      "[886/00863] train_loss: 0.012405\n",
      "[886/00913] train_loss: 0.012324\n",
      "[886/00963] train_loss: 0.012265\n",
      "[886/01013] train_loss: 0.012912\n",
      "[886/01063] train_loss: 0.012310\n",
      "[886/01113] train_loss: 0.012237\n",
      "[886/01163] train_loss: 0.013058\n",
      "[886/01213] train_loss: 0.013050\n",
      "[887/00037] train_loss: 0.015013\n",
      "[887/00087] train_loss: 0.014997\n",
      "[887/00137] train_loss: 0.013349\n",
      "[887/00187] train_loss: 0.013201\n",
      "[887/00237] train_loss: 0.012794\n",
      "[887/00287] train_loss: 0.011937\n",
      "[887/00337] train_loss: 0.011874\n",
      "[887/00387] train_loss: 0.012187\n",
      "[887/00437] train_loss: 0.012487\n",
      "[887/00487] train_loss: 0.012403\n",
      "[887/00537] train_loss: 0.012452\n",
      "[887/00587] train_loss: 0.012589\n",
      "[887/00637] train_loss: 0.011871\n",
      "[887/00687] train_loss: 0.012636\n",
      "[887/00737] train_loss: 0.012093\n",
      "[887/00787] train_loss: 0.012746\n",
      "[887/00837] train_loss: 0.012098\n",
      "[887/00887] train_loss: 0.012049\n",
      "[887/00937] train_loss: 0.012857\n",
      "[887/00987] train_loss: 0.011974\n",
      "[887/01037] train_loss: 0.012793\n",
      "[887/01087] train_loss: 0.013003\n",
      "[887/01137] train_loss: 0.012825\n",
      "[887/01187] train_loss: 0.012529\n",
      "[888/00011] train_loss: 0.014383\n",
      "[888/00061] train_loss: 0.015201\n",
      "[888/00111] train_loss: 0.013684\n",
      "[888/00161] train_loss: 0.012292\n",
      "[888/00211] train_loss: 0.012249\n",
      "[888/00261] train_loss: 0.012775\n",
      "[888/00311] train_loss: 0.013013\n",
      "[888/00361] train_loss: 0.012721\n",
      "[888/00411] train_loss: 0.012862\n",
      "[888/00461] train_loss: 0.013421\n",
      "[888/00511] train_loss: 0.012719\n",
      "[888/00561] train_loss: 0.012541\n",
      "[888/00611] train_loss: 0.012960\n",
      "[888/00661] train_loss: 0.013000\n",
      "[888/00711] train_loss: 0.012195\n",
      "[888/00761] train_loss: 0.011913\n",
      "[888/00811] train_loss: 0.011984\n",
      "[888/00861] train_loss: 0.012496\n",
      "[888/00911] train_loss: 0.012441\n",
      "[888/00961] train_loss: 0.012368\n",
      "[888/01011] train_loss: 0.012482\n",
      "[888/01061] train_loss: 0.012258\n",
      "[888/01111] train_loss: 0.012656\n",
      "[888/01161] train_loss: 0.012615\n",
      "[888/01211] train_loss: 0.012392\n",
      "[889/00035] train_loss: 0.014672\n",
      "[889/00085] train_loss: 0.014349\n",
      "[889/00135] train_loss: 0.013388\n",
      "[889/00185] train_loss: 0.012493\n",
      "[889/00235] train_loss: 0.012476\n",
      "[889/00285] train_loss: 0.012755\n",
      "[889/00335] train_loss: 0.012678\n",
      "[889/00385] train_loss: 0.012535\n",
      "[889/00435] train_loss: 0.012558\n",
      "[889/00485] train_loss: 0.011744\n",
      "[889/00535] train_loss: 0.013291\n",
      "[889/00585] train_loss: 0.011546\n",
      "[889/00635] train_loss: 0.012187\n",
      "[889/00685] train_loss: 0.012654\n",
      "[889/00735] train_loss: 0.012347\n",
      "[889/00785] train_loss: 0.011919\n",
      "[889/00835] train_loss: 0.012608\n",
      "[889/00885] train_loss: 0.012698\n",
      "[889/00935] train_loss: 0.013032\n",
      "[889/00985] train_loss: 0.012604\n",
      "[889/01035] train_loss: 0.012760\n",
      "[889/01085] train_loss: 0.012578\n",
      "[889/01135] train_loss: 0.012596\n",
      "[889/01185] train_loss: 0.012172\n",
      "[890/00009] train_loss: 0.013143\n",
      "[890/00059] train_loss: 0.015069\n",
      "[890/00109] train_loss: 0.013692\n",
      "[890/00159] train_loss: 0.013265\n",
      "[890/00209] train_loss: 0.012487\n",
      "[890/00259] train_loss: 0.012302\n",
      "[890/00309] train_loss: 0.012685\n",
      "[890/00359] train_loss: 0.012527\n",
      "[890/00409] train_loss: 0.012209\n",
      "[890/00459] train_loss: 0.011802\n",
      "[890/00509] train_loss: 0.012319\n",
      "[890/00559] train_loss: 0.012120\n",
      "[890/00609] train_loss: 0.012160\n",
      "[890/00659] train_loss: 0.012211\n",
      "[890/00709] train_loss: 0.012180\n",
      "[890/00759] train_loss: 0.012828\n",
      "[890/00809] train_loss: 0.012825\n",
      "[890/00859] train_loss: 0.013044\n",
      "[890/00909] train_loss: 0.012832\n",
      "[890/00959] train_loss: 0.012603\n",
      "[890/01009] train_loss: 0.011861\n",
      "[890/01059] train_loss: 0.012431\n",
      "[890/01109] train_loss: 0.013488\n",
      "[890/01159] train_loss: 0.012565\n",
      "[890/01209] train_loss: 0.012791\n",
      "[891/00033] train_loss: 0.014965\n",
      "[891/00083] train_loss: 0.014503\n",
      "[891/00133] train_loss: 0.013479\n",
      "[891/00183] train_loss: 0.012981\n",
      "[891/00233] train_loss: 0.013128\n",
      "[891/00283] train_loss: 0.012996\n",
      "[891/00333] train_loss: 0.012122\n",
      "[891/00383] train_loss: 0.011821\n",
      "[891/00433] train_loss: 0.012523\n",
      "[891/00483] train_loss: 0.012380\n",
      "[891/00533] train_loss: 0.012378\n",
      "[891/00583] train_loss: 0.012140\n",
      "[891/00633] train_loss: 0.012269\n",
      "[891/00683] train_loss: 0.012235\n",
      "[891/00733] train_loss: 0.012585\n",
      "[891/00783] train_loss: 0.012394\n",
      "[891/00833] train_loss: 0.012428\n",
      "[891/00883] train_loss: 0.012545\n",
      "[891/00933] train_loss: 0.012792\n",
      "[891/00983] train_loss: 0.014355\n",
      "[891/01033] train_loss: 0.012598\n",
      "[891/01083] train_loss: 0.012449\n",
      "[891/01133] train_loss: 0.012504\n",
      "[891/01183] train_loss: 0.012915\n",
      "[892/00007] train_loss: 0.013108\n",
      "[892/00057] train_loss: 0.014473\n",
      "[892/00107] train_loss: 0.014132\n",
      "[892/00157] train_loss: 0.013628\n",
      "[892/00207] train_loss: 0.012431\n",
      "[892/00257] train_loss: 0.012471\n",
      "[892/00307] train_loss: 0.012950\n",
      "[892/00357] train_loss: 0.012812\n",
      "[892/00407] train_loss: 0.012507\n",
      "[892/00457] train_loss: 0.011708\n",
      "[892/00507] train_loss: 0.012159\n",
      "[892/00557] train_loss: 0.011599\n",
      "[892/00607] train_loss: 0.011700\n",
      "[892/00657] train_loss: 0.012463\n",
      "[892/00707] train_loss: 0.012345\n",
      "[892/00757] train_loss: 0.012886\n",
      "[892/00807] train_loss: 0.012181\n",
      "[892/00857] train_loss: 0.012729\n",
      "[892/00907] train_loss: 0.012744\n",
      "[892/00957] train_loss: 0.013049\n",
      "[892/01007] train_loss: 0.013536\n",
      "[892/01057] train_loss: 0.013267\n",
      "[892/01107] train_loss: 0.012883\n",
      "[892/01157] train_loss: 0.012519\n",
      "[892/01207] train_loss: 0.012532\n",
      "[893/00031] train_loss: 0.014998\n",
      "[893/00081] train_loss: 0.014406\n",
      "[893/00131] train_loss: 0.014556\n",
      "[893/00181] train_loss: 0.012905\n",
      "[893/00231] train_loss: 0.012545\n",
      "[893/00281] train_loss: 0.012760\n",
      "[893/00331] train_loss: 0.012400\n",
      "[893/00381] train_loss: 0.012525\n",
      "[893/00431] train_loss: 0.011971\n",
      "[893/00481] train_loss: 0.012889\n",
      "[893/00531] train_loss: 0.011919\n",
      "[893/00581] train_loss: 0.012394\n",
      "[893/00631] train_loss: 0.013305\n",
      "[893/00681] train_loss: 0.012199\n",
      "[893/00731] train_loss: 0.011703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[893/00781] train_loss: 0.012389\n",
      "[893/00831] train_loss: 0.012362\n",
      "[893/00881] train_loss: 0.012259\n",
      "[893/00931] train_loss: 0.012794\n",
      "[893/00981] train_loss: 0.012307\n",
      "[893/01031] train_loss: 0.012612\n",
      "[893/01081] train_loss: 0.012324\n",
      "[893/01131] train_loss: 0.013515\n",
      "[893/01181] train_loss: 0.012055\n",
      "[894/00005] train_loss: 0.013000\n",
      "[894/00055] train_loss: 0.015319\n",
      "[894/00105] train_loss: 0.014056\n",
      "[894/00155] train_loss: 0.013250\n",
      "[894/00205] train_loss: 0.012868\n",
      "[894/00255] train_loss: 0.013364\n",
      "[894/00305] train_loss: 0.012140\n",
      "[894/00355] train_loss: 0.012602\n",
      "[894/00405] train_loss: 0.012130\n",
      "[894/00455] train_loss: 0.012397\n",
      "[894/00505] train_loss: 0.012354\n",
      "[894/00555] train_loss: 0.012256\n",
      "[894/00605] train_loss: 0.012653\n",
      "[894/00655] train_loss: 0.012924\n",
      "[894/00705] train_loss: 0.012787\n",
      "[894/00755] train_loss: 0.012551\n",
      "[894/00805] train_loss: 0.012454\n",
      "[894/00855] train_loss: 0.012299\n",
      "[894/00905] train_loss: 0.012624\n",
      "[894/00955] train_loss: 0.012298\n",
      "[894/01005] train_loss: 0.012534\n",
      "[894/01055] train_loss: 0.012252\n",
      "[894/01105] train_loss: 0.012435\n",
      "[894/01155] train_loss: 0.012109\n",
      "[894/01205] train_loss: 0.013551\n",
      "[895/00029] train_loss: 0.015006\n",
      "[895/00079] train_loss: 0.014769\n",
      "[895/00129] train_loss: 0.013567\n",
      "[895/00179] train_loss: 0.012962\n",
      "[895/00229] train_loss: 0.012570\n",
      "[895/00279] train_loss: 0.012908\n",
      "[895/00329] train_loss: 0.012876\n",
      "[895/00379] train_loss: 0.012619\n",
      "[895/00429] train_loss: 0.011891\n",
      "[895/00479] train_loss: 0.012417\n",
      "[895/00529] train_loss: 0.012274\n",
      "[895/00579] train_loss: 0.012772\n",
      "[895/00629] train_loss: 0.012579\n",
      "[895/00679] train_loss: 0.012241\n",
      "[895/00729] train_loss: 0.012076\n",
      "[895/00779] train_loss: 0.012535\n",
      "[895/00829] train_loss: 0.013058\n",
      "[895/00879] train_loss: 0.012889\n",
      "[895/00929] train_loss: 0.013050\n",
      "[895/00979] train_loss: 0.012828\n",
      "[895/01029] train_loss: 0.012364\n",
      "[895/01079] train_loss: 0.012055\n",
      "[895/01129] train_loss: 0.012052\n",
      "[895/01179] train_loss: 0.012707\n",
      "[896/00003] train_loss: 0.012757\n",
      "[896/00053] train_loss: 0.015462\n",
      "[896/00103] train_loss: 0.013645\n",
      "[896/00153] train_loss: 0.013707\n",
      "[896/00203] train_loss: 0.012670\n",
      "[896/00253] train_loss: 0.012735\n",
      "[896/00303] train_loss: 0.012822\n",
      "[896/00353] train_loss: 0.012570\n",
      "[896/00403] train_loss: 0.012279\n",
      "[896/00453] train_loss: 0.012708\n",
      "[896/00503] train_loss: 0.012366\n",
      "[896/00553] train_loss: 0.012373\n",
      "[896/00603] train_loss: 0.012234\n",
      "[896/00653] train_loss: 0.012448\n",
      "[896/00703] train_loss: 0.012490\n",
      "[896/00753] train_loss: 0.011683\n",
      "[896/00803] train_loss: 0.012909\n",
      "[896/00853] train_loss: 0.012462\n",
      "[896/00903] train_loss: 0.012579\n",
      "[896/00953] train_loss: 0.012906\n",
      "[896/01003] train_loss: 0.011949\n",
      "[896/01053] train_loss: 0.012023\n",
      "[896/01103] train_loss: 0.012675\n",
      "[896/01153] train_loss: 0.012434\n",
      "[896/01203] train_loss: 0.012838\n",
      "[897/00027] train_loss: 0.013838\n",
      "[897/00077] train_loss: 0.014673\n",
      "[897/00127] train_loss: 0.013332\n",
      "[897/00177] train_loss: 0.013230\n",
      "[897/00227] train_loss: 0.012923\n",
      "[897/00277] train_loss: 0.011921\n",
      "[897/00327] train_loss: 0.012916\n",
      "[897/00377] train_loss: 0.011774\n",
      "[897/00427] train_loss: 0.012608\n",
      "[897/00477] train_loss: 0.012015\n",
      "[897/00527] train_loss: 0.012111\n",
      "[897/00577] train_loss: 0.012591\n",
      "[897/00627] train_loss: 0.012694\n",
      "[897/00677] train_loss: 0.012274\n",
      "[897/00727] train_loss: 0.012045\n",
      "[897/00777] train_loss: 0.012215\n",
      "[897/00827] train_loss: 0.012768\n",
      "[897/00877] train_loss: 0.012937\n",
      "[897/00927] train_loss: 0.012408\n",
      "[897/00977] train_loss: 0.012597\n",
      "[897/01027] train_loss: 0.013067\n",
      "[897/01077] train_loss: 0.012953\n",
      "[897/01127] train_loss: 0.012505\n",
      "[897/01177] train_loss: 0.012303\n",
      "[898/00001] train_loss: 0.012992\n",
      "[898/00051] train_loss: 0.015953\n",
      "[898/00101] train_loss: 0.013970\n",
      "[898/00151] train_loss: 0.013176\n",
      "[898/00201] train_loss: 0.012984\n",
      "[898/00251] train_loss: 0.012218\n",
      "[898/00301] train_loss: 0.012629\n",
      "[898/00351] train_loss: 0.012606\n",
      "[898/00401] train_loss: 0.012176\n",
      "[898/00451] train_loss: 0.012608\n",
      "[898/00501] train_loss: 0.011851\n",
      "[898/00551] train_loss: 0.011537\n",
      "[898/00601] train_loss: 0.012159\n",
      "[898/00651] train_loss: 0.012754\n",
      "[898/00701] train_loss: 0.012692\n",
      "[898/00751] train_loss: 0.012955\n",
      "[898/00801] train_loss: 0.012301\n",
      "[898/00851] train_loss: 0.013082\n",
      "[898/00901] train_loss: 0.013605\n",
      "[898/00951] train_loss: 0.012515\n",
      "[898/01001] train_loss: 0.013039\n",
      "[898/01051] train_loss: 0.012756\n",
      "[898/01101] train_loss: 0.012969\n",
      "[898/01151] train_loss: 0.012200\n",
      "[898/01201] train_loss: 0.012536\n",
      "[899/00025] train_loss: 0.014174\n",
      "[899/00075] train_loss: 0.015218\n",
      "[899/00125] train_loss: 0.013530\n",
      "[899/00175] train_loss: 0.012538\n",
      "[899/00225] train_loss: 0.012471\n",
      "[899/00275] train_loss: 0.012669\n",
      "[899/00325] train_loss: 0.012582\n",
      "[899/00375] train_loss: 0.012272\n",
      "[899/00425] train_loss: 0.012500\n",
      "[899/00475] train_loss: 0.012516\n",
      "[899/00525] train_loss: 0.012365\n",
      "[899/00575] train_loss: 0.012571\n",
      "[899/00625] train_loss: 0.011545\n",
      "[899/00675] train_loss: 0.011910\n",
      "[899/00725] train_loss: 0.012312\n",
      "[899/00775] train_loss: 0.012620\n",
      "[899/00825] train_loss: 0.012312\n",
      "[899/00875] train_loss: 0.012139\n",
      "[899/00925] train_loss: 0.013113\n",
      "[899/00975] train_loss: 0.012460\n",
      "[899/01025] train_loss: 0.012550\n",
      "[899/01075] train_loss: 0.012908\n",
      "[899/01125] train_loss: 0.012778\n",
      "[899/01175] train_loss: 0.012362\n",
      "[899/01225] train_loss: 0.013208\n",
      "[900/00049] train_loss: 0.015769\n",
      "[900/00099] train_loss: 0.013876\n",
      "[900/00149] train_loss: 0.013234\n",
      "[900/00199] train_loss: 0.012057\n",
      "[900/00249] train_loss: 0.012958\n",
      "[900/00299] train_loss: 0.012492\n",
      "[900/00349] train_loss: 0.012639\n",
      "[900/00399] train_loss: 0.012356\n",
      "[900/00449] train_loss: 0.012491\n",
      "[900/00499] train_loss: 0.012455\n",
      "[900/00549] train_loss: 0.012121\n",
      "[900/00599] train_loss: 0.011928\n",
      "[900/00649] train_loss: 0.012421\n",
      "[900/00699] train_loss: 0.011715\n",
      "[900/00749] train_loss: 0.012939\n",
      "[900/00799] train_loss: 0.013239\n",
      "[900/00849] train_loss: 0.012650\n",
      "[900/00899] train_loss: 0.012543\n",
      "[900/00949] train_loss: 0.013058\n",
      "[900/00999] train_loss: 0.013284\n",
      "[900/01049] train_loss: 0.013029\n",
      "[900/01099] train_loss: 0.012393\n",
      "[900/01149] train_loss: 0.011711\n",
      "[900/01199] train_loss: 0.012816\n",
      "[901/00023] train_loss: 0.014566\n",
      "[901/00073] train_loss: 0.014291\n",
      "[901/00123] train_loss: 0.013899\n",
      "[901/00173] train_loss: 0.012356\n",
      "[901/00223] train_loss: 0.012708\n",
      "[901/00273] train_loss: 0.012433\n",
      "[901/00323] train_loss: 0.012623\n",
      "[901/00373] train_loss: 0.012294\n",
      "[901/00423] train_loss: 0.013758\n",
      "[901/00473] train_loss: 0.013140\n",
      "[901/00523] train_loss: 0.012735\n",
      "[901/00573] train_loss: 0.011926\n",
      "[901/00623] train_loss: 0.011690\n",
      "[901/00673] train_loss: 0.012462\n",
      "[901/00723] train_loss: 0.012298\n",
      "[901/00773] train_loss: 0.012266\n",
      "[901/00823] train_loss: 0.012790\n",
      "[901/00873] train_loss: 0.012042\n",
      "[901/00923] train_loss: 0.012252\n",
      "[901/00973] train_loss: 0.012801\n",
      "[901/01023] train_loss: 0.012478\n",
      "[901/01073] train_loss: 0.011838\n",
      "[901/01123] train_loss: 0.013206\n",
      "[901/01173] train_loss: 0.012434\n",
      "[901/01223] train_loss: 0.013113\n",
      "[902/00047] train_loss: 0.015465\n",
      "[902/00097] train_loss: 0.013488\n",
      "[902/00147] train_loss: 0.013241\n",
      "[902/00197] train_loss: 0.012668\n",
      "[902/00247] train_loss: 0.012868\n",
      "[902/00297] train_loss: 0.012352\n",
      "[902/00347] train_loss: 0.012561\n",
      "[902/00397] train_loss: 0.012440\n",
      "[902/00447] train_loss: 0.012278\n",
      "[902/00497] train_loss: 0.012135\n",
      "[902/00547] train_loss: 0.011865\n",
      "[902/00597] train_loss: 0.012153\n",
      "[902/00647] train_loss: 0.013110\n",
      "[902/00697] train_loss: 0.011583\n",
      "[902/00747] train_loss: 0.012185\n",
      "[902/00797] train_loss: 0.012713\n",
      "[902/00847] train_loss: 0.012381\n",
      "[902/00897] train_loss: 0.012245\n",
      "[902/00947] train_loss: 0.012443\n",
      "[902/00997] train_loss: 0.012581\n",
      "[902/01047] train_loss: 0.013392\n",
      "[902/01097] train_loss: 0.012734\n",
      "[902/01147] train_loss: 0.012828\n",
      "[902/01197] train_loss: 0.012734\n",
      "[903/00021] train_loss: 0.013661\n",
      "[903/00071] train_loss: 0.015037\n",
      "[903/00121] train_loss: 0.013881\n",
      "[903/00171] train_loss: 0.013206\n",
      "[903/00221] train_loss: 0.012322\n",
      "[903/00271] train_loss: 0.012425\n",
      "[903/00321] train_loss: 0.012326\n",
      "[903/00371] train_loss: 0.012551\n",
      "[903/00421] train_loss: 0.012199\n",
      "[903/00471] train_loss: 0.012778\n",
      "[903/00521] train_loss: 0.012238\n",
      "[903/00571] train_loss: 0.012431\n",
      "[903/00621] train_loss: 0.013525\n",
      "[903/00671] train_loss: 0.012813\n",
      "[903/00721] train_loss: 0.012268\n",
      "[903/00771] train_loss: 0.012306\n",
      "[903/00821] train_loss: 0.011906\n",
      "[903/00871] train_loss: 0.012461\n",
      "[903/00921] train_loss: 0.012750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[903/00971] train_loss: 0.012126\n",
      "[903/01021] train_loss: 0.012432\n",
      "[903/01071] train_loss: 0.012535\n",
      "[903/01121] train_loss: 0.012064\n",
      "[903/01171] train_loss: 0.012331\n",
      "[903/01221] train_loss: 0.012568\n",
      "[904/00045] train_loss: 0.015047\n",
      "[904/00095] train_loss: 0.014870\n",
      "[904/00145] train_loss: 0.012980\n",
      "[904/00195] train_loss: 0.013185\n",
      "[904/00245] train_loss: 0.012401\n",
      "[904/00295] train_loss: 0.012100\n",
      "[904/00345] train_loss: 0.012676\n",
      "[904/00395] train_loss: 0.012887\n",
      "[904/00445] train_loss: 0.012478\n",
      "[904/00495] train_loss: 0.012808\n",
      "[904/00545] train_loss: 0.013099\n",
      "[904/00595] train_loss: 0.012234\n",
      "[904/00645] train_loss: 0.012507\n",
      "[904/00695] train_loss: 0.012887\n",
      "[904/00745] train_loss: 0.013035\n",
      "[904/00795] train_loss: 0.011959\n",
      "[904/00845] train_loss: 0.012551\n",
      "[904/00895] train_loss: 0.012295\n",
      "[904/00945] train_loss: 0.012485\n",
      "[904/00995] train_loss: 0.012124\n",
      "[904/01045] train_loss: 0.012774\n",
      "[904/01095] train_loss: 0.012434\n",
      "[904/01145] train_loss: 0.012648\n",
      "[904/01195] train_loss: 0.012135\n",
      "[905/00019] train_loss: 0.013307\n",
      "[905/00069] train_loss: 0.014925\n",
      "[905/00119] train_loss: 0.013619\n",
      "[905/00169] train_loss: 0.013454\n",
      "[905/00219] train_loss: 0.013963\n",
      "[905/00269] train_loss: 0.012656\n",
      "[905/00319] train_loss: 0.011998\n",
      "[905/00369] train_loss: 0.012192\n",
      "[905/00419] train_loss: 0.012902\n",
      "[905/00469] train_loss: 0.011817\n",
      "[905/00519] train_loss: 0.012452\n",
      "[905/00569] train_loss: 0.012447\n",
      "[905/00619] train_loss: 0.012930\n",
      "[905/00669] train_loss: 0.012665\n",
      "[905/00719] train_loss: 0.011855\n",
      "[905/00769] train_loss: 0.012191\n",
      "[905/00819] train_loss: 0.012135\n",
      "[905/00869] train_loss: 0.012637\n",
      "[905/00919] train_loss: 0.012634\n",
      "[905/00969] train_loss: 0.011930\n",
      "[905/01019] train_loss: 0.012567\n",
      "[905/01069] train_loss: 0.012470\n",
      "[905/01119] train_loss: 0.013121\n",
      "[905/01169] train_loss: 0.012913\n",
      "[905/01219] train_loss: 0.012629\n",
      "[906/00043] train_loss: 0.015727\n",
      "[906/00093] train_loss: 0.014187\n",
      "[906/00143] train_loss: 0.012802\n",
      "[906/00193] train_loss: 0.012736\n",
      "[906/00243] train_loss: 0.013406\n",
      "[906/00293] train_loss: 0.012157\n",
      "[906/00343] train_loss: 0.012543\n",
      "[906/00393] train_loss: 0.012618\n",
      "[906/00443] train_loss: 0.012136\n",
      "[906/00493] train_loss: 0.011585\n",
      "[906/00543] train_loss: 0.012723\n",
      "[906/00593] train_loss: 0.012732\n",
      "[906/00643] train_loss: 0.012691\n",
      "[906/00693] train_loss: 0.013080\n",
      "[906/00743] train_loss: 0.012041\n",
      "[906/00793] train_loss: 0.012613\n",
      "[906/00843] train_loss: 0.012911\n",
      "[906/00893] train_loss: 0.012334\n",
      "[906/00943] train_loss: 0.012600\n",
      "[906/00993] train_loss: 0.012925\n",
      "[906/01043] train_loss: 0.012600\n",
      "[906/01093] train_loss: 0.011985\n",
      "[906/01143] train_loss: 0.012767\n",
      "[906/01193] train_loss: 0.013011\n",
      "[907/00017] train_loss: 0.013449\n",
      "[907/00067] train_loss: 0.015418\n",
      "[907/00117] train_loss: 0.013778\n",
      "[907/00167] train_loss: 0.013832\n",
      "[907/00217] train_loss: 0.012396\n",
      "[907/00267] train_loss: 0.012676\n",
      "[907/00317] train_loss: 0.011999\n",
      "[907/00367] train_loss: 0.012582\n",
      "[907/00417] train_loss: 0.011699\n",
      "[907/00467] train_loss: 0.012751\n",
      "[907/00517] train_loss: 0.012912\n",
      "[907/00567] train_loss: 0.012471\n",
      "[907/00617] train_loss: 0.011825\n",
      "[907/00667] train_loss: 0.012396\n",
      "[907/00717] train_loss: 0.012897\n",
      "[907/00767] train_loss: 0.011903\n",
      "[907/00817] train_loss: 0.012972\n",
      "[907/00867] train_loss: 0.013163\n",
      "[907/00917] train_loss: 0.012925\n",
      "[907/00967] train_loss: 0.012757\n",
      "[907/01017] train_loss: 0.012759\n",
      "[907/01067] train_loss: 0.011777\n",
      "[907/01117] train_loss: 0.012043\n",
      "[907/01167] train_loss: 0.012235\n",
      "[907/01217] train_loss: 0.012969\n",
      "[908/00041] train_loss: 0.014913\n",
      "[908/00091] train_loss: 0.014110\n",
      "[908/00141] train_loss: 0.013090\n",
      "[908/00191] train_loss: 0.012333\n",
      "[908/00241] train_loss: 0.012682\n",
      "[908/00291] train_loss: 0.012145\n",
      "[908/00341] train_loss: 0.013163\n",
      "[908/00391] train_loss: 0.011837\n",
      "[908/00441] train_loss: 0.012593\n",
      "[908/00491] train_loss: 0.011725\n",
      "[908/00541] train_loss: 0.012690\n",
      "[908/00591] train_loss: 0.012714\n",
      "[908/00641] train_loss: 0.011874\n",
      "[908/00691] train_loss: 0.012405\n",
      "[908/00741] train_loss: 0.012618\n",
      "[908/00791] train_loss: 0.012371\n",
      "[908/00841] train_loss: 0.012282\n",
      "[908/00891] train_loss: 0.012588\n",
      "[908/00941] train_loss: 0.012648\n",
      "[908/00991] train_loss: 0.012764\n",
      "[908/01041] train_loss: 0.012350\n",
      "[908/01091] train_loss: 0.012891\n",
      "[908/01141] train_loss: 0.012676\n",
      "[908/01191] train_loss: 0.013630\n",
      "[909/00015] train_loss: 0.012772\n",
      "[909/00065] train_loss: 0.015294\n",
      "[909/00115] train_loss: 0.014113\n",
      "[909/00165] train_loss: 0.012632\n",
      "[909/00215] train_loss: 0.012567\n",
      "[909/00265] train_loss: 0.012628\n",
      "[909/00315] train_loss: 0.013004\n",
      "[909/00365] train_loss: 0.012187\n",
      "[909/00415] train_loss: 0.012821\n",
      "[909/00465] train_loss: 0.012575\n",
      "[909/00515] train_loss: 0.011661\n",
      "[909/00565] train_loss: 0.012663\n",
      "[909/00615] train_loss: 0.011786\n",
      "[909/00665] train_loss: 0.011974\n",
      "[909/00715] train_loss: 0.013206\n",
      "[909/00765] train_loss: 0.012485\n",
      "[909/00815] train_loss: 0.012776\n",
      "[909/00865] train_loss: 0.012509\n",
      "[909/00915] train_loss: 0.012046\n",
      "[909/00965] train_loss: 0.012344\n",
      "[909/01015] train_loss: 0.013165\n",
      "[909/01065] train_loss: 0.011810\n",
      "[909/01115] train_loss: 0.012778\n",
      "[909/01165] train_loss: 0.011966\n",
      "[909/01215] train_loss: 0.012470\n",
      "[910/00039] train_loss: 0.015345\n",
      "[910/00089] train_loss: 0.015171\n",
      "[910/00139] train_loss: 0.013422\n",
      "[910/00189] train_loss: 0.012975\n",
      "[910/00239] train_loss: 0.012428\n",
      "[910/00289] train_loss: 0.012564\n",
      "[910/00339] train_loss: 0.012095\n",
      "[910/00389] train_loss: 0.013631\n",
      "[910/00439] train_loss: 0.012252\n",
      "[910/00489] train_loss: 0.012667\n",
      "[910/00539] train_loss: 0.011701\n",
      "[910/00589] train_loss: 0.012544\n",
      "[910/00639] train_loss: 0.012510\n",
      "[910/00689] train_loss: 0.012631\n",
      "[910/00739] train_loss: 0.012137\n",
      "[910/00789] train_loss: 0.012108\n",
      "[910/00839] train_loss: 0.012778\n",
      "[910/00889] train_loss: 0.012457\n",
      "[910/00939] train_loss: 0.012975\n",
      "[910/00989] train_loss: 0.012545\n",
      "[910/01039] train_loss: 0.012287\n",
      "[910/01089] train_loss: 0.012332\n",
      "[910/01139] train_loss: 0.012628\n",
      "[910/01189] train_loss: 0.012015\n",
      "[911/00013] train_loss: 0.013909\n",
      "[911/00063] train_loss: 0.014281\n",
      "[911/00113] train_loss: 0.014567\n",
      "[911/00163] train_loss: 0.012644\n",
      "[911/00213] train_loss: 0.012403\n",
      "[911/00263] train_loss: 0.012605\n",
      "[911/00313] train_loss: 0.011992\n",
      "[911/00363] train_loss: 0.013086\n",
      "[911/00413] train_loss: 0.012954\n",
      "[911/00463] train_loss: 0.012800\n",
      "[911/00513] train_loss: 0.012098\n",
      "[911/00563] train_loss: 0.012684\n",
      "[911/00613] train_loss: 0.012761\n",
      "[911/00663] train_loss: 0.012256\n",
      "[911/00713] train_loss: 0.011969\n",
      "[911/00763] train_loss: 0.012761\n",
      "[911/00813] train_loss: 0.011823\n",
      "[911/00863] train_loss: 0.012921\n",
      "[911/00913] train_loss: 0.012400\n",
      "[911/00963] train_loss: 0.012684\n",
      "[911/01013] train_loss: 0.013309\n",
      "[911/01063] train_loss: 0.012134\n",
      "[911/01113] train_loss: 0.012658\n",
      "[911/01163] train_loss: 0.012312\n",
      "[911/01213] train_loss: 0.012307\n",
      "[912/00037] train_loss: 0.014356\n",
      "[912/00087] train_loss: 0.014087\n",
      "[912/00137] train_loss: 0.013116\n",
      "[912/00187] train_loss: 0.012775\n",
      "[912/00237] train_loss: 0.012154\n",
      "[912/00287] train_loss: 0.012654\n",
      "[912/00337] train_loss: 0.012323\n",
      "[912/00387] train_loss: 0.012565\n",
      "[912/00437] train_loss: 0.012295\n",
      "[912/00487] train_loss: 0.011998\n",
      "[912/00537] train_loss: 0.012633\n",
      "[912/00587] train_loss: 0.013226\n",
      "[912/00637] train_loss: 0.013239\n",
      "[912/00687] train_loss: 0.012534\n",
      "[912/00737] train_loss: 0.011956\n",
      "[912/00787] train_loss: 0.011845\n",
      "[912/00837] train_loss: 0.012028\n",
      "[912/00887] train_loss: 0.012120\n",
      "[912/00937] train_loss: 0.012423\n",
      "[912/00987] train_loss: 0.012950\n",
      "[912/01037] train_loss: 0.013030\n",
      "[912/01087] train_loss: 0.012535\n",
      "[912/01137] train_loss: 0.012582\n",
      "[912/01187] train_loss: 0.013225\n",
      "[913/00011] train_loss: 0.013746\n",
      "[913/00061] train_loss: 0.014985\n",
      "[913/00111] train_loss: 0.013916\n",
      "[913/00161] train_loss: 0.012577\n",
      "[913/00211] train_loss: 0.013045\n",
      "[913/00261] train_loss: 0.012820\n",
      "[913/00311] train_loss: 0.012650\n",
      "[913/00361] train_loss: 0.012203\n",
      "[913/00411] train_loss: 0.012831\n",
      "[913/00461] train_loss: 0.012248\n",
      "[913/00511] train_loss: 0.011807\n",
      "[913/00561] train_loss: 0.012855\n",
      "[913/00611] train_loss: 0.012208\n",
      "[913/00661] train_loss: 0.012478\n",
      "[913/00711] train_loss: 0.012537\n",
      "[913/00761] train_loss: 0.012558\n",
      "[913/00811] train_loss: 0.011898\n",
      "[913/00861] train_loss: 0.012497\n",
      "[913/00911] train_loss: 0.012766\n",
      "[913/00961] train_loss: 0.013476\n",
      "[913/01011] train_loss: 0.013052\n",
      "[913/01061] train_loss: 0.012783\n",
      "[913/01111] train_loss: 0.011822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[913/01161] train_loss: 0.012605\n",
      "[913/01211] train_loss: 0.012645\n",
      "[914/00035] train_loss: 0.014557\n",
      "[914/00085] train_loss: 0.014494\n",
      "[914/00135] train_loss: 0.014059\n",
      "[914/00185] train_loss: 0.013465\n",
      "[914/00235] train_loss: 0.012916\n",
      "[914/00285] train_loss: 0.012331\n",
      "[914/00335] train_loss: 0.012519\n",
      "[914/00385] train_loss: 0.012559\n",
      "[914/00435] train_loss: 0.012201\n",
      "[914/00485] train_loss: 0.013126\n",
      "[914/00535] train_loss: 0.012703\n",
      "[914/00585] train_loss: 0.012232\n",
      "[914/00635] train_loss: 0.012799\n",
      "[914/00685] train_loss: 0.012823\n",
      "[914/00735] train_loss: 0.011770\n",
      "[914/00785] train_loss: 0.012130\n",
      "[914/00835] train_loss: 0.011706\n",
      "[914/00885] train_loss: 0.013307\n",
      "[914/00935] train_loss: 0.012496\n",
      "[914/00985] train_loss: 0.012362\n",
      "[914/01035] train_loss: 0.012609\n",
      "[914/01085] train_loss: 0.012006\n",
      "[914/01135] train_loss: 0.012160\n",
      "[914/01185] train_loss: 0.012702\n",
      "[915/00009] train_loss: 0.012776\n",
      "[915/00059] train_loss: 0.014366\n",
      "[915/00109] train_loss: 0.013605\n",
      "[915/00159] train_loss: 0.013617\n",
      "[915/00209] train_loss: 0.012525\n",
      "[915/00259] train_loss: 0.012483\n",
      "[915/00309] train_loss: 0.012734\n",
      "[915/00359] train_loss: 0.012107\n",
      "[915/00409] train_loss: 0.012567\n",
      "[915/00459] train_loss: 0.012987\n",
      "[915/00509] train_loss: 0.012883\n",
      "[915/00559] train_loss: 0.012238\n",
      "[915/00609] train_loss: 0.012575\n",
      "[915/00659] train_loss: 0.012854\n",
      "[915/00709] train_loss: 0.012414\n",
      "[915/00759] train_loss: 0.012982\n",
      "[915/00809] train_loss: 0.010875\n",
      "[915/00859] train_loss: 0.012578\n",
      "[915/00909] train_loss: 0.012170\n",
      "[915/00959] train_loss: 0.013165\n",
      "[915/01009] train_loss: 0.012596\n",
      "[915/01059] train_loss: 0.013178\n",
      "[915/01109] train_loss: 0.012840\n",
      "[915/01159] train_loss: 0.012744\n",
      "[915/01209] train_loss: 0.012109\n",
      "[916/00033] train_loss: 0.013851\n",
      "[916/00083] train_loss: 0.014770\n",
      "[916/00133] train_loss: 0.013446\n",
      "[916/00183] train_loss: 0.013636\n",
      "[916/00233] train_loss: 0.012633\n",
      "[916/00283] train_loss: 0.013183\n",
      "[916/00333] train_loss: 0.012694\n",
      "[916/00383] train_loss: 0.011863\n",
      "[916/00433] train_loss: 0.012881\n",
      "[916/00483] train_loss: 0.012378\n",
      "[916/00533] train_loss: 0.012178\n",
      "[916/00583] train_loss: 0.013169\n",
      "[916/00633] train_loss: 0.012634\n",
      "[916/00683] train_loss: 0.012328\n",
      "[916/00733] train_loss: 0.011691\n",
      "[916/00783] train_loss: 0.012075\n",
      "[916/00833] train_loss: 0.012902\n",
      "[916/00883] train_loss: 0.011957\n",
      "[916/00933] train_loss: 0.012019\n",
      "[916/00983] train_loss: 0.012675\n",
      "[916/01033] train_loss: 0.011972\n",
      "[916/01083] train_loss: 0.012752\n",
      "[916/01133] train_loss: 0.012077\n",
      "[916/01183] train_loss: 0.011795\n",
      "[917/00007] train_loss: 0.013604\n",
      "[917/00057] train_loss: 0.015184\n",
      "[917/00107] train_loss: 0.013978\n",
      "[917/00157] train_loss: 0.012886\n",
      "[917/00207] train_loss: 0.013259\n",
      "[917/00257] train_loss: 0.011789\n",
      "[917/00307] train_loss: 0.012729\n",
      "[917/00357] train_loss: 0.012568\n",
      "[917/00407] train_loss: 0.012511\n",
      "[917/00457] train_loss: 0.012218\n",
      "[917/00507] train_loss: 0.012028\n",
      "[917/00557] train_loss: 0.012066\n",
      "[917/00607] train_loss: 0.012501\n",
      "[917/00657] train_loss: 0.011890\n",
      "[917/00707] train_loss: 0.011915\n",
      "[917/00757] train_loss: 0.012476\n",
      "[917/00807] train_loss: 0.012642\n",
      "[917/00857] train_loss: 0.012762\n",
      "[917/00907] train_loss: 0.012358\n",
      "[917/00957] train_loss: 0.012408\n",
      "[917/01007] train_loss: 0.012892\n",
      "[917/01057] train_loss: 0.012480\n",
      "[917/01107] train_loss: 0.013095\n",
      "[917/01157] train_loss: 0.012253\n",
      "[917/01207] train_loss: 0.012955\n",
      "[918/00031] train_loss: 0.014604\n",
      "[918/00081] train_loss: 0.015048\n",
      "[918/00131] train_loss: 0.013732\n",
      "[918/00181] train_loss: 0.012247\n",
      "[918/00231] train_loss: 0.013025\n",
      "[918/00281] train_loss: 0.013088\n",
      "[918/00331] train_loss: 0.012365\n",
      "[918/00381] train_loss: 0.011802\n",
      "[918/00431] train_loss: 0.012622\n",
      "[918/00481] train_loss: 0.012363\n",
      "[918/00531] train_loss: 0.012463\n",
      "[918/00581] train_loss: 0.012196\n",
      "[918/00631] train_loss: 0.011062\n",
      "[918/00681] train_loss: 0.013114\n",
      "[918/00731] train_loss: 0.012166\n",
      "[918/00781] train_loss: 0.012149\n",
      "[918/00831] train_loss: 0.012831\n",
      "[918/00881] train_loss: 0.012529\n",
      "[918/00931] train_loss: 0.011939\n",
      "[918/00981] train_loss: 0.012507\n",
      "[918/01031] train_loss: 0.012714\n",
      "[918/01081] train_loss: 0.011433\n",
      "[918/01131] train_loss: 0.012619\n",
      "[918/01181] train_loss: 0.013073\n",
      "[919/00005] train_loss: 0.013311\n",
      "[919/00055] train_loss: 0.014527\n",
      "[919/00105] train_loss: 0.014364\n",
      "[919/00155] train_loss: 0.012811\n",
      "[919/00205] train_loss: 0.012874\n",
      "[919/00255] train_loss: 0.012069\n",
      "[919/00305] train_loss: 0.012278\n",
      "[919/00355] train_loss: 0.012314\n",
      "[919/00405] train_loss: 0.013101\n",
      "[919/00455] train_loss: 0.012798\n",
      "[919/00505] train_loss: 0.012472\n",
      "[919/00555] train_loss: 0.012271\n",
      "[919/00605] train_loss: 0.012596\n",
      "[919/00655] train_loss: 0.012270\n",
      "[919/00705] train_loss: 0.011884\n",
      "[919/00755] train_loss: 0.013095\n",
      "[919/00805] train_loss: 0.012483\n",
      "[919/00855] train_loss: 0.012191\n",
      "[919/00905] train_loss: 0.012486\n",
      "[919/00955] train_loss: 0.013342\n",
      "[919/01005] train_loss: 0.012246\n",
      "[919/01055] train_loss: 0.013155\n",
      "[919/01105] train_loss: 0.011932\n",
      "[919/01155] train_loss: 0.012869\n",
      "[919/01205] train_loss: 0.013145\n",
      "[920/00029] train_loss: 0.014069\n",
      "[920/00079] train_loss: 0.014445\n",
      "[920/00129] train_loss: 0.013568\n",
      "[920/00179] train_loss: 0.013194\n",
      "[920/00229] train_loss: 0.012251\n",
      "[920/00279] train_loss: 0.012505\n",
      "[920/00329] train_loss: 0.011843\n",
      "[920/00379] train_loss: 0.012831\n",
      "[920/00429] train_loss: 0.012902\n",
      "[920/00479] train_loss: 0.012266\n",
      "[920/00529] train_loss: 0.012491\n",
      "[920/00579] train_loss: 0.012190\n",
      "[920/00629] train_loss: 0.012249\n",
      "[920/00679] train_loss: 0.012011\n",
      "[920/00729] train_loss: 0.013212\n",
      "[920/00779] train_loss: 0.012101\n",
      "[920/00829] train_loss: 0.012400\n",
      "[920/00879] train_loss: 0.011976\n",
      "[920/00929] train_loss: 0.012760\n",
      "[920/00979] train_loss: 0.012388\n",
      "[920/01029] train_loss: 0.013670\n",
      "[920/01079] train_loss: 0.012956\n",
      "[920/01129] train_loss: 0.012380\n",
      "[920/01179] train_loss: 0.013366\n",
      "[921/00003] train_loss: 0.012642\n",
      "[921/00053] train_loss: 0.014710\n",
      "[921/00103] train_loss: 0.013907\n",
      "[921/00153] train_loss: 0.013230\n",
      "[921/00203] train_loss: 0.012616\n",
      "[921/00253] train_loss: 0.012422\n",
      "[921/00303] train_loss: 0.012851\n",
      "[921/00353] train_loss: 0.012041\n",
      "[921/00403] train_loss: 0.012733\n",
      "[921/00453] train_loss: 0.012437\n",
      "[921/00503] train_loss: 0.012469\n",
      "[921/00553] train_loss: 0.012561\n",
      "[921/00603] train_loss: 0.011665\n",
      "[921/00653] train_loss: 0.012409\n",
      "[921/00703] train_loss: 0.013007\n",
      "[921/00753] train_loss: 0.011965\n",
      "[921/00803] train_loss: 0.013393\n",
      "[921/00853] train_loss: 0.012981\n",
      "[921/00903] train_loss: 0.012005\n",
      "[921/00953] train_loss: 0.012968\n",
      "[921/01003] train_loss: 0.012835\n",
      "[921/01053] train_loss: 0.011898\n",
      "[921/01103] train_loss: 0.012745\n",
      "[921/01153] train_loss: 0.012247\n",
      "[921/01203] train_loss: 0.013032\n",
      "[922/00027] train_loss: 0.014392\n",
      "[922/00077] train_loss: 0.015337\n",
      "[922/00127] train_loss: 0.014049\n",
      "[922/00177] train_loss: 0.013043\n",
      "[922/00227] train_loss: 0.012425\n",
      "[922/00277] train_loss: 0.012331\n",
      "[922/00327] train_loss: 0.012670\n",
      "[922/00377] train_loss: 0.012328\n",
      "[922/00427] train_loss: 0.012553\n",
      "[922/00477] train_loss: 0.012331\n",
      "[922/00527] train_loss: 0.012752\n",
      "[922/00577] train_loss: 0.012693\n",
      "[922/00627] train_loss: 0.012627\n",
      "[922/00677] train_loss: 0.012185\n",
      "[922/00727] train_loss: 0.012966\n",
      "[922/00777] train_loss: 0.011754\n",
      "[922/00827] train_loss: 0.011689\n",
      "[922/00877] train_loss: 0.012535\n",
      "[922/00927] train_loss: 0.012681\n",
      "[922/00977] train_loss: 0.011534\n",
      "[922/01027] train_loss: 0.012312\n",
      "[922/01077] train_loss: 0.012405\n",
      "[922/01127] train_loss: 0.012756\n",
      "[922/01177] train_loss: 0.012154\n",
      "[923/00001] train_loss: 0.012452\n",
      "[923/00051] train_loss: 0.015902\n",
      "[923/00101] train_loss: 0.014004\n",
      "[923/00151] train_loss: 0.013861\n",
      "[923/00201] train_loss: 0.012664\n",
      "[923/00251] train_loss: 0.012623\n",
      "[923/00301] train_loss: 0.012316\n",
      "[923/00351] train_loss: 0.012056\n",
      "[923/00401] train_loss: 0.012040\n",
      "[923/00451] train_loss: 0.011887\n",
      "[923/00501] train_loss: 0.013198\n",
      "[923/00551] train_loss: 0.012968\n",
      "[923/00601] train_loss: 0.012799\n",
      "[923/00651] train_loss: 0.012097\n",
      "[923/00701] train_loss: 0.012489\n",
      "[923/00751] train_loss: 0.012290\n",
      "[923/00801] train_loss: 0.012240\n",
      "[923/00851] train_loss: 0.012059\n",
      "[923/00901] train_loss: 0.012035\n",
      "[923/00951] train_loss: 0.012935\n",
      "[923/01001] train_loss: 0.013132\n",
      "[923/01051] train_loss: 0.011990\n",
      "[923/01101] train_loss: 0.011640\n",
      "[923/01151] train_loss: 0.013033\n",
      "[923/01201] train_loss: 0.012347\n",
      "[924/00025] train_loss: 0.014849\n",
      "[924/00075] train_loss: 0.014570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[924/00125] train_loss: 0.013295\n",
      "[924/00175] train_loss: 0.012766\n",
      "[924/00225] train_loss: 0.013328\n",
      "[924/00275] train_loss: 0.013114\n",
      "[924/00325] train_loss: 0.012271\n",
      "[924/00375] train_loss: 0.012858\n",
      "[924/00425] train_loss: 0.012088\n",
      "[924/00475] train_loss: 0.013471\n",
      "[924/00525] train_loss: 0.012488\n",
      "[924/00575] train_loss: 0.012316\n",
      "[924/00625] train_loss: 0.013292\n",
      "[924/00675] train_loss: 0.011907\n",
      "[924/00725] train_loss: 0.011949\n",
      "[924/00775] train_loss: 0.012824\n",
      "[924/00825] train_loss: 0.012324\n",
      "[924/00875] train_loss: 0.012784\n",
      "[924/00925] train_loss: 0.012395\n",
      "[924/00975] train_loss: 0.012622\n",
      "[924/01025] train_loss: 0.012496\n",
      "[924/01075] train_loss: 0.012242\n",
      "[924/01125] train_loss: 0.012034\n",
      "[924/01175] train_loss: 0.012420\n",
      "[924/01225] train_loss: 0.012099\n",
      "[925/00049] train_loss: 0.014949\n",
      "[925/00099] train_loss: 0.013672\n",
      "[925/00149] train_loss: 0.013478\n",
      "[925/00199] train_loss: 0.012652\n",
      "[925/00249] train_loss: 0.012633\n",
      "[925/00299] train_loss: 0.012710\n",
      "[925/00349] train_loss: 0.012799\n",
      "[925/00399] train_loss: 0.012335\n",
      "[925/00449] train_loss: 0.012544\n",
      "[925/00499] train_loss: 0.012288\n",
      "[925/00549] train_loss: 0.013181\n",
      "[925/00599] train_loss: 0.011527\n",
      "[925/00649] train_loss: 0.012213\n",
      "[925/00699] train_loss: 0.012336\n",
      "[925/00749] train_loss: 0.013122\n",
      "[925/00799] train_loss: 0.011748\n",
      "[925/00849] train_loss: 0.012832\n",
      "[925/00899] train_loss: 0.012723\n",
      "[925/00949] train_loss: 0.012654\n",
      "[925/00999] train_loss: 0.012762\n",
      "[925/01049] train_loss: 0.011825\n",
      "[925/01099] train_loss: 0.012561\n",
      "[925/01149] train_loss: 0.013767\n",
      "[925/01199] train_loss: 0.012508\n",
      "[926/00023] train_loss: 0.013531\n",
      "[926/00073] train_loss: 0.014301\n",
      "[926/00123] train_loss: 0.013903\n",
      "[926/00173] train_loss: 0.012668\n",
      "[926/00223] train_loss: 0.012082\n",
      "[926/00273] train_loss: 0.012365\n",
      "[926/00323] train_loss: 0.011811\n",
      "[926/00373] train_loss: 0.013555\n",
      "[926/00423] train_loss: 0.012321\n",
      "[926/00473] train_loss: 0.012405\n",
      "[926/00523] train_loss: 0.012714\n",
      "[926/00573] train_loss: 0.012279\n",
      "[926/00623] train_loss: 0.012656\n",
      "[926/00673] train_loss: 0.011851\n",
      "[926/00723] train_loss: 0.012939\n",
      "[926/00773] train_loss: 0.011806\n",
      "[926/00823] train_loss: 0.012835\n",
      "[926/00873] train_loss: 0.012922\n",
      "[926/00923] train_loss: 0.012727\n",
      "[926/00973] train_loss: 0.012144\n",
      "[926/01023] train_loss: 0.012221\n",
      "[926/01073] train_loss: 0.012574\n",
      "[926/01123] train_loss: 0.012881\n",
      "[926/01173] train_loss: 0.013003\n",
      "[926/01223] train_loss: 0.013064\n",
      "[927/00047] train_loss: 0.014679\n",
      "[927/00097] train_loss: 0.013847\n",
      "[927/00147] train_loss: 0.013083\n",
      "[927/00197] train_loss: 0.013163\n",
      "[927/00247] train_loss: 0.012378\n",
      "[927/00297] train_loss: 0.013018\n",
      "[927/00347] train_loss: 0.011196\n",
      "[927/00397] train_loss: 0.012054\n",
      "[927/00447] train_loss: 0.012779\n",
      "[927/00497] train_loss: 0.011939\n",
      "[927/00547] train_loss: 0.012836\n",
      "[927/00597] train_loss: 0.012345\n",
      "[927/00647] train_loss: 0.012198\n",
      "[927/00697] train_loss: 0.012161\n",
      "[927/00747] train_loss: 0.012768\n",
      "[927/00797] train_loss: 0.011778\n",
      "[927/00847] train_loss: 0.013121\n",
      "[927/00897] train_loss: 0.012476\n",
      "[927/00947] train_loss: 0.012270\n",
      "[927/00997] train_loss: 0.012929\n",
      "[927/01047] train_loss: 0.012249\n",
      "[927/01097] train_loss: 0.012781\n",
      "[927/01147] train_loss: 0.012077\n",
      "[927/01197] train_loss: 0.012138\n",
      "[928/00021] train_loss: 0.014244\n",
      "[928/00071] train_loss: 0.014778\n",
      "[928/00121] train_loss: 0.013481\n",
      "[928/00171] train_loss: 0.012592\n",
      "[928/00221] train_loss: 0.013007\n",
      "[928/00271] train_loss: 0.012950\n",
      "[928/00321] train_loss: 0.013033\n",
      "[928/00371] train_loss: 0.012781\n",
      "[928/00421] train_loss: 0.012581\n",
      "[928/00471] train_loss: 0.012291\n",
      "[928/00521] train_loss: 0.011991\n",
      "[928/00571] train_loss: 0.012574\n",
      "[928/00621] train_loss: 0.013211\n",
      "[928/00671] train_loss: 0.012271\n",
      "[928/00721] train_loss: 0.012677\n",
      "[928/00771] train_loss: 0.012555\n",
      "[928/00821] train_loss: 0.012784\n",
      "[928/00871] train_loss: 0.011993\n",
      "[928/00921] train_loss: 0.012757\n",
      "[928/00971] train_loss: 0.012477\n",
      "[928/01021] train_loss: 0.011967\n",
      "[928/01071] train_loss: 0.011955\n",
      "[928/01121] train_loss: 0.012419\n",
      "[928/01171] train_loss: 0.012425\n",
      "[928/01221] train_loss: 0.012997\n",
      "[929/00045] train_loss: 0.015173\n",
      "[929/00095] train_loss: 0.014054\n",
      "[929/00145] train_loss: 0.013510\n",
      "[929/00195] train_loss: 0.013264\n",
      "[929/00245] train_loss: 0.012788\n",
      "[929/00295] train_loss: 0.013422\n",
      "[929/00345] train_loss: 0.012722\n",
      "[929/00395] train_loss: 0.012042\n",
      "[929/00445] train_loss: 0.011962\n",
      "[929/00495] train_loss: 0.012039\n",
      "[929/00545] train_loss: 0.013177\n",
      "[929/00595] train_loss: 0.012181\n",
      "[929/00645] train_loss: 0.012696\n",
      "[929/00695] train_loss: 0.012808\n",
      "[929/00745] train_loss: 0.012189\n",
      "[929/00795] train_loss: 0.012240\n",
      "[929/00845] train_loss: 0.012171\n",
      "[929/00895] train_loss: 0.012080\n",
      "[929/00945] train_loss: 0.013125\n",
      "[929/00995] train_loss: 0.011801\n",
      "[929/01045] train_loss: 0.012715\n",
      "[929/01095] train_loss: 0.012967\n",
      "[929/01145] train_loss: 0.012656\n",
      "[929/01195] train_loss: 0.012347\n",
      "[930/00019] train_loss: 0.013429\n",
      "[930/00069] train_loss: 0.015537\n",
      "[930/00119] train_loss: 0.013799\n",
      "[930/00169] train_loss: 0.013215\n",
      "[930/00219] train_loss: 0.012448\n",
      "[930/00269] train_loss: 0.012240\n",
      "[930/00319] train_loss: 0.012459\n",
      "[930/00369] train_loss: 0.013128\n",
      "[930/00419] train_loss: 0.012235\n",
      "[930/00469] train_loss: 0.011772\n",
      "[930/00519] train_loss: 0.012585\n",
      "[930/00569] train_loss: 0.012364\n",
      "[930/00619] train_loss: 0.012486\n",
      "[930/00669] train_loss: 0.012684\n",
      "[930/00719] train_loss: 0.012244\n",
      "[930/00769] train_loss: 0.011283\n",
      "[930/00819] train_loss: 0.012746\n",
      "[930/00869] train_loss: 0.012217\n",
      "[930/00919] train_loss: 0.012295\n",
      "[930/00969] train_loss: 0.012612\n",
      "[930/01019] train_loss: 0.013221\n",
      "[930/01069] train_loss: 0.011818\n",
      "[930/01119] train_loss: 0.013101\n",
      "[930/01169] train_loss: 0.012717\n",
      "[930/01219] train_loss: 0.012833\n",
      "[931/00043] train_loss: 0.014959\n",
      "[931/00093] train_loss: 0.014660\n",
      "[931/00143] train_loss: 0.013111\n",
      "[931/00193] train_loss: 0.012801\n",
      "[931/00243] train_loss: 0.012848\n",
      "[931/00293] train_loss: 0.012301\n",
      "[931/00343] train_loss: 0.012523\n",
      "[931/00393] train_loss: 0.011880\n",
      "[931/00443] train_loss: 0.012023\n",
      "[931/00493] train_loss: 0.012535\n",
      "[931/00543] train_loss: 0.012427\n",
      "[931/00593] train_loss: 0.012193\n",
      "[931/00643] train_loss: 0.012430\n",
      "[931/00693] train_loss: 0.012737\n",
      "[931/00743] train_loss: 0.012932\n",
      "[931/00793] train_loss: 0.012688\n",
      "[931/00843] train_loss: 0.011911\n",
      "[931/00893] train_loss: 0.012779\n",
      "[931/00943] train_loss: 0.012706\n",
      "[931/00993] train_loss: 0.012339\n",
      "[931/01043] train_loss: 0.013195\n",
      "[931/01093] train_loss: 0.013183\n",
      "[931/01143] train_loss: 0.012148\n",
      "[931/01193] train_loss: 0.012117\n",
      "[932/00017] train_loss: 0.014309\n",
      "[932/00067] train_loss: 0.015132\n",
      "[932/00117] train_loss: 0.014066\n",
      "[932/00167] train_loss: 0.013362\n",
      "[932/00217] train_loss: 0.012403\n",
      "[932/00267] train_loss: 0.012728\n",
      "[932/00317] train_loss: 0.011773\n",
      "[932/00367] train_loss: 0.012303\n",
      "[932/00417] train_loss: 0.012868\n",
      "[932/00467] train_loss: 0.012779\n",
      "[932/00517] train_loss: 0.011975\n",
      "[932/00567] train_loss: 0.012294\n",
      "[932/00617] train_loss: 0.012856\n",
      "[932/00667] train_loss: 0.012437\n",
      "[932/00717] train_loss: 0.013286\n",
      "[932/00767] train_loss: 0.012286\n",
      "[932/00817] train_loss: 0.013110\n",
      "[932/00867] train_loss: 0.012532\n",
      "[932/00917] train_loss: 0.011861\n",
      "[932/00967] train_loss: 0.012691\n",
      "[932/01017] train_loss: 0.012234\n",
      "[932/01067] train_loss: 0.012489\n",
      "[932/01117] train_loss: 0.012853\n",
      "[932/01167] train_loss: 0.012322\n",
      "[932/01217] train_loss: 0.012585\n",
      "[933/00041] train_loss: 0.014959\n",
      "[933/00091] train_loss: 0.013490\n",
      "[933/00141] train_loss: 0.012547\n",
      "[933/00191] train_loss: 0.013126\n",
      "[933/00241] train_loss: 0.012526\n",
      "[933/00291] train_loss: 0.012648\n",
      "[933/00341] train_loss: 0.012663\n",
      "[933/00391] train_loss: 0.012352\n",
      "[933/00441] train_loss: 0.012815\n",
      "[933/00491] train_loss: 0.012442\n",
      "[933/00541] train_loss: 0.011821\n",
      "[933/00591] train_loss: 0.012812\n",
      "[933/00641] train_loss: 0.012512\n",
      "[933/00691] train_loss: 0.012840\n",
      "[933/00741] train_loss: 0.011743\n",
      "[933/00791] train_loss: 0.012789\n",
      "[933/00841] train_loss: 0.012037\n",
      "[933/00891] train_loss: 0.012680\n",
      "[933/00941] train_loss: 0.012400\n",
      "[933/00991] train_loss: 0.013181\n",
      "[933/01041] train_loss: 0.011883\n",
      "[933/01091] train_loss: 0.012855\n",
      "[933/01141] train_loss: 0.012651\n",
      "[933/01191] train_loss: 0.012620\n",
      "[934/00015] train_loss: 0.013505\n",
      "[934/00065] train_loss: 0.014853\n",
      "[934/00115] train_loss: 0.013749\n",
      "[934/00165] train_loss: 0.012950\n",
      "[934/00215] train_loss: 0.012725\n",
      "[934/00265] train_loss: 0.012789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[934/00315] train_loss: 0.011986\n",
      "[934/00365] train_loss: 0.011882\n",
      "[934/00415] train_loss: 0.012862\n",
      "[934/00465] train_loss: 0.012465\n",
      "[934/00515] train_loss: 0.011876\n",
      "[934/00565] train_loss: 0.012378\n",
      "[934/00615] train_loss: 0.012339\n",
      "[934/00665] train_loss: 0.012745\n",
      "[934/00715] train_loss: 0.011457\n",
      "[934/00765] train_loss: 0.012716\n",
      "[934/00815] train_loss: 0.012580\n",
      "[934/00865] train_loss: 0.012182\n",
      "[934/00915] train_loss: 0.012473\n",
      "[934/00965] train_loss: 0.012455\n",
      "[934/01015] train_loss: 0.012761\n",
      "[934/01065] train_loss: 0.011918\n",
      "[934/01115] train_loss: 0.012470\n",
      "[934/01165] train_loss: 0.012999\n",
      "[934/01215] train_loss: 0.013006\n",
      "[935/00039] train_loss: 0.015325\n",
      "[935/00089] train_loss: 0.014524\n",
      "[935/00139] train_loss: 0.012630\n",
      "[935/00189] train_loss: 0.013802\n",
      "[935/00239] train_loss: 0.012572\n",
      "[935/00289] train_loss: 0.012836\n",
      "[935/00339] train_loss: 0.012557\n",
      "[935/00389] train_loss: 0.011934\n",
      "[935/00439] train_loss: 0.012657\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_deepsdf\n",
    "\n",
    "generalization_config = {\n",
    "    'experiment_name': '3_2_deepsdf_generalization',\n",
    "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
    "    'is_overfit': False,\n",
    "    'num_sample_points': 4096, # you can adjust this such that the model fits on your gpu\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,  # not necessary to run for 2000 epochs if you're short on time, at 500 epochs you should start to see reasonable results\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 5000,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(generalization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Inference using the trained model on observed SDF values\n",
    "\n",
    "Fill in the inference script `exercise_3/inference/infer_deepsdf.py`. Note that it's not simply a forward pass, but an optimization of the latent code such that we have lowest error on observed SDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_2_deepsdf_generalization\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try inference on a shape from validation set, for which we have a complete observation of sdf values. This is an easier problem as compared to shape completion,\n",
    "since we have all the information already in the input.\n",
    "\n",
    "Let's visualize the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are very complete\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reconstruction on these observations with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try the shape completion task, i.e., inference on a shape from validation set, for which we do not have a complete observation of sdf values. The observed points are visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93_incomplete\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are incomplete\n",
    "# making this is a shape completion task\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape completion using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Latent space interpolation\n",
    "\n",
    "The latent space learned by DeepSDF is interpolatable, meaning that decoding latent codes from this space produced meaningful shapes. Given two latent codes, a linearly interpolatable latent space will decode\n",
    "each of the intermediate codes to some valid shape. Let's see if this holds for our trained model.\n",
    "\n",
    "We'll pick two shapes from the train set as visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_3.data.shape_implicit import ShapeImplicit\n",
    "from exercise_3.util.visualization import visualize_mesh\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"494fe53da65650b8c358765b76c296\")\n",
    "print('GT Shape A')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"5ca1ef55ff5f68501921e7a85cf9da35\")\n",
    "print('GT Shape B')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the missing parts in `exercise_3/inference/infer_deepsdf.py` such that it interpolates two given latent vectors, and run the code fragement below once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_2_deepsdf_generalization\", torch.device('cuda:0'))\n",
    "# interpolate; also exports interpolated meshes to disk\n",
    "inference_handler.interpolate('494fe53da65650b8c358765b76c296', '5ca1ef55ff5f68501921e7a85cf9da35', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the interpolation below. If everything works out correctly, you should see a smooth transformation between the shapes, with all intermediate shapes being valid sofas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.util.mesh_collection_to_gif import  meshes_to_gif\n",
    "from exercise_3.util.misc import show_gif\n",
    "\n",
    "# create list of meshes (just exported) to be visualized\n",
    "mesh_paths = sorted([x for x in Path(\"exercise_3/runs/3_2_deepsdf_generalization/interpolation\").iterdir() if int(x.name.split('.')[0].split(\"_\")[1]) == 0], key=lambda x: int(x.name.split('.')[0].split(\"_\")[0]))\n",
    "mesh_paths = mesh_paths + mesh_paths[::-1]\n",
    "\n",
    "# create a visualization of the interpolation process\n",
    "meshes_to_gif(mesh_paths, \"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\", 20)\n",
    "show_gif(\"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "This is the end of exercise 3 🙂. Please create a zip containing all files we provided, everything you modified, your visualization images/gif (no need to submit generated OBJs), including your checkpoints. Name it with your matriculation number(s) as described in exercise 1. Make sure this notebook can be run without problems. Then, submit via Moodle.\n",
    "\n",
    "**Note**: The maximum submission file size limit for Moodle is 100M. You do not need to submit your overfitting checkpoints; however, the generalization checkpoint will be >200M. The easiest way to still be able to submit that one is to split it with zip like this: `zip -s 100M model_best.ckpt.zip model_best.ckpt` which creates a `.zip` and a `.z01`. You can then submit both files alongside another zip containing all your code and outputs.\n",
    "\n",
    "**Submission Deadline**: 22.12.2023, 23:55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Dai, Angela, Charles Ruizhongtai Qi, and Matthias Nießner. \"Shape completion using 3d-encoder-predictor cnns and shape synthesis.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n",
    "\n",
    "[2] Park, Jeong Joon, et al. \"Deepsdf: Learning continuous signed distance functions for shape representation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
